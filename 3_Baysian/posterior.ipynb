{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "from scipy import stats\n",
    "import arviz as az\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>19218.8</td>\n",
       "      <td>1.925172</td>\n",
       "      <td>5.451580</td>\n",
       "      <td>-1.142358</td>\n",
       "      <td>0.861027</td>\n",
       "      <td>-0.335091</td>\n",
       "      <td>0.431894</td>\n",
       "      <td>-1.122869</td>\n",
       "      <td>0.912786</td>\n",
       "      <td>-0.619038</td>\n",
       "      <td>-0.434581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>2020-12-02</td>\n",
       "      <td>19433.3</td>\n",
       "      <td>1.582994</td>\n",
       "      <td>3.559479</td>\n",
       "      <td>-0.653910</td>\n",
       "      <td>1.251390</td>\n",
       "      <td>-0.337836</td>\n",
       "      <td>-1.237844</td>\n",
       "      <td>-0.313913</td>\n",
       "      <td>0.794368</td>\n",
       "      <td>-0.194111</td>\n",
       "      <td>-0.184261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>2020-12-03</td>\n",
       "      <td>18658.1</td>\n",
       "      <td>1.175193</td>\n",
       "      <td>3.092115</td>\n",
       "      <td>-1.930997</td>\n",
       "      <td>0.743688</td>\n",
       "      <td>-0.094971</td>\n",
       "      <td>-1.303851</td>\n",
       "      <td>-0.833903</td>\n",
       "      <td>1.148260</td>\n",
       "      <td>-0.693432</td>\n",
       "      <td>-0.112931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>2020-12-04</td>\n",
       "      <td>19146.5</td>\n",
       "      <td>1.046626</td>\n",
       "      <td>2.240449</td>\n",
       "      <td>-0.903165</td>\n",
       "      <td>1.246917</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>-0.401272</td>\n",
       "      <td>-0.090789</td>\n",
       "      <td>0.776876</td>\n",
       "      <td>-0.929971</td>\n",
       "      <td>0.171880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>19379.9</td>\n",
       "      <td>0.576253</td>\n",
       "      <td>0.169815</td>\n",
       "      <td>-1.095204</td>\n",
       "      <td>1.964635</td>\n",
       "      <td>0.133399</td>\n",
       "      <td>-1.614727</td>\n",
       "      <td>-0.163228</td>\n",
       "      <td>0.659043</td>\n",
       "      <td>-0.519185</td>\n",
       "      <td>0.786180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date    Price       PC1       PC2       PC3       PC4       PC5  \\\n",
       "700  2020-12-01  19218.8  1.925172  5.451580 -1.142358  0.861027 -0.335091   \n",
       "701  2020-12-02  19433.3  1.582994  3.559479 -0.653910  1.251390 -0.337836   \n",
       "702  2020-12-03  18658.1  1.175193  3.092115 -1.930997  0.743688 -0.094971   \n",
       "703  2020-12-04  19146.5  1.046626  2.240449 -0.903165  1.246917  0.051724   \n",
       "704  2020-12-05  19379.9  0.576253  0.169815 -1.095204  1.964635  0.133399   \n",
       "\n",
       "          PC6       PC7       PC8       PC9      PC10  \n",
       "700  0.431894 -1.122869  0.912786 -0.619038 -0.434581  \n",
       "701 -1.237844 -0.313913  0.794368 -0.194111 -0.184261  \n",
       "702 -1.303851 -0.833903  1.148260 -0.693432 -0.112931  \n",
       "703 -0.401272 -0.090789  0.776876 -0.929971  0.171880  \n",
       "704 -1.614727 -0.163228  0.659043 -0.519185  0.786180  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('pca_data.csv')\n",
    "df = df[700:]\n",
    "y = df[\"Price\"].values\n",
    "df_x = df.drop(columns=[\"Date\", \"Price\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>2021-10-17</td>\n",
       "      <td>62056.3</td>\n",
       "      <td>8.247989</td>\n",
       "      <td>-6.235256</td>\n",
       "      <td>-0.467159</td>\n",
       "      <td>-0.015834</td>\n",
       "      <td>-1.848409</td>\n",
       "      <td>0.520881</td>\n",
       "      <td>-0.291738</td>\n",
       "      <td>0.797574</td>\n",
       "      <td>-0.658913</td>\n",
       "      <td>-0.664539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>2021-10-18</td>\n",
       "      <td>64278.5</td>\n",
       "      <td>7.769368</td>\n",
       "      <td>-2.800591</td>\n",
       "      <td>-1.965221</td>\n",
       "      <td>-1.538361</td>\n",
       "      <td>-1.019428</td>\n",
       "      <td>1.423679</td>\n",
       "      <td>1.055461</td>\n",
       "      <td>1.265406</td>\n",
       "      <td>-0.163010</td>\n",
       "      <td>0.122867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>2021-10-19</td>\n",
       "      <td>65979.1</td>\n",
       "      <td>9.114730</td>\n",
       "      <td>-1.343815</td>\n",
       "      <td>-1.896115</td>\n",
       "      <td>-1.721794</td>\n",
       "      <td>-3.317679</td>\n",
       "      <td>3.028115</td>\n",
       "      <td>3.559169</td>\n",
       "      <td>3.329187</td>\n",
       "      <td>0.833770</td>\n",
       "      <td>1.369422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>2021-10-20</td>\n",
       "      <td>62210.2</td>\n",
       "      <td>8.975927</td>\n",
       "      <td>-2.094760</td>\n",
       "      <td>-1.719892</td>\n",
       "      <td>-1.823947</td>\n",
       "      <td>-3.041510</td>\n",
       "      <td>1.546296</td>\n",
       "      <td>1.514364</td>\n",
       "      <td>0.405193</td>\n",
       "      <td>0.770918</td>\n",
       "      <td>0.181783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>2021-10-21</td>\n",
       "      <td>60697.3</td>\n",
       "      <td>9.921635</td>\n",
       "      <td>-1.617694</td>\n",
       "      <td>-0.205104</td>\n",
       "      <td>-1.418701</td>\n",
       "      <td>-0.830756</td>\n",
       "      <td>3.150038</td>\n",
       "      <td>0.674089</td>\n",
       "      <td>1.157297</td>\n",
       "      <td>-0.859862</td>\n",
       "      <td>0.156889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    Price       PC1       PC2       PC3       PC4       PC5  \\\n",
       "1020  2021-10-17  62056.3  8.247989 -6.235256 -0.467159 -0.015834 -1.848409   \n",
       "1021  2021-10-18  64278.5  7.769368 -2.800591 -1.965221 -1.538361 -1.019428   \n",
       "1022  2021-10-19  65979.1  9.114730 -1.343815 -1.896115 -1.721794 -3.317679   \n",
       "1023  2021-10-20  62210.2  8.975927 -2.094760 -1.719892 -1.823947 -3.041510   \n",
       "1024  2021-10-21  60697.3  9.921635 -1.617694 -0.205104 -1.418701 -0.830756   \n",
       "\n",
       "           PC6       PC7       PC8       PC9      PC10  \n",
       "1020  0.520881 -0.291738  0.797574 -0.658913 -0.664539  \n",
       "1021  1.423679  1.055461  1.265406 -0.163010  0.122867  \n",
       "1022  3.028115  3.559169  3.329187  0.833770  1.369422  \n",
       "1023  1.546296  1.514364  0.405193  0.770918  0.181783  \n",
       "1024  3.150038  0.674089  1.157297 -0.859862  0.156889  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 5., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 5., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 5., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 5., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 5., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 5., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 5., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 5., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 5.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I = np.eye(df_x.shape[1])\n",
    "α = 5\n",
    "β = 1 / 10000\n",
    "num_of_vars = 10\n",
    "X = X[:,:num_of_vars]\n",
    "w_mean = np.zeros(num_of_vars)\n",
    "w_cov = α*I\n",
    "w_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "w[0]    494.074\n",
       "w[1]    -57.609\n",
       "w[2]    -18.301\n",
       "w[3]    -26.893\n",
       "w[4]    -15.743\n",
       "w[5]      2.141\n",
       "w[6]     11.003\n",
       "w[7]     -1.080\n",
       "w[8]     -4.295\n",
       "w[9]     -3.688\n",
       "Name: mean, dtype: float64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_mean = az.summary(trace)[\"mean\"]\n",
    "w_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-118-45c6b557d1d0>:9: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:59<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 184 seconds.\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as our_first_model:\n",
    "    w = pm.MvNormal('w', mu=prior_m_of_w, cov=α*I, shape=(num_of_vars, ))\n",
    "    mu = pm.math.dot(X, w)\n",
    "    xTx = pm.math.dot(X.T, X)\n",
    "    test = xTx*β\n",
    "    S = (xTx*β + α*I)**-1\n",
    "    pred_sigma = np.sqrt(1/β + xTx*S)\n",
    "    likelihood = pm.Normal('likelihood', mu=mu, sigma=1/β, observed=y)\n",
    "    trace = pm.sample(11000, random_seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:50<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 212 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    898.643\n",
      "w[1]    -85.166\n",
      "w[2]    -61.140\n",
      "w[3]    -72.707\n",
      "w[4]    -74.524\n",
      "w[5]     -1.330\n",
      "w[6]     95.976\n",
      "w[7]    -20.164\n",
      "w[8]    -13.613\n",
      "w[9]     61.922\n",
      "Name: mean, dtype: float64\n",
      "[[ 3.31411582 -0.12173027 -0.17442279 -0.32243896 -0.57902385 -0.1291837\n",
      "   0.82032995 -0.16278064 -0.11944143  0.83191378]\n",
      " [-0.12173027  2.75640437 -0.43041369  0.81181784 -0.51625793  0.67004036\n",
      "  -0.89608347  0.21382962 -0.62334957 -0.71301911]\n",
      " [-0.17442279 -0.43041369  4.70855746 -0.16006     0.06328913 -1.02415171\n",
      "   0.65514783  0.42838605  0.47902187  0.53782599]\n",
      " [-0.32243896  0.81181784 -0.16006     3.17994868 -0.30511814  0.221281\n",
      "  -0.34983102  0.27394758 -0.14071098 -0.86295795]\n",
      " [-0.57902385 -0.51625793  0.06328913 -0.30511814  4.41776879 -0.00838553\n",
      "   1.31283638 -0.31774818 -0.33342619  0.38134599]\n",
      " [-0.1291837   0.67004036 -1.02415171  0.221281   -0.00838553  2.78840521\n",
      "  -0.89856651  0.32006064 -0.77191631 -0.11855963]\n",
      " [ 0.82032995 -0.89608347  0.65514783 -0.34983102  1.31283638 -0.89856651\n",
      "   6.74176717  0.22296284  0.18201474  1.42939364]\n",
      " [-0.16278064  0.21382962  0.42838605  0.27394758 -0.31774818  0.32006064\n",
      "   0.22296284  3.58218921  0.11812937 -0.91959113]\n",
      " [-0.11944143 -0.62334957  0.47902187 -0.14071098 -0.33342619 -0.77191631\n",
      "   0.18201474  0.11812937  3.63281635 -0.13006031]\n",
      " [ 0.83191378 -0.71301911  0.53782599 -0.86295795  0.38134599 -0.11855963\n",
      "   1.42939364 -0.91959113 -0.13006031  4.32570398]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:45<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 185 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    901.536\n",
      "w[1]    -85.563\n",
      "w[2]    -61.424\n",
      "w[3]    -73.186\n",
      "w[4]    -75.075\n",
      "w[5]     -1.483\n",
      "w[6]     96.841\n",
      "w[7]    -20.333\n",
      "w[8]    -13.688\n",
      "w[9]     62.692\n",
      "Name: mean, dtype: float64\n",
      "[[ 3.2792343  -0.13075525 -0.14586496 -0.32280449 -0.57820588 -0.14238707\n",
      "   0.85809573 -0.12907136 -0.12711759  0.85333339]\n",
      " [-0.13075525  2.76997456 -0.44863732  0.8241377  -0.55120362  0.67696338\n",
      "  -0.92862726  0.21978139 -0.64536457 -0.73458192]\n",
      " [-0.14586496 -0.44863732  4.63618775 -0.18001464  0.08509469 -1.02557859\n",
      "   0.73042409  0.40177005  0.48719479  0.61246401]\n",
      " [-0.32280449  0.8241377  -0.18001464  3.15733443 -0.33768692  0.22652708\n",
      "  -0.37688616  0.27669227 -0.13971879 -0.88881549]\n",
      " [-0.57820588 -0.55120362  0.08509469 -0.33768692  4.39672184 -0.01140844\n",
      "   1.25223347 -0.33926624 -0.32553422  0.38640975]\n",
      " [-0.14238707  0.67696338 -1.02557859  0.22652708 -0.01140844  2.78459926\n",
      "  -0.93149925  0.31753843 -0.77501426 -0.14852342]\n",
      " [ 0.85809573 -0.92862726  0.73042409 -0.37688616  1.25223347 -0.93149925\n",
      "   6.73487532  0.21312891  0.19759623  1.46473993]\n",
      " [-0.12907136  0.21978139  0.40177005  0.27669227 -0.33926624  0.31753843\n",
      "   0.21312891  3.53595576  0.13129886 -0.90458273]\n",
      " [-0.12711759 -0.64536457  0.48719479 -0.13971879 -0.32553422 -0.77501426\n",
      "   0.19759623  0.13129886  3.59864823 -0.11879955]\n",
      " [ 0.85333339 -0.73458192  0.61246401 -0.88881549  0.38640975 -0.14852342\n",
      "   1.46473993 -0.90458273 -0.11879955  4.34461969]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:45<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 182 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    904.403\n",
      "w[1]    -85.978\n",
      "w[2]    -61.670\n",
      "w[3]    -73.673\n",
      "w[4]    -75.613\n",
      "w[5]     -1.655\n",
      "w[6]     97.747\n",
      "w[7]    -20.470\n",
      "w[8]    -13.753\n",
      "w[9]     63.502\n",
      "Name: mean, dtype: float64\n",
      "[[ 3.21219236 -0.1058392  -0.14329005 -0.30734289 -0.56593948 -0.13699467\n",
      "   0.8495915  -0.09660461 -0.13005522  0.8201071 ]\n",
      " [-0.1058392   2.76729719 -0.4561709   0.83240959 -0.56317143  0.67727301\n",
      "  -0.96063169  0.2164217  -0.65326947 -0.75560632]\n",
      " [-0.14329005 -0.4561709   4.67240757 -0.17081015  0.14383347 -1.00714033\n",
      "   0.7915593   0.41121731  0.4731276   0.60872415]\n",
      " [-0.30734289  0.83240959 -0.17081015  3.1153869  -0.3395555   0.22368685\n",
      "  -0.33497733  0.28337939 -0.13180748 -0.87530228]\n",
      " [-0.56593948 -0.56317143  0.14383347 -0.3395555   4.39868834 -0.0374786\n",
      "   1.24362403 -0.32154301 -0.31676766  0.39603284]\n",
      " [-0.13699467  0.67727301 -1.00714033  0.22368685 -0.0374786   2.72158533\n",
      "  -0.97073566  0.30152764 -0.78303971 -0.17109612]\n",
      " [ 0.8495915  -0.96063169  0.7915593  -0.33497733  1.24362403 -0.97073566\n",
      "   6.77247821  0.25990706  0.20915422  1.48823619]\n",
      " [-0.09660461  0.2164217   0.41121731  0.28337939 -0.32154301  0.30152764\n",
      "   0.25990706  3.47160267  0.11013729 -0.87987632]\n",
      " [-0.13005522 -0.65326947  0.4731276  -0.13180748 -0.31676766 -0.78303971\n",
      "   0.20915422  0.11013729  3.5253924  -0.11000369]\n",
      " [ 0.8201071  -0.75560632  0.60872415 -0.87530228  0.39603284 -0.17109612\n",
      "   1.48823619 -0.87987632 -0.11000369  4.32467022]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:46<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 205 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    907.202\n",
      "w[1]    -86.380\n",
      "w[2]    -61.910\n",
      "w[3]    -74.147\n",
      "w[4]    -76.138\n",
      "w[5]     -1.819\n",
      "w[6]     98.646\n",
      "w[7]    -20.589\n",
      "w[8]    -13.846\n",
      "w[9]     64.290\n",
      "Name: mean, dtype: float64\n",
      "[[ 3.2439455  -0.12315145 -0.18573022 -0.30764821 -0.57152299 -0.1420933\n",
      "   0.89431397 -0.13000519 -0.12046804  0.82727438]\n",
      " [-0.12315145  2.74000217 -0.45639312  0.82409528 -0.57234294  0.67175342\n",
      "  -0.93776343  0.24232827 -0.65675979 -0.76958461]\n",
      " [-0.18573022 -0.45639312  4.67221177 -0.13774848  0.14032826 -1.01527496\n",
      "   0.82846106  0.4439512   0.50412757  0.60340091]\n",
      " [-0.30764821  0.82409528 -0.13774848  3.08458241 -0.30397609  0.22772395\n",
      "  -0.32369329  0.30330143 -0.12350907 -0.84831526]\n",
      " [-0.57152299 -0.57234294  0.14032826 -0.30397609  4.32632196 -0.03012\n",
      "   1.27453998 -0.2851338  -0.3307906   0.3886286 ]\n",
      " [-0.1420933   0.67175342 -1.01527496  0.22772395 -0.03012     2.72023047\n",
      "  -0.94569027  0.28949544 -0.79937416 -0.17905371]\n",
      " [ 0.89431397 -0.93776343  0.82846106 -0.32369329  1.27453998 -0.94569027\n",
      "   6.77107024  0.26507889  0.19890434  1.49701118]\n",
      " [-0.13000519  0.24232827  0.4439512   0.30330143 -0.2851338   0.28949544\n",
      "   0.26507889  3.43577006  0.06638825 -0.82027915]\n",
      " [-0.12046804 -0.65675979  0.50412757 -0.12350907 -0.3307906  -0.79937416\n",
      "   0.19890434  0.06638825  3.54372301 -0.08120614]\n",
      " [ 0.82727438 -0.76958461  0.60340091 -0.84831526  0.3886286  -0.17905371\n",
      "   1.49701118 -0.82027915 -0.08120614  4.249666  ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:50<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 187 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    910.042\n",
      "w[1]    -86.792\n",
      "w[2]    -62.194\n",
      "w[3]    -74.630\n",
      "w[4]    -76.658\n",
      "w[5]     -1.982\n",
      "w[6]     99.582\n",
      "w[7]    -20.754\n",
      "w[8]    -13.916\n",
      "w[9]     65.092\n",
      "Name: mean, dtype: float64\n",
      "[[ 3.25984929 -0.12882438 -0.16347959 -0.34354111 -0.59056553 -0.16002979\n",
      "   0.93667261 -0.11278067 -0.11310606  0.83767801]\n",
      " [-0.12882438  2.74488158 -0.49608263  0.84490032 -0.58361997  0.6617587\n",
      "  -0.9814047   0.22484465 -0.65466283 -0.80262327]\n",
      " [-0.16347959 -0.49608263  4.71326628 -0.13903358  0.13270345 -1.01630412\n",
      "   0.86792362  0.45341067  0.49423448  0.67177432]\n",
      " [-0.34354111  0.84490032 -0.13903358  3.0919465  -0.33418525  0.23245524\n",
      "  -0.30345591  0.28258255 -0.10490368 -0.88589652]\n",
      " [-0.59056553 -0.58361997  0.13270345 -0.33418525  4.29491474 -0.03823631\n",
      "   1.26899509 -0.30161483 -0.32130892  0.40676126]\n",
      " [-0.16002979  0.6617587  -1.01630412  0.23245524 -0.03823631  2.71090519\n",
      "  -1.00137827  0.29011488 -0.76873193 -0.2148391 ]\n",
      " [ 0.93667261 -0.9814047   0.86792362 -0.30345591  1.26899509 -1.00137827\n",
      "   6.8520919   0.25639558  0.21851683  1.57574556]\n",
      " [-0.11278067  0.22484465  0.45341067  0.28258255 -0.30161483  0.29011488\n",
      "   0.25639558  3.39046817  0.0731909  -0.82540917]\n",
      " [-0.11310606 -0.65466283  0.49423448 -0.10490368 -0.32130892 -0.76873193\n",
      "   0.21851683  0.0731909   3.49453461 -0.08172443]\n",
      " [ 0.83767801 -0.80262327  0.67177432 -0.88589652  0.40676126 -0.2148391\n",
      "   1.57574556 -0.82540917 -0.08172443  4.25040847]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:49<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 190 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    912.877\n",
      "w[1]    -87.201\n",
      "w[2]    -62.448\n",
      "w[3]    -75.125\n",
      "w[4]    -77.188\n",
      "w[5]     -2.157\n",
      "w[6]    100.547\n",
      "w[7]    -20.894\n",
      "w[8]    -13.977\n",
      "w[9]     65.879\n",
      "Name: mean, dtype: float64\n",
      "[[ 3.26823086 -0.15059687 -0.18376186 -0.35427597 -0.58276361 -0.15750183\n",
      "   0.96379887 -0.11447718 -0.10576934  0.83570433]\n",
      " [-0.15059687  2.76870558 -0.49141412  0.87859113 -0.6242101   0.68635664\n",
      "  -1.02026193  0.24690267 -0.67948575 -0.80746908]\n",
      " [-0.18376186 -0.49141412  4.66619489 -0.15146568  0.16206635 -0.99036571\n",
      "   0.86284087  0.48635274  0.509097    0.68896765]\n",
      " [-0.35427597  0.87859113 -0.15146568  3.09664625 -0.35039639  0.24893217\n",
      "  -0.30530924  0.27749884 -0.12216592 -0.913225  ]\n",
      " [-0.58276361 -0.6242101   0.16206635 -0.35039639  4.27761376 -0.04079564\n",
      "   1.29780158 -0.31549921 -0.28317417  0.41170674]\n",
      " [-0.15750183  0.68635664 -0.99036571  0.24893217 -0.04079564  2.75839889\n",
      "  -0.98790601  0.33772768 -0.80523083 -0.22155332]\n",
      " [ 0.96379887 -1.02026193  0.86284087 -0.30530924  1.29780158 -0.98790601\n",
      "   6.93137438  0.28012847  0.22930223  1.61975735]\n",
      " [-0.11447718  0.24690267  0.48635274  0.27749884 -0.31549921  0.33772768\n",
      "   0.28012847  3.37359602  0.08218605 -0.80672405]\n",
      " [-0.10576934 -0.67948575  0.509097   -0.12216592 -0.28317417 -0.80523083\n",
      "   0.22930223  0.08218605  3.50105994 -0.08379939]\n",
      " [ 0.83570433 -0.80746908  0.68896765 -0.913225    0.41170674 -0.22155332\n",
      "   1.61975735 -0.80672405 -0.08379939  4.21036263]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:46<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 201 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    915.739\n",
      "w[1]    -87.635\n",
      "w[2]    -62.719\n",
      "w[3]    -75.653\n",
      "w[4]    -77.713\n",
      "w[5]     -2.344\n",
      "w[6]    101.533\n",
      "w[7]    -21.037\n",
      "w[8]    -14.023\n",
      "w[9]     66.688\n",
      "Name: mean, dtype: float64\n",
      "[[ 3.22981109 -0.13746084 -0.1774742  -0.37781724 -0.59236841 -0.18632576\n",
      "   0.93853158 -0.13271559 -0.06617409  0.81196419]\n",
      " [-0.13746084  2.73300679 -0.51648682  0.82774827 -0.64589098  0.66481073\n",
      "  -1.0200774   0.23308121 -0.68683296 -0.80885088]\n",
      " [-0.1774742  -0.51648682  4.69000625 -0.15603207  0.17604702 -0.99550685\n",
      "   0.88775849  0.47433977  0.48766077  0.73267115]\n",
      " [-0.37781724  0.82774827 -0.15603207  3.03991154 -0.33715472  0.25770276\n",
      "  -0.32124043  0.29229239 -0.12477137 -0.8843647 ]\n",
      " [-0.59236841 -0.64589098  0.17604702 -0.33715472  4.21487633 -0.07118605\n",
      "   1.31097918 -0.31328792 -0.25634899  0.38772321]\n",
      " [-0.18632576  0.66481073 -0.99550685  0.25770276 -0.07118605  2.74189757\n",
      "  -1.03254747  0.34152676 -0.79311432 -0.23370239]\n",
      " [ 0.93853158 -1.0200774   0.88775849 -0.32124043  1.31097918 -1.03254747\n",
      "   6.87660327  0.28462989  0.208171    1.5769282 ]\n",
      " [-0.13271559  0.23308121  0.47433977  0.29229239 -0.31328792  0.34152676\n",
      "   0.28462989  3.3368395   0.07900547 -0.80808069]\n",
      " [-0.06617409 -0.68683296  0.48766077 -0.12477137 -0.25634899 -0.79311432\n",
      "   0.208171    0.07900547  3.43847829 -0.07808363]\n",
      " [ 0.81196419 -0.80885088  0.73267115 -0.8843647   0.38772321 -0.23370239\n",
      "   1.5769282  -0.80808069 -0.07808363  4.19043507]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:46<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 184 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    918.553\n",
      "w[1]    -88.056\n",
      "w[2]    -62.987\n",
      "w[3]    -76.191\n",
      "w[4]    -78.247\n",
      "w[5]     -2.541\n",
      "w[6]    102.497\n",
      "w[7]    -21.175\n",
      "w[8]    -14.041\n",
      "w[9]     67.470\n",
      "Name: mean, dtype: float64\n",
      "[[ 3.18294065 -0.12667548 -0.19828654 -0.36472057 -0.59254167 -0.16092537\n",
      "   0.95575003 -0.08078162 -0.11093455  0.78065223]\n",
      " [-0.12667548  2.66633562 -0.52051332  0.80472716 -0.64704461  0.62643561\n",
      "  -0.99872171  0.21975153 -0.66604218 -0.80876406]\n",
      " [-0.19828654 -0.52051332  4.62388497 -0.16393405  0.14323538 -0.95777027\n",
      "   0.86906004  0.44604428  0.47367981  0.72198325]\n",
      " [-0.36472057  0.80472716 -0.16393405  2.98640559 -0.3478547   0.21890813\n",
      "  -0.29997284  0.29809792 -0.10917753 -0.87143539]\n",
      " [-0.59254167 -0.64704461  0.14323538 -0.3478547   4.231875   -0.07348524\n",
      "   1.35919637 -0.32156408 -0.27014371  0.40321652]\n",
      " [-0.16092537  0.62643561 -0.95777027  0.21890813 -0.07348524  2.66549651\n",
      "  -1.00224221  0.31732432 -0.78296073 -0.21763864]\n",
      " [ 0.95575003 -0.99872171  0.86906004 -0.29997284  1.35919637 -1.00224221\n",
      "   6.86560335  0.2509642   0.19702942  1.52428678]\n",
      " [-0.08078162  0.21975153  0.44604428  0.29809792 -0.32156408  0.31732432\n",
      "   0.2509642   3.28524046  0.08753078 -0.82295828]\n",
      " [-0.11093455 -0.66604218  0.47367981 -0.10917753 -0.27014371 -0.78296073\n",
      "   0.19702942  0.08753078  3.41101724 -0.12714269]\n",
      " [ 0.78065223 -0.80876406  0.72198325 -0.87143539  0.40321652 -0.21763864\n",
      "   1.52428678 -0.82295828 -0.12714269  4.21422185]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:47<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 185 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    921.325\n",
      "w[1]    -88.443\n",
      "w[2]    -63.280\n",
      "w[3]    -76.699\n",
      "w[4]    -78.778\n",
      "w[5]     -2.706\n",
      "w[6]    103.464\n",
      "w[7]    -21.276\n",
      "w[8]    -14.112\n",
      "w[9]     68.220\n",
      "Name: mean, dtype: float64\n",
      "[[ 3.16372798 -0.12893377 -0.14768723 -0.34888755 -0.6151312  -0.17578234\n",
      "   0.98193895 -0.08195569 -0.07958719  0.76445391]\n",
      " [-0.12893377  2.65427019 -0.57211853  0.79644632 -0.64630887  0.65231983\n",
      "  -1.00470386  0.23572451 -0.6801975  -0.84270674]\n",
      " [-0.14768723 -0.57211853  4.67036303 -0.2085777   0.18693101 -0.97632408\n",
      "   0.96445637  0.44105333  0.45723707  0.75284801]\n",
      " [-0.34888755  0.79644632 -0.2085777   2.91806746 -0.34694223  0.26748543\n",
      "  -0.31076786  0.29252694 -0.12257502 -0.88277308]\n",
      " [-0.6151312  -0.64630887  0.18693101 -0.34694223  4.15047819 -0.08296006\n",
      "   1.32470917 -0.3420219  -0.24660153  0.39929342]\n",
      " [-0.17578234  0.65231983 -0.97632408  0.26748543 -0.08296006  2.66291469\n",
      "  -1.03401688  0.28541066 -0.79613106 -0.23250528]\n",
      " [ 0.98193895 -1.00470386  0.96445637 -0.31076786  1.32470917 -1.03401688\n",
      "   6.86352265  0.25245258  0.24660611  1.52146903]\n",
      " [-0.08195569  0.23572451  0.44105333  0.29252694 -0.3420219   0.28541066\n",
      "   0.25245258  3.24860879  0.10707593 -0.88682979]\n",
      " [-0.07958719 -0.6801975   0.45723707 -0.12257502 -0.24660153 -0.79613106\n",
      "   0.24660611  0.10707593  3.3549024  -0.11682708]\n",
      " [ 0.76445391 -0.84270674  0.75284801 -0.88277308  0.39929342 -0.23250528\n",
      "   1.52146903 -0.88682979 -0.11682708  4.24060348]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:50<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 217 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    924.073\n",
      "w[1]    -88.823\n",
      "w[2]    -63.525\n",
      "w[3]    -77.179\n",
      "w[4]    -79.319\n",
      "w[5]     -2.885\n",
      "w[6]    104.453\n",
      "w[7]    -21.382\n",
      "w[8]    -14.146\n",
      "w[9]     68.955\n",
      "Name: mean, dtype: float64\n",
      "[[ 3.13170744 -0.13763189 -0.15818838 -0.3186213  -0.61178461 -0.16438687\n",
      "   0.95975278 -0.0835807  -0.08014102  0.761421  ]\n",
      " [-0.13763189  2.66359345 -0.61657103  0.83307579 -0.68095839  0.70181218\n",
      "  -1.03750399  0.2439669  -0.68752752 -0.86638346]\n",
      " [-0.15818838 -0.61657103  4.65395633 -0.26223739  0.21098882 -0.99546699\n",
      "   0.98579169  0.41233793  0.5159635   0.78339709]\n",
      " [-0.3186213   0.83307579 -0.26223739  2.91754721 -0.35731446  0.30064761\n",
      "  -0.33081458  0.27992315 -0.11577411 -0.90277219]\n",
      " [-0.61178461 -0.68095839  0.21098882 -0.35731446  4.12851964 -0.1334659\n",
      "   1.35572416 -0.37299456 -0.24019425  0.44517601]\n",
      " [-0.16438687  0.70181218 -0.99546699  0.30064761 -0.1334659   2.66865473\n",
      "  -1.05904806  0.30548662 -0.81854654 -0.26519596]\n",
      " [ 0.95975278 -1.03750399  0.98579169 -0.33081458  1.35572416 -1.05904806\n",
      "   6.8821382   0.21745955  0.29352035  1.58046724]\n",
      " [-0.0835807   0.2439669   0.41233793  0.27992315 -0.37299456  0.30548662\n",
      "   0.21745955  3.24558019  0.13886893 -0.90897299]\n",
      " [-0.08014102 -0.68752752  0.5159635  -0.11577411 -0.24019425 -0.81854654\n",
      "   0.29352035  0.13886893  3.35855605 -0.09802684]\n",
      " [ 0.761421   -0.86638346  0.78339709 -0.90277219  0.44517601 -0.26519596\n",
      "   1.58046724 -0.90897299 -0.09802684  4.25984503]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:48<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 189 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    926.809\n",
      "w[1]    -89.220\n",
      "w[2]    -63.753\n",
      "w[3]    -77.651\n",
      "w[4]    -79.861\n",
      "w[5]     -3.082\n",
      "w[6]    105.442\n",
      "w[7]    -21.493\n",
      "w[8]    -14.177\n",
      "w[9]     69.695\n",
      "Name: mean, dtype: float64\n",
      "[[ 3.08011452 -0.11501992 -0.15527748 -0.32934225 -0.59519785 -0.16299385\n",
      "   0.96685693 -0.09558502 -0.03901697  0.75804376]\n",
      " [-0.11501992  2.63816806 -0.6168607   0.83953676 -0.67090598  0.67490331\n",
      "  -1.03527609  0.21556507 -0.65765507 -0.87682251]\n",
      " [-0.15527748 -0.6168607   4.63945712 -0.24370836  0.22130775 -0.9474874\n",
      "   0.99937352  0.42578367  0.47746574  0.82253889]\n",
      " [-0.32934225  0.83953676 -0.24370836  2.91979805 -0.33800343  0.30289085\n",
      "  -0.33552788  0.23766754 -0.14584111 -0.88400655]\n",
      " [-0.59519785 -0.67090598  0.22130775 -0.33800343  4.12670625 -0.13062361\n",
      "   1.35974314 -0.35786287 -0.25239058  0.47027091]\n",
      " [-0.16299385  0.67490331 -0.9474874   0.30289085 -0.13062361  2.65377725\n",
      "  -1.0695658   0.28392785 -0.77828961 -0.25636403]\n",
      " [ 0.96685693 -1.03527609  0.99937352 -0.33552788  1.35974314 -1.0695658\n",
      "   6.9460143   0.19713347  0.25898362  1.58708463]\n",
      " [-0.09558502  0.21556507  0.42578367  0.23766754 -0.35786287  0.28392785\n",
      "   0.19713347  3.19633584  0.16373999 -0.90704074]\n",
      " [-0.03901697 -0.65765507  0.47746574 -0.14584111 -0.25239058 -0.77828961\n",
      "   0.25898362  0.16373999  3.30463613 -0.11419372]\n",
      " [ 0.75804376 -0.87682251  0.82253889 -0.88400655  0.47027091 -0.25636403\n",
      "   1.58708463 -0.90704074 -0.11419372  4.25324991]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:48<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 187 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    929.483\n",
      "w[1]    -89.582\n",
      "w[2]    -63.995\n",
      "w[3]    -78.125\n",
      "w[4]    -80.381\n",
      "w[5]     -3.262\n",
      "w[6]    106.421\n",
      "w[7]    -21.600\n",
      "w[8]    -14.185\n",
      "w[9]     70.414\n",
      "Name: mean, dtype: float64\n",
      "[[ 3.00800088 -0.1437377  -0.12782106 -0.33541639 -0.57528903 -0.18902669\n",
      "   0.97254495 -0.10130091 -0.01700342  0.74858046]\n",
      " [-0.1437377   2.61379815 -0.6263039   0.85288257 -0.68196411  0.69278584\n",
      "  -1.07953785  0.21718139 -0.65250023 -0.90956948]\n",
      " [-0.12782106 -0.6263039   4.60674441 -0.27490641  0.22303684 -0.94672093\n",
      "   1.05575828  0.42879847  0.48389341  0.85726527]\n",
      " [-0.33541639  0.85288257 -0.27490641  2.95090962 -0.34273541  0.3255255\n",
      "  -0.35870863  0.23294694 -0.15068064 -0.92212253]\n",
      " [-0.57528903 -0.68196411  0.22303684 -0.34273541  4.08698537 -0.14685593\n",
      "   1.37722623 -0.37388556 -0.24567023  0.48961223]\n",
      " [-0.18902669  0.69278584 -0.94672093  0.3255255  -0.14685593  2.6739765\n",
      "  -1.09860982  0.29388959 -0.8205895  -0.29793996]\n",
      " [ 0.97254495 -1.07953785  1.05575828 -0.35870863  1.37722623 -1.09860982\n",
      "   6.99088503  0.18518248  0.2777973   1.61194879]\n",
      " [-0.10130091  0.21718139  0.42879847  0.23294694 -0.37388556  0.29388959\n",
      "   0.18518248  3.17672714  0.16606611 -0.89569451]\n",
      " [-0.01700342 -0.65250023  0.48389341 -0.15068064 -0.24567023 -0.8205895\n",
      "   0.2777973   0.16606611  3.29584114 -0.10031229]\n",
      " [ 0.74858046 -0.90956948  0.85726527 -0.92212253  0.48961223 -0.29793996\n",
      "   1.61194879 -0.89569451 -0.10031229  4.2474482 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:03<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 225 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    932.099\n",
      "w[1]    -89.975\n",
      "w[2]    -64.201\n",
      "w[3]    -78.605\n",
      "w[4]    -80.898\n",
      "w[5]     -3.467\n",
      "w[6]    107.422\n",
      "w[7]    -21.720\n",
      "w[8]    -14.161\n",
      "w[9]     71.150\n",
      "Name: mean, dtype: float64\n",
      "[[ 3.00553517 -0.15601977 -0.16706534 -0.30936696 -0.62215486 -0.18001804\n",
      "   0.94720718 -0.09204865 -0.04686576  0.7363324 ]\n",
      " [-0.15601977  2.58141754 -0.65362004  0.85315178 -0.70153672  0.70346012\n",
      "  -1.07323389  0.21700484 -0.64373955 -0.94317463]\n",
      " [-0.16706534 -0.65362004  4.57288306 -0.25788689  0.26039858 -0.95907334\n",
      "   1.06023853  0.41295715  0.50738041  0.8687444 ]\n",
      " [-0.30936696  0.85315178 -0.25788689  2.8984342  -0.35058751  0.31926975\n",
      "  -0.36986786  0.23173482 -0.14963781 -0.92297224]\n",
      " [-0.62215486 -0.70153672  0.26039858 -0.35058751  4.07450188 -0.17400422\n",
      "   1.38873323 -0.38726407 -0.18285693  0.55381943]\n",
      " [-0.18001804  0.70346012 -0.95907334  0.31926975 -0.17400422  2.66580804\n",
      "  -1.06650673  0.31571325 -0.83102902 -0.29784414]\n",
      " [ 0.94720718 -1.07323389  1.06023853 -0.36986786  1.38873323 -1.06650673\n",
      "   6.946011    0.19396359  0.28786356  1.60225511]\n",
      " [-0.09204865  0.21700484  0.41295715  0.23173482 -0.38726407  0.31571325\n",
      "   0.19396359  3.13288244  0.13583028 -0.8419284 ]\n",
      " [-0.04686576 -0.64373955  0.50738041 -0.14963781 -0.18285693 -0.83102902\n",
      "   0.28786356  0.13583028  3.27015364 -0.06055352]\n",
      " [ 0.7363324  -0.94317463  0.8687444  -0.92297224  0.55381943 -0.29784414\n",
      "   1.60225511 -0.8419284  -0.06055352  4.20790742]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:51<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 215 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    934.723\n",
      "w[1]    -90.370\n",
      "w[2]    -64.459\n",
      "w[3]    -79.073\n",
      "w[4]    -81.459\n",
      "w[5]     -3.661\n",
      "w[6]    108.397\n",
      "w[7]    -21.834\n",
      "w[8]    -14.169\n",
      "w[9]     71.872\n",
      "Name: mean, dtype: float64\n",
      "[[ 3.03087306 -0.20974499 -0.16246958 -0.30752927 -0.60549373 -0.18801452\n",
      "   0.99811967 -0.10243458 -0.05495183  0.76844197]\n",
      " [-0.20974499  2.57354761 -0.67625365  0.86705258 -0.72616948  0.72079722\n",
      "  -1.13272624  0.23444714 -0.65219118 -0.97852155]\n",
      " [-0.16246958 -0.67625365  4.54843518 -0.26514778  0.33532717 -0.96496817\n",
      "   1.11657665  0.41408146  0.50294159  0.91512764]\n",
      " [-0.30752927  0.86705258 -0.26514778  2.92517502 -0.363416    0.33712963\n",
      "  -0.42265991  0.22155401 -0.1744919  -0.93815746]\n",
      " [-0.60549373 -0.72616948  0.33532717 -0.363416    4.03394181 -0.18579418\n",
      "   1.3894014  -0.40350409 -0.16824401  0.58414591]\n",
      " [-0.18801452  0.72079722 -0.96496817  0.33712963 -0.18579418  2.67007559\n",
      "  -1.09830129  0.31147148 -0.84667353 -0.32422733]\n",
      " [ 0.99811967 -1.13272624  1.11657665 -0.42265991  1.3894014  -1.09830129\n",
      "   6.97171201  0.2044184   0.30169482  1.69579677]\n",
      " [-0.10243458  0.23444714  0.41408146  0.22155401 -0.40350409  0.31147148\n",
      "   0.2044184   3.15382213  0.10884553 -0.86149666]\n",
      " [-0.05495183 -0.65219118  0.50294159 -0.1744919  -0.16824401 -0.84667353\n",
      "   0.30169482  0.10884553  3.24674855 -0.05995848]\n",
      " [ 0.76844197 -0.97852155  0.91512764 -0.93815746  0.58414591 -0.32422733\n",
      "   1.69579677 -0.86149666 -0.05995848  4.22756834]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:51<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 193 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    937.371\n",
      "w[1]    -90.824\n",
      "w[2]    -64.687\n",
      "w[3]    -79.549\n",
      "w[4]    -81.987\n",
      "w[5]     -3.870\n",
      "w[6]    109.430\n",
      "w[7]    -21.948\n",
      "w[8]    -14.192\n",
      "w[9]     72.624\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.99420371 -0.19642169 -0.15649695 -0.29881541 -0.5884725  -0.16550445\n",
      "   1.00202762 -0.08377743 -0.06175808  0.75958244]\n",
      " [-0.19642169  2.57316936 -0.72553661  0.88748383 -0.7441911   0.73972324\n",
      "  -1.18036471  0.22210061 -0.67223358 -0.995964  ]\n",
      " [-0.15649695 -0.72553661  4.51121836 -0.28341387  0.34062067 -0.98951436\n",
      "   1.14403933  0.4028179   0.55393814  0.91427922]\n",
      " [-0.29881541  0.88748383 -0.28341387  2.93000863 -0.35623959  0.35987059\n",
      "  -0.45066198  0.2526875  -0.21459478 -0.94098754]\n",
      " [-0.5884725  -0.7441911   0.34062067 -0.35623959  4.00713086 -0.21672783\n",
      "   1.44172656 -0.39606717 -0.14241362  0.60416358]\n",
      " [-0.16550445  0.73972324 -0.98951436  0.35987059 -0.21672783  2.69373407\n",
      "  -1.12868417  0.2835313  -0.86640026 -0.33635   ]\n",
      " [ 1.00202762 -1.18036471  1.14403933 -0.45066198  1.44172656 -1.12868417\n",
      "   7.02037592  0.23905464  0.3646558   1.70892084]\n",
      " [-0.08377743  0.22210061  0.4028179   0.2526875  -0.39606717  0.2835313\n",
      "   0.23905464  3.1441349   0.14009088 -0.87010602]\n",
      " [-0.06175808 -0.67223358  0.55393814 -0.21459478 -0.14241362 -0.86640026\n",
      "   0.3646558   0.14009088  3.26431839 -0.02789199]\n",
      " [ 0.75958244 -0.995964    0.91427922 -0.94098754  0.60416358 -0.33635\n",
      "   1.70892084 -0.87010602 -0.02789199  4.20282441]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:48<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 202 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    939.986\n",
      "w[1]    -91.251\n",
      "w[2]    -64.915\n",
      "w[3]    -80.010\n",
      "w[4]    -82.507\n",
      "w[5]     -4.061\n",
      "w[6]    110.471\n",
      "w[7]    -22.050\n",
      "w[8]    -14.209\n",
      "w[9]     73.372\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.97984523 -0.19453729 -0.13364234 -0.31474362 -0.61804225 -0.17423682\n",
      "   1.03781045 -0.06071484 -0.06355086  0.780751  ]\n",
      " [-0.19453729  2.58808762 -0.75164745  0.91707384 -0.76975541  0.7633396\n",
      "  -1.21210992  0.20337639 -0.68480445 -1.02897977]\n",
      " [-0.13364234 -0.75164745  4.51723292 -0.29478997  0.3598166  -0.990182\n",
      "   1.18666026  0.4040247   0.55598203  0.93820271]\n",
      " [-0.31474362  0.91707384 -0.29478997  2.93946646 -0.34073399  0.36186438\n",
      "  -0.46405591  0.25465212 -0.24587893 -0.95677841]\n",
      " [-0.61804225 -0.76975541  0.3598166  -0.34073399  3.99419095 -0.23087012\n",
      "   1.45420797 -0.37501315 -0.1192988   0.58359558]\n",
      " [-0.17423682  0.7633396  -0.990182    0.36186438 -0.23087012  2.68616805\n",
      "  -1.13736356  0.2694422  -0.86688579 -0.35402303]\n",
      " [ 1.03781045 -1.21210992  1.18666026 -0.46405591  1.45420797 -1.13736356\n",
      "   7.06729708  0.27607468  0.3661236   1.727558  ]\n",
      " [-0.06071484  0.20337639  0.4040247   0.25465212 -0.37501315  0.2694422\n",
      "   0.27607468  3.10387194  0.10647452 -0.84789103]\n",
      " [-0.06355086 -0.68480445  0.55598203 -0.24587893 -0.1192988  -0.86688579\n",
      "   0.3661236   0.10647452  3.23595568 -0.02590586]\n",
      " [ 0.780751   -1.02897977  0.93820271 -0.95677841  0.58359558 -0.35402303\n",
      "   1.727558   -0.84789103 -0.02590586  4.19144252]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:48<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 187 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    942.576\n",
      "w[1]    -91.680\n",
      "w[2]    -65.105\n",
      "w[3]    -80.478\n",
      "w[4]    -83.043\n",
      "w[5]     -4.261\n",
      "w[6]    111.529\n",
      "w[7]    -22.131\n",
      "w[8]    -14.223\n",
      "w[9]     74.137\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.94838984 -0.20446857 -0.14164504 -0.31939533 -0.59404643 -0.18965354\n",
      "   1.09916716 -0.06791647 -0.06111475  0.80229273]\n",
      " [-0.20446857  2.60879202 -0.8068235   0.93657769 -0.78464303  0.80824074\n",
      "  -1.27805987  0.20936424 -0.71736828 -1.06517862]\n",
      " [-0.14164504 -0.8068235   4.53015867 -0.34567419  0.42585434 -1.02813511\n",
      "   1.27890885  0.35772464  0.57994249  0.98743917]\n",
      " [-0.31939533  0.93657769 -0.34567419  2.90830563 -0.36606594  0.3965673\n",
      "  -0.52908769  0.2426736  -0.24484365 -0.96833952]\n",
      " [-0.59404643 -0.78464303  0.42585434 -0.36606594  3.96526704 -0.263055\n",
      "   1.47554799 -0.33688616 -0.06353926  0.60035617]\n",
      " [-0.18965354  0.80824074 -1.02813511  0.3965673  -0.263055    2.70261112\n",
      "  -1.19686398  0.25908043 -0.89914898 -0.39735186]\n",
      " [ 1.09916716 -1.27805987  1.27890885 -0.52908769  1.47554799 -1.19686398\n",
      "   7.10370105  0.25699066  0.41365788  1.77153218]\n",
      " [-0.06791647  0.20936424  0.35772464  0.2426736  -0.33688616  0.25908043\n",
      "   0.25699066  3.05227565  0.10784597 -0.84757705]\n",
      " [-0.06111475 -0.71736828  0.57994249 -0.24484365 -0.06353926 -0.89914898\n",
      "   0.41365788  0.10784597  3.23217006  0.01980549]\n",
      " [ 0.80229273 -1.06517862  0.98743917 -0.96833952  0.60035617 -0.39735186\n",
      "   1.77153218 -0.84757705  0.01980549  4.21782385]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:51<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 192 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    945.132\n",
      "w[1]    -92.122\n",
      "w[2]    -65.300\n",
      "w[3]    -80.942\n",
      "w[4]    -83.545\n",
      "w[5]     -4.476\n",
      "w[6]    112.658\n",
      "w[7]    -22.207\n",
      "w[8]    -14.236\n",
      "w[9]     74.923\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.92646729 -0.21209605 -0.09893541 -0.31676641 -0.56900077 -0.18901787\n",
      "   1.12855985 -0.0188849  -0.05339275  0.814889  ]\n",
      " [-0.21209605  2.64682136 -0.87801742  0.98499799 -0.81384551  0.83825269\n",
      "  -1.32969034  0.20115788 -0.73852145 -1.11556692]\n",
      " [-0.09893541 -0.87801742  4.61759132 -0.38350229  0.48141896 -1.03402134\n",
      "   1.36602187  0.36290003  0.58374477  1.08537656]\n",
      " [-0.31676641  0.98499799 -0.38350229  2.90172322 -0.3966169   0.41427116\n",
      "  -0.55872074  0.22611187 -0.26063024 -1.00787056]\n",
      " [-0.56900077 -0.81384551  0.48141896 -0.3966169   3.92020787 -0.28067084\n",
      "   1.46762035 -0.37453062 -0.05410086  0.66887986]\n",
      " [-0.18901787  0.83825269 -1.03402134  0.41427116 -0.28067084  2.72090954\n",
      "  -1.27291219  0.25315294 -0.91612326 -0.46502195]\n",
      " [ 1.12855985 -1.32969034  1.36602187 -0.55872074  1.46762035 -1.27291219\n",
      "   7.17442135  0.25888938  0.43982478  1.85124828]\n",
      " [-0.0188849   0.20115788  0.36290003  0.22611187 -0.37453062  0.25315294\n",
      "   0.25888938  3.02957497  0.13032989 -0.84353112]\n",
      " [-0.05339275 -0.73852145  0.58374477 -0.26063024 -0.05410086 -0.91612326\n",
      "   0.43982478  0.13032989  3.19156127  0.05029191]\n",
      " [ 0.814889   -1.11556692  1.08537656 -1.00787056  0.66887986 -0.46502195\n",
      "   1.85124828 -0.84353112  0.05029191  4.25973534]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:52<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 211 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    947.683\n",
      "w[1]    -92.584\n",
      "w[2]    -65.465\n",
      "w[3]    -81.429\n",
      "w[4]    -84.034\n",
      "w[5]     -4.692\n",
      "w[6]    113.808\n",
      "w[7]    -22.250\n",
      "w[8]    -14.247\n",
      "w[9]     75.726\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.93012137e+00 -2.38768155e-01 -8.07624794e-02 -3.44021442e-01\n",
      "  -5.47559861e-01 -2.16168332e-01  1.15250967e+00  7.31254527e-03\n",
      "  -3.15019402e-02  8.55179068e-01]\n",
      " [-2.38768155e-01  2.67757954e+00 -9.69647704e-01  1.02864509e+00\n",
      "  -8.42530982e-01  8.87712087e-01 -1.41285202e+00  2.18852698e-01\n",
      "  -7.53570339e-01 -1.15924350e+00]\n",
      " [-8.07624794e-02 -9.69647704e-01  4.69724598e+00 -4.38573118e-01\n",
      "   5.17135311e-01 -1.07189419e+00  1.44892365e+00  3.82518466e-01\n",
      "   5.96522334e-01  1.16960625e+00]\n",
      " [-3.44021442e-01  1.02864509e+00 -4.38573118e-01  2.87317327e+00\n",
      "  -4.28905940e-01  4.81399927e-01 -6.47083590e-01  2.52633376e-01\n",
      "  -2.85860058e-01 -1.06535263e+00]\n",
      " [-5.47559861e-01 -8.42530982e-01  5.17135311e-01 -4.28905940e-01\n",
      "   3.89992158e+00 -3.12322849e-01  1.50976681e+00 -3.43908638e-01\n",
      "  -2.75314524e-02  6.91200224e-01]\n",
      " [-2.16168332e-01  8.87712087e-01 -1.07189419e+00  4.81399927e-01\n",
      "  -3.12322849e-01  2.73180364e+00 -1.35267208e+00  2.53521323e-01\n",
      "  -9.19709859e-01 -4.92015134e-01]\n",
      " [ 1.15250967e+00 -1.41285202e+00  1.44892365e+00 -6.47083590e-01\n",
      "   1.50976681e+00 -1.35267208e+00  7.33917140e+00  2.48708309e-01\n",
      "   4.85613047e-01  1.93308955e+00]\n",
      " [ 7.31254527e-03  2.18852698e-01  3.82518466e-01  2.52633376e-01\n",
      "  -3.43908638e-01  2.53521323e-01  2.48708309e-01  2.98321788e+00\n",
      "   1.46955157e-01 -8.27290438e-01]\n",
      " [-3.15019402e-02 -7.53570339e-01  5.96522334e-01 -2.85860058e-01\n",
      "  -2.75314524e-02 -9.19709859e-01  4.85613047e-01  1.46955157e-01\n",
      "   3.14539497e+00  5.76796919e-02]\n",
      " [ 8.55179068e-01 -1.15924350e+00  1.16960625e+00 -1.06535263e+00\n",
      "   6.91200224e-01 -4.92015134e-01  1.93308955e+00 -8.27290438e-01\n",
      "   5.76796919e-02  4.30387383e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:49<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 189 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    950.230\n",
      "w[1]    -93.082\n",
      "w[2]    -65.575\n",
      "w[3]    -81.946\n",
      "w[4]    -84.499\n",
      "w[5]     -4.956\n",
      "w[6]    115.004\n",
      "w[7]    -22.276\n",
      "w[8]    -14.216\n",
      "w[9]     76.569\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.95823765e+00 -2.50245336e-01 -8.82211242e-02 -3.50060405e-01\n",
      "  -5.37496599e-01 -2.26234826e-01  1.17960913e+00  1.60690559e-03\n",
      "  -2.02928163e-02  8.39836605e-01]\n",
      " [-2.50245336e-01  2.72844458e+00 -1.00665811e+00  1.06621097e+00\n",
      "  -8.76500082e-01  9.33271063e-01 -1.49468254e+00  2.26222937e-01\n",
      "  -7.71193443e-01 -1.23199984e+00]\n",
      " [-8.82211242e-02 -1.00665811e+00  4.73087986e+00 -4.46194173e-01\n",
      "   5.61526728e-01 -1.11043483e+00  1.46733627e+00  3.68575146e-01\n",
      "   6.33581453e-01  1.22352560e+00]\n",
      " [-3.50060405e-01  1.06621097e+00 -4.46194173e-01  2.90935402e+00\n",
      "  -4.72162742e-01  5.32953081e-01 -6.96034150e-01  2.68606044e-01\n",
      "  -3.19269211e-01 -1.07899128e+00]\n",
      " [-5.37496599e-01 -8.76500082e-01  5.61526728e-01 -4.72162742e-01\n",
      "   3.85244543e+00 -3.47480035e-01  1.54362707e+00 -3.65058762e-01\n",
      "  -7.16097200e-03  7.47619787e-01]\n",
      " [-2.26234826e-01  9.33271063e-01 -1.11043483e+00  5.32953081e-01\n",
      "  -3.47480035e-01  2.73181275e+00 -1.41531411e+00  2.45680074e-01\n",
      "  -9.49271372e-01 -5.65839960e-01]\n",
      " [ 1.17960913e+00 -1.49468254e+00  1.46733627e+00 -6.96034150e-01\n",
      "   1.54362707e+00 -1.41531411e+00  7.47036045e+00  2.54914928e-01\n",
      "   5.23357924e-01  1.99757762e+00]\n",
      " [ 1.60690559e-03  2.26222937e-01  3.68575146e-01  2.68606044e-01\n",
      "  -3.65058762e-01  2.45680074e-01  2.54914928e-01  2.92972804e+00\n",
      "   1.50482043e-01 -8.28248878e-01]\n",
      " [-2.02928163e-02 -7.71193443e-01  6.33581453e-01 -3.19269211e-01\n",
      "  -7.16097200e-03 -9.49271372e-01  5.23357924e-01  1.50482043e-01\n",
      "   3.16476987e+00  7.66138294e-02]\n",
      " [ 8.39836605e-01 -1.23199984e+00  1.22352560e+00 -1.07899128e+00\n",
      "   7.47619787e-01 -5.65839960e-01  1.99757762e+00 -8.28248878e-01\n",
      "   7.66138294e-02  4.32443161e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:53<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 193 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    952.805\n",
      "w[1]    -93.574\n",
      "w[2]    -65.714\n",
      "w[3]    -82.458\n",
      "w[4]    -84.956\n",
      "w[5]     -5.217\n",
      "w[6]    116.212\n",
      "w[7]    -22.303\n",
      "w[8]    -14.177\n",
      "w[9]     77.388\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.92623015 -0.2740655  -0.04465588 -0.34494804 -0.52463707 -0.25446806\n",
      "   1.19630634 -0.01677459 -0.01447508  0.85257883]\n",
      " [-0.2740655   2.76765569 -1.06050307  1.11677234 -0.92003814  0.99279215\n",
      "  -1.58403959  0.22083005 -0.80308553 -1.28163547]\n",
      " [-0.04465588 -1.06050307  4.70572883 -0.47146368  0.62531436 -1.1511131\n",
      "   1.53464804  0.34473986  0.6578151   1.30869521]\n",
      " [-0.34494804  1.11677234 -0.47146368  2.90497289 -0.48863538  0.5603809\n",
      "  -0.72016906  0.25220355 -0.33353295 -1.07611424]\n",
      " [-0.52463707 -0.92003814  0.62531436 -0.48863538  3.83845616 -0.36845814\n",
      "   1.61952273 -0.38108305  0.02107472  0.80995629]\n",
      " [-0.25446806  0.99279215 -1.1511131   0.5603809  -0.36845814  2.7353849\n",
      "  -1.47888425  0.24120339 -0.95475158 -0.63962919]\n",
      " [ 1.19630634 -1.58403959  1.53464804 -0.72016906  1.61952273 -1.47888425\n",
      "   7.50152677  0.23112597  0.57625577  2.05643715]\n",
      " [-0.01677459  0.22083005  0.34473986  0.25220355 -0.38108305  0.24120339\n",
      "   0.23112597  2.85160014  0.13337919 -0.82005041]\n",
      " [-0.01447508 -0.80308553  0.6578151  -0.33353295  0.02107472 -0.95475158\n",
      "   0.57625577  0.13337919  3.17134175  0.13964026]\n",
      " [ 0.85257883 -1.28163547  1.30869521 -1.07611424  0.80995629 -0.63962919\n",
      "   2.05643715 -0.82005041  0.13964026  4.31520652]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:50<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 204 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    955.356\n",
      "w[1]    -94.095\n",
      "w[2]    -65.805\n",
      "w[3]    -82.969\n",
      "w[4]    -85.395\n",
      "w[5]     -5.502\n",
      "w[6]    117.445\n",
      "w[7]    -22.330\n",
      "w[8]    -14.132\n",
      "w[9]     78.227\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.94173594e+00 -2.97959560e-01 -7.41180978e-03 -3.69288139e-01\n",
      "  -5.14270357e-01 -2.93960609e-01  1.22528971e+00 -2.97192844e-02\n",
      "  -3.80174316e-03  8.86809611e-01]\n",
      " [-2.97959560e-01  2.84416771e+00 -1.14545518e+00  1.14757926e+00\n",
      "  -9.69707975e-01  1.06161221e+00 -1.73112245e+00  2.51228918e-01\n",
      "  -8.40054023e-01 -1.37748044e+00]\n",
      " [-7.41180978e-03 -1.14545518e+00  4.78410879e+00 -4.86170769e-01\n",
      "   6.34729685e-01 -1.20830682e+00  1.61643375e+00  3.20730176e-01\n",
      "   6.98994673e-01  1.39198871e+00]\n",
      " [-3.69288139e-01  1.14757926e+00 -4.86170769e-01  2.89430549e+00\n",
      "  -5.29541898e-01  5.84807144e-01 -8.12443214e-01  2.55684892e-01\n",
      "  -3.51164915e-01 -1.10351213e+00]\n",
      " [-5.14270357e-01 -9.69707975e-01  6.34729685e-01 -5.29541898e-01\n",
      "   3.89551603e+00 -3.98397769e-01  1.73932611e+00 -4.08180056e-01\n",
      "   4.28152969e-02  8.80280619e-01]\n",
      " [-2.93960609e-01  1.06161221e+00 -1.20830682e+00  5.84807144e-01\n",
      "  -3.98397769e-01  2.78921101e+00 -1.57105665e+00  2.51757650e-01\n",
      "  -9.95973296e-01 -7.05100430e-01]\n",
      " [ 1.22528971e+00 -1.73112245e+00  1.61643375e+00 -8.12443214e-01\n",
      "   1.73932611e+00 -1.57105665e+00  7.61065931e+00  1.99329248e-01\n",
      "   6.24213316e-01  2.18907090e+00]\n",
      " [-2.97192844e-02  2.51228918e-01  3.20730176e-01  2.55684892e-01\n",
      "  -4.08180056e-01  2.51757650e-01  1.99329248e-01  2.82494441e+00\n",
      "   1.20757575e-01 -8.41596060e-01]\n",
      " [-3.80174316e-03 -8.40054023e-01  6.98994673e-01 -3.51164915e-01\n",
      "   4.28152969e-02 -9.95973296e-01  6.24213316e-01  1.20757575e-01\n",
      "   3.13441067e+00  1.79578669e-01]\n",
      " [ 8.86809611e-01 -1.37748044e+00  1.39198871e+00 -1.10351213e+00\n",
      "   8.80280619e-01 -7.05100430e-01  2.18907090e+00 -8.41596060e-01\n",
      "   1.79578669e-01  4.37348387e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:55<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 198 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    957.919\n",
      "w[1]    -94.629\n",
      "w[2]    -65.858\n",
      "w[3]    -83.499\n",
      "w[4]    -85.818\n",
      "w[5]     -5.837\n",
      "w[6]    118.709\n",
      "w[7]    -22.384\n",
      "w[8]    -14.090\n",
      "w[9]     79.094\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.97354477 -0.31127026  0.01251548 -0.39877591 -0.49919777 -0.32814624\n",
      "   1.26464587 -0.0332548   0.01473705  0.91464139]\n",
      " [-0.31127026  2.92276133 -1.1935363   1.20010847 -0.98600951  1.12327472\n",
      "  -1.80865386  0.25956642 -0.87708375 -1.43836115]\n",
      " [ 0.01251548 -1.1935363   4.80032287 -0.52053591  0.64973408 -1.29702421\n",
      "   1.70516428  0.29306687  0.74499172  1.45482373]\n",
      " [-0.39877591  1.20010847 -0.52053591  2.94082082 -0.53754773  0.63340993\n",
      "  -0.89090296  0.27486761 -0.37721072 -1.15686939]\n",
      " [-0.49919777 -0.98600951  0.64973408 -0.53754773  3.85383983 -0.417936\n",
      "   1.78522612 -0.39211904  0.05728562  0.90557522]\n",
      " [-0.32814624  1.12327472 -1.29702421  0.63340993 -0.417936    2.83206053\n",
      "  -1.66662731  0.26365944 -1.04092981 -0.72689286]\n",
      " [ 1.26464587 -1.80865386  1.70516428 -0.89090296  1.78522612 -1.66662731\n",
      "   7.70986754  0.19229922  0.68164544  2.29532469]\n",
      " [-0.0332548   0.25956642  0.29306687  0.27486761 -0.39211904  0.26365944\n",
      "   0.19229922  2.78135073  0.10219416 -0.83703125]\n",
      " [ 0.01473705 -0.87708375  0.74499172 -0.37721072  0.05728562 -1.04092981\n",
      "   0.68164544  0.10219416  3.14393096  0.22827769]\n",
      " [ 0.91464139 -1.43836115  1.45482373 -1.15686939  0.90557522 -0.72689286\n",
      "   2.29532469 -0.83703125  0.22827769  4.38266625]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:52<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 196 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    960.507\n",
      "w[1]    -95.194\n",
      "w[2]    -65.877\n",
      "w[3]    -84.065\n",
      "w[4]    -86.238\n",
      "w[5]     -6.217\n",
      "w[6]    120.025\n",
      "w[7]    -22.442\n",
      "w[8]    -14.012\n",
      "w[9]     80.005\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.95102525 -0.31818455 -0.01202969 -0.39236655 -0.45581718 -0.34468341\n",
      "   1.29648299 -0.02641161  0.03836963  0.91809636]\n",
      " [-0.31818455  2.97562898 -1.28976497  1.24067725 -1.02687391  1.16090504\n",
      "  -1.91094393  0.24661869 -0.9029505  -1.48717389]\n",
      " [-0.01202969 -1.28976497  4.93217311 -0.57923991  0.72222484 -1.36153671\n",
      "   1.80772737  0.30338648  0.78358553  1.54915804]\n",
      " [-0.39236655  1.24067725 -0.57923991  2.92568666 -0.55481749  0.64299804\n",
      "  -0.97365171  0.23595783 -0.39771941 -1.16186078]\n",
      " [-0.45581718 -1.02687391  0.72222484 -0.55481749  3.8649787  -0.44993443\n",
      "   1.8486444  -0.42525383  0.07205678  0.99330226]\n",
      " [-0.34468341  1.16090504 -1.36153671  0.64299804 -0.44993443  2.84253616\n",
      "  -1.7749096   0.26942511 -1.0903359  -0.81503168]\n",
      " [ 1.29648299 -1.91094393  1.80772737 -0.97365171  1.8486444  -1.7749096\n",
      "   7.9232451   0.12999585  0.75012825  2.43100429]\n",
      " [-0.02641161  0.24661869  0.30338648  0.23595783 -0.42525383  0.26942511\n",
      "   0.12999585  2.780585    0.12108201 -0.82718171]\n",
      " [ 0.03836963 -0.9029505   0.78358553 -0.39771941  0.07205678 -1.0903359\n",
      "   0.75012825  0.12108201  3.14221943  0.24653471]\n",
      " [ 0.91809636 -1.48717389  1.54915804 -1.16186078  0.99330226 -0.81503168\n",
      "   2.43100429 -0.82718171  0.24653471  4.39509926]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:52<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 207 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    963.083\n",
      "w[1]    -95.777\n",
      "w[2]    -65.915\n",
      "w[3]    -84.623\n",
      "w[4]    -86.596\n",
      "w[5]     -6.621\n",
      "w[6]    121.399\n",
      "w[7]    -22.496\n",
      "w[8]    -13.917\n",
      "w[9]     80.923\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.93829560e+00 -3.54310734e-01  2.60054969e-02 -4.16775017e-01\n",
      "  -4.62589391e-01 -3.72171299e-01  1.33156556e+00 -1.42994211e-03\n",
      "   3.94147745e-02  9.32318086e-01]\n",
      " [-3.54310734e-01  3.00868559e+00 -1.35630039e+00  1.28503339e+00\n",
      "  -1.04903353e+00  1.23716765e+00 -2.03009435e+00  2.74568367e-01\n",
      "  -9.37570514e-01 -1.56163365e+00]\n",
      " [ 2.60054969e-02 -1.35630039e+00  4.96511610e+00 -6.59012305e-01\n",
      "   7.53325101e-01 -1.42418222e+00  1.90757144e+00  3.00395102e-01\n",
      "   8.29156126e-01  1.63950845e+00]\n",
      " [-4.16775017e-01  1.28503339e+00 -6.59012305e-01  2.93581146e+00\n",
      "  -5.96284899e-01  6.85193261e-01 -1.06376564e+00  2.24219546e-01\n",
      "  -4.54732539e-01 -1.21070887e+00]\n",
      " [-4.62589391e-01 -1.04903353e+00  7.53325101e-01 -5.96284899e-01\n",
      "   3.87504388e+00 -4.76683073e-01  1.90608787e+00 -4.33425615e-01\n",
      "   8.79442815e-02  1.04792674e+00]\n",
      " [-3.72171299e-01  1.23716765e+00 -1.42418222e+00  6.85193261e-01\n",
      "  -4.76683073e-01  2.91279435e+00 -1.84609060e+00  3.06985513e-01\n",
      "  -1.14449824e+00 -8.75398451e-01]\n",
      " [ 1.33156556e+00 -2.03009435e+00  1.90757144e+00 -1.06376564e+00\n",
      "   1.90608787e+00 -1.84609060e+00  8.07622789e+00  1.38308196e-01\n",
      "   7.88444759e-01  2.49917334e+00]\n",
      " [-1.42994211e-03  2.74568367e-01  3.00395102e-01  2.24219546e-01\n",
      "  -4.33425615e-01  3.06985513e-01  1.38308196e-01  2.81956318e+00\n",
      "   1.04230416e-01 -8.34834497e-01]\n",
      " [ 3.94147745e-02 -9.37570514e-01  8.29156126e-01 -4.54732539e-01\n",
      "   8.79442815e-02 -1.14449824e+00  7.88444759e-01  1.04230416e-01\n",
      "   3.12679099e+00  2.72245252e-01]\n",
      " [ 9.32318086e-01 -1.56163365e+00  1.63950845e+00 -1.21070887e+00\n",
      "   1.04792674e+00 -8.75398451e-01  2.49917334e+00 -8.34834497e-01\n",
      "   2.72245252e-01  4.44530730e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:52<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 193 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    965.640\n",
      "w[1]    -96.367\n",
      "w[2]    -65.935\n",
      "w[3]    -85.196\n",
      "w[4]    -86.968\n",
      "w[5]     -7.025\n",
      "w[6]    122.781\n",
      "w[7]    -22.523\n",
      "w[8]    -13.825\n",
      "w[9]     81.825\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.9147687  -0.39708     0.0460324  -0.43748974 -0.46082556 -0.40711302\n",
      "   1.35066825 -0.01422056  0.05941479  0.95303415]\n",
      " [-0.39708     3.08387725 -1.42138014  1.33746645 -1.1193646   1.29902632\n",
      "  -2.13540938  0.28874045 -0.98512615 -1.62693456]\n",
      " [ 0.0460324  -1.42138014  4.99404819 -0.69929599  0.83769363 -1.46336894\n",
      "   2.0155038   0.26812777  0.89543864  1.70905888]\n",
      " [-0.43748974  1.33746645 -0.69929599  2.96812754 -0.65644774  0.7181157\n",
      "  -1.18773007  0.23898866 -0.50154291 -1.26422389]\n",
      " [-0.46082556 -1.1193646   0.83769363 -0.65644774  3.96027185 -0.52544524\n",
      "   2.01788508 -0.44337574  0.11155727  1.09534529]\n",
      " [-0.40711302  1.29902632 -1.46336894  0.7181157  -0.52544524  2.94991136\n",
      "  -1.95164433  0.32048685 -1.18176056 -0.9150828 ]\n",
      " [ 1.35066825 -2.13540938  2.0155038  -1.18773007  2.01788508 -1.95164433\n",
      "   8.19414266  0.09192159  0.87554071  2.61424344]\n",
      " [-0.01422056  0.28874045  0.26812777  0.23898866 -0.44337574  0.32048685\n",
      "   0.09192159  2.79204346  0.09679584 -0.85046941]\n",
      " [ 0.05941479 -0.98512615  0.89543864 -0.50154291  0.11155727 -1.18176056\n",
      "   0.87554071  0.09679584  3.16710221  0.30491222]\n",
      " [ 0.95303415 -1.62693456  1.70905888 -1.26422389  1.09534529 -0.9150828\n",
      "   2.61424344 -0.85046941  0.30491222  4.49046247]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:56<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 198 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    968.186\n",
      "w[1]    -97.022\n",
      "w[2]    -65.922\n",
      "w[3]    -85.806\n",
      "w[4]    -87.339\n",
      "w[5]     -7.474\n",
      "w[6]    124.199\n",
      "w[7]    -22.565\n",
      "w[8]    -13.698\n",
      "w[9]     82.774\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.91137114 -0.42558443  0.060245   -0.45038641 -0.44463788 -0.40148949\n",
      "   1.37624913 -0.02258621  0.07354933  0.99059882]\n",
      " [-0.42558443  3.18362649 -1.51173386  1.4150939  -1.20583304  1.37943294\n",
      "  -2.30062636  0.32083694 -1.03580399 -1.73816435]\n",
      " [ 0.060245   -1.51173386  5.03290002 -0.73872423  0.93187114 -1.52946521\n",
      "   2.1446855   0.23017399  0.92702952  1.79859354]\n",
      " [-0.45038641  1.4150939  -0.73872423  2.99180855 -0.69570518  0.75728985\n",
      "  -1.28836394  0.2613926  -0.53138952 -1.36794064]\n",
      " [-0.44463788 -1.20583304  0.93187114 -0.69570518  3.96619418 -0.61388252\n",
      "   2.17239768 -0.46082976  0.14064327  1.18952089]\n",
      " [-0.40148949  1.37943294 -1.52946521  0.75728985 -0.61388252  3.01399454\n",
      "  -2.04265647  0.34171128 -1.22211851 -1.01042343]\n",
      " [ 1.37624913 -2.30062636  2.1446855  -1.28836394  2.17239768 -2.04265647\n",
      "   8.34721255  0.03389909  0.93773125  2.71962821]\n",
      " [-0.02258621  0.32083694  0.23017399  0.2613926  -0.46082976  0.34171128\n",
      "   0.03389909  2.77899305  0.07619946 -0.86870349]\n",
      " [ 0.07354933 -1.03580399  0.92702952 -0.53138952  0.14064327 -1.22211851\n",
      "   0.93773125  0.07619946  3.19156649  0.35604442]\n",
      " [ 0.99059882 -1.73816435  1.79859354 -1.36794064  1.18952089 -1.01042343\n",
      "   2.71962821 -0.86870349  0.35604442  4.59194097]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:54<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 213 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    970.722\n",
      "w[1]    -97.701\n",
      "w[2]    -65.889\n",
      "w[3]    -86.413\n",
      "w[4]    -87.684\n",
      "w[5]     -7.924\n",
      "w[6]    125.648\n",
      "w[7]    -22.614\n",
      "w[8]    -13.567\n",
      "w[9]     83.756\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.86772141 -0.44054073  0.0591054  -0.47320613 -0.41336025 -0.41082422\n",
      "   1.40593261 -0.02623595  0.06721213  1.00505679]\n",
      " [-0.44054073  3.29091417 -1.62108347  1.47335951 -1.30092209  1.45601427\n",
      "  -2.48196217  0.33338489 -1.07151834 -1.84825437]\n",
      " [ 0.0591054  -1.62108347  5.15129624 -0.80711898  1.05495168 -1.61784658\n",
      "   2.36499561  0.23507376  0.98167786  1.92067924]\n",
      " [-0.47320613  1.47335951 -0.80711898  3.00963926 -0.76964846  0.81803498\n",
      "  -1.41549639  0.27678393 -0.56318888 -1.4342433 ]\n",
      " [-0.41336025 -1.30092209  1.05495168 -0.76964846  4.01676025 -0.71754701\n",
      "   2.31588097 -0.49487763  0.20341984  1.26171335]\n",
      " [-0.41082422  1.45601427 -1.61784658  0.81803498 -0.71754701  3.07154694\n",
      "  -2.19358084  0.3420147  -1.25496177 -1.11161282]\n",
      " [ 1.40593261 -2.48196217  2.36499561 -1.41549639  2.31588097 -2.19358084\n",
      "   8.66691113  0.0329456   1.01709491  2.91655868]\n",
      " [-0.02623595  0.33338489  0.23507376  0.27678393 -0.49487763  0.3420147\n",
      "   0.0329456   2.76080882  0.05871308 -0.85726033]\n",
      " [ 0.06721213 -1.07151834  0.98167786 -0.56318888  0.20341984 -1.25496177\n",
      "   1.01709491  0.05871308  3.17863676  0.41988309]\n",
      " [ 1.00505679 -1.84825437  1.92067924 -1.4342433   1.26171335 -1.11161282\n",
      "   2.91655868 -0.85726033  0.41988309  4.69211951]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:53<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 195 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    973.236\n",
      "w[1]    -98.414\n",
      "w[2]    -65.849\n",
      "w[3]    -87.046\n",
      "w[4]    -87.991\n",
      "w[5]     -8.399\n",
      "w[6]    127.137\n",
      "w[7]    -22.673\n",
      "w[8]    -13.439\n",
      "w[9]     84.771\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.81586934 -0.47080585  0.07173902 -0.47966231 -0.39052312 -0.42728528\n",
      "   1.45746441  0.01459565  0.11650722  0.98750274]\n",
      " [-0.47080585  3.39928278 -1.7666577   1.55727033 -1.4002374   1.56671567\n",
      "  -2.65237732  0.3640613  -1.11991787 -1.96359777]\n",
      " [ 0.07173902 -1.7666577   5.2720837  -0.92395558  1.19353291 -1.71368647\n",
      "   2.58935083  0.18254153  1.04392204  2.07156013]\n",
      " [-0.47966231  1.55727033 -0.92395558  3.04998266 -0.84169421  0.90024134\n",
      "  -1.54825413  0.30487223 -0.61359789 -1.51211705]\n",
      " [-0.39052312 -1.4002374   1.19353291 -0.84169421  4.06444505 -0.81086628\n",
      "   2.45704609 -0.54254909  0.22706665  1.39369041]\n",
      " [-0.42728528  1.56671567 -1.71368647  0.90024134 -0.81086628  3.16465193\n",
      "  -2.3299494   0.36038032 -1.32491281 -1.21873986]\n",
      " [ 1.45746441 -2.65237732  2.58935083 -1.54825413  2.45704609 -2.3299494\n",
      "   8.89986768  0.029141    1.10365898  3.0693901 ]\n",
      " [ 0.01459565  0.3640613   0.18254153  0.30487223 -0.54254909  0.36038032\n",
      "   0.029141    2.72279651  0.04391624 -0.87772028]\n",
      " [ 0.11650722 -1.11991787  1.04392204 -0.61359789  0.22706665 -1.32491281\n",
      "   1.10365898  0.04391624  3.17533308  0.49443048]\n",
      " [ 0.98750274 -1.96359777  2.07156013 -1.51211705  1.39369041 -1.21873986\n",
      "   3.0693901  -0.87772028  0.49443048  4.77507243]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:51<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 202 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    975.696\n",
      "w[1]    -99.149\n",
      "w[2]    -65.785\n",
      "w[3]    -87.694\n",
      "w[4]    -88.277\n",
      "w[5]     -8.877\n",
      "w[6]    128.664\n",
      "w[7]    -22.696\n",
      "w[8]    -13.255\n",
      "w[9]     85.764\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.83574427e+00 -5.43889571e-01  1.44482856e-01 -5.33679586e-01\n",
      "  -3.67428541e-01 -4.92160374e-01  1.56940751e+00  9.56326418e-03\n",
      "   1.46068680e-01  1.05633772e+00]\n",
      " [-5.43889571e-01  3.54387565e+00 -1.93000922e+00  1.65467793e+00\n",
      "  -1.47950836e+00  1.70581149e+00 -2.90422939e+00  3.61614225e-01\n",
      "  -1.22729584e+00 -2.13728113e+00]\n",
      " [ 1.44482856e-01 -1.93000922e+00  5.38059243e+00 -1.04049016e+00\n",
      "   1.31117215e+00 -1.83037101e+00  2.88505463e+00  2.05001607e-01\n",
      "   1.09924450e+00  2.24389671e+00]\n",
      " [-5.33679586e-01  1.65467793e+00 -1.04049016e+00  3.07974051e+00\n",
      "  -8.96701875e-01  1.01460719e+00 -1.76134052e+00  3.18001978e-01\n",
      "  -6.76448346e-01 -1.66082996e+00]\n",
      " [-3.67428541e-01 -1.47950836e+00  1.31117215e+00 -8.96701875e-01\n",
      "   4.13485134e+00 -8.84122222e-01  2.66503380e+00 -5.53843651e-01\n",
      "   2.59234581e-01  1.55653653e+00]\n",
      " [-4.92160374e-01  1.70581149e+00 -1.83037101e+00  1.01460719e+00\n",
      "  -8.84122222e-01  3.24896691e+00 -2.56066171e+00  3.68548138e-01\n",
      "  -1.38377633e+00 -1.38623832e+00]\n",
      " [ 1.56940751e+00 -2.90422939e+00  2.88505463e+00 -1.76134052e+00\n",
      "   2.66503380e+00 -2.56066171e+00  9.33984046e+00 -3.60963655e-03\n",
      "   1.21694798e+00  3.38710078e+00]\n",
      " [ 9.56326418e-03  3.61614225e-01  2.05001607e-01  3.18001978e-01\n",
      "  -5.53843651e-01  3.68548138e-01 -3.60963655e-03  2.67017452e+00\n",
      "   1.81422383e-02 -8.82059401e-01]\n",
      " [ 1.46068680e-01 -1.22729584e+00  1.09924450e+00 -6.76448346e-01\n",
      "   2.59234581e-01 -1.38377633e+00  1.21694798e+00  1.81422383e-02\n",
      "   3.19286159e+00  5.89311772e-01]\n",
      " [ 1.05633772e+00 -2.13728113e+00  2.24389671e+00 -1.66082996e+00\n",
      "   1.55653653e+00 -1.38623832e+00  3.38710078e+00 -8.82059401e-01\n",
      "   5.89311772e-01  4.95001216e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:54<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 210 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    978.176\n",
      "w[1]    -99.920\n",
      "w[2]    -65.668\n",
      "w[3]    -88.369\n",
      "w[4]    -88.553\n",
      "w[5]     -9.390\n",
      "w[6]    130.246\n",
      "w[7]    -22.728\n",
      "w[8]    -13.062\n",
      "w[9]     86.808\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.80874578 -0.58255667  0.20358781 -0.53837339 -0.33785832 -0.52943684\n",
      "   1.60337981  0.0255053   0.19401663  1.0657546 ]\n",
      " [-0.58255667  3.68415053 -2.07946933  1.7573226  -1.58797109  1.82996866\n",
      "  -3.13696693  0.37784773 -1.30609117 -2.3130656 ]\n",
      " [ 0.20358781 -2.07946933  5.46586038 -1.16242141  1.43859441 -1.93862442\n",
      "   3.12973334  0.15988967  1.16024592  2.42238991]\n",
      " [-0.53837339  1.7573226  -1.16242141  3.12260571 -0.97811501  1.1196716\n",
      "  -1.93092219  0.32587688 -0.75410542 -1.78112523]\n",
      " [-0.33785832 -1.58797109  1.43859441 -0.97811501  4.20854495 -0.96045167\n",
      "   2.82266694 -0.59769255  0.29088595  1.70125367]\n",
      " [-0.52943684  1.82996866 -1.93862442  1.1196716  -0.96045167  3.33082044\n",
      "  -2.74550835  0.38409242 -1.44392569 -1.51614751]\n",
      " [ 1.60337981 -3.13696693  3.12973334 -1.93092219  2.82266694 -2.74550835\n",
      "   9.66078595 -0.04404348  1.33608258  3.59214792]\n",
      " [ 0.0255053   0.37784773  0.15988967  0.32587688 -0.59769255  0.38409242\n",
      "  -0.04404348  2.65678031  0.02015998 -0.90840313]\n",
      " [ 0.19401663 -1.30609117  1.16024592 -0.75410542  0.29088595 -1.44392569\n",
      "   1.33608258  0.02015998  3.2185218   0.69580022]\n",
      " [ 1.0657546  -2.3130656   2.42238991 -1.78112523  1.70125367 -1.51614751\n",
      "   3.59214792 -0.90840313  0.69580022  5.0931809 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:58<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 218 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    980.648\n",
      "w[1]   -100.776\n",
      "w[2]    -65.435\n",
      "w[3]    -89.083\n",
      "w[4]    -88.769\n",
      "w[5]    -10.006\n",
      "w[6]    131.968\n",
      "w[7]    -22.738\n",
      "w[8]    -12.789\n",
      "w[9]     87.911\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.83520745 -0.62246405  0.27294039 -0.57435333 -0.31860491 -0.59715015\n",
      "   1.6721815   0.05190364  0.21833507  1.12800809]\n",
      " [-0.62246405  3.82648827 -2.24370166  1.87542241 -1.71052102  1.97390106\n",
      "  -3.35808318  0.40182785 -1.40682829 -2.49888904]\n",
      " [ 0.27294039 -2.24370166  5.61280417 -1.28352595  1.56224992 -2.07016922\n",
      "   3.36625467  0.09564026  1.25407829  2.62287949]\n",
      " [-0.57435333  1.87542241 -1.28352595  3.18906076 -1.076052    1.2163983\n",
      "  -2.10006703  0.33212831 -0.83740956 -1.90426986]\n",
      " [-0.31860491 -1.71052102  1.56224992 -1.076052    4.27705504 -1.04749114\n",
      "   2.94480793 -0.60928281  0.35463639  1.83581164]\n",
      " [-0.59715015  1.97390106 -2.07016922  1.2163983  -1.04749114  3.43048409\n",
      "  -2.93980011  0.40600618 -1.50558611 -1.67545841]\n",
      " [ 1.6721815  -3.35808318  3.36625467 -2.10006703  2.94480793 -2.93980011\n",
      "   9.98604723 -0.04384227  1.45459679  3.87887126]\n",
      " [ 0.05190364  0.40182785  0.09564026  0.33212831 -0.60928281  0.40600618\n",
      "  -0.04384227  2.62366156 -0.01667344 -0.92882684]\n",
      " [ 0.21833507 -1.40682829  1.25407829 -0.83740956  0.35463639 -1.50558611\n",
      "   1.45459679 -0.01667344  3.25879043  0.82924391]\n",
      " [ 1.12800809 -2.49888904  2.62287949 -1.90426986  1.83581164 -1.67545841\n",
      "   3.87887126 -0.92882684  0.82924391  5.28026841]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:53<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 222 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    983.152\n",
      "w[1]   -101.693\n",
      "w[2]    -65.131\n",
      "w[3]    -89.852\n",
      "w[4]    -88.941\n",
      "w[5]    -10.694\n",
      "w[6]    133.790\n",
      "w[7]    -22.720\n",
      "w[8]    -12.487\n",
      "w[9]     89.096\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.82046523 -0.64592371  0.29845121 -0.59679323 -0.26765009 -0.63378748\n",
      "   1.69346504  0.04467049  0.23242395  1.13707636]\n",
      " [-0.64592371  3.93275174 -2.35238159  1.97816273 -1.82565691  2.05828906\n",
      "  -3.52945368  0.41452397 -1.46133803 -2.61625901]\n",
      " [ 0.29845121 -2.35238159  5.7099228  -1.41164789  1.69719237 -2.16957721\n",
      "   3.588756    0.09938937  1.31869258  2.76078694]\n",
      " [-0.59679323  1.97816273 -1.41164789  3.24067195 -1.17401754  1.32524596\n",
      "  -2.2441081   0.35466663 -0.88453661 -2.01660563]\n",
      " [-0.26765009 -1.82565691  1.69719237 -1.17401754  4.39190331 -1.14708346\n",
      "   3.10910333 -0.63640249  0.39149576  1.99025707]\n",
      " [-0.63378748  2.05828906 -2.16957721  1.32524596 -1.14708346  3.48554702\n",
      "  -3.08361082  0.39864903 -1.54494295 -1.78730793]\n",
      " [ 1.69346504 -3.52945368  3.588756   -2.2441081   3.10910333 -3.08361082\n",
      "  10.27133852 -0.05611296  1.54952647  4.08669304]\n",
      " [ 0.04467049  0.41452397  0.09938937  0.35466663 -0.63640249  0.39864903\n",
      "  -0.05611296  2.61661538 -0.01390978 -0.96768872]\n",
      " [ 0.23242395 -1.46133803  1.31869258 -0.88453661  0.39149576 -1.54494295\n",
      "   1.54952647 -0.01390978  3.28213177  0.89758979]\n",
      " [ 1.13707636 -2.61625901  2.76078694 -2.01660563  1.99025707 -1.78730793\n",
      "   4.08669304 -0.96768872  0.89758979  5.41865346]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:54<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 196 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    985.624\n",
      "w[1]   -102.606\n",
      "w[2]    -64.818\n",
      "w[3]    -90.625\n",
      "w[4]    -89.093\n",
      "w[5]    -11.385\n",
      "w[6]    135.588\n",
      "w[7]    -22.715\n",
      "w[8]    -12.189\n",
      "w[9]     90.262\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.83269341 -0.6257054   0.30790342 -0.59793189 -0.27812466 -0.64427633\n",
      "   1.68989321  0.04816043  0.23852533  1.1223681 ]\n",
      " [-0.6257054   4.03984208 -2.4804823   2.03335367 -1.93607815  2.16488494\n",
      "  -3.68998622  0.45514969 -1.51260867 -2.75162475]\n",
      " [ 0.30790342 -2.4804823   5.82454636 -1.51336615  1.82568411 -2.28746229\n",
      "   3.82919306  0.03123431  1.36606824  2.95783337]\n",
      " [-0.59793189  2.03335367 -1.51336615  3.25290429 -1.25903677  1.40820726\n",
      "  -2.36572861  0.38153062 -0.92443652 -2.11811518]\n",
      " [-0.27812466 -1.93607815  1.82568411 -1.25903677  4.49551704 -1.25841912\n",
      "   3.28313951 -0.66490177  0.44094932  2.13253625]\n",
      " [-0.64427633  2.16488494 -2.28746229  1.40820726 -1.25841912  3.57107979\n",
      "  -3.25621335  0.46111194 -1.58441339 -1.92962437]\n",
      " [ 1.68989321 -3.68998622  3.82919306 -2.36572861  3.28313951 -3.25621335\n",
      "  10.51002167 -0.10412999  1.62108708  4.29774071]\n",
      " [ 0.04816043  0.45514969  0.03123431  0.38153062 -0.66490177  0.46111194\n",
      "  -0.10412999  2.59305803 -0.06016057 -1.00140385]\n",
      " [ 0.23852533 -1.51260867  1.36606824 -0.92443652  0.44094932 -1.58441339\n",
      "   1.62108708 -0.06016057  3.29138397  0.98253405]\n",
      " [ 1.1223681  -2.75162475  2.95783337 -2.11811518  2.13253625 -1.92962437\n",
      "   4.29774071 -1.00140385  0.98253405  5.58796364]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:55<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 198 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    988.107\n",
      "w[1]   -103.511\n",
      "w[2]    -64.493\n",
      "w[3]    -91.401\n",
      "w[4]    -89.237\n",
      "w[5]    -12.090\n",
      "w[6]    137.396\n",
      "w[7]    -22.720\n",
      "w[8]    -11.877\n",
      "w[9]     91.430\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.81566515e+00 -6.56403976e-01  3.34357389e-01 -6.36509527e-01\n",
      "  -2.35166587e-01 -6.75074198e-01  1.76169576e+00  4.43372641e-02\n",
      "   2.57707316e-01  1.17120673e+00]\n",
      " [-6.56403976e-01  4.21714745e+00 -2.68206108e+00  2.16442229e+00\n",
      "  -2.08153703e+00  2.29371209e+00 -3.93417861e+00  4.93493721e-01\n",
      "  -1.59064250e+00 -2.94105329e+00]\n",
      " [ 3.34357389e-01 -2.68206108e+00  5.98620709e+00 -1.65876500e+00\n",
      "   1.97795451e+00 -2.45019709e+00  4.09220890e+00 -2.46416815e-03\n",
      "   1.46439051e+00  3.13688210e+00]\n",
      " [-6.36509527e-01  2.16442229e+00 -1.65876500e+00  3.31289661e+00\n",
      "  -1.35931992e+00  1.50194079e+00 -2.57147350e+00  4.12413615e-01\n",
      "  -1.00691247e+00 -2.27698789e+00]\n",
      " [-2.35166587e-01 -2.08153703e+00  1.97795451e+00 -1.35931992e+00\n",
      "   4.60613175e+00 -1.36301401e+00  3.47052973e+00 -7.15794008e-01\n",
      "   4.88771167e-01  2.28358767e+00]\n",
      " [-6.75074198e-01  2.29371209e+00 -2.45019709e+00  1.50194079e+00\n",
      "  -1.36301401e+00  3.67998246e+00 -3.47388710e+00  4.78307537e-01\n",
      "  -1.64249026e+00 -2.05785120e+00]\n",
      " [ 1.76169576e+00 -3.93417861e+00  4.09220890e+00 -2.57147350e+00\n",
      "   3.47052973e+00 -3.47388710e+00  1.09209602e+01 -1.81201124e-01\n",
      "   1.74017996e+00  4.60942049e+00]\n",
      " [ 4.43372641e-02  4.93493721e-01 -2.46416815e-03  4.12413615e-01\n",
      "  -7.15794008e-01  4.78307537e-01 -1.81201124e-01  2.53758013e+00\n",
      "  -5.92024646e-02 -1.04112786e+00]\n",
      " [ 2.57707316e-01 -1.59064250e+00  1.46439051e+00 -1.00691247e+00\n",
      "   4.88771167e-01 -1.64249026e+00  1.74017996e+00 -5.92024646e-02\n",
      "   3.30095287e+00  1.08906691e+00]\n",
      " [ 1.17120673e+00 -2.94105329e+00  3.13688210e+00 -2.27698789e+00\n",
      "   2.28358767e+00 -2.05785120e+00  4.60942049e+00 -1.04112786e+00\n",
      "   1.08906691e+00  5.78717287e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:58<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 221 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    990.572\n",
      "w[1]   -104.459\n",
      "w[2]    -64.115\n",
      "w[3]    -92.222\n",
      "w[4]    -89.336\n",
      "w[5]    -12.844\n",
      "w[6]    139.279\n",
      "w[7]    -22.734\n",
      "w[8]    -11.547\n",
      "w[9]     92.665\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.81228161 -0.71239675  0.40006753 -0.66935782 -0.19060958 -0.71566954\n",
      "   1.83747426  0.04832673  0.28626387  1.24161428]\n",
      " [-0.71239675  4.42610076 -2.90711211  2.29878187 -2.23926657  2.4449102\n",
      "  -4.19185931  0.52923331 -1.68329785 -3.13485487]\n",
      " [ 0.40006753 -2.90711211  6.14671622 -1.80869972  2.14939228 -2.59941025\n",
      "   4.44338376 -0.03090729  1.55700421  3.33872213]\n",
      " [-0.66935782  2.29878187 -1.80869972  3.38061172 -1.478224    1.61859018\n",
      "  -2.76556865  0.43106636 -1.06956602 -2.42232738]\n",
      " [-0.19060958 -2.23926657  2.14939228 -1.478224    4.73506621 -1.46135284\n",
      "   3.66503919 -0.76442881  0.53362379  2.47528346]\n",
      " [-0.71566954  2.4449102  -2.59941025  1.61859018 -1.46135284  3.7773968\n",
      "  -3.628512    0.51600326 -1.71982446 -2.23276469]\n",
      " [ 1.83747426 -4.19185931  4.44338376 -2.76556865  3.66503919 -3.628512\n",
      "  11.23740457 -0.23687155  1.88037162  4.91311631]\n",
      " [ 0.04832673  0.52923331 -0.03090729  0.43106636 -0.76442881  0.51600326\n",
      "  -0.23687155  2.53612148 -0.08066418 -1.06132127]\n",
      " [ 0.28626387 -1.68329785  1.55700421 -1.06956602  0.53362379 -1.71982446\n",
      "   1.88037162 -0.08066418  3.35429577  1.18487773]\n",
      " [ 1.24161428 -3.13485487  3.33872213 -2.42232738  2.47528346 -2.23276469\n",
      "   4.91311631 -1.06132127  1.18487773  6.01935742]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:55<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 208 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    993.059\n",
      "w[1]   -105.493\n",
      "w[2]    -63.632\n",
      "w[3]    -93.093\n",
      "w[4]    -89.376\n",
      "w[5]    -13.664\n",
      "w[6]    141.272\n",
      "w[7]    -22.733\n",
      "w[8]    -11.161\n",
      "w[9]     93.993\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.80069999 -0.79683352  0.47675527 -0.7177321  -0.1079453  -0.7621472\n",
      "   1.9477623   0.02342335  0.3191793   1.33452386]\n",
      " [-0.79683352  4.68305341 -3.16871321  2.49233567 -2.44655821  2.65289297\n",
      "  -4.54451295  0.5708629  -1.79733298 -3.3888533 ]\n",
      " [ 0.47675527 -3.16871321  6.40630586 -2.03355999  2.37955267 -2.84344471\n",
      "   4.88711909 -0.09902693  1.69592426  3.60508214]\n",
      " [-0.7177321   2.49233567 -2.03355999  3.48905537 -1.64989012  1.77523336\n",
      "  -3.0743538   0.45676617 -1.14496042 -2.63534144]\n",
      " [-0.1079453  -2.44655821  2.37955267 -1.64989012  4.85272384 -1.64670371\n",
      "   3.97757232 -0.77250798  0.62126894  2.69873703]\n",
      " [-0.7621472   2.65289297 -2.84344471  1.77523336 -1.64670371  3.9466091\n",
      "  -3.94313845  0.56418    -1.80191637 -2.4511296 ]\n",
      " [ 1.9477623  -4.54451295  4.88711909 -3.0743538   3.97757232 -3.94313845\n",
      "  11.72534027 -0.30864416  2.02030522  5.33036459]\n",
      " [ 0.02342335  0.5708629  -0.09902693  0.45676617 -0.77250798  0.56418\n",
      "  -0.30864416  2.49919347 -0.13235161 -1.10955616]\n",
      " [ 0.3191793  -1.79733298  1.69592426 -1.14496042  0.62126894 -1.80191637\n",
      "   2.02030522 -0.13235161  3.3977605   1.2969616 ]\n",
      " [ 1.33452386 -3.3888533   3.60508214 -2.63534144  2.69873703 -2.4511296\n",
      "   5.33036459 -1.10955616  1.2969616   6.30640353]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:59<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 203 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    995.525\n",
      "w[1]   -106.600\n",
      "w[2]    -63.093\n",
      "w[3]    -94.006\n",
      "w[4]    -89.328\n",
      "w[5]    -14.521\n",
      "w[6]    143.364\n",
      "w[7]    -22.769\n",
      "w[8]    -10.751\n",
      "w[9]     95.413\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.8027721  -0.8534515   0.52904817 -0.77967263 -0.05520763 -0.80345191\n",
      "   2.05572204  0.04986079  0.3178846   1.40078545]\n",
      " [-0.8534515   4.84641383 -3.3439945   2.61183381 -2.56370342  2.82280598\n",
      "  -4.79181835  0.59574419 -1.89852095 -3.58322081]\n",
      " [ 0.52904817 -3.3439945   6.55238104 -2.17924036  2.49472838 -2.99308786\n",
      "   5.14133012 -0.11964421  1.81264299  3.76591294]\n",
      " [-0.77967263  2.61183381 -2.17924036  3.56352274 -1.73455897  1.90933589\n",
      "  -3.28742477  0.4762815  -1.20217566 -2.7835607 ]\n",
      " [-0.05520763 -2.56370342  2.49472838 -1.73455897  4.92755039 -1.78712098\n",
      "   4.17592136 -0.77360698  0.71536256  2.82254689]\n",
      " [-0.80345191  2.82280598 -2.99308786  1.90933589 -1.78712098  4.06792733\n",
      "  -4.18666224  0.59055518 -1.88794839 -2.64920765]\n",
      " [ 2.05572204 -4.79181835  5.14133012 -3.28742477  4.17592136 -4.18666224\n",
      "  12.20942676 -0.32244778  2.16169904  5.6578714 ]\n",
      " [ 0.04986079  0.59574419 -0.11964421  0.4762815  -0.77360698  0.59055518\n",
      "  -0.32244778  2.48171228 -0.15424266 -1.12614415]\n",
      " [ 0.3178846  -1.89852095  1.81264299 -1.20217566  0.71536256 -1.88794839\n",
      "   2.16169904 -0.15424266  3.45390639  1.42118299]\n",
      " [ 1.40078545 -3.58322081  3.76591294 -2.7835607   2.82254689 -2.64920765\n",
      "   5.6578714  -1.12614415  1.42118299  6.51210865]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:57<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 215 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    997.987\n",
      "w[1]   -107.758\n",
      "w[2]    -62.497\n",
      "w[3]    -94.977\n",
      "w[4]    -89.239\n",
      "w[5]    -15.430\n",
      "w[6]    145.551\n",
      "w[7]    -22.770\n",
      "w[8]    -10.346\n",
      "w[9]     96.891\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.78971257 -0.95587303  0.63081943 -0.83713829  0.04299045 -0.90181771\n",
      "   2.212482    0.0259872   0.38324959  1.48612082]\n",
      " [-0.95587303  5.16109216 -3.65418314  2.88642713 -2.82571431  3.09713406\n",
      "  -5.28796531  0.67242228 -2.08748782 -3.92777889]\n",
      " [ 0.63081943 -3.65418314  6.7938501  -2.42341969  2.7422959  -3.25605668\n",
      "   5.60430913 -0.19719106  1.98024119  4.08013558]\n",
      " [-0.83713829  2.88642713 -2.42341969  3.74200051 -1.94389266  2.11975863\n",
      "  -3.66772329  0.53709313 -1.35761209 -3.05899301]\n",
      " [ 0.04299045 -2.82571431  2.7422959  -1.94389266  5.09187127 -1.98577895\n",
      "   4.53776528 -0.82229657  0.85473175  3.10494124]\n",
      " [-0.90181771  3.09713406 -3.25605668  2.11975863 -1.98577895  4.29047878\n",
      "  -4.57591948  0.63335252 -2.03475921 -2.91844739]\n",
      " [ 2.212482   -5.28796531  5.60430913 -3.66772329  4.53776528 -4.57591948\n",
      "  12.85470358 -0.43685618  2.4570479   6.14850031]\n",
      " [ 0.0259872   0.67242228 -0.19719106  0.53709313 -0.82229657  0.63335252\n",
      "  -0.43685618  2.44597779 -0.19274602 -1.19800485]\n",
      " [ 0.38324959 -2.08748782  1.98024119 -1.35761209  0.85473175 -2.03475921\n",
      "   2.4570479  -0.19274602  3.53410715  1.60867293]\n",
      " [ 1.48612082 -3.92777889  4.08013558 -3.05899301  3.10494124 -2.91844739\n",
      "   6.14850031 -1.19800485  1.60867293  6.85818898]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:21<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 244 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1000.446\n",
      "w[1]    -109.008\n",
      "w[2]     -61.814\n",
      "w[3]     -95.994\n",
      "w[4]     -89.056\n",
      "w[5]     -16.421\n",
      "w[6]     147.883\n",
      "w[7]     -22.802\n",
      "w[8]      -9.882\n",
      "w[9]      98.425\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.76230798e+00 -1.03938442e+00  7.43415246e-01 -9.01569745e-01\n",
      "   1.20139435e-01 -9.79945242e-01  2.34797508e+00  8.55770251e-03\n",
      "   4.28222004e-01  1.57430194e+00]\n",
      " [-1.03938442e+00  5.52623410e+00 -4.02851693e+00  3.16707803e+00\n",
      "  -3.08158497e+00  3.37526121e+00 -5.83005182e+00  7.45670331e-01\n",
      "  -2.28550251e+00 -4.30029926e+00]\n",
      " [ 7.43415246e-01 -4.02851693e+00  7.15552000e+00 -2.69433803e+00\n",
      "   2.98906633e+00 -3.57073993e+00  6.14232303e+00 -2.87907921e-01\n",
      "   2.18408016e+00  4.46392540e+00]\n",
      " [-9.01569745e-01  3.16707803e+00 -2.69433803e+00  3.91414290e+00\n",
      "  -2.15614239e+00  2.32198443e+00 -4.09575070e+00  5.78184271e-01\n",
      "  -1.49396463e+00 -3.33861766e+00]\n",
      " [ 1.20139435e-01 -3.08158497e+00  2.98906633e+00 -2.15614239e+00\n",
      "   5.26833638e+00 -2.17497579e+00  4.96523720e+00 -8.83014625e-01\n",
      "   1.00501094e+00  3.39054294e+00]\n",
      " [-9.79945242e-01  3.37526121e+00 -3.57073993e+00  2.32198443e+00\n",
      "  -2.17497579e+00  4.50800952e+00 -4.97586873e+00  6.79075092e-01\n",
      "  -2.20381665e+00 -3.22346460e+00]\n",
      " [ 2.34797508e+00 -5.83005182e+00  6.14232303e+00 -4.09575070e+00\n",
      "   4.96523720e+00 -4.97586873e+00  1.36580591e+01 -5.72982581e-01\n",
      "   2.76807659e+00  6.75589782e+00]\n",
      " [ 8.55770251e-03  7.45670331e-01 -2.87907921e-01  5.78184271e-01\n",
      "  -8.83014625e-01  6.79075092e-01 -5.72982581e-01  2.41794826e+00\n",
      "  -2.37248536e-01 -1.27591189e+00]\n",
      " [ 4.28222004e-01 -2.28550251e+00  2.18408016e+00 -1.49396463e+00\n",
      "   1.00501094e+00 -2.20381665e+00  2.76807659e+00 -2.37248536e-01\n",
      "   3.62225073e+00  1.82283809e+00]\n",
      " [ 1.57430194e+00 -4.30029926e+00  4.46392540e+00 -3.33861766e+00\n",
      "   3.39054294e+00 -3.22346460e+00  6.75589782e+00 -1.27591189e+00\n",
      "   1.82283809e+00  7.26341342e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:20<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 272 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1002.898\n",
      "w[1]    -110.393\n",
      "w[2]     -60.963\n",
      "w[3]     -97.118\n",
      "w[4]     -88.763\n",
      "w[5]     -17.520\n",
      "w[6]     150.436\n",
      "w[7]     -22.854\n",
      "w[8]      -9.348\n",
      "w[9]     100.111\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.76565329e+00 -1.17901552e+00  9.20012733e-01 -9.95869527e-01\n",
      "   2.12205611e-01 -1.10303744e+00  2.51572324e+00  4.69771417e-04\n",
      "   5.14368865e-01  1.70579048e+00]\n",
      " [-1.17901552e+00  5.83602647e+00 -4.33153636e+00  3.42755954e+00\n",
      "  -3.27113929e+00  3.64902788e+00 -6.28817769e+00  7.69422740e-01\n",
      "  -2.46623369e+00 -4.62215796e+00]\n",
      " [ 9.20012733e-01 -4.33153636e+00  7.46346499e+00 -2.96371346e+00\n",
      "   3.19750234e+00 -3.84601044e+00  6.61522610e+00 -3.23437995e-01\n",
      "   2.38634482e+00  4.81412351e+00]\n",
      " [-9.95869527e-01  3.42755954e+00 -2.96371346e+00  4.11895155e+00\n",
      "  -2.33278359e+00  2.52719234e+00 -4.45027777e+00  5.87453565e-01\n",
      "  -1.65228979e+00 -3.58535675e+00]\n",
      " [ 2.12205611e-01 -3.27113929e+00  3.19750234e+00 -2.33278359e+00\n",
      "   5.35053073e+00 -2.35463157e+00  5.24956895e+00 -9.10492012e-01\n",
      "   1.08277744e+00  3.63261968e+00]\n",
      " [-1.10303744e+00  3.64902788e+00 -3.84601044e+00  2.52719234e+00\n",
      "  -2.35463157e+00  4.71779296e+00 -5.36121732e+00  6.94327463e-01\n",
      "  -2.35325744e+00 -3.47885840e+00]\n",
      " [ 2.51572324e+00 -6.28817769e+00  6.61522610e+00 -4.45027777e+00\n",
      "   5.24956895e+00 -5.36121732e+00  1.42788499e+01 -6.37857015e-01\n",
      "   3.00557403e+00  7.23925370e+00]\n",
      " [ 4.69771417e-04  7.69422740e-01 -3.23437995e-01  5.87453565e-01\n",
      "  -9.10492012e-01  6.94327463e-01 -6.37857015e-01  2.43734284e+00\n",
      "  -2.43346476e-01 -1.32018236e+00]\n",
      " [ 5.14368865e-01 -2.46623369e+00  2.38634482e+00 -1.65228979e+00\n",
      "   1.08277744e+00 -2.35325744e+00  3.00557403e+00 -2.43346476e-01\n",
      "   3.70032922e+00  1.99942250e+00]\n",
      " [ 1.70579048e+00 -4.62215796e+00  4.81412351e+00 -3.58535675e+00\n",
      "   3.63261968e+00 -3.47885840e+00  7.23925370e+00 -1.32018236e+00\n",
      "   1.99942250e+00  7.57964211e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:59<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 207 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1005.369\n",
      "w[1]    -111.941\n",
      "w[2]     -59.906\n",
      "w[3]     -98.356\n",
      "w[4]     -88.367\n",
      "w[5]     -18.761\n",
      "w[6]     153.183\n",
      "w[7]     -22.922\n",
      "w[8]      -8.707\n",
      "w[9]     101.959\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.78800952 -1.29052017  1.02551584 -1.07912408  0.28747925 -1.18409483\n",
      "   2.64347925 -0.01733377  0.55863349  1.81056049]\n",
      " [-1.29052017  6.21435256 -4.72019471  3.7245057  -3.56733735  3.97063336\n",
      "  -6.84342403  0.84928667 -2.68265071 -5.06870992]\n",
      " [ 1.02551584 -4.72019471  7.80567847 -3.28946861  3.50176109 -4.17770826\n",
      "   7.16488182 -0.41593137  2.60786063  5.2329388 ]\n",
      " [-1.07912408  3.7245057  -3.28946861  4.32577544 -2.55987824  2.79941404\n",
      "  -4.87263316  0.66077428 -1.79971558 -3.91454528]\n",
      " [ 0.28747925 -3.56733735  3.50176109 -2.55987824  5.52332623 -2.61236194\n",
      "   5.65082421 -0.99599993  1.24762593  3.97323308]\n",
      " [-1.18409483  3.97063336 -4.17770826  2.79941404 -2.61236194  4.98379948\n",
      "  -5.81198897  0.73690854 -2.51809072 -3.82501738]\n",
      " [ 2.64347925 -6.84342403  7.16488182 -4.87263316  5.65082421 -5.81198897\n",
      "  14.99787727 -0.78134672  3.31657693  7.83602865]\n",
      " [-0.01733377  0.84928667 -0.41593137  0.66077428 -0.99599993  0.73690854\n",
      "  -0.78134672  2.43520495 -0.25998219 -1.43891547]\n",
      " [ 0.55863349 -2.68265071  2.60786063 -1.79971558  1.24762593 -2.51809072\n",
      "   3.31657693 -0.25998219  3.77288345  2.20047822]\n",
      " [ 1.81056049 -5.06870992  5.2329388  -3.91454528  3.97323308 -3.82501738\n",
      "   7.83602865 -1.43891547  2.20047822  8.02669254]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:01<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 206 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1007.856\n",
      "w[1]    -113.576\n",
      "w[2]     -58.783\n",
      "w[3]     -99.652\n",
      "w[4]     -87.914\n",
      "w[5]     -20.074\n",
      "w[6]     156.008\n",
      "w[7]     -23.009\n",
      "w[8]      -8.036\n",
      "w[9]     103.881\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.81517312e+00 -1.41950041e+00  1.16827077e+00 -1.18642322e+00\n",
      "   3.95440539e-01 -1.28651661e+00  2.83872187e+00 -1.14478204e-02\n",
      "   6.39757387e-01  1.94281416e+00]\n",
      " [-1.41950041e+00  6.64779229e+00 -5.17365789e+00  4.03199279e+00\n",
      "  -3.87673432e+00  4.32066286e+00 -7.41065642e+00  9.35124387e-01\n",
      "  -2.89291846e+00 -5.52656788e+00]\n",
      " [ 1.16827077e+00 -5.17365789e+00  8.28465315e+00 -3.63353449e+00\n",
      "   3.81702229e+00 -4.55273379e+00  7.79685733e+00 -4.88624008e-01\n",
      "   2.85306101e+00  5.69112634e+00]\n",
      " [-1.18642322e+00  4.03199279e+00 -3.63353449e+00  4.53740109e+00\n",
      "  -2.81720572e+00  3.03146804e+00 -5.33021424e+00  7.32862557e-01\n",
      "  -1.96418693e+00 -4.27012723e+00]\n",
      " [ 3.95440539e-01 -3.87673432e+00  3.81702229e+00 -2.81720572e+00\n",
      "   5.74876011e+00 -2.88892518e+00  6.06301806e+00 -1.09058898e+00\n",
      "   1.39365361e+00  4.32690322e+00]\n",
      " [-1.28651661e+00  4.32066286e+00 -4.55273379e+00  3.03146804e+00\n",
      "  -2.88892518e+00  5.25677225e+00 -6.26622663e+00  7.98833465e-01\n",
      "  -2.69221365e+00 -4.18097247e+00]\n",
      " [ 2.83872187e+00 -7.41065642e+00  7.79685733e+00 -5.33021424e+00\n",
      "   6.06301806e+00 -6.26622663e+00  1.57405134e+01 -8.74482580e-01\n",
      "   3.60801238e+00  8.43293576e+00]\n",
      " [-1.14478204e-02  9.35124387e-01 -4.88624008e-01  7.32862557e-01\n",
      "  -1.09058898e+00  7.98833465e-01 -8.74482580e-01  2.47654963e+00\n",
      "  -2.81192989e-01 -1.54287846e+00]\n",
      " [ 6.39757387e-01 -2.89291846e+00  2.85306101e+00 -1.96418693e+00\n",
      "   1.39365361e+00 -2.69221365e+00  3.60801238e+00 -2.81192989e-01\n",
      "   3.87852324e+00  2.42040307e+00]\n",
      " [ 1.94281416e+00 -5.52656788e+00  5.69112634e+00 -4.27012723e+00\n",
      "   4.32690322e+00 -4.18097247e+00  8.43293576e+00 -1.54287846e+00\n",
      "   2.42040307e+00  8.48907884e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:02<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 224 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1010.361\n",
      "w[1]    -115.359\n",
      "w[2]     -57.505\n",
      "w[3]    -101.059\n",
      "w[4]     -87.325\n",
      "w[5]     -21.487\n",
      "w[6]     159.067\n",
      "w[7]     -23.086\n",
      "w[8]      -7.279\n",
      "w[9]     105.956\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.84608127 -1.55427869  1.2934416  -1.27574839  0.49799416 -1.38238291\n",
      "   3.03658979 -0.0318929   0.71423521  2.06006853]\n",
      " [-1.55427869  7.12033564 -5.69578615  4.37315029 -4.24380891  4.72175553\n",
      "  -8.17450026  1.03645751 -3.14362688 -6.04408776]\n",
      " [ 1.2934416  -5.69578615  8.71731606 -4.00194227  4.21250395 -4.94330321\n",
      "   8.53608943 -0.57590126  3.12248835  6.18801037]\n",
      " [-1.27574839  4.37315029 -4.00194227  4.77825845 -3.11700631  3.33830088\n",
      "  -5.85459332  0.79431493 -2.16591072 -4.63932611]\n",
      " [ 0.49799416 -4.24380891  4.21250395 -3.11700631  6.0531034  -3.19161035\n",
      "   6.61027492 -1.18389689  1.56547368  4.72664274]\n",
      " [-1.38238291  4.72175553 -4.94330321  3.33830088 -3.19161035  5.56397389\n",
      "  -6.83559907  0.88185687 -2.88584322 -4.58849677]\n",
      " [ 3.03658979 -8.17450026  8.53608943 -5.85459332  6.61027492 -6.83559907\n",
      "  16.75703534 -1.00795845  3.98121196  9.16876442]\n",
      " [-0.0318929   1.03645751 -0.57590126  0.79431493 -1.18389689  0.88185687\n",
      "  -1.00795845  2.55190657 -0.30090657 -1.66608756]\n",
      " [ 0.71423521 -3.14362688  3.12248835 -2.16591072  1.56547368 -2.88584322\n",
      "   3.98121196 -0.30090657  4.02085926  2.67167435]\n",
      " [ 2.06006853 -6.04408776  6.18801037 -4.63932611  4.72664274 -4.58849677\n",
      "   9.16876442 -1.66608756  2.67167435  9.00802455]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:58<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 203 seconds.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1012.934\n",
      "w[1]    -117.337\n",
      "w[2]     -56.025\n",
      "w[3]    -102.604\n",
      "w[4]     -86.596\n",
      "w[5]     -23.056\n",
      "w[6]     162.417\n",
      "w[7]     -23.214\n",
      "w[8]      -6.420\n",
      "w[9]     108.224\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.87818472 -1.60979666  1.31659796 -1.31453422  0.52287585 -1.40261965\n",
      "   3.12089834 -0.01971844  0.73445318  2.12046969]\n",
      " [-1.60979666  7.3285023  -5.91318435  4.5348012  -4.42420218  4.89040696\n",
      "  -8.49839071  1.07074059 -3.28254615 -6.28471029]\n",
      " [ 1.31659796 -5.91318435  8.88887105 -4.1680357   4.39652493 -5.13147738\n",
      "   8.78033774 -0.62483851  3.2711591   6.40947132]\n",
      " [-1.31453422  4.5348012  -4.1680357   4.86416034 -3.25765723  3.49766545\n",
      "  -6.09632361  0.82613219 -2.2819339  -4.80022415]\n",
      " [ 0.52287585 -4.42420218  4.39652493 -3.25765723  6.17495355 -3.34756048\n",
      "   6.8188724  -1.27336054  1.65798732  4.91489027]\n",
      " [-1.40261965  4.89040696 -5.13147738  3.49766545 -3.34756048  5.69176323\n",
      "  -7.08149757  0.90047092 -3.01382451 -4.79651848]\n",
      " [ 3.12089834 -8.49839071  8.78033774 -6.09632361  6.8188724  -7.08149757\n",
      "  17.18029571 -1.08030734  4.16957549  9.49286677]\n",
      " [-0.01971844  1.07074059 -0.62483851  0.82613219 -1.27336054  0.90047092\n",
      "  -1.08030734  2.60013699 -0.28488242 -1.72731697]\n",
      " [ 0.73445318 -3.28254615  3.2711591  -2.2819339   1.65798732 -3.01382451\n",
      "   4.16957549 -0.28488242  4.11824738  2.78347064]\n",
      " [ 2.12046969 -6.28471029  6.40947132 -4.80022415  4.91489027 -4.79651848\n",
      "   9.49286677 -1.72731697  2.78347064  9.22885145]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:04<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 208 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1015.529\n",
      "w[1]    -119.339\n",
      "w[2]     -54.544\n",
      "w[3]    -104.171\n",
      "w[4]     -85.851\n",
      "w[5]     -24.627\n",
      "w[6]     165.828\n",
      "w[7]     -23.313\n",
      "w[8]      -5.544\n",
      "w[9]     110.532\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.92324217 -1.75360019  1.44076399 -1.42371167  0.62415927 -1.52670281\n",
      "   3.33412813 -0.01886456  0.81429028  2.24264714]\n",
      " [-1.75360019  7.78294393 -6.35449507  4.876043   -4.76817984  5.27304542\n",
      "  -9.18162556  1.15761699 -3.51849402 -6.79252071]\n",
      " [ 1.44076399 -6.35449507  9.30625662 -4.51658958  4.74348282 -5.5070188\n",
      "   9.39720331 -0.71533766  3.51313926  6.8774214 ]\n",
      " [-1.42371167  4.876043   -4.51658958  5.09601839 -3.55832387  3.80880313\n",
      "  -6.6489662   0.91124605 -2.44532826 -5.18471829]\n",
      " [ 0.62415927 -4.76817984  4.74348282 -3.55832387  6.45317736 -3.63647674\n",
      "   7.36675137 -1.38296999  1.8200174   5.35725372]\n",
      " [-1.52670281  5.27304542 -5.5070188   3.80880313 -3.63647674  6.03144384\n",
      "  -7.68473525  0.9651177  -3.2215479  -5.24283177]\n",
      " [ 3.33412813 -9.18162556  9.39720331 -6.6489662   7.36675137 -7.68473525\n",
      "  18.22622549 -1.21218628  4.50095535 10.21991978]\n",
      " [-0.01886456  1.15761699 -0.71533766  0.91124605 -1.38296999  0.9651177\n",
      "  -1.21218628  2.64265018 -0.31140868 -1.84533515]\n",
      " [ 0.81429028 -3.51849402  3.51313926 -2.44532826  1.8200174  -3.2215479\n",
      "   4.50095535 -0.31140868  4.24624084  3.01508158]\n",
      " [ 2.24264714 -6.79252071  6.8774214  -5.18471829  5.35725372 -5.24283177\n",
      "  10.21991978 -1.84533515  3.01508158  9.75512907]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:01<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 221 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1018.177\n",
      "w[1]    -121.503\n",
      "w[2]     -52.920\n",
      "w[3]    -105.842\n",
      "w[4]     -85.004\n",
      "w[5]     -26.344\n",
      "w[6]     169.466\n",
      "w[7]     -23.418\n",
      "w[8]      -4.578\n",
      "w[9]     112.984\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.98626212 -1.91349568  1.5947324  -1.53812836  0.75142004 -1.6522985\n",
      "   3.57488614 -0.02572025  0.88871049  2.4163524 ]\n",
      " [-1.91349568  8.18257661 -6.75932978  5.20220127 -5.06662762  5.62069632\n",
      "  -9.75179255  1.25886839 -3.7539582  -7.24073478]\n",
      " [ 1.5947324  -6.75932978  9.69925848 -4.84400445  5.02371745 -5.86607718\n",
      "   9.96197317 -0.80112443  3.71747619  7.31570902]\n",
      " [-1.53812836  5.20220127 -4.84400445  5.33011014 -3.77531677  4.07577867\n",
      "  -7.09919105  0.9856049  -2.63144807 -5.53318439]\n",
      " [ 0.75142004 -5.06662762  5.02371745 -3.77531677  6.58406185 -3.89824139\n",
      "   7.73585745 -1.48583262  1.98061254  5.66829809]\n",
      " [-1.6522985   5.62069632 -5.86607718  4.07577867 -3.89824139  6.30387588\n",
      "  -8.1555539   1.0478192  -3.42033549 -5.62427848]\n",
      " [ 3.57488614 -9.75179255  9.96197317 -7.09919105  7.73585745 -8.1555539\n",
      "  19.03315675 -1.33353254  4.83526173 10.86026198]\n",
      " [-0.02572025  1.25886839 -0.80112443  0.9856049  -1.48583262  1.0478192\n",
      "  -1.33353254  2.74660363 -0.33802474 -1.97416896]\n",
      " [ 0.88871049 -3.7539582   3.71747619 -2.63144807  1.98061254 -3.42033549\n",
      "   4.83526173 -0.33802474  4.38348165  3.23973947]\n",
      " [ 2.4163524  -7.24073478  7.31570902 -5.53318439  5.66829809 -5.62427848\n",
      "  10.86026198 -1.97416896  3.23973947 10.2417837 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:04<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 227 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1020.865\n",
      "w[1]    -123.822\n",
      "w[2]     -51.139\n",
      "w[3]    -107.631\n",
      "w[4]     -84.020\n",
      "w[5]     -28.182\n",
      "w[6]     173.326\n",
      "w[7]     -23.541\n",
      "w[8]      -3.530\n",
      "w[9]     115.595\n",
      "Name: mean, dtype: float64\n",
      "[[  3.05401706  -2.09336061   1.73964232  -1.67558819   0.85433046\n",
      "   -1.78442267   3.80799174  -0.02255875   0.98629042   2.58251633]\n",
      " [ -2.09336061   8.68040682  -7.26380758   5.58070761  -5.43882404\n",
      "    6.00148707 -10.44643542   1.34884763  -3.99504772  -7.77527724]\n",
      " [  1.73964232  -7.26380758  10.24650205  -5.25045685   5.40369309\n",
      "   -6.28666655  10.67554448  -0.89842178   3.9855775    7.87474947]\n",
      " [ -1.67558819   5.58070761  -5.25045685   5.62227801  -4.0820584\n",
      "    4.37860072  -7.66272339   1.04828513  -2.81366089  -5.96278664]\n",
      " [  0.85433046  -5.43882404   5.40369309  -4.0820584    6.849404\n",
      "   -4.1931353    8.2504433   -1.60553681   2.17964085   6.07786295]\n",
      " [ -1.78442267   6.00148707  -6.28666655   4.37860072  -4.1931353\n",
      "    6.57303341  -8.69114909   1.11129647  -3.61074928  -6.05937279]\n",
      " [  3.80799174 -10.44643542  10.67554448  -7.66272339   8.2504433\n",
      "   -8.69114909  20.0107595   -1.47700848   5.20987249  11.64895609]\n",
      " [ -0.02255875   1.34884763  -0.89842178   1.04828513  -1.60553681\n",
      "    1.11129647  -1.47700848   2.76358157  -0.36360999  -2.07376525]\n",
      " [  0.98629042  -3.99504772   3.9855775   -2.81366089   2.17964085\n",
      "   -3.61074928   5.20987249  -0.36360999   4.48252033   3.51738797]\n",
      " [  2.58251633  -7.77527724   7.87474947  -5.96278664   6.07786295\n",
      "   -6.05937279  11.64895609  -2.07376525   3.51738797  10.81671982]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:01<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 235 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1023.649\n",
      "w[1]    -126.382\n",
      "w[2]     -49.153\n",
      "w[3]    -109.610\n",
      "w[4]     -82.891\n",
      "w[5]     -30.202\n",
      "w[6]     177.507\n",
      "w[7]     -23.684\n",
      "w[8]      -2.358\n",
      "w[9]     118.449\n",
      "Name: mean, dtype: float64\n",
      "[[  3.14584376  -2.35499114   2.02581455  -1.87496193   1.03858664\n",
      "   -2.00662151   4.21355322  -0.06042221   1.11440533   2.86702723]\n",
      " [ -2.35499114   9.43636179  -8.06202253   6.14306666  -6.02874899\n",
      "    6.63266753 -11.63082283   1.52111333  -4.3705066   -8.61814425]\n",
      " [  2.02581455  -8.06202253  11.03512678  -5.84870558   5.99387196\n",
      "   -6.96889678  11.86489434  -1.06853726   4.41978334   8.73957001]\n",
      " [ -1.87496193   6.14306666  -5.84870558   6.04009343  -4.54251077\n",
      "    4.84047622  -8.53646392   1.17401825  -3.06985829  -6.60266277]\n",
      " [  1.03858664  -6.02874899   5.99387196  -4.54251077   7.31456778\n",
      "   -4.68292189   9.12927702  -1.76288974   2.48389688   6.71901433]\n",
      " [ -2.00662151   6.63266753  -6.96889678   4.84047622  -4.68292189\n",
      "    7.07247803  -9.6543953    1.23701784  -3.93067082  -6.76282601]\n",
      " [  4.21355322 -11.63082283  11.86489434  -8.53646392   9.12927702\n",
      "   -9.6543953   21.73886348  -1.72592673   5.80276256  12.89803863]\n",
      " [ -0.06042221   1.52111333  -1.06853726   1.17401825  -1.76288974\n",
      "    1.23701784  -1.72592673   2.84897342  -0.40906263  -2.29349949]\n",
      " [  1.11440533  -4.3705066    4.41978334  -3.06985829   2.48389688\n",
      "   -3.93067082   5.80276256  -0.40906263   4.66341148   3.93076701]\n",
      " [  2.86702723  -8.61814425   8.73957001  -6.60266277   6.71901433\n",
      "   -6.76282601  12.89803863  -2.29349949   3.93076701  11.75570942]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:01<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 207 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1026.533\n",
      "w[1]    -129.222\n",
      "w[2]     -46.847\n",
      "w[3]    -111.791\n",
      "w[4]     -81.554\n",
      "w[5]     -32.449\n",
      "w[6]     182.134\n",
      "w[7]     -23.867\n",
      "w[8]      -1.057\n",
      "w[9]     121.611\n",
      "Name: mean, dtype: float64\n",
      "[[  3.18358074  -2.52868983   2.21125802  -1.99962216   1.14017641\n",
      "   -2.14555875   4.45761008  -0.04794097   1.20449113   3.03400369]\n",
      " [ -2.52868983   9.96706129  -8.6310584    6.54298967  -6.41766605\n",
      "    7.0805276  -12.43670928   1.60960109  -4.67146428  -9.22864806]\n",
      " [  2.21125802  -8.6310584   11.62081855  -6.2532898    6.43403106\n",
      "   -7.44712605  12.75080981  -1.19428591   4.76212866   9.38717944]\n",
      " [ -1.99962216   6.54298967  -6.2532898    6.31707617  -4.83621432\n",
      "    5.18002287  -9.15195326   1.24103312  -3.29897616  -7.02604077]\n",
      " [  1.14017641  -6.41766605   6.43403106  -4.83621432   7.61403053\n",
      "   -5.01417632   9.71469249  -1.87714973   2.68514903   7.17087783]\n",
      " [ -2.14555875   7.0805276   -7.44712605   5.18002287  -5.01417632\n",
      "    7.44051729 -10.31155072   1.30660032  -4.18208875  -7.26635354]\n",
      " [  4.45761008 -12.43670928  12.75080981  -9.15195326   9.71469249\n",
      "  -10.31155072  22.92166964  -1.85043572   6.23565098  13.77758093]\n",
      " [ -0.04794097   1.60960109  -1.19428591   1.24103312  -1.87714973\n",
      "    1.30660032  -1.85043572   2.90690811  -0.45439556  -2.40725717]\n",
      " [  1.20449113  -4.67146428   4.76212866  -3.29897616   2.68514903\n",
      "   -4.18208875   6.23565098  -0.45439556   4.82309647   4.25832961]\n",
      " [  3.03400369  -9.22864806   9.38717944  -7.02604077   7.17087783\n",
      "   -7.26635354  13.77758093  -2.40725717   4.25832961  12.42516327]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:02<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 208 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1029.436\n",
      "w[1]    -132.143\n",
      "w[2]     -44.449\n",
      "w[3]    -114.039\n",
      "w[4]     -80.167\n",
      "w[5]     -34.781\n",
      "w[6]     186.900\n",
      "w[7]     -24.031\n",
      "w[8]       0.286\n",
      "w[9]     124.853\n",
      "Name: mean, dtype: float64\n",
      "[[  3.29041497  -2.84646033   2.52532262  -2.24653312   1.33357779\n",
      "   -2.4140755    4.91238277  -0.03852109   1.39759092   3.3426876 ]\n",
      " [ -2.84646033  10.85895246  -9.48680993   7.20197153  -7.00702612\n",
      "    7.81519091 -13.65389915   1.7152097   -5.15866229 -10.16376542]\n",
      " [  2.52532262  -9.48680993  12.42844804  -6.90566642   6.99242545\n",
      "   -8.16508947  13.96363967  -1.27999141   5.26466481  10.25923326]\n",
      " [ -2.24653312   7.20197153  -6.90566642   6.7937628   -5.26459531\n",
      "    5.7302372  -10.08162646   1.30592639  -3.66827317  -7.71865517]\n",
      " [  1.33357779  -7.00702612   6.99242545  -5.26459531   7.98660942\n",
      "   -5.52576679  10.51321319  -1.96824547   2.97034983   7.76763792]\n",
      " [ -2.4140755    7.81519091  -8.16508947   5.7302372   -5.52576679\n",
      "    8.01301923 -11.35372638   1.37345061  -4.59074536  -8.02751751]\n",
      " [  4.91238277 -13.65389915  13.96363967 -10.08162646  10.51321319\n",
      "  -11.35372638  24.61340776  -1.97111997   6.89140783  15.01430746]\n",
      " [ -0.03852109   1.7152097   -1.27999141   1.30592639  -1.96824547\n",
      "    1.37345061  -1.97111997   2.93989694  -0.49279393  -2.50458041]\n",
      " [  1.39759092  -5.15866229   5.26466481  -3.66827317   2.97034983\n",
      "   -4.59074536   6.89140783  -0.49279393   5.07230367   4.76500446]\n",
      " [  3.3426876  -10.16376542  10.25923326  -7.71865517   7.76763792\n",
      "   -8.02751751  15.01430746  -2.50458041   4.76500446  13.28300717]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:07<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 233 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1032.453\n",
      "w[1]    -135.457\n",
      "w[2]     -41.658\n",
      "w[3]    -116.581\n",
      "w[4]     -78.523\n",
      "w[5]     -37.442\n",
      "w[6]     192.208\n",
      "w[7]     -24.201\n",
      "w[8]       1.866\n",
      "w[9]     128.479\n",
      "Name: mean, dtype: float64\n",
      "[[ 3.39688358e+00 -3.02661557e+00  2.75032395e+00 -2.38412599e+00\n",
      "   1.45927042e+00 -2.57508838e+00  5.23215386e+00  8.32751579e-03\n",
      "   1.48892850e+00  3.54817425e+00]\n",
      " [-3.02661557e+00  1.14653146e+01 -1.01394880e+01  7.66419232e+00\n",
      "  -7.54720447e+00  8.35766043e+00 -1.46314482e+01  1.80145068e+00\n",
      "  -5.49558525e+00 -1.08398845e+01]\n",
      " [ 2.75032395e+00 -1.01394880e+01  1.31124989e+01 -7.40130154e+00\n",
      "   7.53097421e+00 -8.73781141e+00  1.49739593e+01 -1.32277012e+00\n",
      "   5.61513766e+00  1.09443035e+01]\n",
      " [-2.38412599e+00  7.66419232e+00 -7.40130154e+00  7.13110317e+00\n",
      "  -5.66907735e+00  6.14211707e+00 -1.07880307e+01  1.35391610e+00\n",
      "  -3.90871063e+00 -8.20118737e+00]\n",
      " [ 1.45927042e+00 -7.54720447e+00  7.53097421e+00 -5.66907735e+00\n",
      "   8.38883952e+00 -5.96311364e+00  1.12789285e+01 -2.08782898e+00\n",
      "   3.23652046e+00  8.34450798e+00]\n",
      " [-2.57508838e+00  8.35766043e+00 -8.73781141e+00  6.14211707e+00\n",
      "  -5.96311364e+00  8.46557827e+00 -1.21541959e+01  1.42982886e+00\n",
      "  -4.85507516e+00 -8.58987499e+00]\n",
      " [ 5.23215386e+00 -1.46314482e+01  1.49739593e+01 -1.07880307e+01\n",
      "   1.12789285e+01 -1.21541959e+01  2.61118864e+01 -2.04481123e+00\n",
      "   7.38816393e+00  1.60589859e+01]\n",
      " [ 8.32751579e-03  1.80145068e+00 -1.32277012e+00  1.35391610e+00\n",
      "  -2.08782898e+00  1.42982886e+00 -2.04481123e+00  3.06707450e+00\n",
      "  -5.11938699e-01 -2.61282749e+00]\n",
      " [ 1.48892850e+00 -5.49558525e+00  5.61513766e+00 -3.90871063e+00\n",
      "   3.23652046e+00 -4.85507516e+00  7.38816393e+00 -5.11938699e-01\n",
      "   5.21474669e+00  5.12489621e+00]\n",
      " [ 3.54817425e+00 -1.08398845e+01  1.09443035e+01 -8.20118737e+00\n",
      "   8.34450798e+00 -8.58987499e+00  1.60589859e+01 -2.61282749e+00\n",
      "   5.12489621e+00  1.40263485e+01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:02<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 224 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1035.609\n",
      "w[1]    -139.017\n",
      "w[2]     -38.568\n",
      "w[3]    -119.329\n",
      "w[4]     -76.694\n",
      "w[5]     -40.311\n",
      "w[6]     197.952\n",
      "w[7]     -24.342\n",
      "w[8]       3.573\n",
      "w[9]     132.400\n",
      "Name: mean, dtype: float64\n",
      "[[ 3.51107095e+00 -3.28593206e+00  3.04202926e+00 -2.58538731e+00\n",
      "   1.61925026e+00 -2.81347122e+00  5.64120979e+00  5.23416427e-03\n",
      "   1.65192099e+00  3.80645576e+00]\n",
      " [-3.28593206e+00  1.24018886e+01 -1.10554463e+01  8.32056706e+00\n",
      "  -8.23697500e+00  9.08536647e+00 -1.59012474e+01  1.98702172e+00\n",
      "  -5.97126172e+00 -1.17831808e+01]\n",
      " [ 3.04202926e+00 -1.10554463e+01  1.39913439e+01 -8.03648903e+00\n",
      "   8.22020907e+00 -9.46512417e+00  1.62228611e+01 -1.49104479e+00\n",
      "   6.09893651e+00  1.18303698e+01]\n",
      " [-2.58538731e+00  8.32056706e+00 -8.03648903e+00  7.58767561e+00\n",
      "  -6.16254591e+00  6.66923340e+00 -1.17174746e+01  1.49730586e+00\n",
      "  -4.23628895e+00 -8.87677982e+00]\n",
      " [ 1.61925026e+00 -8.23697500e+00  8.22020907e+00 -6.16254591e+00\n",
      "   8.91487476e+00 -6.50072097e+00  1.22111574e+01 -2.31084168e+00\n",
      "   3.57380262e+00  9.06895865e+00]\n",
      " [-2.81347122e+00  9.08536647e+00 -9.46512417e+00  6.66923340e+00\n",
      "  -6.50072097e+00  9.01573576e+00 -1.31593635e+01  1.54842902e+00\n",
      "  -5.21207753e+00 -9.33768253e+00]\n",
      " [ 5.64120979e+00 -1.59012474e+01  1.62228611e+01 -1.17174746e+01\n",
      "   1.22111574e+01 -1.31593635e+01  2.78344389e+01 -2.28943485e+00\n",
      "   8.05476091e+00  1.73315588e+01]\n",
      " [ 5.23416427e-03  1.98702172e+00 -1.49104479e+00  1.49730586e+00\n",
      "  -2.31084168e+00  1.54842902e+00 -2.28943485e+00  3.17243630e+00\n",
      "  -5.37310192e-01 -2.83090540e+00]\n",
      " [ 1.65192099e+00 -5.97126172e+00  6.09893651e+00 -4.23628895e+00\n",
      "   3.57380262e+00 -5.21207753e+00  8.05476091e+00 -5.37310192e-01\n",
      "   5.46679252e+00  5.59414678e+00]\n",
      " [ 3.80645576e+00 -1.17831808e+01  1.18303698e+01 -8.87677982e+00\n",
      "   9.06895865e+00 -9.33768253e+00  1.73315588e+01 -2.83090540e+00\n",
      "   5.59414678e+00  1.49280995e+01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:01<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 216 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1038.862\n",
      "w[1]    -142.841\n",
      "w[2]     -35.217\n",
      "w[3]    -122.264\n",
      "w[4]     -74.697\n",
      "w[5]     -43.419\n",
      "w[6]     204.088\n",
      "w[7]     -24.506\n",
      "w[8]       5.436\n",
      "w[9]     136.583\n",
      "Name: mean, dtype: float64\n",
      "[[  3.64044122  -3.51907328   3.31176242  -2.76476629   1.75720014\n",
      "   -2.98453543   6.03675634   0.05685997   1.7554284    4.05481719]\n",
      " [ -3.51907328  13.00414774 -11.73458804   8.79183357  -8.75007806\n",
      "    9.57180418 -16.89629146   2.10017563  -6.25040067 -12.47689928]\n",
      " [  3.31176242 -11.73458804  14.66530986  -8.56486102   8.77413534\n",
      "  -10.00062304  17.28071767  -1.61881043   6.42492057  12.58137471]\n",
      " [ -2.76476629   8.79183357  -8.56486102   7.9454511   -6.56124983\n",
      "    7.04085225 -12.49434543   1.57570456  -4.46314743  -9.41328483]\n",
      " [  1.75720014  -8.75007806   8.77413534  -6.56124983   9.31803972\n",
      "   -6.91778305  12.98521828  -2.46166647   3.83246228   9.65896116]\n",
      " [ -2.98453543   9.57180418 -10.00062304   7.04085225  -6.91778305\n",
      "    9.37076584 -13.90413756   1.63669576  -5.44328012  -9.904428  ]\n",
      " [  6.03675634 -16.89629146  17.28071767 -12.49434543  12.98521828\n",
      "  -13.90413756  29.34959889  -2.4331079    8.52521223  18.43441529]\n",
      " [  0.05685997   2.10017563  -1.61881043   1.57570456  -2.46166647\n",
      "    1.63669576  -2.4331079    3.29362648  -0.56969506  -2.97039191]\n",
      " [  1.7554284   -6.25040067   6.42492057  -4.46314743   3.83246228\n",
      "   -5.44328012   8.52521223  -0.56969506   5.57558295   5.93026254]\n",
      " [  4.05481719 -12.47689928  12.58137471  -9.41328483   9.65896116\n",
      "   -9.904428    18.43441529  -2.97039191   5.93026254  15.71387848]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:08<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 231 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1042.229\n",
      "w[1]    -146.891\n",
      "w[2]     -31.586\n",
      "w[3]    -125.376\n",
      "w[4]     -72.572\n",
      "w[5]     -46.693\n",
      "w[6]     210.591\n",
      "w[7]     -24.629\n",
      "w[8]       7.411\n",
      "w[9]     140.991\n",
      "Name: mean, dtype: float64\n",
      "[[  3.70048109  -3.62046082   3.41894366  -2.83865635   1.78027994\n",
      "   -3.04535335   6.18567171   0.10835739   1.82599418   4.14498434]\n",
      " [ -3.62046082  13.55267181 -12.32412545   9.20661739  -9.17573657\n",
      "   10.01841542 -17.70071723   2.21999591  -6.55299403 -13.02934226]\n",
      " [  3.41894366 -12.32412545  15.2338214   -9.00321604   9.18788035\n",
      "  -10.45726914  18.06251851  -1.7211979    6.71676378  13.15050657]\n",
      " [ -2.83865635   9.20661739  -9.00321604   8.24402875  -6.88665866\n",
      "    7.37469881 -13.11062548   1.66271965  -4.67032588  -9.84131715]\n",
      " [  1.78027994  -9.17573657   9.18788035  -6.88665866   9.65306544\n",
      "   -7.25108865  13.54262486  -2.62310492   4.03967067  10.10438687]\n",
      " [ -3.04535335  10.01841542 -10.45726914   7.37469881  -7.25108865\n",
      "    9.72071287 -14.532718     1.71032672  -5.67156866 -10.37241365]\n",
      " [  6.18567171 -17.70071723  18.06251851 -13.11062548  13.54262486\n",
      "  -14.532718    30.4048004   -2.59046068   8.94706796  19.24775927]\n",
      " [  0.10835739   2.21999591  -1.7211979    1.66271965  -2.62310492\n",
      "    1.71032672  -2.59046068   3.42079868  -0.57327732  -3.10035795]\n",
      " [  1.82599418  -6.55299403   6.71676378  -4.67032588   4.03967067\n",
      "   -5.67156866   8.94706796  -0.57327732   5.72029154   6.23465343]\n",
      " [  4.14498434 -13.02934226  13.15050657  -9.84131715  10.10438687\n",
      "  -10.37241365  19.24775927  -3.10035795   6.23465343  16.27469298]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:08<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 236 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1045.675\n",
      "w[1]    -151.095\n",
      "w[2]     -27.799\n",
      "w[3]    -128.599\n",
      "w[4]     -70.371\n",
      "w[5]     -50.074\n",
      "w[6]     217.346\n",
      "w[7]     -24.706\n",
      "w[8]       9.482\n",
      "w[9]     145.550\n",
      "Name: mean, dtype: float64\n",
      "[[  3.84344219  -3.87615663   3.66452457  -3.01845203   1.94055583\n",
      "   -3.26205652   6.60241988   0.14297637   1.95475573   4.38933418]\n",
      " [ -3.87615663  14.42439064 -13.1581403    9.84067311  -9.8122021\n",
      "   10.73415887 -18.98314478   2.34998413  -7.0198893  -13.92414392]\n",
      " [  3.66452457 -13.1581403   16.02423417  -9.62127059   9.81398903\n",
      "  -11.15391917  19.26936712  -1.82018582   7.19596333  13.9519135 ]\n",
      " [ -3.01845203   9.84067311  -9.62127059   8.71072129  -7.36636834\n",
      "    7.91521826 -14.00954373   1.75811639  -5.00881303 -10.48342415]\n",
      " [  1.94055583  -9.8122021    9.81398903  -7.36636834  10.16172672\n",
      "   -7.78093478  14.41917723  -2.78944702   4.3895606   10.76533395]\n",
      " [ -3.26205652  10.73415887 -11.15391917   7.91521826  -7.78093478\n",
      "   10.31716121 -15.57294011   1.81479234  -6.05900673 -11.08369451]\n",
      " [  6.60241988 -18.98314478  19.26936712 -14.00954373  14.41917723\n",
      "  -15.57294011  32.16822685  -2.75157753   9.62920809  20.50283219]\n",
      " [  0.14297637   2.34998413  -1.82018582   1.75811639  -2.78944702\n",
      "    1.81479234  -2.75157753   3.57768666  -0.60495071  -3.28372492]\n",
      " [  1.95475573  -7.0198893    7.19596333  -5.00881303   4.3895606\n",
      "   -6.05900673   9.62920809  -0.60495071   5.9501358    6.70394962]\n",
      " [  4.38933418 -13.92414392  13.9519135  -10.48342415  10.76533395\n",
      "  -11.08369451  20.50283219  -3.28372492   6.70394962  17.15292345]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:04<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 226 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1049.250\n",
      "w[1]    -155.577\n",
      "w[2]     -23.760\n",
      "w[3]    -132.015\n",
      "w[4]     -68.001\n",
      "w[5]     -53.670\n",
      "w[6]     224.519\n",
      "w[7]     -24.773\n",
      "w[8]      11.677\n",
      "w[9]     150.377\n",
      "Name: mean, dtype: float64\n",
      "[[  4.01631368  -4.19049295   3.99376953  -3.25271264   2.13063857\n",
      "   -3.53798287   7.11023004   0.15353108   2.12095926   4.71881092]\n",
      " [ -4.19049295  15.42126347 -14.19457218  10.57402656 -10.57230476\n",
      "   11.59781019 -20.46741345   2.49785685  -7.57294306 -14.9698927 ]\n",
      " [  3.99376953 -14.19457218  17.07902888 -10.39187654  10.61192688\n",
      "  -12.05704586  20.82879178  -1.94641041   7.77059689  15.01228191]\n",
      " [ -3.25271264  10.57402656 -10.39187654   9.22964095  -7.94497511\n",
      "    8.56454243 -15.14575784   1.86690448  -5.42389339 -11.2608424 ]\n",
      " [  2.13063857 -10.57230476  10.61192688  -7.94497511  10.78421506\n",
      "   -8.45033469  15.547192    -2.96090934   4.78510998  11.58780589]\n",
      " [ -3.53798287  11.59781019 -12.05704586   8.56454243  -8.45033469\n",
      "   11.06133441 -16.87083948   1.95028451  -6.53529482 -12.02440183]\n",
      " [  7.11023004 -20.46741345  20.82879178 -15.14575784  15.547192\n",
      "  -16.87083948  34.29280109  -2.93724383  10.44150748  22.03628167]\n",
      " [  0.15353108   2.49785685  -1.94641041   1.86690448  -2.96090934\n",
      "    1.95028451  -2.93724383   3.67287827  -0.65602333  -3.46867156]\n",
      " [  2.12095926  -7.57294306   7.77059689  -5.42389339   4.78510998\n",
      "   -6.53529482  10.44150748  -0.65602333   6.28390109   7.26026523]\n",
      " [  4.71881092 -14.9698927   15.01228191 -11.2608424   11.58780589\n",
      "  -12.02440183  22.03628167  -3.46867156   7.26026523  18.23646269]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:03<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 211 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1052.978\n",
      "w[1]    -160.361\n",
      "w[2]     -19.391\n",
      "w[3]    -135.662\n",
      "w[4]     -65.434\n",
      "w[5]     -57.541\n",
      "w[6]     232.166\n",
      "w[7]     -24.834\n",
      "w[8]      14.041\n",
      "w[9]     155.511\n",
      "Name: mean, dtype: float64\n",
      "[[  4.19292802  -4.37942522   4.17227447  -3.40254026   2.20211696\n",
      "   -3.69955177   7.42806129   0.19979338   2.24287556   4.91651149]\n",
      " [ -4.37942522  16.13607934 -14.91730444  11.11753593 -11.12067992\n",
      "   12.17518208 -21.48515834   2.67994198  -7.9510398  -15.69987346]\n",
      " [  4.17227447 -14.91730444  17.7603101  -10.95594916  11.16380954\n",
      "  -12.60429519  21.83228459  -2.11443217   8.15967562  15.7275882 ]\n",
      " [ -3.40254026  11.11753593 -10.95594916   9.62133446  -8.38466401\n",
      "    8.99277299 -15.92266114   1.98804295  -5.69674051 -11.8311975 ]\n",
      " [  2.20211696 -11.12067992  11.16380954  -8.38466401  11.24740628\n",
      "   -8.88653784  16.28549255  -3.1647374    5.03801512  12.1670682 ]\n",
      " [ -3.69955177  12.17518208 -12.60429519   8.99277299  -8.88653784\n",
      "   11.49968627 -17.68781115   2.0757647   -6.8352119  -12.60277396]\n",
      " [  7.42806129 -21.48515834  21.83228459 -15.92266114  16.28549255\n",
      "  -17.68781115  35.72601383  -3.14530867  10.94572224  23.07107949]\n",
      " [  0.19979338   2.67994198  -2.11443217   1.98804295  -3.1647374\n",
      "    2.0757647   -3.14530867   3.81045547  -0.72911274  -3.66109292]\n",
      " [  2.24287556  -7.9510398    8.15967562  -5.69674051   5.03801512\n",
      "   -6.8352119   10.94572224  -0.72911274   6.49323648   7.61845904]\n",
      " [  4.91651149 -15.69987346  15.7275882  -11.8311975   12.1670682\n",
      "  -12.60277396  23.07107949  -3.66109292   7.61845904  18.98760346]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:06<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 214 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1056.839\n",
      "w[1]    -165.260\n",
      "w[2]     -14.896\n",
      "w[3]    -139.392\n",
      "w[4]     -62.837\n",
      "w[5]     -61.517\n",
      "w[6]     240.029\n",
      "w[7]     -24.852\n",
      "w[8]      16.493\n",
      "w[9]     160.789\n",
      "Name: mean, dtype: float64\n",
      "[[  4.39047258  -4.77643731   4.53130406  -3.71915114   2.44057631\n",
      "   -4.02839609   8.03909152   0.15580636   2.45363941   5.32911701]\n",
      " [ -4.77643731  17.50556379 -16.22991749  12.15944923 -12.17556067\n",
      "   13.31312161 -23.47073956   3.05832002  -8.7097352  -17.19153594]\n",
      " [  4.53130406 -16.22991749  19.01918613 -11.9532895   12.17675232\n",
      "  -13.67759253  23.7230851   -2.46297811   8.90927703  17.16685272]\n",
      " [ -3.71915114  12.15944923 -11.9532895   10.38833924  -9.1589855\n",
      "    9.83237409 -17.4463219    2.27333121  -6.25871395 -12.96411089]\n",
      " [  2.44057631 -12.17556067  12.17675232  -9.1589855   12.07618668\n",
      "   -9.73859455  17.78883254  -3.52794945   5.58537112  13.33690372]\n",
      " [ -4.02839609  13.31312161 -13.67759253   9.83237409  -9.73859455\n",
      "   12.39921304 -19.31772266   2.35443491  -7.46079308 -13.82590331]\n",
      " [  8.03909152 -23.47073956  23.7230851  -17.4463219   17.78883254\n",
      "  -19.31772266  38.67165651  -3.63592386  12.04171977  25.21288604]\n",
      " [  0.15580636   3.05832002  -2.46297811   2.27333121  -3.52794945\n",
      "    2.35443491  -3.63592386   4.02908582  -0.86513013  -4.11988682]\n",
      " [  2.45363941  -8.7097352    8.90927703  -6.25871395   5.58537112\n",
      "   -7.46079308  12.04171977  -0.86513013   6.92947973   8.40728248]\n",
      " [  5.32911701 -17.19153594  17.16685272 -12.96411089  13.33690372\n",
      "  -13.82590331  25.21288604  -4.11988682   8.40728248  20.62677532]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:06<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 234 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1060.945\n",
      "w[1]    -170.711\n",
      "w[2]      -9.908\n",
      "w[3]    -143.550\n",
      "w[4]     -59.878\n",
      "w[5]     -65.955\n",
      "w[6]     248.731\n",
      "w[7]     -24.962\n",
      "w[8]      19.235\n",
      "w[9]     166.629\n",
      "Name: mean, dtype: float64\n",
      "[[  4.53757172  -4.93891722   4.66983739  -3.83115882   2.50073617\n",
      "   -4.15736684   8.32641129   0.20151321   2.53204715   5.48426545]\n",
      " [ -4.93891722  18.46090921 -17.21052841  12.85845389 -12.98592476\n",
      "   14.12148693 -24.83242594   3.31863784  -9.24436486 -18.20615004]\n",
      " [  4.66983739 -17.21052841  20.00352647 -12.69477677  13.02422416\n",
      "  -14.49815754  25.11481622  -2.72330797   9.47137187  18.19146865]\n",
      " [ -3.83115882  12.85845389 -12.69477677  10.85354994  -9.76522204\n",
      "   10.42621054 -18.44527215   2.46313987  -6.63430464 -13.69809931]\n",
      " [  2.50073617 -12.98592476  13.02422416  -9.76522204  12.8225814\n",
      "  -10.42431025  18.89949146  -3.83129008   6.03089524  14.21644622]\n",
      " [ -4.15736684  14.12148693 -14.49815754  10.42621054 -10.42431025\n",
      "   13.03998952 -20.44953375   2.56062093  -7.90283854 -14.66511168]\n",
      " [  8.32641129 -24.83242594  25.11481622 -18.44527215  18.89949146\n",
      "  -20.44953375  40.62915003  -3.98120577  12.83803937  26.65443487]\n",
      " [  0.20151321   3.31863784  -2.72330797   2.46313987  -3.83129008\n",
      "    2.56062093  -3.98120577   4.23838916  -0.95589933  -4.44709492]\n",
      " [  2.53204715  -9.24436486   9.47137187  -6.63430464   6.03089524\n",
      "   -7.90283854  12.83803937  -0.95589933   7.22843247   8.95904109]\n",
      " [  5.48426545 -18.20615004  18.19146865 -13.69809931  14.21644622\n",
      "  -14.66511168  26.65443487  -4.44709492   8.95904109  21.65812186]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:04<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 229 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1065.180\n",
      "w[1]    -176.432\n",
      "w[2]      -4.659\n",
      "w[3]    -147.900\n",
      "w[4]     -56.749\n",
      "w[5]     -70.617\n",
      "w[6]     257.852\n",
      "w[7]     -25.083\n",
      "w[8]      22.115\n",
      "w[9]     172.742\n",
      "Name: mean, dtype: float64\n",
      "[[  4.78608423  -5.23210062   4.98269096  -4.08591877   2.64653913\n",
      "   -4.40740582   8.82735494   0.28118327   2.71285348   5.78744628]\n",
      " [ -5.23210062  19.28333272 -18.09707408  13.51581228 -13.60212587\n",
      "   14.80489897 -26.08590299   3.38326132  -9.74049216 -19.04607549]\n",
      " [  4.98269096 -18.09707408  20.95475964 -13.38409937  13.65888334\n",
      "  -15.24519342  26.45299904  -2.77829776  10.01453697  19.09882803]\n",
      " [ -4.08591877  13.51581228 -13.38409937  11.35263839 -10.24025896\n",
      "   10.94479545 -19.43256022   2.49116672  -7.02869132 -14.35433964]\n",
      " [  2.64653913 -13.60212587  13.65888334 -10.24025896  13.27065296\n",
      "  -10.9258218   19.74877126  -3.96815878   6.38176187  14.84785234]\n",
      " [ -4.40740582  14.80489897 -15.24519342  10.94479545 -10.9258218\n",
      "   13.61838166 -21.47823945   2.5974665   -8.30143143 -15.38446423]\n",
      " [  8.82735494 -26.08590299  26.45299904 -19.43256022  19.74877126\n",
      "  -21.47823945  42.45131697  -4.04643444  13.58810547  27.88746845]\n",
      " [  0.28118327   3.38326132  -2.77829776   2.49116672  -3.96815878\n",
      "    2.5974665   -4.04643444   4.34953078  -0.96027413  -4.5135044 ]\n",
      " [  2.71285348  -9.74049216  10.01453697  -7.02869132   6.38176187\n",
      "   -8.30143143  13.58810547  -0.96027413   7.51894791   9.47264925]\n",
      " [  5.78744628 -19.04607549  19.09882803 -14.35433964  14.84785234\n",
      "  -15.38446423  27.88746845  -4.5135044    9.47264925  22.511648  ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:10<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 254 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1069.594\n",
      "w[1]    -182.271\n",
      "w[2]       0.738\n",
      "w[3]    -152.377\n",
      "w[4]     -53.592\n",
      "w[5]     -75.387\n",
      "w[6]     267.226\n",
      "w[7]     -25.073\n",
      "w[8]      25.098\n",
      "w[9]     178.974\n",
      "Name: mean, dtype: float64\n",
      "[[  5.02525451  -5.66550886   5.4464213   -4.43603845   2.93226569\n",
      "   -4.77529035   9.55095161   0.29690849   2.95002686   6.27514947]\n",
      " [ -5.66550886  20.75677602 -19.67118392  14.66110279 -14.79393546\n",
      "   16.05581128 -28.30030945   3.72536808 -10.51517161 -20.69582359]\n",
      " [  5.4464213  -19.67118392  22.57919937 -14.59329927  14.88677259\n",
      "  -16.56200091  28.7771927   -3.14092235  10.86224604  20.83431848]\n",
      " [ -4.43603845  14.66110279 -14.59329927  12.22329189 -11.15159106\n",
      "   11.90413663 -21.13811829   2.75262745  -7.62692234 -15.64317908]\n",
      " [  2.93226569 -14.79393546  14.88677259 -11.15159106  14.26694887\n",
      "  -11.94779091  21.47425709  -4.36771483   6.9851967   16.19808848]\n",
      " [ -4.77529035  16.05581128 -16.56200091  11.90413663 -11.94779091\n",
      "   14.6701623  -23.36045715   2.89050904  -8.96687958 -16.79663714]\n",
      " [  9.55095161 -28.30030945  28.7771927  -21.13811829  21.47425709\n",
      "  -23.36045715  45.78595414  -4.48961673  14.77033115  30.36761233]\n",
      " [  0.29690849   3.72536808  -3.14092235   2.75262745  -4.36771483\n",
      "    2.89050904  -4.48961673   4.67183675  -1.07405378  -4.97677128]\n",
      " [  2.95002686 -10.51517161  10.86224604  -7.62692234   6.9851967\n",
      "   -8.96687958  14.77033115  -1.07405378   7.9347656   10.32745059]\n",
      " [  6.27514947 -20.69582359  20.83431848 -15.64317908  16.19808848\n",
      "  -16.79663714  30.36761233  -4.97677128  10.32745059  24.37909016]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:06<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 247 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1074.270\n",
      "w[1]    -188.663\n",
      "w[2]       6.718\n",
      "w[3]    -157.293\n",
      "w[4]     -50.045\n",
      "w[5]     -80.610\n",
      "w[6]     277.492\n",
      "w[7]     -25.114\n",
      "w[8]      28.371\n",
      "w[9]     185.829\n",
      "Name: mean, dtype: float64\n",
      "[[  5.25407969  -5.82494921   5.57674382  -4.56102763   2.93872918\n",
      "   -4.93403695   9.90629562   0.39583732   3.04281319   6.43524121]\n",
      " [ -5.82494921  21.54309985 -20.43658626  15.26071617 -15.33965542\n",
      "   16.70113174 -29.42533524   3.8308497  -10.95667686 -21.46013006]\n",
      " [  5.57674382 -20.43658626  23.29583108 -15.18021797  15.44853175\n",
      "  -17.20139886  29.8680044   -3.26019439  11.33441358  21.58769783]\n",
      " [ -4.56102763  15.26071617 -15.18021797  12.65114232 -11.57618253\n",
      "   12.40344455 -22.01897322   2.84233382  -7.95674208 -16.2218966 ]\n",
      " [  2.93872918 -15.33965542  15.44853175 -11.57618253  14.72687814\n",
      "  -12.39768871  22.22566934  -4.56052072   7.26554295  16.76295247]\n",
      " [ -4.93403695  16.70113174 -17.20139886  12.40344455 -12.39768871\n",
      "   15.22424878 -24.31582392   2.95893634  -9.33416186 -17.43124111]\n",
      " [  9.90629562 -29.42533524  29.8680044  -22.01897322  22.22566934\n",
      "  -24.31582392  47.43370622  -4.60026575  15.38817992  31.50400211]\n",
      " [  0.39583732   3.8308497   -3.26019439   2.84233382  -4.56052072\n",
      "    2.95893634  -4.60026575   4.8564811   -1.08244918  -5.14284854]\n",
      " [  3.04281319 -10.95667686  11.33441358  -7.95674208   7.26554295\n",
      "   -9.33416186  15.38817992  -1.08244918   8.17106455  10.73719322]\n",
      " [  6.43524121 -21.46013006  21.58769783 -16.2218966   16.76295247\n",
      "  -17.43124111  31.50400211  -5.14284854  10.73719322  25.14349398]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:11<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 233 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1079.123\n",
      "w[1]    -195.148\n",
      "w[2]      12.757\n",
      "w[3]    -162.278\n",
      "w[4]     -46.525\n",
      "w[5]     -85.938\n",
      "w[6]     287.981\n",
      "w[7]     -25.050\n",
      "w[8]      31.706\n",
      "w[9]     192.757\n",
      "Name: mean, dtype: float64\n",
      "[[  5.52206256  -6.13965519   5.88309141  -4.81378147   3.09474049\n",
      "   -5.21217163  10.46517804   0.43594567   3.21665498   6.76548725]\n",
      " [ -6.13965519  22.05413831 -20.96463783  15.64977026 -15.7162387\n",
      "   17.12456374 -30.31512962   3.92075387 -11.23391458 -22.05765376]\n",
      " [  5.88309141 -20.96463783  23.78401403 -15.57576196  15.81173233\n",
      "  -17.61993636  30.72339731  -3.32952453  11.61625672  22.16885257]\n",
      " [ -4.81378147  15.64977026 -15.57576196  12.93322584 -11.84724984\n",
      "   12.73869808 -22.74215544   2.89535767  -8.17626161 -16.68341942]\n",
      " [  3.09474049 -15.7162387   15.81173233 -11.84724984  15.01939525\n",
      "  -12.68823124  22.82828461  -4.68802941   7.4215046   17.19596509]\n",
      " [ -5.21217163  17.12456374 -17.61993636  12.73869808 -12.68823124\n",
      "   15.59323065 -25.06961017   3.00790277  -9.5758441  -17.92643102]\n",
      " [ 10.46517804 -30.31512962  30.72339731 -22.74215544  22.82828461\n",
      "  -25.06961017  48.8801294   -4.72935435  15.85725719  32.49961365]\n",
      " [  0.43594567   3.92075387  -3.32952453   2.89535767  -4.68802941\n",
      "    3.00790277  -4.72935435   4.9893154   -1.06375455  -5.29735274]\n",
      " [  3.21665498 -11.23391458  11.61625672  -8.17626161   7.4215046\n",
      "   -9.5758441   15.85725719  -1.06375455   8.35768655  11.02008969]\n",
      " [  6.76548725 -22.05765376  22.16885257 -16.68341942  17.19596509\n",
      "  -17.92643102  32.49961365  -5.29735274  11.02008969  25.80772752]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:07<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 232 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1084.254\n",
      "w[1]    -202.018\n",
      "w[2]      19.198\n",
      "w[3]    -167.577\n",
      "w[4]     -42.771\n",
      "w[5]     -91.607\n",
      "w[6]     299.146\n",
      "w[7]     -24.969\n",
      "w[8]      35.250\n",
      "w[9]     200.119\n",
      "Name: mean, dtype: float64\n",
      "[[  5.64061472  -6.38217777   6.14789099  -5.01647276   3.2745953\n",
      "   -5.40772234  10.82477807   0.46710834   3.34443428   7.01942027]\n",
      " [ -6.38217777  23.07892064 -22.02640156  16.43216736 -16.63071483\n",
      "   17.94297285 -31.77754354   4.1727261  -11.75220793 -23.15014098]\n",
      " [  6.14789099 -22.02640156  24.88233729 -16.39869486  16.73490837\n",
      "  -18.47361217  32.20510188  -3.54727723  12.17462242  23.28662673]\n",
      " [ -5.01647276  16.43216736 -16.39869486  13.52153086 -12.55544049\n",
      "   13.37751234 -23.85628084   3.08889406  -8.56970787 -17.53974366]\n",
      " [  3.2745953  -16.63071483  16.73490837 -12.55544049  15.83450773\n",
      "  -13.41450177  24.10408215  -5.00044408   7.88881183  18.21487749]\n",
      " [ -5.40772234  17.94297285 -18.47361217  13.37751234 -13.41450177\n",
      "   16.24228869 -26.21307986   3.19864626  -9.99929346 -18.81839405]\n",
      " [ 10.82477807 -31.77754354  32.20510188 -23.85628084  24.10408215\n",
      "  -26.21307986  50.87841141  -5.05797663  16.56785329  34.07255588]\n",
      " [  0.46710834   4.1727261   -3.54727723   3.08889406  -5.00044408\n",
      "    3.19864626  -5.05797663   5.22297438  -1.12748764  -5.60895294]\n",
      " [  3.34443428 -11.75220793  12.17462242  -8.56970787   7.88881183\n",
      "   -9.99929346  16.56785329  -1.12748764   8.63141394  11.56698488]\n",
      " [  7.01942027 -23.15014098  23.28662673 -17.53974366  18.21487749\n",
      "  -18.81839405  34.07255588  -5.60895294  11.56698488  27.01457598]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:09<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 231 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1089.491\n",
      "w[1]    -209.140\n",
      "w[2]      25.901\n",
      "w[3]    -173.074\n",
      "w[4]     -38.852\n",
      "w[5]     -97.471\n",
      "w[6]     310.663\n",
      "w[7]     -24.882\n",
      "w[8]      38.914\n",
      "w[9]     207.733\n",
      "Name: mean, dtype: float64\n",
      "[[  5.92841247  -6.76290486   6.49434106  -5.2847613    3.44167602\n",
      "   -5.72140439  11.44462372   0.53316076   3.55023303   7.40528427]\n",
      " [ -6.76290486  24.35704332 -23.27303749  17.33754869 -17.48549649\n",
      "   18.94226467 -33.53474584   4.33584336 -12.42157226 -24.4068138 ]\n",
      " [  6.49434106 -23.27303749  26.04136007 -17.27142177  17.56344195\n",
      "  -19.42563814  33.86074867  -3.7043533   12.85526179  24.47767655]\n",
      " [ -5.2847613   17.33754869 -17.27142177  14.14934354 -13.15706276\n",
      "   14.07685429 -25.10342194   3.20510554  -9.05986118 -18.43270243]\n",
      " [  3.44167602 -17.48549649  17.56344195 -13.15706276  16.49866311\n",
      "  -14.05994188  25.2605804   -5.25557801   8.31083476  19.08808783]\n",
      " [ -5.72140439  18.94226467 -19.42563814  14.07685429 -14.05994188\n",
      "   16.99503048 -27.57321845   3.30362785 -10.5188304  -19.75982175]\n",
      " [ 11.44462372 -33.53474584  33.86074867 -25.10342194  25.2605804\n",
      "  -27.57321845  53.32246525  -5.2918643   17.49095004  35.8304256 ]\n",
      " [  0.53316076   4.33584336  -3.7043533    3.20510554  -5.25557801\n",
      "    3.30362785  -5.2918643    5.46866457  -1.12605709  -5.84044492]\n",
      " [  3.55023303 -12.42157226  12.85526179  -9.05986118   8.31083476\n",
      "  -10.5188304   17.49095004  -1.12605709   9.02317399  12.19407735]\n",
      " [  7.40528427 -24.4068138   24.47767655 -18.43270243  19.08808783\n",
      "  -19.75982175  35.8304256   -5.84044492  12.19407735  28.29426099]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:16<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 248 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1095.004\n",
      "w[1]    -216.720\n",
      "w[2]      33.047\n",
      "w[3]    -178.895\n",
      "w[4]     -34.687\n",
      "w[5]    -103.709\n",
      "w[6]     322.926\n",
      "w[7]     -24.747\n",
      "w[8]      42.836\n",
      "w[9]     215.810\n",
      "Name: mean, dtype: float64\n",
      "[[  6.20731068  -7.0787247    6.82703432  -5.53986257   3.54392583\n",
      "   -5.992076    11.99921596   0.64614632   3.75114017   7.75334353]\n",
      " [ -7.0787247   25.6761209  -24.64196432  18.3582935  -18.50734386\n",
      "   20.00603347 -35.44877821   4.55213906 -13.19368064 -25.82490215]\n",
      " [  6.82703432 -24.64196432  27.45294295 -18.32739689  18.59366652\n",
      "  -20.5331725   35.84466671  -3.84725606  13.66939882  25.88561373]\n",
      " [ -5.53986257  18.3582935  -18.32739689  14.92566033 -13.94203417\n",
      "   14.89610028 -26.5888815    3.3595866   -9.63802211 -19.50922011]\n",
      " [  3.54392583 -18.50734386  18.59366652 -13.94203417  17.37489722\n",
      "  -14.85884621  26.65433189  -5.59850861   8.82428395  20.19665736]\n",
      " [ -5.992076    20.00603347 -20.5331725   14.89610028 -14.85884621\n",
      "   17.82379084 -29.10529707   3.44990024 -11.13624752 -20.87530231]\n",
      " [ 11.99921596 -35.44877821  35.84466671 -26.5888815   26.65433189\n",
      "  -29.10529707  56.11135777  -5.52740168  18.58389698  37.90876006]\n",
      " [  0.64614632   4.55213906  -3.84725606   3.3595866   -5.59850861\n",
      "    3.44990024  -5.52740168   5.80194745  -1.10729125  -6.12261898]\n",
      " [  3.75114017 -13.19368064  13.66939882  -9.63802211   8.82428395\n",
      "  -11.13624752  18.58389698  -1.10729125   9.52636109  12.93224437]\n",
      " [  7.75334353 -25.82490215  25.88561373 -19.50922011  20.19665736\n",
      "  -20.87530231  37.90876006  -6.12261898  12.93224437  29.82824096]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:10<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 239 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1100.765\n",
      "w[1]    -224.654\n",
      "w[2]      40.545\n",
      "w[3]    -185.001\n",
      "w[4]     -30.341\n",
      "w[5]    -110.253\n",
      "w[6]     335.758\n",
      "w[7]     -24.554\n",
      "w[8]      46.975\n",
      "w[9]     224.290\n",
      "Name: mean, dtype: float64\n",
      "[[  6.62231606  -7.56312867   7.28888997  -5.89203357   3.6962281\n",
      "   -6.41174705  12.76419076   0.84965241   4.03503661   8.18749234]\n",
      " [ -7.56312867  27.48635173 -26.44066556  19.65363239 -19.84923866\n",
      "   21.48164604 -37.89191679   4.88172672 -14.16388143 -27.6501446 ]\n",
      " [  7.28888997 -26.44066556  29.19641467 -19.63184733  19.91671696\n",
      "  -21.9909115   38.24974873  -4.16697143  14.66479171  27.68334216]\n",
      " [ -5.89203357  19.65363239 -19.63184733  15.86488732 -14.91740506\n",
      "   15.97450112 -28.38498669   3.59154154 -10.34031578 -20.84159734]\n",
      " [  3.6962281  -19.84923866  19.91671696 -14.91740506  18.49738906\n",
      "  -15.9498983   28.38396343  -6.09812256   9.49824645  21.62068455]\n",
      " [ -6.41174705  21.48164604 -21.9909115   15.97450112 -15.9498983\n",
      "   19.04126006 -31.13821868   3.6860108  -11.93097105 -22.38189024]\n",
      " [ 12.76419076 -37.89191679  38.24974873 -28.38498669  28.38396343\n",
      "  -31.13821868  59.4228011   -5.84707568  19.9362456   40.35849301]\n",
      " [  0.84965241   4.88172672  -4.16697143   3.59154154  -6.09812256\n",
      "    3.6860108   -5.84707568   6.26836931  -1.18221565  -6.57292201]\n",
      " [  4.03503661 -14.16388143  14.66479171 -10.34031578   9.49824645\n",
      "  -11.93097105  19.9362456   -1.18221565  10.08146211  13.90489143]\n",
      " [  8.18749234 -27.6501446   27.68334216 -20.84159734  21.62068455\n",
      "  -22.38189024  40.35849301  -6.57292201  13.90489143  31.71043762]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:10<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 267 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1106.931\n",
      "w[1]    -233.088\n",
      "w[2]      48.546\n",
      "w[3]    -191.469\n",
      "w[4]     -25.804\n",
      "w[5]    -117.227\n",
      "w[6]     349.374\n",
      "w[7]     -24.185\n",
      "w[8]      51.394\n",
      "w[9]     233.219\n",
      "Name: mean, dtype: float64\n",
      "[[  6.88992729  -7.83390235   7.56707027  -6.10566608   3.76063078\n",
      "   -6.66432825  13.29413567   0.97223996   4.21385329   8.45926165]\n",
      " [ -7.83390235  28.73390639 -27.75989424  20.55527824 -20.74431177\n",
      "   22.5675739  -39.68075956   5.08064242 -14.94083738 -28.88644462]\n",
      " [  7.56707027 -27.75989424  30.5477503  -20.60294217  20.84766107\n",
      "  -23.13584433  40.10970208  -4.3836943   15.49989465  28.96699469]\n",
      " [ -6.10566608  20.55527824 -20.60294217  16.51177506 -15.58190373\n",
      "   16.75991945 -29.70583277   3.74136043 -10.88929302 -21.74064441]\n",
      " [  3.76063078 -20.74431177  20.84766107 -15.58190373  19.2438104\n",
      "  -16.71373676  29.59577299  -6.38140418  10.04568064  22.5546383 ]\n",
      " [ -6.66432825  22.5675739  -23.13584433  16.75991945 -16.71373676\n",
      "   19.9638609  -32.68808621   3.83652514 -12.59856395 -23.46735608]\n",
      " [ 13.29413567 -39.68075956  40.10970208 -29.70583277  29.59577299\n",
      "  -32.68808621  62.01208018  -6.04448839  21.05098578  42.1021666 ]\n",
      " [  0.97223996   5.08064242  -4.3836943    3.74136043  -6.38140418\n",
      "    3.83652514  -6.04448839   6.47659052  -1.25718591  -6.80743982]\n",
      " [  4.21385329 -14.94083738  15.49989465 -10.88929302  10.04568064\n",
      "  -12.59856395  21.05098578  -1.25718591  10.5470195   14.65496923]\n",
      " [  8.45926165 -28.88644462  28.96699469 -21.74064441  22.5546383\n",
      "  -23.46735608  42.1021666   -6.80743982  14.65496923  32.90061558]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:17<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 236 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1113.258\n",
      "w[1]    -241.719\n",
      "w[2]      56.748\n",
      "w[3]    -198.076\n",
      "w[4]     -21.223\n",
      "w[5]    -124.380\n",
      "w[6]     363.374\n",
      "w[7]     -23.736\n",
      "w[8]      55.945\n",
      "w[9]     242.339\n",
      "Name: mean, dtype: float64\n",
      "[[  7.2262487   -8.11028757   7.81256409  -6.32635094   3.86548581\n",
      "   -6.9022052   13.82595956   1.06322768   4.30307978   8.78672698]\n",
      " [ -8.11028757  29.93129182 -28.9896092   21.45113057 -21.66559612\n",
      "   23.5469251  -41.33189875   5.3031837  -15.61346399 -30.12973799]\n",
      " [  7.81256409 -28.9896092   31.76146893 -21.5020396   21.76340532\n",
      "  -24.11183142  41.80168716  -4.55600845  16.21722963  30.17817979]\n",
      " [ -6.32635094  21.45113057 -21.5020396   17.17940932 -16.27404211\n",
      "   17.50268527 -30.96191432   3.90617975 -11.38135343 -22.66293238]\n",
      " [  3.86548581 -21.66559612  21.76340532 -16.27404211  19.97736787\n",
      "  -17.45883664  30.79204418  -6.67711434  10.55419023  23.5292902 ]\n",
      " [ -6.9022052   23.5469251  -24.11183142  17.50268527 -17.45883664\n",
      "   20.73801294 -34.04254005   3.97628341 -13.15820507 -24.47804315]\n",
      " [ 13.82595956 -41.33189875  41.80168716 -30.96191432  30.79204418\n",
      "  -34.04254005  64.34451516  -6.25564295  21.96628566  43.8171463 ]\n",
      " [  1.06322768   5.3031837   -4.55600845   3.90617975  -6.67711434\n",
      "    3.97628341  -6.25564295   6.78238427  -1.31340611  -7.08444522]\n",
      " [  4.30307978 -15.61346399  16.21722963 -11.38135343  10.55419023\n",
      "  -13.15820507  21.96628566  -1.31340611  10.9659455   15.30824131]\n",
      " [  8.78672698 -30.12973799  30.17817979 -22.66293238  23.5292902\n",
      "  -24.47804315  43.8171463   -7.08444522  15.30824131  34.20455829]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:29<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 264 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1119.938\n",
      "w[1]    -250.843\n",
      "w[2]      65.427\n",
      "w[3]    -205.063\n",
      "w[4]     -16.375\n",
      "w[5]    -131.954\n",
      "w[6]     378.186\n",
      "w[7]     -23.241\n",
      "w[8]      60.734\n",
      "w[9]     252.004\n",
      "Name: mean, dtype: float64\n",
      "[[  7.65163778  -8.64828593   8.3438376   -6.76792181   4.13947289\n",
      "   -7.35052604  14.81076504   1.20953237   4.59001675   9.35428452]\n",
      " [ -8.64828593  31.65180706 -30.71676103  22.75676829 -22.89292287\n",
      "   24.93822922 -43.90904326   5.49497423 -16.55401687 -31.89537963]\n",
      " [  8.3438376  -30.71676103  33.44607521 -22.78882204  22.969071\n",
      "  -25.48458727  44.37080272  -4.71432078  17.21241997  31.90088807]\n",
      " [ -6.76792181  22.75676829 -22.78882204  18.16419764 -17.18611569\n",
      "   18.56421698 -32.92257185   4.04363209 -12.09535107 -24.00609769]\n",
      " [  4.13947289 -22.89292287  22.969071   -17.18611569  20.91030569\n",
      "  -18.44225438  32.56974907  -6.97401175  11.21082815  24.80206653]\n",
      " [ -7.35052604  24.93822922 -25.48458727  18.56421698 -18.44225438\n",
      "   21.86765861 -36.13960549   4.09954549 -13.93526437 -25.87618008]\n",
      " [ 14.81076504 -43.90904326  44.37080272 -32.92257185  32.56974907\n",
      "  -36.13960549  68.32901442  -6.46100378  23.39005997  46.46131528]\n",
      " [  1.20953237   5.49497423  -4.71432078   4.04363209  -6.97401175\n",
      "    4.09954549  -6.46100378   7.11126259  -1.31556917  -7.36663097]\n",
      " [  4.59001675 -16.55401687  17.21241997 -12.09535107  11.21082815\n",
      "  -13.93526437  23.39005997  -1.31556917  11.52150624  16.22143355]\n",
      " [  9.35428452 -31.89537963  31.90088807 -24.00609769  24.80206653\n",
      "  -25.87618008  46.46131528  -7.36663097  16.22143355  36.03867599]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:11<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 236 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1126.961\n",
      "w[1]    -260.347\n",
      "w[2]      74.481\n",
      "w[3]    -212.375\n",
      "w[4]     -11.358\n",
      "w[5]    -139.839\n",
      "w[6]     393.731\n",
      "w[7]     -22.594\n",
      "w[8]      65.736\n",
      "w[9]     262.056\n",
      "Name: mean, dtype: float64\n",
      "[[  8.11494802  -9.17741789   8.89465626  -7.19331859   4.38369333\n",
      "   -7.86179364  15.7780323    1.31747399   4.9171052    9.95783511]\n",
      " [ -9.17741789  33.80821375 -33.01598862  24.39775119 -24.56397138\n",
      "   26.84361945 -47.11573122   5.98953851 -17.84200709 -34.27457025]\n",
      " [  8.89465626 -33.01598862  35.85192861 -24.52012437  24.70126754\n",
      "  -27.46676391  47.70828175  -5.21098807  18.58995285  34.37437498]\n",
      " [ -7.19331859  24.39775119 -24.52012437  19.3903561  -18.44636728\n",
      "   20.00277481 -35.34653921   4.40524939 -13.0573408  -25.7996445 ]\n",
      " [  4.38369333 -24.56397138  24.70126754 -18.44636728  22.30654041\n",
      "  -19.86679483  34.92663     -7.54987683  12.11888799  26.66647568]\n",
      " [ -7.86179364  26.84361945 -27.46676391  20.00277481 -19.86679483\n",
      "   23.52206648 -38.95057691   4.47875795 -15.07520976 -27.93635019]\n",
      " [ 15.7780323  -47.11573122  47.70828175 -35.34653921  34.92663\n",
      "  -38.95057691  73.07944461  -7.09768825  25.24251068  50.00064506]\n",
      " [  1.31747399   5.98953851  -5.21098807   4.40524939  -7.54987683\n",
      "    4.47875795  -7.09768825   7.49460965  -1.47412652  -7.96291809]\n",
      " [  4.9171052  -17.84200709  18.58995285 -13.0573408   12.11888799\n",
      "  -15.07520976  25.24251068  -1.47412652  12.36452393  17.5381309 ]\n",
      " [  9.95783511 -34.27457025  34.37437498 -25.7996445   26.66647568\n",
      "  -27.93635019  50.00064506  -7.96291809  17.5381309   38.64663625]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:10<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 243 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1134.388\n",
      "w[1]    -270.409\n",
      "w[2]      84.117\n",
      "w[3]    -220.143\n",
      "w[4]      -6.040\n",
      "w[5]    -148.271\n",
      "w[6]     410.252\n",
      "w[7]     -21.904\n",
      "w[8]      71.085\n",
      "w[9]     272.754\n",
      "Name: mean, dtype: float64\n",
      "[[  8.54926044  -9.72946822   9.42581522  -7.60414608   4.64334268\n",
      "   -8.33502468  16.70489365   1.43336234   5.23988188  10.53583408]\n",
      " [ -9.72946822  35.96266084 -35.22305539  25.99813676 -26.20712807\n",
      "   28.59213592 -50.17204265   6.44449379 -18.98619899 -36.54668516]\n",
      " [  9.42581522 -35.22305539  38.06855767 -26.14246518  26.35095715\n",
      "  -29.25481598  50.77865246  -5.59748032  19.82721928  36.6411021 ]\n",
      " [ -7.60414608  25.99813676 -26.14246518  20.56336294 -19.6726771\n",
      "   21.29681452 -37.62234324   4.76216268 -13.9012834  -27.51508202]\n",
      " [  4.64334268 -26.20712807  26.35095715 -19.6726771   23.66590347\n",
      "  -21.14924676  37.15778163  -8.12296184  12.90118423  28.45879505]\n",
      " [ -8.33502468  28.59213592 -29.25481598  21.29681452 -21.14924676\n",
      "   24.94812317 -41.43447464   4.77271203 -16.03966048 -29.7802094 ]\n",
      " [ 16.70489365 -50.17204265  50.77865246 -37.62234324  37.15778163\n",
      "  -41.43447464  77.39291502  -7.60973039  26.86213719  53.21188933]\n",
      " [  1.43336234   6.44449379  -5.59748032   4.76216268  -8.12296184\n",
      "    4.77271203  -7.60973039   8.04983337  -1.50543647  -8.59349221]\n",
      " [  5.23988188 -18.98619899  19.82721928 -13.9012834   12.90118423\n",
      "  -16.03966048  26.86213719  -1.50543647  13.0872634   18.67678664]\n",
      " [ 10.53583408 -36.54668516  36.6411021  -27.51508202  28.45879505\n",
      "  -29.7802094   53.21188933  -8.59349221  18.67678664  41.12066911]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:18<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 252 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1142.205\n",
      "w[1]    -281.047\n",
      "w[2]      94.303\n",
      "w[3]    -228.321\n",
      "w[4]      -0.397\n",
      "w[5]    -157.170\n",
      "w[6]     427.705\n",
      "w[7]     -21.175\n",
      "w[8]      76.725\n",
      "w[9]     284.061\n",
      "Name: mean, dtype: float64\n",
      "[[  8.9932686  -10.3194876   10.01640529  -8.05663094   4.94965187\n",
      "   -8.83744313  17.68639872   1.50925442   5.59614202  11.14655485]\n",
      " [-10.3194876   38.27967607 -37.45863268  27.70781907 -28.0933663\n",
      "   30.48963201 -53.48427706   7.18207646 -20.16488056 -39.0612546 ]\n",
      " [ 10.01640529 -37.45863268  40.20974578 -27.80309859  28.15010867\n",
      "  -31.09133564  53.9840042   -6.24355685  20.99118773  39.06141494]\n",
      " [ -8.05663094  27.70781907 -27.80309859  21.7862591  -21.04708899\n",
      "   22.69031311 -40.08899129   5.30076225 -14.76793173 -29.35636427]\n",
      " [  4.94965187 -28.0933663   28.15010867 -21.04708899  25.34836987\n",
      "  -22.67847891  39.78996855  -8.99372226  13.76613254  30.56907877]\n",
      " [ -8.83744313  30.48963201 -31.09133564  22.69031311 -22.67847891\n",
      "   26.49091115 -44.1577886    5.33910789 -16.99065953 -31.81528619]\n",
      " [ 17.68639872 -53.48427706  53.9840042  -40.08899129  39.78996855\n",
      "  -44.1577886   82.1748363   -8.52945362  28.56588495  56.80376205]\n",
      " [  1.50925442   7.18207646  -6.24355685   5.30076225  -8.99372226\n",
      "    5.33910789  -8.52945362   8.73006529  -1.7151026   -9.5062796 ]\n",
      " [  5.59614202 -20.16488056  20.99118773 -14.76793173  13.76613254\n",
      "  -16.99065953  28.56588495  -1.7151026   13.73871203  19.89977266]\n",
      " [ 11.14655485 -39.0612546   39.06141494 -29.35636427  30.56907877\n",
      "  -31.81528619  56.80376205  -9.5062796   19.89977266  43.86861525]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:15<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 256 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1150.394\n",
      "w[1]    -292.324\n",
      "w[2]     105.152\n",
      "w[3]    -236.988\n",
      "w[4]       5.624\n",
      "w[5]    -166.634\n",
      "w[6]     446.175\n",
      "w[7]     -20.427\n",
      "w[8]      82.766\n",
      "w[9]     296.025\n",
      "Name: mean, dtype: float64\n",
      "[[  9.39487869 -10.96291704  10.62755159  -8.54062076   5.34600667\n",
      "   -9.37593745  18.71537271   1.51705096   5.93474865  11.83784433]\n",
      " [-10.96291704  40.85385631 -40.03388646  29.56596904 -30.05212698\n",
      "   32.59363134 -57.13658399   7.69728659 -21.65202993 -41.73972413]\n",
      " [ 10.62755159 -40.03388646  42.82093824 -29.647337    30.08744296\n",
      "  -33.19643174  57.59035586  -6.69894049  22.51668432  41.68000477]\n",
      " [ -8.54062076  29.56596904 -29.647337    23.07998704 -22.44326913\n",
      "   24.20817616 -42.73204922   5.68828581 -15.82461693 -31.27974646]\n",
      " [  5.34600667 -30.05212698  30.08744296 -22.44326913  26.87905865\n",
      "  -24.25803119  42.48826435  -9.52870678  14.86875708  32.62296126]\n",
      " [ -9.37593745  32.59363134 -33.19643174  24.20817616 -24.25803119\n",
      "   28.21670954 -47.1206909    5.73182601 -18.2023731  -33.98046084]\n",
      " [ 18.71537271 -57.13658399  57.59035586 -42.73204922  42.48826435\n",
      "  -47.1206909   87.36391178  -9.19381224  30.63827712  60.5596138 ]\n",
      " [  1.51705096   7.69728659  -6.69894049   5.68828581  -9.52870678\n",
      "    5.73182601  -9.19381224   9.11786724  -1.90725513 -10.12934939]\n",
      " [  5.93474865 -21.65202993  22.51668432 -15.82461693  14.86875708\n",
      "  -18.2023731   30.63827712  -1.90725513  14.6337621   21.39248441]\n",
      " [ 11.83784433 -41.73972413  41.68000477 -31.27974646  32.62296126\n",
      "  -33.98046084  60.5596138  -10.12934939  21.39248441  46.6208496 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:16<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 294 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1158.984\n",
      "w[1]    -304.297\n",
      "w[2]     116.661\n",
      "w[3]    -246.173\n",
      "w[4]      12.079\n",
      "w[5]    -176.671\n",
      "w[6]     465.744\n",
      "w[7]     -19.675\n",
      "w[8]      89.184\n",
      "w[9]     308.734\n",
      "Name: mean, dtype: float64\n",
      "[[  9.91378121 -11.53571666  11.15615609  -9.02323361   5.59398221\n",
      "   -9.87570667  19.7418275    1.59729541   6.21116629  12.47260175]\n",
      " [-11.53571666  42.83494139 -42.05115151  31.14269107 -31.55944867\n",
      "   34.2688431  -60.13313506   8.05184779 -22.73560864 -43.8281584 ]\n",
      " [ 11.15615609 -42.05115151  44.82752354 -31.22560416  31.60836279\n",
      "  -34.88760262  60.58998338  -7.00557143  23.66700609  43.74304513]\n",
      " [ -9.02323361  31.14269107 -31.22560416  24.33306519 -23.64136477\n",
      "   25.53931908 -45.09338755   5.99596136 -16.66632545 -32.96413659]\n",
      " [  5.59398221 -31.55944867  31.60836279 -23.64136477  28.15498837\n",
      "  -25.51357086  44.67398099 -10.03668478  15.66981217  34.27360856]\n",
      " [ -9.87570667  34.2688431  -34.88760262  25.53931908 -25.51357086\n",
      "   29.61627106 -49.63879902   5.98978104 -19.11466162 -35.73867562]\n",
      " [ 19.7418275  -60.13313506  60.58998338 -45.09338755  44.67398099\n",
      "  -49.63879902  91.89585063  -9.69494667  32.26471324  63.77267454]\n",
      " [  1.59729541   8.05184779  -7.00557143   5.99596136 -10.03668478\n",
      "    5.98978104  -9.69494667   9.5373543   -1.94984283 -10.65583127]\n",
      " [  6.21116629 -22.73560864  23.66700609 -16.66632545  15.66981217\n",
      "  -19.11466162  32.26471324  -1.94984283  15.28453529  22.45473165]\n",
      " [ 12.47260175 -43.8281584   43.74304513 -32.96413659  34.27360856\n",
      "  -35.73867562  63.77267454 -10.65583127  22.45473165  48.92797958]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:26<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 253 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1168.013\n",
      "w[1]    -316.859\n",
      "w[2]     128.725\n",
      "w[3]    -255.856\n",
      "w[4]      18.853\n",
      "w[5]    -187.220\n",
      "w[6]     486.348\n",
      "w[7]     -18.910\n",
      "w[8]      95.881\n",
      "w[9]     322.094\n",
      "Name: mean, dtype: float64\n",
      "[[ 10.45187865 -12.16338006  11.75892137  -9.53758482   5.89296915\n",
      "  -10.41491537  20.86968946   1.74309299   6.53328395  13.18769734]\n",
      " [-12.16338006  44.42542302 -43.67527048  32.32831228 -32.52295225\n",
      "   35.61861958 -62.52636566   7.99793803 -23.75319921 -45.46473023]\n",
      " [ 11.75892137 -43.67527048  46.41443873 -32.42651719  32.60678872\n",
      "  -36.22329133  62.99333846  -6.93329949  24.73152131  45.3582192 ]\n",
      " [ -9.53758482  32.32831228 -32.42651719  25.22413742 -24.35485098\n",
      "   26.55592436 -46.91089259   5.95935607 -17.40553275 -34.19678775]\n",
      " [  5.89296915 -32.52295225  32.60678872 -24.35485098  28.77071071\n",
      "  -26.32891613  46.04903035 -10.11263261  16.29786507  35.27721897]\n",
      " [-10.41491537  35.61861958 -36.22329133  26.55592436 -26.32891613\n",
      "   30.72935175 -51.65540363   5.93488824 -19.99404978 -37.09981407]\n",
      " [ 20.86968946 -62.52636566  62.99333846 -46.91089259  46.04903035\n",
      "  -51.65540363  95.55759723  -9.52931771  33.77118705  66.25604695]\n",
      " [  1.74309299   7.99793803  -6.93329949   5.95935607 -10.11263261\n",
      "    5.93488824  -9.52931771   9.80104669  -1.82435519 -10.67586167]\n",
      " [  6.53328395 -23.75319921  24.73152131 -17.40553275  16.29786507\n",
      "  -19.99404978  33.77118705  -1.82435519  16.01763772  23.4254779 ]\n",
      " [ 13.18769734 -45.46473023  45.3582192  -34.19678775  35.27721897\n",
      "  -37.09981407  66.25604695 -10.67586167  23.4254779   50.61788039]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:25<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 274 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1177.498\n",
      "w[1]    -329.984\n",
      "w[2]     141.323\n",
      "w[3]    -265.994\n",
      "w[4]      25.901\n",
      "w[5]    -198.244\n",
      "w[6]     507.902\n",
      "w[7]     -18.048\n",
      "w[8]     102.870\n",
      "w[9]     336.103\n",
      "Name: mean, dtype: float64\n",
      "[[ 11.09838518 -13.11137756  12.61941199 -10.27725206   6.42644034\n",
      "  -11.18555728  22.41629379   1.70289798   6.96530565  14.24473021]\n",
      " [-13.11137756  47.30680973 -46.54424523  34.5276811  -34.59057851\n",
      "   38.00149897 -66.69060707   8.47202365 -25.37316025 -48.54554938]\n",
      " [ 12.61941199 -46.54424523  49.25911855 -34.58344039  34.62460748\n",
      "  -38.56576032  67.02567903  -7.33698459  26.40137934  48.35434936]\n",
      " [-10.27725206  34.5276811  -34.58344039  26.88791794 -25.90072523\n",
      "   28.36934058 -50.06676154   6.3152405  -18.61732436 -36.53983614]\n",
      " [  6.42644034 -34.59057851  34.62460748 -25.90072523  30.30448999\n",
      "  -28.01292268  48.90049257 -10.60586356  17.42937528  37.48051679]\n",
      " [-11.18555728  38.00149897 -38.56576032  28.36934058 -28.01292268\n",
      "   32.66675659 -55.04717839   6.28076851 -21.34539015 -39.60169463]\n",
      " [ 22.41629379 -66.69060707  67.02567903 -50.06676154  48.90049257\n",
      "  -55.04717839 101.57242744 -10.17135936  36.04514192  70.72878647]\n",
      " [  1.70289798   8.47202365  -7.33698459   6.3152405  -10.60586356\n",
      "    6.28076851 -10.17135936  10.1510754   -1.95715486 -11.28260835]\n",
      " [  6.96530565 -25.37316025  26.40137934 -18.61732436  17.42937528\n",
      "  -21.34539015  36.04514192  -1.95715486  17.03548862  25.05555812]\n",
      " [ 14.24473021 -48.54554938  48.35434936 -36.53983614  37.48051679\n",
      "  -39.60169463  70.72878647 -11.28260835  25.05555812  53.97966565]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:10<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 256 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1187.488\n",
      "w[1]    -343.811\n",
      "w[2]     154.560\n",
      "w[3]    -276.687\n",
      "w[4]      33.332\n",
      "w[5]    -209.839\n",
      "w[6]     530.630\n",
      "w[7]     -17.194\n",
      "w[8]     110.169\n",
      "w[9]     350.892\n",
      "Name: mean, dtype: float64\n",
      "[[ 11.62396013 -13.94295791  13.42198997 -10.94252534   6.93791864\n",
      "  -11.88664583  23.76644752   1.65440999   7.35570798  15.19489024]\n",
      " [-13.94295791  51.02635151 -50.29889819  37.3672411  -37.64334432\n",
      "   41.08724988 -72.08138001   9.3519848  -27.32947931 -52.55606295]\n",
      " [ 13.42198997 -50.29889819  53.04451919 -37.44620764  37.66395489\n",
      "  -41.66855503  72.40645842  -8.15539922  28.40383672  52.34094863]\n",
      " [-10.94252534  37.3672411  -37.44620764  29.03058805 -28.20200414\n",
      "   30.71504792 -54.1755539    6.97470357 -20.09951933 -39.57719846]\n",
      " [  6.93791864 -37.64334432  37.66395489 -28.20200414  32.92292107\n",
      "  -30.52728293  53.23361663 -11.52710188  18.9828817   40.77224812]\n",
      " [-11.88664583  41.08724988 -41.66855503  30.71504792 -30.52728293\n",
      "   35.19480052 -59.51765206   6.98690012 -22.96699871 -42.9109115 ]\n",
      " [ 23.76644752 -72.08138001  72.40645842 -54.1755539   53.23361663\n",
      "  -59.51765206 109.33413221 -11.39561406  38.83837837  76.49555904]\n",
      " [  1.65440999   9.3519848   -8.15539922   6.97470357 -11.52710188\n",
      "    6.98690012 -11.39561406  10.6904382   -2.30308363 -12.31100193]\n",
      " [  7.35570798 -27.32947931  28.40383672 -20.09951933  18.9828817\n",
      "  -22.96699871  38.83837837  -2.30308363  18.11928428  27.08754684]\n",
      " [ 15.19489024 -52.55606295  52.34094863 -39.57719846  40.77224812\n",
      "  -42.9109115   76.49555904 -12.31100193  27.08754684  58.31568162]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:59<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 305 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1198.022\n",
      "w[1]    -358.759\n",
      "w[2]     168.898\n",
      "w[3]    -288.254\n",
      "w[4]      41.517\n",
      "w[5]    -222.376\n",
      "w[6]     555.098\n",
      "w[7]     -16.472\n",
      "w[8]     118.032\n",
      "w[9]     366.931\n",
      "Name: mean, dtype: float64\n",
      "[[ 12.2220748  -14.9316838   14.38343839 -11.70487274   7.45333498\n",
      "  -12.7209759   25.33034206   1.76312355   7.91406007  16.18937673]\n",
      " [-14.9316838   53.85987283 -53.17464924  39.56497351 -39.64689763\n",
      "   43.46623546 -76.35639842   9.69210006 -28.9250597  -55.47114674]\n",
      " [ 14.38343839 -53.17464924  55.95988968 -39.66469544  39.67764262\n",
      "  -44.08213835  76.71169758  -8.43708471  30.07981991  55.25222978]\n",
      " [-11.70487274  39.56497351 -39.66469544  30.71741502 -29.75275269\n",
      "   32.57003434 -57.49022691   7.23711253 -21.33277855 -41.82723994]\n",
      " [  7.45333498 -39.64689763  39.67764262 -29.75275269  34.50770016\n",
      "  -32.19385307  56.22210692 -12.02047474  20.05197632  42.89587857]\n",
      " [-12.7209759   43.46623546 -44.08213835  32.57003434 -32.19385307\n",
      "   37.18282778 -63.08335833   7.21779218 -24.32586351 -45.35747379]\n",
      " [ 25.33034206 -76.35639842  76.71169758 -57.49022691  56.22210692\n",
      "  -63.08335833 115.73700993 -11.84997745  41.2364626   80.858125  ]\n",
      " [  1.76312355   9.69210006  -8.43708471   7.23711253 -12.02047474\n",
      "    7.21779218 -11.84997745  11.155372    -2.32509538 -12.79140419]\n",
      " [  7.91406007 -28.9250597   30.07981991 -21.33277855  20.05197632\n",
      "  -24.32586351  41.2364626   -2.32509538  19.10438446  28.66858327]\n",
      " [ 16.18937673 -55.47114674  55.25222978 -41.82723994  42.89587857\n",
      "  -45.35747379  80.858125   -12.79140419  28.66858327  61.36041141]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:19<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 302 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1209.066\n",
      "w[1]    -374.648\n",
      "w[2]     184.159\n",
      "w[3]    -300.541\n",
      "w[4]      50.224\n",
      "w[5]    -235.706\n",
      "w[6]     581.030\n",
      "w[7]     -15.685\n",
      "w[8]     126.431\n",
      "w[9]     383.912\n",
      "Name: mean, dtype: float64\n",
      "[[ 12.97841036 -15.81417043  15.21893141 -12.41758312   7.90804501\n",
      "  -13.50358347  26.88599404   1.77419852   8.28378751  17.24368638]\n",
      " [-15.81417043  57.58163323 -56.90147096  42.37181239 -42.47682135\n",
      "   46.53498619 -81.65074692  10.61406003 -30.944076   -59.4086295 ]\n",
      " [ 15.21893141 -56.90147096  59.71614559 -42.48585822  42.47324971\n",
      "  -47.16700081  82.01194191  -9.29403884  32.16624681  59.16126056]\n",
      " [-12.41758312  42.37181239 -42.48585822  32.84023783 -31.87457359\n",
      "   34.89650981 -61.53420473   7.90474758 -22.85856995 -44.81153678]\n",
      " [  7.90804501 -42.47682135  42.47324971 -31.87457359  36.82750707\n",
      "  -34.48875064  60.11436339 -12.96731212  21.55346587  45.90262907]\n",
      " [-13.50358347  46.53498619 -47.16700081  34.89650981 -34.48875064\n",
      "   39.73915622 -67.480233     7.88880236 -26.02527538 -48.58462109]\n",
      " [ 26.88599404 -81.65074692  82.01194191 -61.53420473  60.11436339\n",
      "  -67.480233   123.43271058 -13.04244524  44.04637204  86.548156  ]\n",
      " [  1.77419852  10.61406003  -9.29403884   7.90474758 -12.96731212\n",
      "    7.88880236 -13.04244524  11.70203477  -2.69523168 -13.81515135]\n",
      " [  8.28378751 -30.944076    32.16624681 -22.85856995  21.55346587\n",
      "  -26.02527538  44.04637204  -2.69523168  20.29174834  30.72333663]\n",
      " [ 17.24368638 -59.4086295   59.16126056 -44.81153678  45.90262907\n",
      "  -48.58462109  86.548156   -13.81515135  30.72333663  65.5991812 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:14<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 296 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1220.711\n",
      "w[1]    -391.144\n",
      "w[2]     199.997\n",
      "w[3]    -313.337\n",
      "w[4]      59.211\n",
      "w[5]    -249.589\n",
      "w[6]     608.095\n",
      "w[7]     -14.841\n",
      "w[8]     135.082\n",
      "w[9]     401.639\n",
      "Name: mean, dtype: float64\n",
      "[[ 13.64999143 -16.53332756  15.89638074 -12.99241387   8.28810835\n",
      "  -14.11754129  28.17544086   1.84772859   8.56609195  18.07743475]\n",
      " [-16.53332756  60.8520988  -60.17563477  44.80780757 -45.25081327\n",
      "   49.19719753 -86.4265405   11.52615573 -32.61665249 -62.93663849]\n",
      " [ 15.89638074 -60.17563477  63.02466412 -44.90442737  45.21224395\n",
      "  -49.82778231  86.77427292 -10.12215489  33.9223115   62.61855897]\n",
      " [-12.99241387  44.80780757 -44.90442737  34.65112633 -33.93731205\n",
      "   36.89905939 -65.10523883   8.60204994 -24.09923044 -47.45439278]\n",
      " [  8.28810835 -45.25081327  45.21224395 -33.93731205  39.29110065\n",
      "  -36.72527547  64.03838548 -13.98464947  22.95646944  48.89523887]\n",
      " [-14.11754129  49.19719753 -49.82778231  36.89905939 -36.72527547\n",
      "   41.88816234 -71.37755562   8.57850933 -27.39919091 -51.45694989]\n",
      " [ 28.17544086 -86.4265405   86.77427292 -65.10523883  64.03838548\n",
      "  -71.37755562 130.44179329 -14.25278913  46.45574829  91.69732635]\n",
      " [  1.84772859  11.52615573 -10.12215489   8.60204994 -13.98464947\n",
      "    8.57850933 -14.25278913  12.42638713  -3.03394403 -14.92047704]\n",
      " [  8.56609195 -32.61665249  33.9223115  -24.09923044  22.95646944\n",
      "  -27.39919091  46.45574829  -3.03394403  21.23861476  32.46713363]\n",
      " [ 18.07743475 -62.93663849  62.61855897 -47.45439278  48.89523887\n",
      "  -51.45694989  91.69732635 -14.92047704  32.46713363  69.46588249]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:17<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 253 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1232.886\n",
      "w[1]    -408.419\n",
      "w[2]     216.567\n",
      "w[3]    -326.736\n",
      "w[4]      68.704\n",
      "w[5]    -264.116\n",
      "w[6]     636.442\n",
      "w[7]     -14.055\n",
      "w[8]     144.034\n",
      "w[9]     420.261\n",
      "Name: mean, dtype: float64\n",
      "[[ 14.39107244 -17.19761033  16.55812825 -13.56738922   8.51355693\n",
      "  -14.70091736  29.44254595   2.0884761    8.93400601  18.79853026]\n",
      " [-17.19761033  63.70162815 -63.20955241  47.05902617 -47.59540084\n",
      "   51.59556873 -90.64157596  12.28859788 -34.24715282 -66.12624516]\n",
      " [ 16.55812825 -63.20955241  66.22541453 -47.26420357  47.64240256\n",
      "  -52.3786815   91.23199344 -10.80495412  35.72638178  65.90733558]\n",
      " [-13.56738922  47.05902617 -47.26420357  36.39141415 -35.72548149\n",
      "   38.7781375  -68.43754883   9.15542739 -25.36538986 -49.94162653]\n",
      " [  8.51355693 -47.59540084  47.64240256 -35.72548149  41.37908352\n",
      "  -38.61397422  67.29675779 -14.98019795  24.17800612  51.5522744 ]\n",
      " [-14.70091736  51.59556873 -52.3786815   38.7781375  -38.61397422\n",
      "   43.91313239 -74.92377655   9.10451765 -28.79943223 -54.09508004]\n",
      " [ 29.44254595 -90.64157596  91.23199344 -68.43754883  67.29675779\n",
      "  -74.92377655 136.76612893 -15.12629382  48.86722184  96.35395197]\n",
      " [  2.0884761   12.28859788 -10.80495412   9.15542739 -14.98019795\n",
      "    9.10451765 -15.12629382  13.34423833  -3.19433941 -15.94342077]\n",
      " [  8.93400601 -34.24715282  35.72638178 -25.36538986  24.17800612\n",
      "  -28.79943223  48.86722184  -3.19433941  22.3247049   34.16408545]\n",
      " [ 18.79853026 -66.12624516  65.90733558 -49.94162653  51.5522744\n",
      "  -54.09508004  96.35395197 -15.94342077  34.16408545  73.0487106 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 01:53<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 227 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1245.643\n",
      "w[1]    -426.311\n",
      "w[2]     233.787\n",
      "w[3]    -340.679\n",
      "w[4]      78.487\n",
      "w[5]    -279.188\n",
      "w[6]     665.944\n",
      "w[7]     -13.116\n",
      "w[8]     153.344\n",
      "w[9]     439.553\n",
      "Name: mean, dtype: float64\n",
      "[[ 15.0233653  -17.74307738  17.08882772 -14.04936654   8.77691339\n",
      "  -15.15489945  30.59228542   2.24176767   9.16181793  19.46142063]\n",
      " [-17.74307738  65.58512121 -65.11209064  48.50271041 -49.09707414\n",
      "   53.1090355  -93.60632005  12.69739656 -35.19266793 -68.21143919]\n",
      " [ 17.08882772 -65.11209064  68.17583873 -48.71330028  49.11548149\n",
      "  -53.94262235  94.21066453 -11.11793686  36.77280177  67.97663992]\n",
      " [-14.04936654  48.50271041 -48.71330028  37.49210844 -36.86487955\n",
      "   39.94483544 -70.75031596   9.45553143 -26.08104016 -51.55439963]\n",
      " [  8.77691339 -49.09707414  49.11548149 -36.86487955  42.66294042\n",
      "  -39.79206062  69.49617007 -15.56875223  24.87928752  53.2479982 ]\n",
      " [-15.15489945  53.1090355  -53.94262235  39.94483544 -39.79206062\n",
      "   45.13952797 -77.34455042   9.36977501 -29.60148722 -55.75213511]\n",
      " [ 30.59228542 -93.60632005  94.21066453 -70.75031596  69.49617007\n",
      "  -77.34455042 141.59212492 -15.60344438  50.35278775  99.64768088]\n",
      " [  2.24176767  12.69739656 -11.11793686   9.45553143 -15.56875223\n",
      "    9.36977501 -15.60344438  13.94262322  -3.21577364 -16.50069236]\n",
      " [  9.16181793 -35.19266793  36.77280177 -26.08104016  24.87928752\n",
      "  -29.60148722  50.35278775  -3.21577364  22.92623489  35.1271484 ]\n",
      " [ 19.46142063 -68.21143919  67.97663992 -51.55439963  53.2479982\n",
      "  -55.75213511  99.64768088 -16.50069236  35.1271484   75.41325037]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:17<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 247 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1258.909\n",
      "w[1]    -444.574\n",
      "w[2]     251.358\n",
      "w[3]    -354.956\n",
      "w[4]      88.420\n",
      "w[5]    -294.572\n",
      "w[6]     696.281\n",
      "w[7]     -12.034\n",
      "w[8]     162.802\n",
      "w[9]     459.329\n",
      "Name: mean, dtype: float64\n",
      "[[  15.8265448   -18.73064034   18.02926413  -14.80142462    9.26195188\n",
      "   -15.99567113   32.28177078    2.36133971    9.68135551   20.54214547]\n",
      " [ -18.73064034   70.37316395  -69.92856771   52.04836362  -52.92079624\n",
      "    57.07787878 -100.51156985   13.95575814  -37.91856479  -73.27568901]\n",
      " [  18.02926413  -69.92856771   73.04683213  -52.26651322   52.91132253\n",
      "   -57.93725007  101.1201434   -12.26218044   39.59616111   72.99271453]\n",
      " [ -14.80142462   52.04836362  -52.26651322   40.08232286  -39.67028618\n",
      "    42.86354492  -75.8284004    10.37730687  -28.07986205  -55.28054423]\n",
      " [   9.26195188  -52.92079624   52.91132253  -39.67028618   45.89348019\n",
      "   -42.92022594   74.83990143  -16.91562652   26.96208512   57.29479431]\n",
      " [ -15.99567113   57.07787878  -57.93725007   42.86354492  -42.92022594\n",
      "    48.42229107  -83.07889123   10.34416932  -31.87549405  -59.9332109 ]\n",
      " [  32.28177078 -100.51156985  101.1201434   -75.8284004    74.83990143\n",
      "   -83.07889123  151.58652841  -17.2546686    54.2466173   106.93192666]\n",
      " [   2.36133971   13.95575814  -12.26218044   10.37730687  -16.91562652\n",
      "    10.34416932  -17.2546686    14.89867799   -3.67971414  -17.95574445]\n",
      " [   9.68135551  -37.91856479   39.59616111  -28.07986205   26.96208512\n",
      "   -31.87549405   54.2466173    -3.67971414   24.59868597   37.87911105]\n",
      " [  20.54214547  -73.27568901   72.99271453  -55.28054423   57.29479431\n",
      "   -59.9332109   106.93192666  -17.95574445   37.87911105   80.76803566]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:15<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 258 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1272.819\n",
      "w[1]    -463.807\n",
      "w[2]     269.854\n",
      "w[3]    -369.965\n",
      "w[4]      98.899\n",
      "w[5]    -310.779\n",
      "w[6]     728.219\n",
      "w[7]     -10.922\n",
      "w[8]     172.779\n",
      "w[9]     480.145\n",
      "Name: mean, dtype: float64\n",
      "[[  16.53934596  -19.05093796   18.30089196  -15.11570675    9.22046351\n",
      "   -16.24075254   33.08128166    2.65910855    9.7658754    20.97484112]\n",
      " [ -19.05093796   72.49422757  -72.11885196   53.67515908  -54.7871503\n",
      "    58.7289638  -103.559024     14.65242211  -39.02108632  -75.6542978 ]\n",
      " [  18.30089196  -72.11885196   75.31120535  -53.91908955   54.79643235\n",
      "   -59.63905452  104.21787984  -12.91159575   40.82192309   75.36383977]\n",
      " [ -15.11570675   53.67515908  -53.91908955   41.31488502  -41.0895529\n",
      "    44.12049521  -78.17739083   10.91727004  -28.89899609  -57.09946763]\n",
      " [   9.22046351  -54.7871503    54.79643235  -41.0895529    47.76880492\n",
      "   -44.3658543    77.35439637  -17.96792076   27.84707837   59.46384017]\n",
      " [ -16.24075254   58.7289638   -59.63905452   44.12049521  -44.3658543\n",
      "    49.68887093  -85.45456393   10.87395327  -32.74165533  -61.77475978]\n",
      " [  33.08128166 -103.559024    104.21787984  -78.17739083   77.35439637\n",
      "   -85.45456393  156.08899567  -18.11010537   55.78902022  110.3854396 ]\n",
      " [   2.65910855   14.65242211  -12.91159575   10.91727004  -17.96792076\n",
      "    10.87395327  -18.11010537   15.85176804   -3.77827763  -18.92935987]\n",
      " [   9.7658754   -39.02108632   40.82192309  -28.89899609   27.84707837\n",
      "   -32.74165533   55.78902022   -3.77827763   25.3367676    38.96231888]\n",
      " [  20.97484112  -75.6542978    75.36383977  -57.09946763   59.46384017\n",
      "   -61.77475978  110.3854396   -18.92935987   38.96231888   83.51958732]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:00<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 260 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1287.218\n",
      "w[1]    -483.254\n",
      "w[2]     288.536\n",
      "w[3]    -385.183\n",
      "w[4]     109.357\n",
      "w[5]    -327.131\n",
      "w[6]     760.693\n",
      "w[7]      -9.634\n",
      "w[8]     182.790\n",
      "w[9]     501.278\n",
      "Name: mean, dtype: float64\n",
      "[[  17.24170653  -19.71355684   18.91558583  -15.65643205    9.55750955\n",
      "   -16.78985535   34.35879829    2.74446966   10.03972524   21.75496439]\n",
      " [ -19.71355684   75.78456639  -75.37577092   56.06355196  -57.49847301\n",
      "    61.41811557 -108.38368306   15.3634951   -40.82845009  -79.08737009]\n",
      " [  18.91558583  -75.37577092   78.53241396  -56.27383273   57.46924158\n",
      "   -62.30730629  108.95997506  -13.56257391   42.66483764   78.71031084]\n",
      " [ -15.65643205   56.06355196  -56.27383273   43.05018339  -43.05072986\n",
      "    46.0725939   -81.72043843   11.45000185  -30.18042773  -59.6207244 ]\n",
      " [   9.55750955  -57.49847301   57.46924158  -43.05072986   50.13909903\n",
      "   -46.57863833   81.21115331  -18.77812161   29.29006004   62.3272615 ]\n",
      " [ -16.78985535   61.41811557  -62.30730629   46.0725939   -46.57863833\n",
      "    51.86766616  -89.38647995   11.44438723  -34.22348368  -64.56216038]\n",
      " [  34.35879829 -108.38368306  108.95997506  -81.72043843   81.21115331\n",
      "   -89.38647995  163.28071437  -19.04901382   58.38708238  115.4528402 ]\n",
      " [   2.74446966   15.3634951   -13.56257391   11.45000185  -18.77812161\n",
      "    11.44438723  -19.04901382   16.39058294   -4.02592873  -19.78017321]\n",
      " [  10.03972524  -40.82845009   42.66483764  -30.18042773   29.29006004\n",
      "   -34.22348368   58.38708238   -4.02592873   26.45096849   40.74321826]\n",
      " [  21.75496439  -79.08737009   78.71031084  -59.6207244    62.3272615\n",
      "   -64.56216038  115.4528402   -19.78017321   40.74321826   87.14774364]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:28<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 265 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1302.198\n",
      "w[1]    -503.374\n",
      "w[2]     307.851\n",
      "w[3]    -400.943\n",
      "w[4]     120.204\n",
      "w[5]    -344.041\n",
      "w[6]     794.414\n",
      "w[7]      -8.308\n",
      "w[8]     193.099\n",
      "w[9]     523.180\n",
      "Name: mean, dtype: float64\n",
      "[[  18.26934846  -21.32463148   20.42531041  -16.88714794   10.53280162\n",
      "   -18.09497445   36.96065312    2.75034963   10.82924096   23.48177673]\n",
      " [ -21.32463148   80.7765253   -80.41246352   59.7798176   -61.11989562\n",
      "    65.45776548 -115.61336171   16.07759438  -43.67114679  -84.24255696]\n",
      " [  20.42531041  -80.41246352   83.60576641  -60.0008564    61.12345941\n",
      "   -66.37648572  116.16588171  -14.23645202   45.62098695   83.8263685 ]\n",
      " [ -16.88714794   59.7798176   -60.0008564    45.80882152  -45.76680549\n",
      "    49.07995537  -87.13422594   12.00734494  -32.25793953  -63.50854835]\n",
      " [  10.53280162  -61.11989562   61.12345941  -45.76680549   52.91315811\n",
      "   -49.51362697   86.33178257  -19.59884744   31.2856929    66.15353187]\n",
      " [ -18.09497445   65.45776548  -66.37648572   49.07995537  -49.51362697\n",
      "    55.14478644  -95.24701702   11.98071751  -36.54683638  -68.73495389]\n",
      " [  36.96065312 -115.61336171  116.16588171  -87.13422594   86.33178257\n",
      "   -95.24701702  173.84311896  -19.95991775   62.46542153  122.95989125]\n",
      " [   2.75034963   16.07759438  -14.23645202   12.00734494  -19.59884744\n",
      "    11.98071751  -19.95991775   17.04876693   -4.2024084   -20.71149465]\n",
      " [  10.82924096  -43.67114679   45.62098695  -32.25793953   31.2856929\n",
      "   -36.54683638   62.46542153   -4.2024084    28.2466764    43.53296755]\n",
      " [  23.48177673  -84.24255696   83.8263685   -63.50854835   66.15353187\n",
      "   -68.73495389  122.95989125  -20.71149465   43.53296755   92.61225001]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:17<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 296 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1317.983\n",
      "w[1]    -524.919\n",
      "w[2]     328.518\n",
      "w[3]    -417.780\n",
      "w[4]     131.943\n",
      "w[5]    -362.100\n",
      "w[6]     830.363\n",
      "w[7]      -6.994\n",
      "w[8]     204.146\n",
      "w[9]     546.579\n",
      "Name: mean, dtype: float64\n",
      "[[  19.60363074  -22.82652034   21.91445637  -18.10578643   11.22252796\n",
      "   -19.38586087   39.67087299    3.11230869   11.62759028   25.12316742]\n",
      " [ -22.82652034   85.00608502  -84.70599918   62.94784063  -64.11527203\n",
      "    69.00706197 -121.97536952   16.62089427  -46.04351387  -88.60706973]\n",
      " [  21.91445637  -84.70599918   88.02639421  -63.20519653   64.09909419\n",
      "   -70.00184157  122.63328507  -14.64733477   48.17107443   88.19283166]\n",
      " [ -18.10578643   62.94784063  -63.20519653   48.18751977  -47.98476251\n",
      "    51.74762684  -91.96290637   12.39493972  -34.02247241  -66.81893147]\n",
      " [  11.22252796  -64.11527203   64.09909419  -47.98476251   55.30707168\n",
      "   -51.99232961   90.61695594  -20.52401355   32.84319749   69.3290072 ]\n",
      " [ -19.38586087   69.00706197  -70.00184157   51.74762684  -51.99232961\n",
      "    58.12952615 -100.60433914   12.34318195  -38.59153121  -72.39526461]\n",
      " [  39.67087299 -121.97536952  122.63328507  -91.96290637   90.61695594\n",
      "  -100.60433914  183.63146325  -20.47599971   66.05619952  129.57595561]\n",
      " [   3.11230869   16.62089427  -14.64733477   12.39493972  -20.52401355\n",
      "    12.34318195  -20.47599971   18.04997157   -4.15630939  -21.47569318]\n",
      " [  11.62759028  -46.04351387   48.17107443  -34.02247241   32.84319749\n",
      "   -38.59153121   66.05619952   -4.15630939   29.79571536   45.84601237]\n",
      " [  25.12316742  -88.60706973   88.19283166  -66.81893147   69.3290072\n",
      "   -72.39526461  129.57595561  -21.47569318   45.84601237   97.28510745]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 03:20<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 427 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1334.755\n",
      "w[1]    -547.488\n",
      "w[2]     350.203\n",
      "w[3]    -435.455\n",
      "w[4]     144.128\n",
      "w[5]    -381.045\n",
      "w[6]     868.216\n",
      "w[7]      -5.420\n",
      "w[8]     215.714\n",
      "w[9]     571.111\n",
      "Name: mean, dtype: float64\n",
      "[[  20.85360513  -23.84623898   22.87754254  -18.96280697   11.62422752\n",
      "   -20.31413456   41.70844292    3.36291844   12.0577696    26.37201494]\n",
      " [ -23.84623898   91.21275595  -91.15579201   67.56068143  -69.28085202\n",
      "    74.13922335 -130.79378399   18.29123745  -49.38378382  -95.22220372]\n",
      " [  22.87754254  -91.15579201   94.74963574  -67.96463116   69.39724028\n",
      "   -75.34535695  131.70509513  -16.23875578   51.73814947   94.94254711]\n",
      " [ -18.96280697   67.56068143  -67.96463116   51.60211827  -51.79484775\n",
      "    55.56489375  -98.55497547   13.6178528   -36.47443976  -71.74215262]\n",
      " [  11.62422752  -69.28085202   69.39724028  -51.79484775   59.91555462\n",
      "   -56.1714625    97.71338014  -22.48126492   35.4973194    74.92319606]\n",
      " [ -20.31413456   74.13922335  -75.34535695   55.56489375  -56.1714625\n",
      "    62.38828334 -107.92109685   13.58309037  -41.3899974   -77.82429893]\n",
      " [  41.70844292 -130.79378399  131.70509513  -98.55497547   97.71338014\n",
      "  -107.92109685  196.40837045  -22.59265545   70.73826289  139.05251383]\n",
      " [   3.36291844   18.29123745  -16.23875578   13.6178528   -22.48126492\n",
      "    13.58309037  -22.59265545   19.4719978    -4.68010893  -23.52080878]\n",
      " [  12.0577696   -49.38378382   51.73814947  -36.47443976   35.4973194\n",
      "   -41.3899974    70.73826289   -4.68010893   31.81043414   49.1864668 ]\n",
      " [  26.37201494  -95.22220372   94.94254711  -71.74215262   74.92319606\n",
      "   -77.82429893  139.05251383  -23.52080878   49.1864668   104.48518114]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:49<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 324 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1352.508\n",
      "w[1]    -571.013\n",
      "w[2]     372.824\n",
      "w[3]    -453.922\n",
      "w[4]     156.787\n",
      "w[5]    -400.855\n",
      "w[6]     907.906\n",
      "w[7]      -3.700\n",
      "w[8]     227.702\n",
      "w[9]     596.806\n",
      "Name: mean, dtype: float64\n",
      "[[  22.05416252  -24.64263908   23.69832112  -19.63523644   11.63110592\n",
      "   -21.07118767   43.34338081    4.035671     12.58770971   27.19243752]\n",
      " [ -24.64263908   93.95640182  -94.0986123    69.62011775  -71.05187153\n",
      "    76.54095206 -134.67342728   18.4153383   -51.18657595  -97.87767389]\n",
      " [  23.69832112  -94.0986123    97.92871722  -70.17238734   71.24965649\n",
      "   -77.91222055  135.86103483  -16.23195698   53.75952415   97.71805108]\n",
      " [ -19.63523644   69.62011775  -70.17238734   53.15683851  -53.11917553\n",
      "    57.36712511 -101.54162804   13.71079798  -37.79725565  -73.78584112]\n",
      " [  11.63110592  -71.05187153   71.24965649  -53.11917553   61.45561101\n",
      "   -57.670888     99.96184258  -23.22034379   36.48423197   76.77631118]\n",
      " [ -21.07118767   76.54095206  -77.91222055   57.36712511  -57.670888\n",
      "    64.4894736  -111.36051771   13.59184629  -42.9940142   -80.12449869]\n",
      " [  43.34338081 -134.67342728  135.86103483 -101.54162804   99.96184258\n",
      "  -111.36051771  202.18343643  -22.41914614   73.30346487  142.85464535]\n",
      " [   4.035671     18.4153383   -16.23195698   13.71079798  -23.22034379\n",
      "    13.59184629  -22.41914614   20.60141953   -4.37731167  -23.91920775]\n",
      " [  12.58770971  -51.18657595   53.75952415  -37.79725565   36.48423197\n",
      "   -42.9940142    73.30346487   -4.37731167   33.22449996   50.74256784]\n",
      " [  27.19243752  -97.87767389   97.71805108  -73.78584112   76.77631118\n",
      "   -80.12449869  142.85464535  -23.91920775   50.74256784  107.22740766]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:10<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 484 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1371.146\n",
      "w[1]    -595.097\n",
      "w[2]     396.036\n",
      "w[3]    -472.856\n",
      "w[4]     169.384\n",
      "w[5]    -421.203\n",
      "w[6]     948.738\n",
      "w[7]      -1.404\n",
      "w[8]     240.112\n",
      "w[9]     623.033\n",
      "Name: mean, dtype: float64\n",
      "[[  23.10179994  -25.75930103   24.83845618  -20.54847046   12.0836265\n",
      "   -22.0514313    45.38734716    4.4356928    13.25183125   28.38889638]\n",
      " [ -25.75930103  100.89616995 -101.16979289   74.80581382  -76.92832454\n",
      "    82.27650387 -144.48967587   20.59622024  -54.87228678 -105.35872087]\n",
      " [  24.83845618 -101.16979289  105.14838033  -75.43915203   77.16049288\n",
      "   -83.75761753  145.82168356  -18.30671586   57.59036798  105.2508627 ]\n",
      " [ -20.54847046   74.80581382  -75.43915203   57.01900266  -57.48790347\n",
      "    61.63499512 -108.91292709   15.33084636  -40.50558121  -79.39220372]\n",
      " [  12.0836265   -76.92832454   77.16049288  -57.48790347   66.85411045\n",
      "   -62.45746406  108.01995774  -25.79998299   39.37744127   83.26127272]\n",
      " [ -22.0514313    82.27650387  -83.75761753   61.63499512  -62.45746406\n",
      "    69.19790379 -119.45787187   15.29100301  -46.05720132  -86.26824541]\n",
      " [  45.38734716 -144.48967587  145.82168356 -108.91292709  108.01995774\n",
      "  -119.45787187  216.27207994  -25.15186183   78.50911989  153.43721948]\n",
      " [   4.4356928    20.59622024  -18.30671586   15.33084636  -25.79998299\n",
      "    15.29100301  -25.15186183   22.55725887   -5.08798696  -26.56319672]\n",
      " [  13.25183125  -54.87228678   57.59036798  -40.50558121   39.37744127\n",
      "   -46.05720132   78.50911989   -5.08798696   35.38921782   54.5244436 ]\n",
      " [  28.38889638 -105.35872087  105.2508627   -79.39220372   83.26127272\n",
      "   -86.26824541  153.43721948  -26.56319672   54.5244436   115.40558115]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 03:13<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 385 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1390.489\n",
      "w[1]    -620.152\n",
      "w[2]     420.224\n",
      "w[3]    -492.576\n",
      "w[4]     182.503\n",
      "w[5]    -442.395\n",
      "w[6]     991.245\n",
      "w[7]       1.044\n",
      "w[8]     253.064\n",
      "w[9]     650.318\n",
      "Name: mean, dtype: float64\n",
      "[[  24.57999328  -26.63333881   25.74884317  -21.28274064   12.06811881\n",
      "   -22.8525493    47.28746809    5.2172586    13.7777769    29.33524751]\n",
      " [ -26.63333881  107.44539335 -108.14095264   79.73175276  -82.45183303\n",
      "    87.74370834 -153.70947774   22.35273554  -58.6704592  -112.31366057]\n",
      " [  25.74884317 -108.14095264  112.62531507  -80.64708528   82.92073487\n",
      "   -89.60095827  155.57256388  -19.9295502    61.79974259  112.52587493]\n",
      " [ -21.28274064   79.73175276  -80.64708528   60.71334741  -61.60486886\n",
      "    65.7409341  -115.8522253    16.6415747   -43.32457775  -84.64198869]\n",
      " [  12.06811881  -82.45183303   82.92073487  -61.60486886   72.060769\n",
      "   -66.97323451  115.39200978  -28.23482181   42.30661151   89.29770618]\n",
      " [ -22.8525493    87.74370834  -89.60095827   65.7409341   -66.97323451\n",
      "    73.7764237  -127.15323855   16.59323029  -49.28578129  -92.00988683]\n",
      " [  47.28746809 -153.70947774  155.57256388 -115.8522253   115.39200978\n",
      "  -127.15323855  229.49828426  -27.13439305   83.83053184  163.20604739]\n",
      " [   5.2172586    22.35273554  -19.9295502    16.6415747   -28.23482181\n",
      "    16.59323029  -27.13439305   24.63003574   -5.52185116  -28.83791527]\n",
      " [  13.7777769   -58.6704592    61.79974259  -43.32457775   42.30661151\n",
      "   -49.28578129   83.83053184   -5.52185116   37.91625974   58.28077116]\n",
      " [  29.33524751 -112.31366057  112.52587493  -84.64198869   89.29770618\n",
      "   -92.00988683  163.20604739  -28.83791527   58.28077116  122.96234067]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 03:20<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 372 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1410.927\n",
      "w[1]    -645.866\n",
      "w[2]     445.119\n",
      "w[3]    -512.858\n",
      "w[4]     195.635\n",
      "w[5]    -464.194\n",
      "w[6]    1035.199\n",
      "w[7]       4.058\n",
      "w[8]     266.424\n",
      "w[9]     678.325\n",
      "Name: mean, dtype: float64\n",
      "[[  25.95416829  -27.77431618   26.82887309  -22.19955488   12.36883552\n",
      "   -23.83094198   49.50316755    5.73468753   14.37428557   30.54574372]\n",
      " [ -27.77431618  114.01579058 -114.83093537   84.57130306  -87.68743188\n",
      "    93.04228175 -163.0022184    23.8595691   -62.43236314 -119.0880341 ]\n",
      " [  26.82887309 -114.83093537  119.47253196  -85.57338164   88.19274505\n",
      "   -95.02162876  164.99413728  -21.3070711    65.76832234  119.32150285]\n",
      " [ -22.19955488   84.57130306  -85.57338164   64.28945712  -65.45116876\n",
      "    69.64543736 -122.76233149   17.74384053  -46.07770551  -89.66493127]\n",
      " [  12.36883552  -87.68743188   88.19274505  -65.45116876   76.7034687\n",
      "   -71.10668277  122.50102669  -30.20288952   45.12270284   94.86085278]\n",
      " [ -23.83094198   93.04228175  -95.02162876   69.64543736  -71.10668277\n",
      "    78.06002052 -134.71454823   17.63680826  -52.40436805  -97.42706505]\n",
      " [  49.50316755 -163.0022184   164.99413728 -122.76233149  122.50102669\n",
      "  -134.71454823  242.98147546  -28.88820307   89.12784288  172.83133753]\n",
      " [   5.73468753   23.8595691   -21.3070711    17.74384053  -30.20288952\n",
      "    17.63680826  -28.88820307   26.26157157   -5.95109946  -30.75795353]\n",
      " [  14.37428557  -62.43236314   65.76832234  -46.07770551   45.12270284\n",
      "   -52.40436805   89.12784288   -5.95109946   40.35280853   61.92935982]\n",
      " [  30.54574372 -119.0880341   119.32150285  -89.66493127   94.86085278\n",
      "   -97.42706505  172.83133753  -30.75795353   61.92935982  130.17148279]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:55<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 357 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1432.347\n",
      "w[1]    -672.416\n",
      "w[2]     470.808\n",
      "w[3]    -533.796\n",
      "w[4]     208.984\n",
      "w[5]    -486.700\n",
      "w[6]    1080.754\n",
      "w[7]       7.445\n",
      "w[8]     280.231\n",
      "w[9]     707.214\n",
      "Name: mean, dtype: float64\n",
      "[[  27.66074296  -29.63327959   28.6252876   -23.67275904   13.16095337\n",
      "   -25.40800087   52.7852045     6.14832326   15.35042415   32.52015339]\n",
      " [ -29.63327959  123.9888415  -124.77302739   91.99977241  -96.00043165\n",
      "   101.13191506 -177.10368294   26.9780909   -67.60468683 -129.79539529]\n",
      " [  28.6252876  -124.77302739  129.4409683   -92.97251115   96.39282297\n",
      "  -103.11852366  179.00806591  -24.23225735   71.05301579  129.87324195]\n",
      " [ -23.67275904   91.99977241  -92.97251115   69.82161818  -71.59005276\n",
      "    75.67167803 -133.27987706   20.02668239  -49.92038733  -97.63398247]\n",
      " [  13.16095337  -96.00043165   96.39282297  -71.59005276   84.13586235\n",
      "   -77.74125552  133.84248856  -33.68607884   49.22552322  103.90592547]\n",
      " [ -25.40800087  101.13191506 -103.11852366   75.67167803  -77.74125552\n",
      "    84.62076868 -146.17355732   19.97971446  -56.67495835 -106.03714241]\n",
      " [  52.7852045  -177.10368294  179.00806591 -133.27987706  133.84248856\n",
      "  -146.17355732  263.12477667  -32.80107455   96.44367928  187.9053003 ]\n",
      " [   6.14832326   26.9780909   -24.23225735   20.02668239  -33.68607884\n",
      "    19.97971446  -32.80107455   28.74518583   -7.09273659  -34.47848854]\n",
      " [  15.35042415  -67.60468683   71.05301579  -49.92038733   49.22552322\n",
      "   -56.67495835   96.44367928   -7.09273659   43.27167111   67.25585814]\n",
      " [  32.52015339 -129.79539529  129.87324195  -97.63398247  103.90592547\n",
      "  -106.03714241  187.9053003   -34.47848854   67.25585814  141.79509052]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 03:01<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 370 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1455.010\n",
      "w[1]    -700.482\n",
      "w[2]     497.972\n",
      "w[3]    -555.922\n",
      "w[4]     223.065\n",
      "w[5]    -510.494\n",
      "w[6]    1128.926\n",
      "w[7]      11.072\n",
      "w[8]     294.825\n",
      "w[9]     737.705\n",
      "Name: mean, dtype: float64\n",
      "[[  29.60746343  -32.01193988   30.87142148  -25.60564108   14.54990706\n",
      "   -27.38337552   56.96224006    6.22897331   16.40475848   35.25725625]\n",
      " [ -32.01193988  132.9929984  -133.9469553    98.85524801 -103.00592852\n",
      "   108.48776479 -190.1392363    28.84999473  -72.51726085 -139.33993543]\n",
      " [  30.87142148 -133.9469553   138.87221332  -99.93986774  103.50314598\n",
      "  -110.62106329  192.22573108  -25.95728792   76.24049089  139.46299364]\n",
      " [ -25.60564108   98.85524801  -99.93986774   75.04898224  -76.90400546\n",
      "    81.27410001 -143.28287842   21.45391898  -53.6143122  -104.95199995]\n",
      " [  14.54990706 -103.00592852  103.50314598  -76.90400546   89.90969213\n",
      "   -83.40695173  143.7400063   -35.72748387   52.92247121  111.4372463 ]\n",
      " [ -27.38337552  108.48776479 -110.62106329   81.27410001  -83.40695173\n",
      "    90.62405734 -156.82904766   21.38158378  -60.72874564 -113.77806188]\n",
      " [  56.96224006 -190.1392363   192.22573108 -143.28287842  143.7400063\n",
      "  -156.82904766  282.43080257  -35.19883537  103.42408029  201.87924568]\n",
      " [   6.22897331   28.84999473  -25.95728792   21.45391898  -35.72748387\n",
      "    21.38158378  -35.19883537   30.27107391   -7.71532138  -36.78299471]\n",
      " [  16.40475848  -72.51726085   76.24049089  -53.6143122    52.92247121\n",
      "   -60.72874564  103.42408029   -7.71532138   46.27605718   72.19291025]\n",
      " [  35.25725625 -139.33993543  139.46299364 -104.95199995  111.4372463\n",
      "  -113.77806188  201.87924568  -36.78299471   72.19291025  152.15421423]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 02:51<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 334 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1478.987\n",
      "w[1]    -730.383\n",
      "w[2]     526.899\n",
      "w[3]    -579.538\n",
      "w[4]     238.316\n",
      "w[5]    -535.799\n",
      "w[6]    1180.229\n",
      "w[7]      14.658\n",
      "w[8]     310.251\n",
      "w[9]     770.295\n",
      "Name: mean, dtype: float64\n",
      "[[  30.71891739  -32.50146779   31.44998844  -26.05035569   14.27745473\n",
      "   -27.95369344   58.21419287    7.19333045   16.91771025   35.67665236]\n",
      " [ -32.50146779  138.09779416 -139.31015385  102.5804941  -107.14163393\n",
      "   112.76274518 -197.06079997   29.85923122  -75.75805553 -144.46602936]\n",
      " [  31.44998844 -139.31015385  144.53488171 -103.82213615  107.6924043\n",
      "  -115.12745226  199.52187086  -26.736812     79.79780575  144.72051197]\n",
      " [ -26.05035569  102.5804941  -103.82213615   77.76255527  -79.88565287\n",
      "    84.38240386 -148.36725087   22.18389772  -55.94632072 -108.71026744]\n",
      " [  14.27745473 -107.14163393  107.6924043   -79.88565287   93.83580725\n",
      "   -86.7365585   148.96872835  -37.57866957   55.21281101  115.80081343]\n",
      " [ -27.95369344  112.76274518 -115.12745226   84.38240386  -86.7365585\n",
      "    94.18170069 -162.70524092   21.99046106  -63.51754869 -118.02569943]\n",
      " [  58.21419287 -197.06079997  199.52187086 -148.36725087  148.96872835\n",
      "  -162.70524092  292.13248743  -35.99812336  107.95927917  208.79026946]\n",
      " [   7.19333045   29.85923122  -26.736812     22.18389772  -37.57866957\n",
      "    21.99046106  -35.99812336   32.28819712   -7.69451775  -38.24993254]\n",
      " [  16.91771025  -75.75805553   79.79780575  -55.94632072   55.21281101\n",
      "   -63.51754869  107.95927917   -7.69451775   48.65218998   75.20772308]\n",
      " [  35.67665236 -144.46602936  144.72051197 -108.71026744  115.80081343\n",
      "  -118.02569943  208.79026946  -38.24993254   75.20772308  157.45269481]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 03:43<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 517 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1503.760\n",
      "w[1]    -760.547\n",
      "w[2]     556.136\n",
      "w[3]    -603.405\n",
      "w[4]     253.273\n",
      "w[5]    -561.444\n",
      "w[6]    1232.291\n",
      "w[7]      18.983\n",
      "w[8]     326.003\n",
      "w[9]     803.081\n",
      "Name: mean, dtype: float64\n",
      "[[  32.16620117  -34.16975618   33.05344303  -27.42160342   15.19669676\n",
      "   -29.38310208   61.20190591    7.23554087   17.63590354   37.63866351]\n",
      " [ -34.16975618  146.46083624 -147.72168184  108.8427967  -114.10232727\n",
      "   119.57806125 -208.98511272   32.3644362   -80.05064485 -153.49830669]\n",
      " [  33.05344303 -147.72168184  153.06629444 -110.10669573  114.60660144\n",
      "  -122.00542609  211.43764097  -29.00247257   84.30372235  153.6518356 ]\n",
      " [ -27.42160342  108.8427967  -110.10669573   82.4655756   -85.0833859\n",
      "    89.48948659 -157.34209036   24.06115998  -59.11247919 -115.52175045]\n",
      " [  15.19669676 -114.10232727  114.60660144  -85.0833859   100.03077813\n",
      "   -92.32462206  158.64716933  -40.35693115   58.56876719  123.46754856]\n",
      " [ -29.38310208  119.57806125 -122.00542609   89.48948659  -92.32462206\n",
      "    99.74403194 -172.4410162    23.88324625  -67.07623982 -125.3132747 ]\n",
      " [  61.20190591 -208.98511272  211.43764097 -157.34209036  158.64716933\n",
      "  -172.4410162   309.40617443  -39.32389288  113.96346437  221.77203205]\n",
      " [   7.23554087   32.3644362   -29.00247257   24.06115998  -40.35693115\n",
      "    23.88324625  -39.32389288   34.28430139   -8.42674377  -41.34832151]\n",
      " [  17.63590354  -80.05064485   84.30372235  -59.11247919   58.56876719\n",
      "   -67.07623982  113.96346437   -8.42674377   51.22586093   79.52128513]\n",
      " [  37.63866351 -153.49830669  153.6518356  -115.52175045  123.46754856\n",
      "  -125.3132747   221.77203205  -41.34832151   79.52128513  167.42471698]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 03:48<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 554 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1529.263\n",
      "w[1]    -791.304\n",
      "w[2]     585.928\n",
      "w[3]    -627.790\n",
      "w[4]     268.529\n",
      "w[5]    -587.602\n",
      "w[6]    1285.569\n",
      "w[7]      23.321\n",
      "w[8]     341.907\n",
      "w[9]     836.666\n",
      "Name: mean, dtype: float64\n",
      "[[  34.10079335  -35.66313311   34.50472434  -28.71356137   15.69003976\n",
      "   -30.69327678   64.23740375    7.9024743    18.29877279   39.40077069]\n",
      " [ -35.66313311  154.52890146 -156.07494961  114.84720927 -120.5689161\n",
      "   126.22849386 -220.35915299   34.0713223   -84.68877047 -161.96441339]\n",
      " [  34.50472434 -156.07494961  161.77288965 -116.2869404   121.16255803\n",
      "  -128.89215478  223.1328987   -30.44556087   89.33545793  162.22816452]\n",
      " [ -28.71356137  114.84720927 -116.2869404    86.94710318  -89.85361386\n",
      "    94.43853024 -165.92014639   25.32810362  -62.48630992 -121.88789885]\n",
      " [  15.69003976 -120.5689161   121.16255803  -89.85361386  105.80586428\n",
      "   -97.56309145  167.36100202  -42.83347726   61.96617612  130.5126591 ]\n",
      " [ -30.69327678  126.22849386 -128.89215478   94.43853024  -97.56309145\n",
      "   105.21245595 -181.85168579   25.09149706  -70.96265136 -132.22419098]\n",
      " [  64.23740375 -220.35915299  223.1328987  -165.92014639  167.36100202\n",
      "  -181.85168579  325.88338151  -41.22648971  120.35909118  233.81516295]\n",
      " [   7.9024743    34.0713223   -30.44556087   25.32810362  -42.83347726\n",
      "    25.09149706  -41.22648971   36.72671443   -8.61505896  -43.76471166]\n",
      " [  18.29877279  -84.68877047   89.33545793  -62.48630992   61.96617612\n",
      "   -70.96265136  120.35909118   -8.61505896   54.42866547   83.91029529]\n",
      " [  39.40077069 -161.96441339  162.22816452 -121.88789885  130.5126591\n",
      "  -132.22419098  233.81516295  -43.76471166   83.91029529  176.67161074]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:05<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 528 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1556.116\n",
      "w[1]    -823.254\n",
      "w[2]     616.881\n",
      "w[3]    -653.195\n",
      "w[4]     284.270\n",
      "w[5]    -614.804\n",
      "w[6]    1341.165\n",
      "w[7]      28.054\n",
      "w[8]     358.360\n",
      "w[9]     871.647\n",
      "Name: mean, dtype: float64\n",
      "[[  36.47228508  -37.55893572   36.24969066  -30.29150333   16.26989316\n",
      "   -32.34642644   67.95725162    8.58098882   19.14845064   41.51580335]\n",
      " [ -37.55893572  162.20358807 -163.88575831  120.64077105 -126.43081222\n",
      "   132.63235266 -231.44993995   35.59105785  -88.95282953 -169.98806421]\n",
      " [  36.24969066 -163.88575831  169.82997227 -122.14875575  127.00551792\n",
      "  -135.44977632  234.27453552  -31.67970389   93.96364756  170.18543843]\n",
      " [ -30.29150333  120.64077105 -122.14875575   91.33713983  -94.26372897\n",
      "    99.25804919 -174.3749773    26.51237682  -65.63835325 -128.01684158]\n",
      " [  16.26989316 -126.43081222  127.00551792  -94.26372897  110.96381766\n",
      "  -102.3304942   175.39808577  -45.18054648   64.88577271  136.90058005]\n",
      " [ -32.34642644  132.63235266 -135.44977632   99.25804919 -102.3304942\n",
      "   110.56885222 -191.13194453   26.1471354   -74.62624154 -138.83214516]\n",
      " [  67.95725162 -231.44993995  234.27453552 -174.3749773   175.39808577\n",
      "  -191.13194453  342.41951448  -42.93578441  126.39131838  245.50143802]\n",
      " [   8.58098882   35.59105785  -31.67970389   26.51237682  -45.18054648\n",
      "    26.1471354   -42.93578441   39.17077514   -8.62554649  -46.02286053]\n",
      " [  19.14845064  -88.95282953   93.96364756  -65.63835325   64.88577271\n",
      "   -74.62624154  126.39131838   -8.62554649   57.3866446    87.90899657]\n",
      " [  41.51580335 -169.98806421  170.18543843 -128.01684158  136.90058005\n",
      "  -138.83214516  245.50143802  -46.02286053   87.90899657  185.41486379]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:09<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 555 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1584.474\n",
      "w[1]    -856.008\n",
      "w[2]     648.560\n",
      "w[3]    -679.313\n",
      "w[4]     300.020\n",
      "w[5]    -642.752\n",
      "w[6]    1398.607\n",
      "w[7]      33.385\n",
      "w[8]     375.142\n",
      "w[9]     907.560\n",
      "Name: mean, dtype: float64\n",
      "[[  37.65745538  -37.65732414   36.30567101  -30.49599816   15.79395522\n",
      "   -32.51661203   68.73614439    9.23740022   19.13251742   41.75499719]\n",
      " [ -37.65732414  164.69828955 -166.70106098  122.57661252 -128.50384624\n",
      "   134.82133841 -234.91188617   36.28959087  -90.52877532 -172.57990711]\n",
      " [  36.30567101 -166.70106098  173.02722397 -124.29837514  129.24704207\n",
      "  -137.93991846  238.12977073  -32.23585708   95.89087735  172.95207283]\n",
      " [ -30.49599816  122.57661252 -124.29837514   92.8454167   -95.84240132\n",
      "   100.94628073 -177.12249245   27.07081352  -66.80568221 -130.06161346]\n",
      " [  15.79395522 -128.50384624  129.24704207  -95.84240132  113.16056509\n",
      "  -104.03246039  178.00101173  -46.60755584   65.94040522  139.21068173]\n",
      " [ -32.51661203  134.82133841 -137.93991846  100.94628073 -104.03246039\n",
      "   112.49172536 -194.2088308    26.53900325  -76.08457713 -141.0204277 ]\n",
      " [  68.73614439 -234.91188617  238.12977073 -177.12249245  178.00101173\n",
      "  -194.2088308   347.59093692  -43.62934935  128.4957574   249.20533431]\n",
      " [   9.23740022   36.28959087  -32.23585708   27.07081352  -46.60755584\n",
      "    26.53900325  -43.62934935   40.82019817   -8.46468703  -47.1705927 ]\n",
      " [  19.13251742  -90.52877532   95.89087735  -66.80568221   65.94040522\n",
      "   -76.08457713  128.4957574    -8.46468703   58.73125436   89.23258968]\n",
      " [  41.75499719 -172.57990711  172.95207283 -130.06161346  139.21068173\n",
      "  -141.0204277   249.20533431  -47.1705927    89.23258968  188.29373244]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:09<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 553 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1613.433\n",
      "w[1]    -888.804\n",
      "w[2]     680.266\n",
      "w[3]    -705.538\n",
      "w[4]     315.502\n",
      "w[5]    -670.786\n",
      "w[6]    1456.441\n",
      "w[7]      39.079\n",
      "w[8]     391.928\n",
      "w[9]     943.578\n",
      "Name: mean, dtype: float64\n",
      "[[  38.95664731  -38.62155175   37.18836588  -31.29112743   15.9550161\n",
      "   -33.3822999    70.6208661     9.79433741   19.67534937   42.75882211]\n",
      " [ -38.62155175  169.68060004 -171.92949372  126.34092178 -132.44897665\n",
      "   139.01846289 -242.06067162   37.08857165  -93.52818777 -177.67799813]\n",
      " [  37.18836588 -171.92949372  178.57124791 -128.22309298  133.33773794\n",
      "  -142.34094214  245.55952946  -32.89463538   99.20036869  178.15618326]\n",
      " [ -31.29112743  126.34092178 -128.22309298   95.70128673  -98.82032317\n",
      "   104.11180598 -182.55381813   27.70512112  -69.03674475 -133.9555538 ]\n",
      " [  15.9550161  -132.44897665  133.33773794  -98.82032317  116.8244237\n",
      "  -107.28298262  183.40408322  -48.14006907   68.06232542  143.49035091]\n",
      " [ -33.3822999   139.01846289 -142.34094214  104.11180598 -107.28298262\n",
      "   116.01637503 -200.25330343   27.07040007  -78.65368171 -145.2636544 ]\n",
      " [  70.6208661  -242.06067162  245.55952946 -182.55381813  183.40408322\n",
      "  -200.25330343  358.0572783   -44.50413328  132.77213544  256.57100281]\n",
      " [   9.79433741   37.08857165  -32.89463538   27.70512112  -48.14006907\n",
      "    27.07040007  -44.50413328   42.52356449   -8.33583583  -48.54101495]\n",
      " [  19.67534937  -93.52818777   99.20036869  -69.03674475   68.06232542\n",
      "   -78.65368171  132.77213544   -8.33583583   60.89212545   91.99122415]\n",
      " [  42.75882211 -177.67799813  178.15618326 -133.9555538   143.49035091\n",
      "  -145.2636544   256.57100281  -48.54101495   91.99122415  193.77587885]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:09<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 571 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1643.127\n",
      "w[1]    -921.623\n",
      "w[2]     711.903\n",
      "w[3]    -731.835\n",
      "w[4]     330.609\n",
      "w[5]    -698.879\n",
      "w[6]    1514.637\n",
      "w[7]      45.274\n",
      "w[8]     408.713\n",
      "w[9]     979.613\n",
      "Name: mean, dtype: float64\n",
      "[[  41.25817866  -39.67451416   38.17957791  -32.2485794    15.69465315\n",
      "   -34.34897323   73.30441446   10.99468527   20.20011094   43.94792014]\n",
      " [ -39.67451416  175.88102026 -178.36020504  131.05157222 -137.19692678\n",
      "   144.21780289 -250.79902147   38.4009931   -97.20780786 -183.91353426]\n",
      " [  38.17957791 -178.36020504  185.35406566 -133.06767165  138.174332\n",
      "  -147.7823569   254.57285371  -33.97931343  103.22593257  184.44348907]\n",
      " [ -32.2485794   131.05157222 -133.06767165   99.26105065 -102.35608961\n",
      "   108.05534851 -189.26500935   28.62711974  -71.79050235 -138.72348832]\n",
      " [  15.69465315 -137.19692678  138.174332   -102.35608961  121.17668839\n",
      "  -111.16924931  189.47323385  -50.33552022   70.64700179  148.43512844]\n",
      " [ -34.34897323  144.21780289 -147.7823569   108.05534851 -111.16924931\n",
      "   120.38924006 -207.64647026   27.99319612  -81.81664319 -150.45415785]\n",
      " [  73.30441446 -250.79902147  254.57285371 -189.26500935  189.47323385\n",
      "  -207.64647026  371.0207857   -45.50689708  137.94532982  265.41405164]\n",
      " [  10.99468527   38.4009931   -33.97931343   28.62711974  -50.33552022\n",
      "    27.99319612  -45.50689708   44.89025125   -8.50183157  -50.30564526]\n",
      " [  20.20011094  -97.20780786  103.22593257  -71.79050235   70.64700179\n",
      "   -81.81664319  137.94532982   -8.50183157   63.47188648   95.37347397]\n",
      " [  43.94792014 -183.91353426  184.44348907 -138.72348832  148.43512844\n",
      "  -150.45415785  265.41405164  -50.30564526   95.37347397  200.2849318 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:08<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 573 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1674.301\n",
      "w[1]    -955.082\n",
      "w[2]     744.187\n",
      "w[3]    -758.725\n",
      "w[4]     345.479\n",
      "w[5]    -727.584\n",
      "w[6]    1574.555\n",
      "w[7]      52.330\n",
      "w[8]     425.858\n",
      "w[9]    1016.341\n",
      "Name: mean, dtype: float64\n",
      "[[  43.39573586  -39.30584289   37.61516155  -32.11349763   14.38613643\n",
      "   -34.11405765   73.91516754   12.3818647    19.82634927   43.77973076]\n",
      " [ -39.30584289  178.22076852 -180.55290352  132.71419734 -139.6941701\n",
      "   145.99887954 -253.71379137   39.91017426  -98.28666494 -186.55237607]\n",
      " [  37.61516155 -180.55290352  187.48567957 -134.57245392  140.42035818\n",
      "  -149.47502008  257.13830035  -35.10784338  104.47829841  186.69188872]\n",
      " [ -32.11349763  132.71419734 -134.57245392  100.44236352 -104.10627096\n",
      "   109.29185335 -191.3902738    29.72334271  -72.48969656 -140.6508289 ]\n",
      " [  14.38613643 -139.6941701   140.42035818 -104.10627096  124.57135368\n",
      "  -112.93815852  192.11509268  -53.21056299   71.43606506  151.49027828]\n",
      " [ -34.11405765  145.99887954 -149.47502008  109.29185335 -112.93815852\n",
      "   121.74927754 -209.86040774   28.89854518  -82.74499385 -152.3441618 ]\n",
      " [  73.91516754 -253.71379137  257.13830035 -191.3902738   192.11509268\n",
      "  -209.86040774  375.17781465  -46.84139575  139.15531651  268.80967382]\n",
      " [  12.3818647    39.91017426  -35.10784338   29.72334271  -53.21056299\n",
      "    28.89854518  -46.84139575   48.19566379   -8.30408543  -52.66673731]\n",
      " [  19.82634927  -98.28666494  104.47829841  -72.48969656   71.43606506\n",
      "   -82.74499385  139.15531651   -8.30408543   64.55302412   96.08300302]\n",
      " [  43.77973076 -186.55237607  186.69188872 -140.6508289   151.49027828\n",
      "  -152.3441618   268.80967382  -52.66673731   96.08300302  203.63860419]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:07<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 544 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1706.490\n",
      "w[1]    -987.153\n",
      "w[2]     774.907\n",
      "w[3]    -784.663\n",
      "w[4]     358.698\n",
      "w[5]    -755.166\n",
      "w[6]    1633.160\n",
      "w[7]      60.367\n",
      "w[8]     442.075\n",
      "w[9]    1051.803\n",
      "Name: mean, dtype: float64\n",
      "[[  47.15349592  -42.51655165   40.51900495  -34.72591841   15.64178565\n",
      "   -36.86189154   80.08277755   13.10429634   21.15022337   47.55322112]\n",
      " [ -42.51655165  188.11464408 -190.61746184  140.12052939 -147.07854917\n",
      "   154.16475144 -268.49995602   41.54468943 -103.66301401 -197.01915001]\n",
      " [  40.51900495 -190.61746184  197.8729768  -142.06656442  147.87694281\n",
      "  -157.80774734  271.95262508  -36.5582498   110.22163067  197.08279575]\n",
      " [ -34.72591841  140.12052939 -142.06656442  106.00266358 -109.55928805\n",
      "   115.38768207 -202.55392091   30.92382139  -76.43909018 -148.55260462]\n",
      " [  15.64178565 -147.07854917  147.87694281 -109.55928805  130.85426806\n",
      "  -118.9087298   202.57935643  -55.65208858   75.19394559  159.48387821]\n",
      " [ -36.86189154  154.16475144 -157.80774734  115.38768207 -118.9087298\n",
      "   128.50703084 -222.11015001   30.03895232  -87.26233944 -160.93135625]\n",
      " [  80.08277755 -268.49995602  271.95262508 -202.55392091  202.57935643\n",
      "  -222.11015001  397.89680723  -48.71575696  146.94027217  284.67435996]\n",
      " [  13.10429634   41.54468943  -36.5582498    30.92382139  -55.65208858\n",
      "    30.03895232  -48.71575696   50.5008357    -8.50552037  -54.97039085]\n",
      " [  21.15022337 -103.66301401  110.22163067  -76.43909018   75.19394559\n",
      "   -87.26233944  146.94027217   -8.50552037   68.05286595  101.27139195]\n",
      " [  47.55322112 -197.01915001  197.08279575 -148.55260462  159.48387821\n",
      "  -160.93135625  284.67435996  -54.97039085  101.27139195  215.15741305]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:00<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 535 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1741.127\n",
      "w[1]   -1020.998\n",
      "w[2]     807.170\n",
      "w[3]    -812.055\n",
      "w[4]     372.462\n",
      "w[5]    -784.277\n",
      "w[6]    1695.336\n",
      "w[7]      68.956\n",
      "w[8]     458.951\n",
      "w[9]    1089.397\n",
      "Name: mean, dtype: float64\n",
      "[[  50.12544822  -44.62605905   42.47169622  -36.53081647   16.13222548\n",
      "   -38.71324789   84.45794754   14.07443704   22.0410002    50.04289862]\n",
      " [ -44.62605905  199.11589981 -201.86212216  148.2421041  -155.77739816\n",
      "   163.20656196 -284.14919293   43.97134457 -109.89550595 -208.38828613]\n",
      " [  42.47169622 -201.86212216  209.51026323 -150.33940964  156.67534944\n",
      "  -167.08959487  287.80116188  -38.73683242  116.8833829   208.48748473]\n",
      " [ -36.53081647  148.2421041  -150.33940964  112.03024109 -115.90471554\n",
      "   122.07832712 -214.24629008   32.64554703  -80.97509347 -157.01391353]\n",
      " [  16.13222548 -155.77739816  156.67534944 -115.90471554  138.58285474\n",
      "  -125.93498306  214.31944281  -58.90128187   79.86014377  168.65935107]\n",
      " [ -38.71324789  163.20656196 -167.08959487  122.07832712 -125.93498306\n",
      "   135.94105447 -235.02812137   31.79592294  -92.47327993 -170.22416045]\n",
      " [  84.45794754 -284.14919293  287.80116188 -214.24629008  214.31944281\n",
      "  -235.02812137  420.8962955   -51.43303395  155.60839375  301.04733202]\n",
      " [  14.07443704   43.97134457  -38.73683242   32.64554703  -58.90128187\n",
      "    31.79592294  -51.43303395   53.30149579   -9.14597246  -58.01153662]\n",
      " [  22.0410002  -109.89550595  116.8833829   -80.97509347   79.86014377\n",
      "   -92.47327993  155.60839375   -9.14597246   72.17085825  107.24423038]\n",
      " [  50.04289862 -208.38828613  208.48748473 -157.01391353  168.65935107\n",
      "  -170.22416045  301.04733202  -58.01153662  107.24423038  227.27779853]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:25<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 543 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1777.272\n",
      "w[1]   -1055.884\n",
      "w[2]     840.407\n",
      "w[3]    -840.362\n",
      "w[4]     386.441\n",
      "w[5]    -814.309\n",
      "w[6]    1759.742\n",
      "w[7]      78.053\n",
      "w[8]     476.263\n",
      "w[9]    1128.244\n",
      "Name: mean, dtype: float64\n",
      "[[  52.37865696  -46.75875757   44.68232256  -38.25587352   16.89931131\n",
      "   -40.62790538   88.58246862   14.94699394   23.29907434   52.37725969]\n",
      " [ -46.75875757  207.4327622  -210.44343398  154.53111239 -162.12985861\n",
      "   170.12614559 -296.36493331   45.32512874 -114.70362862 -217.11096645]\n",
      " [  44.68232256 -210.44343398  218.41200851 -156.82310643  163.12077222\n",
      "  -174.22976577  300.39278285  -39.89374447  121.97894807  217.37748353]\n",
      " [ -38.25587352  154.53111239 -156.82310643  116.77940277 -120.65594284\n",
      "   127.31236343 -223.54384022   33.61753788  -84.5849005  -163.61605477]\n",
      " [  16.89931131 -162.12985861  163.12077222 -120.65594284  144.05146025\n",
      "  -131.09082828  223.1364923   -60.98682809   83.26009454  175.47917528]\n",
      " [ -40.62790538  170.12614559 -174.22976577  127.31236343 -131.09082828\n",
      "   141.69086427 -245.25728152   32.7220414   -96.51170499 -177.42692698]\n",
      " [  88.58246862 -296.36493331  300.39278285 -223.54384022  223.1364923\n",
      "  -245.25728152  439.37563979  -52.77519585  162.65462635  313.92407965]\n",
      " [  14.94699394   45.32512874  -39.89374447   33.61753788  -60.98682809\n",
      "    32.7220414   -52.77519585   55.34584883   -9.33260092  -59.83346386]\n",
      " [  23.29907434 -114.70362862  121.97894807  -84.5849005    83.26009454\n",
      "   -96.51170499  162.65462635   -9.33260092   75.26276489  111.99800557]\n",
      " [  52.37725969 -217.11096645  217.37748353 -163.61605477  175.47917528\n",
      "  -177.42692698  313.92407965  -59.83346386  111.99800557  236.65273398]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:22<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 580 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1814.550\n",
      "w[1]   -1091.409\n",
      "w[2]     874.359\n",
      "w[3]    -869.213\n",
      "w[4]     400.406\n",
      "w[5]    -844.964\n",
      "w[6]    1825.682\n",
      "w[7]      87.829\n",
      "w[8]     494.009\n",
      "w[9]    1167.799\n",
      "Name: mean, dtype: float64\n",
      "[[  53.65354766  -49.47951273   47.33758011  -40.30695347   18.82707165\n",
      "   -42.90316352   92.88582075   14.36404191   24.57356459   55.41867002]\n",
      " [ -49.47951273  216.78529091 -219.9254218   161.44385173 -168.86302807\n",
      "   177.80234351 -310.07271062   46.51444912 -120.00799668 -226.69095575]\n",
      " [  47.33758011 -219.9254218   228.12955704 -163.80032874  169.81649017\n",
      "  -182.03734344  314.21624688  -40.77436284  127.58536268  226.87833209]\n",
      " [ -40.30695347  161.44385173 -163.80032874  121.88369184 -125.65687372\n",
      "   132.9872744  -233.70407824   34.56325774  -88.46648554 -170.73354673]\n",
      " [  18.82707165 -168.86302807  169.81649017 -125.65687372  149.0603266\n",
      "  -136.5323584   232.94907668  -62.17011297   86.87217575  182.51091273]\n",
      " [ -42.90316352  177.80234351 -182.03734344  132.9872744  -136.5323584\n",
      "   147.98224212 -256.52431496   33.56402585 -100.92203248 -185.23513782]\n",
      " [  92.88582075 -310.07271062  314.21624688 -233.70407824  232.94907668\n",
      "  -256.52431496  459.62641801  -54.60845171  170.27047708  328.08317531]\n",
      " [  14.36404191   46.51444912  -40.77436284   34.56325774  -62.17011297\n",
      "    33.56402585  -54.60845171   56.22847798   -9.43264112  -61.49622805]\n",
      " [  24.57356459 -120.00799668  127.58536268  -88.46648554   86.87217575\n",
      "  -100.92203248  170.27047708   -9.43264112   78.7146164   117.06698689]\n",
      " [  55.41867002 -226.69095575  226.87833209 -170.73354673  182.51091273\n",
      "  -185.23513782  328.08317531  -61.49622805  117.06698689  246.72636903]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 03:36<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 555 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1852.328\n",
      "w[1]   -1128.289\n",
      "w[2]     909.600\n",
      "w[3]    -899.063\n",
      "w[4]     415.425\n",
      "w[5]    -876.744\n",
      "w[6]    1893.705\n",
      "w[7]      97.125\n",
      "w[8]     512.342\n",
      "w[9]    1208.890\n",
      "Name: mean, dtype: float64\n",
      "[[  57.07235825  -52.85973117   50.50694419  -43.10567479   20.19053561\n",
      "   -45.79601943   99.14444853   15.2478414    26.24730296   59.1679129 ]\n",
      " [ -52.85973117  231.32513372 -234.46537993  172.38338298 -180.52737732\n",
      "   189.58324021 -330.97098515   50.23298071 -127.55521791 -242.23062887]\n",
      " [  50.50694419 -234.46537993  242.85245103 -174.66559904  181.25185047\n",
      "  -193.86404238  334.97585409  -43.90606343  135.56807838  242.0569554 ]\n",
      " [ -43.10567479  172.38338298 -174.66559904  130.11405791 -134.36559089\n",
      "   141.83782386 -249.56495758   37.34939471  -94.03840405 -182.49906127]\n",
      " [  20.19053561 -180.52737732  181.25185047 -134.36559089  159.67133817\n",
      "  -145.75725465  249.0432523   -67.26597041   92.23079143  195.49331989]\n",
      " [ -45.79601943  189.58324021 -193.86404238  141.83782386 -145.75725465\n",
      "   157.5435648  -273.52101862   36.16891016 -107.20144932 -197.67158119]\n",
      " [  99.14444853 -330.97098515  334.97585409 -249.56495758  249.0432523\n",
      "  -273.52101862  490.3870885   -59.13691254  181.02724524  350.53503033]\n",
      " [  15.2478414    50.23298071  -43.90606343   37.34939471  -67.26597041\n",
      "    36.16891016  -59.13691254   60.94875736   -9.82075517  -66.65398159]\n",
      " [  26.24730296 -127.55521791  135.56807838  -94.03840405   92.23079143\n",
      "  -107.20144932  181.02724524   -9.82075517   83.57525269  124.35774583]\n",
      " [  59.1679129  -242.23062887  242.0569554  -182.49906127  195.49331989\n",
      "  -197.67158119  350.53503033  -66.65398159  124.35774583  263.93720185]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 03:57<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 477 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1891.998\n",
      "w[1]   -1166.593\n",
      "w[2]     946.127\n",
      "w[3]    -930.146\n",
      "w[4]     430.789\n",
      "w[5]    -909.756\n",
      "w[6]    1964.606\n",
      "w[7]     107.077\n",
      "w[8]     531.339\n",
      "w[9]    1251.597\n",
      "Name: mean, dtype: float64\n",
      "[[  60.5285403   -55.4666393    52.97840342  -45.30919771   20.98494456\n",
      "   -48.14031508  104.48087831   16.24183598   27.3554931    62.29512288]\n",
      " [ -55.4666393   242.5789007  -246.1199367   180.82195047 -189.05090755\n",
      "   199.00631502 -346.95616861   52.28689067 -134.08175889 -253.86139116]\n",
      " [  52.97840342 -246.1199367   255.1225743  -183.3523383   189.89314322\n",
      "  -203.68328323  351.39968122  -45.51603347  142.72859244  253.73335447]\n",
      " [ -45.30919771  180.82195047 -183.3523383   136.46570196 -140.71584143\n",
      "   148.90179713 -261.70817186   38.91128985  -98.80558396 -191.33058554]\n",
      " [  20.98494456 -189.05090755  189.89314322 -140.71584143  167.11133434\n",
      "  -152.71307383  260.48261626  -70.54150675   96.70020308  204.6659865 ]\n",
      " [ -48.14031508  199.00631502 -203.68328323  148.90179713 -152.71307383\n",
      "   165.44938392 -286.99267823   37.56626045 -112.76853573 -207.31823067]\n",
      " [ 104.48087831 -346.95616861  351.39968122 -261.70817186  260.48261626\n",
      "  -286.99267823  513.98151457  -61.24809551  190.05759349  367.29065353]\n",
      " [  16.24183598   52.28689067  -45.51603347   38.91128985  -70.54150675\n",
      "    37.56626045  -61.24809551   64.52084508   -9.78026122  -69.76301288]\n",
      " [  27.3554931  -134.08175889  142.72859244  -98.80558396   96.70020308\n",
      "  -112.76853573  190.05759349   -9.78026122   88.22245887  130.32224782]\n",
      " [  62.29512288 -253.86139116  253.73335447 -191.33058554  204.6659865\n",
      "  -207.31823067  367.29065353  -69.76301288  130.32224782  276.60487916]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:01<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 466 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1933.377\n",
      "w[1]   -1205.450\n",
      "w[2]     983.118\n",
      "w[3]    -961.794\n",
      "w[4]     445.909\n",
      "w[5]    -943.340\n",
      "w[6]    2037.197\n",
      "w[7]     117.754\n",
      "w[8]     550.446\n",
      "w[9]    1295.120\n",
      "Name: mean, dtype: float64\n",
      "[[  63.55492325  -56.99819746   54.19918914  -46.64288254   20.99302458\n",
      "   -49.48425614  108.03137779   17.21924476   27.77527715   64.22135279]\n",
      " [ -56.99819746  254.49995313 -258.10718891  189.74017907 -199.52648539\n",
      "   208.72845053 -363.55346193   56.87135392 -140.08708969 -266.89974575]\n",
      " [  54.19918914 -258.10718891  267.3695379  -192.2488354   200.28407299\n",
      "  -213.50778191  367.87708539  -49.6839712   149.16198515  266.51305183]\n",
      " [ -46.64288254  189.74017907 -192.2488354   143.14732406 -148.53969489\n",
      "   156.15023615 -274.20872686   42.40742203 -103.18138356 -201.17697391]\n",
      " [  20.99302458 -199.52648539  200.28407299 -148.53969489  177.44176214\n",
      "  -161.09028213  274.42569086  -76.36099222  101.53956542  216.50656082]\n",
      " [ -49.48425614  208.72845053 -213.50778191  156.15023615 -161.09028213\n",
      "   173.38889432 -300.55137184   40.98757577 -117.81379382 -217.83448502]\n",
      " [ 108.03137779 -363.55346193  367.87708539 -274.20872686  274.42569086\n",
      "  -300.55137184  537.73905101  -66.9339752   198.20236108  385.58757989]\n",
      " [  17.21924476   56.87135392  -49.6839712    42.40742203  -76.36099222\n",
      "    40.98757577  -66.9339752    69.3825901   -10.97437847  -75.72999054]\n",
      " [  27.77527715 -140.08708969  149.16198515 -103.18138356  101.53956542\n",
      "  -117.81379382  198.20236108  -10.97437847   92.06297796  136.22554996]\n",
      " [  64.22135279 -266.89974575  266.51305183 -201.17697391  216.50656082\n",
      "  -217.83448502  385.58757989  -75.72999054  136.22554996  291.40496561]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:21<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 484 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    1976.121\n",
      "w[1]   -1244.371\n",
      "w[2]    1019.973\n",
      "w[3]    -993.571\n",
      "w[4]     460.472\n",
      "w[5]    -977.009\n",
      "w[6]    2110.553\n",
      "w[7]     129.050\n",
      "w[8]     569.326\n",
      "w[9]    1338.870\n",
      "Name: mean, dtype: float64\n",
      "[[  67.76203016  -58.46726774   55.40539546  -48.14798441   20.58462229\n",
      "   -50.85713666  112.21993812   18.91268572   28.03888092   66.26815425]\n",
      " [ -58.46726774  264.94294779 -268.74580948  197.62430441 -208.50521758\n",
      "   217.1175334  -378.32631321   60.158256   -145.61400148 -278.1483686 ]\n",
      " [  55.40539546 -268.74580948  278.46054411 -200.18103186  209.12367103\n",
      "  -222.15730689  382.73104752  -52.22584403  155.41119347  277.45366572]\n",
      " [ -48.14798441  197.62430441 -200.18103186  149.13924308 -155.25708525\n",
      "   162.47176181 -285.5837944    44.90883108 -107.15773233 -209.81118078]\n",
      " [  20.58462229 -208.50521758  209.12367103 -155.25708525  186.56983651\n",
      "  -168.04443425  286.30860191  -81.65825714  105.58228352  226.7371933 ]\n",
      " [ -50.85713666  217.1175334  -222.15730689  162.47176181 -168.04443425\n",
      "   180.16197172 -312.49981126   43.13202311 -122.45988859 -226.69087362]\n",
      " [ 112.21993812 -378.32631321  382.73104752 -285.5837944   286.30860191\n",
      "  -312.49981126  559.73317994  -70.57676007  205.66548103  401.79844284]\n",
      " [  18.91268572   60.158256    -52.22584403   44.90883108  -81.65825714\n",
      "    43.13202311  -70.57676007   75.05730709  -10.91574016  -80.71277604]\n",
      " [  28.03888092 -145.61400148  155.41119347 -107.15773233  105.58228352\n",
      "  -122.45988859  205.66548103  -10.91574016   96.28304697  141.10335682]\n",
      " [  66.26815425 -278.1483686   277.45366572 -209.81118078  226.7371933\n",
      "  -226.69087362  401.79844284  -80.71277604  141.10335682  304.37150211]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:37<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 486 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    2020.764\n",
      "w[1]   -1282.723\n",
      "w[2]    1056.116\n",
      "w[3]   -1025.151\n",
      "w[4]     473.820\n",
      "w[5]   -1010.304\n",
      "w[6]    2184.199\n",
      "w[7]     141.500\n",
      "w[8]     587.584\n",
      "w[9]    1382.310\n",
      "Name: mean, dtype: float64\n",
      "[[  71.54438316  -60.99970861   57.42814416  -50.26217504   21.33381333\n",
      "   -52.97125942  117.56746774   19.51083114   28.69281147   69.49285273]\n",
      " [ -60.99970861  284.57315105 -288.71871114  212.16735648 -225.14368803\n",
      "   233.05953035 -405.44590549   66.32520509 -156.20832902 -298.89585209]\n",
      " [  57.42814416 -288.71871114  299.12688139 -214.84366339  225.78702312\n",
      "  -238.46604745  409.98231139  -57.66513343  166.90515224  297.93465977]\n",
      " [ -50.26217504  212.16735648 -214.84366339  159.9294811  -167.59682275\n",
      "   174.2403171  -305.79985038   49.64368249 -114.79138685 -225.32880161]\n",
      " [  21.33381333 -225.14368803  225.78702312 -167.59682275  202.05784902\n",
      "  -181.34299441  308.59363503  -89.26283658  113.78004176  244.99245909]\n",
      " [ -52.97125942  233.05953035 -238.46604745  174.2403171  -181.34299441\n",
      "   193.13546677 -334.53764414   47.70931815 -131.27176983 -243.33565261]\n",
      " [ 117.56746774 -405.44590549  409.98231139 -305.79985038  308.59363503\n",
      "  -334.53764414  598.17405147  -78.45494869  219.84679661  430.78412389]\n",
      " [  19.51083114   66.32520509  -57.66513343   49.64368249  -89.26283658\n",
      "    47.70931815  -78.45494869   81.53851846  -12.19946546  -88.95925627]\n",
      " [  28.69281147 -156.20832902  166.90515224 -114.79138685  113.78004176\n",
      "  -131.27176983  219.84679661  -12.19946546  103.47590322  151.03352573]\n",
      " [  69.49285273 -298.89585209  297.93465977 -225.32880161  244.99245909\n",
      "  -243.33565261  430.78412389  -88.95925627  151.03352573  327.30517968]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 18:01<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1523 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    2067.083\n",
      "w[1]   -1321.301\n",
      "w[2]    1092.134\n",
      "w[3]   -1057.012\n",
      "w[4]     486.785\n",
      "w[5]   -1043.776\n",
      "w[6]    2259.055\n",
      "w[7]     154.295\n",
      "w[8]     605.462\n",
      "w[9]    1426.355\n",
      "Name: mean, dtype: float64\n",
      "[[  74.2154043   -59.99777213   56.05546489  -49.83225053   19.53087332\n",
      "   -52.25931495  117.70035949   20.74805038   27.53119516   69.09947751]\n",
      " [ -59.99777213  294.18620306 -298.87843178  219.12531    -234.08765245\n",
      "   240.8089941  -417.74667313   70.01218185 -161.84231414 -308.60585477]\n",
      " [  56.05546489 -298.87843178  310.14864619 -222.11310988  234.92877408\n",
      "  -246.77110971  422.82997738  -60.77163337  173.48141213  307.69207807]\n",
      " [ -49.83225053  219.12531    -222.11310988  165.00408515 -174.04906409\n",
      "   179.84784033 -314.88177567   52.39301221 -118.69403208 -232.50454369]\n",
      " [  19.53087332 -234.08765245  234.92877408 -174.04906409  211.3782544\n",
      "  -188.35420276  319.61897227  -94.48588725  118.30414282  254.52761756]\n",
      " [ -52.25931495  240.8089941  -246.77110971  179.84784033 -188.35420276\n",
      "   199.42873009 -344.51581199   50.25884292 -136.02982798 -250.99854198]\n",
      " [ 117.70035949 -417.74667313  422.82997738 -314.88177567  319.61897227\n",
      "  -344.51581199  614.68811222  -82.77638771  226.71422123  443.59027976]\n",
      " [  20.74805038   70.01218185  -60.77163337   52.39301221  -94.48588725\n",
      "    50.25884292  -82.77638771   86.41812101  -12.59656106  -94.00072247]\n",
      " [  27.53119516 -161.84231414  173.48141213 -118.69403208  118.30414282\n",
      "  -136.02982798  226.71422123  -12.59656106  108.07987007  155.6484185 ]\n",
      " [  69.09947751 -308.60585477  307.69207807 -232.50454369  254.52761756\n",
      "  -250.99854198  443.59027976  -94.00072247  155.6484185   337.95905451]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 20:19<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 2259 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    2114.470\n",
      "w[1]   -1358.075\n",
      "w[2]    1126.127\n",
      "w[3]   -1087.697\n",
      "w[4]     497.870\n",
      "w[5]   -1075.812\n",
      "w[6]    2332.116\n",
      "w[7]     167.919\n",
      "w[8]     621.995\n",
      "w[9]    1468.898\n",
      "Name: mean, dtype: float64\n",
      "[[  76.48639209  -60.01112801   55.71758447  -50.02996053   18.67030388\n",
      "   -52.29309266  118.93223847   21.56708229   27.06478831   69.57241716]\n",
      " [ -60.01112801  292.8263054  -297.74467329  218.16272965 -232.83777668\n",
      "   239.82545222 -415.97778601   69.26757163 -161.38273647 -307.19924873]\n",
      " [  55.71758447 -297.74467329  309.43820926 -221.25471131  233.75487282\n",
      "  -246.00884574  421.11731426  -59.69872515  173.54831417  306.16069377]\n",
      " [ -50.02996053  218.16272965 -221.25471131  164.33336086 -173.15512525\n",
      "   179.16127583 -313.74797999   51.92675088 -118.24516518 -231.60876557]\n",
      " [  18.67030388 -232.83777668  233.75487282 -173.15512525  211.0131472\n",
      "  -187.35499168  317.58446567  -95.09187363  117.44267227  253.54669486]\n",
      " [ -52.29309266  239.82545222 -246.00884574  179.16127583 -187.35499168\n",
      "   198.7257308  -343.23291441   49.52174414 -135.82014577 -249.89568029]\n",
      " [ 118.93223847 -415.97778601  421.11731426 -313.74797999  317.58446567\n",
      "  -343.23291441  613.04470447  -81.51087326  225.75925076  442.07822532]\n",
      " [  21.56708229   69.26757163  -59.69872515   51.92675088  -95.09187363\n",
      "    49.52174414  -81.51087326   88.39896803  -11.19637036  -94.13129427]\n",
      " [  27.06478831 -161.38273647  173.54831417 -118.24516518  117.44267227\n",
      "  -135.82014577  225.75925076  -11.19637036  108.82880099  154.41150053]\n",
      " [  69.57241716 -307.19924873  306.16069377 -231.60876557  253.54669486\n",
      "  -249.89568029  442.07822532  -94.13129427  154.41150053  337.12791192]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 17:01<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 2125 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    2162.252\n",
      "w[1]   -1393.334\n",
      "w[2]    1158.392\n",
      "w[3]   -1117.314\n",
      "w[4]     507.557\n",
      "w[5]   -1106.573\n",
      "w[6]    2403.414\n",
      "w[7]     181.932\n",
      "w[8]     637.409\n",
      "w[9]    1510.108\n",
      "Name: mean, dtype: float64\n",
      "[[  80.75895935  -59.56923959   55.02761378  -50.03215233   16.18786749\n",
      "   -52.1643725   120.54972188   24.57319497   26.63768022   69.24525087]\n",
      " [ -59.56923959  300.88943701 -306.3171435   223.93052559 -240.06035374\n",
      "   246.31878437 -426.12169982   71.79234327 -166.42052302 -315.16877502]\n",
      " [  55.02761378 -306.3171435   318.89164919 -227.3224443   241.00866973\n",
      "  -253.06682128  431.81077995  -61.36826373  179.62503224  314.06621885]\n",
      " [ -50.03215233  223.93052559 -227.3224443   168.49821141 -178.27863364\n",
      "   183.80372257 -321.19017877   53.7658755  -121.69786535 -237.43368843]\n",
      " [  16.18786749 -240.06035374  241.00866973 -178.27863364  219.39524685\n",
      "  -192.81248976  325.63371918 -100.76633384  120.8035076   261.59639825]\n",
      " [ -52.1643725   246.31878437 -253.06682128  183.80372257 -192.81248976\n",
      "   204.03311824 -351.52425136   50.86974222 -140.19875609 -256.05850764]\n",
      " [ 120.54972188 -426.12169982  431.81077995 -321.19017877  325.63371918\n",
      "  -351.52425136  626.93240197  -83.32353057  231.98085537  452.21117449]\n",
      " [  24.57319497   71.79234327  -61.36826373   53.7658755  -100.76633384\n",
      "    50.86974222  -83.32353057   95.44637642  -10.2506627   -98.64874101]\n",
      " [  26.63768022 -166.42052302  179.62503224 -121.69786535  120.8035076\n",
      "  -140.19875609  231.98085537  -10.2506627   113.54276091  158.10810153]\n",
      " [  69.24525087 -315.16877502  314.06621885 -237.43368843  261.59639825\n",
      "  -256.05850764  452.21117449  -98.64874101  158.10810153  346.0173188 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 18:31<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 2018 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    2212.028\n",
      "w[1]   -1427.300\n",
      "w[2]    1189.233\n",
      "w[3]   -1146.126\n",
      "w[4]     515.078\n",
      "w[5]   -1136.404\n",
      "w[6]    2474.023\n",
      "w[7]     197.836\n",
      "w[8]     652.058\n",
      "w[9]    1549.965\n",
      "Name: mean, dtype: float64\n",
      "[[  85.64401589  -62.0952738    57.203918    -52.25974072   16.24017732\n",
      "   -54.49489904  126.45805079   26.42292749   27.59155346   72.28897568]\n",
      " [ -62.0952738   319.79846614 -325.2592128   238.08880615 -256.62653161\n",
      "   261.5623763  -452.5968618    78.96124853 -176.0140009  -335.82070038]\n",
      " [  57.203918   -325.2592128   338.15939664 -241.39690617  257.25541863\n",
      "  -268.40618039  458.05308459  -67.67303783  189.89151597  334.15632683]\n",
      " [ -52.25974072  238.08880615 -241.39690617  179.13124801 -190.65717086\n",
      "   195.20850041 -341.18706059   59.20658741 -128.68172511 -253.05163768]\n",
      " [  16.24017732 -256.62653161  257.25541863 -190.65717086  235.79767343\n",
      "  -205.85439425  347.74965958 -110.25479105  128.26055262  280.4875626 ]\n",
      " [ -54.49489904  261.5623763  -268.40618039  195.20850041 -205.85439425\n",
      "   216.34708955 -372.98005955   56.11041319 -148.10628284 -272.53831175]\n",
      " [ 126.45805079 -452.5968618   458.05308459 -341.18706059  347.74965958\n",
      "  -372.98005955  665.20116424  -92.05334912  245.12244291  481.31767761]\n",
      " [  26.42292749   78.96124853  -67.67303783   59.20658741 -110.25479105\n",
      "    56.11041319  -92.05334912  103.93098644  -11.70266875 -108.32682902]\n",
      " [  27.59155346 -176.0140009   189.89151597 -128.68172511  128.26055262\n",
      "  -148.10628284  245.12244291  -11.70266875  119.80153306  167.35227711]\n",
      " [  72.28897568 -335.82070038  334.15632683 -253.05163768  280.4875626\n",
      "  -272.53831175  481.31767761 -108.32682902  167.35227711  369.56282605]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 03:49<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 457 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    2263.690\n",
      "w[1]   -1460.585\n",
      "w[2]    1219.221\n",
      "w[3]   -1174.581\n",
      "w[4]     521.104\n",
      "w[5]   -1165.816\n",
      "w[6]    2544.751\n",
      "w[7]     215.143\n",
      "w[8]     666.181\n",
      "w[9]    1589.251\n",
      "Name: mean, dtype: float64\n",
      "[[  88.04053146  -60.32709345   55.1154762   -51.24251716   13.78716658\n",
      "   -53.1536957   125.46828832   28.05942842   26.17382363   70.91946015]\n",
      " [ -60.32709345  327.53047227 -333.13484015  243.72850524 -265.01535039\n",
      "   267.58884729 -461.97812442   84.13992934 -179.7807926  -344.53086434]\n",
      " [  55.1154762  -333.13484015  346.35922311 -247.04963072  265.57688023\n",
      "  -274.6031878   467.39521967  -72.37835123  194.16292844  342.62598972]\n",
      " [ -51.24251716  243.72850524 -247.04963072  183.29226888 -196.77298357\n",
      "   199.58186588 -348.20642201   63.09444045 -131.2542126  -259.56747109]\n",
      " [  13.78716658 -265.01535039  265.57688023 -196.77298357  245.51469739\n",
      "  -212.23409987  357.6290995  -117.1540239   131.83043701  290.29468227]\n",
      " [ -53.1536957   267.58884729 -274.6031878   199.58186588 -212.23409987\n",
      "   221.06877001 -380.29342581   59.83259307 -151.20498225 -279.20054183]\n",
      " [ 125.46828832 -461.97812442  467.39521967 -348.20642201  357.6290995\n",
      "  -380.29342581  677.20833712  -98.18966582  249.29414673  492.28097018]\n",
      " [  28.05942842   84.13992934  -72.37835123   63.09444045 -117.1540239\n",
      "    59.83259307  -98.18966582  110.12649628  -12.84305478 -115.24271159]\n",
      " [  26.17382363 -179.7807926   194.16292844 -131.2542126   131.83043701\n",
      "  -151.20498225  249.29414673  -12.84305478  122.63124539  170.72724494]\n",
      " [  70.91946015 -344.53086434  342.62598972 -259.56747109  290.29468227\n",
      "  -279.20054183  492.28097018 -115.24271159  170.72724494  380.10182985]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:07<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 479 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    2315.767\n",
      "w[1]   -1491.305\n",
      "w[2]    1246.468\n",
      "w[3]   -1201.256\n",
      "w[4]     524.837\n",
      "w[5]   -1193.145\n",
      "w[6]    2612.381\n",
      "w[7]     233.288\n",
      "w[8]     678.627\n",
      "w[9]    1626.102\n",
      "Name: mean, dtype: float64\n",
      "[[  93.11291204  -64.88170372   59.64367111  -54.88441181   15.26335424\n",
      "   -57.20911219  134.04484246   29.96345167   28.71245622   75.81383173]\n",
      " [ -64.88170372  343.59007057 -349.17053987  255.57382081 -277.17613605\n",
      "   280.72681377 -485.16125111   87.1702978  -188.49562805 -361.35862807]\n",
      " [  59.64367111 -349.17053987  362.57669374 -258.8128581   277.34714149\n",
      "  -287.80097027  490.48397136  -74.59602596  203.34839276  358.97451594]\n",
      " [ -54.88441181  255.57382081 -258.8128581   192.03665119 -205.67193431\n",
      "   209.26707247 -365.41392739   65.29557172 -137.56352259 -272.06844884]\n",
      " [  15.26335424 -277.17613605  277.34714149 -205.67193431  256.3658114\n",
      "  -221.85980611  374.14418174 -122.25598947  137.55795855  303.66850137]\n",
      " [ -57.20911219  280.72681377 -287.80097027  209.26707247 -221.85980611\n",
      "   231.85591086 -399.40107253   61.74921695 -158.51808289 -292.80043778]\n",
      " [ 134.04484246 -485.16125111  490.48397136 -365.41392739  374.14418174\n",
      "  -399.40107253  711.62878197 -101.18511472  261.83491008  516.63795292]\n",
      " [  29.96345167   87.1702978   -74.59602596   65.29557172 -122.25598947\n",
      "    61.74921695 -101.18511472  115.7528889   -12.61991845 -119.87440806]\n",
      " [  28.71245622 -188.49562805  203.34839276 -137.56352259  137.55795855\n",
      "  -158.51808289  261.83491008  -12.61991845  128.41852359  178.92294278]\n",
      " [  75.81383173 -361.35862807  358.97451594 -272.06844884  303.66850137\n",
      "  -292.80043778  516.63795292 -119.87440806  178.92294278  398.50355962]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:50<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 852 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    2369.862\n",
      "w[1]   -1523.008\n",
      "w[2]    1274.698\n",
      "w[3]   -1228.763\n",
      "w[4]     528.333\n",
      "w[5]   -1221.440\n",
      "w[6]    2682.314\n",
      "w[7]     252.657\n",
      "w[8]     691.716\n",
      "w[9]    1663.974\n",
      "Name: mean, dtype: float64\n",
      "[[  96.80819147  -64.96068004   59.31699079  -55.36944714   14.11937565\n",
      "   -57.41301359  136.15037623   31.06343827   27.8254596    76.76494197]\n",
      " [ -64.96068004  350.88757633 -356.41008746  261.03202126 -284.56836886\n",
      "   286.59163043 -494.84357777   91.62247553 -191.70088881 -369.8259922 ]\n",
      " [  59.31699079 -356.41008746  370.14507105 -264.0789178   284.21175107\n",
      "  -293.7493219   499.83357052  -77.80685932  207.42165216  366.64082546]\n",
      " [ -55.36944714  261.03202126 -264.0789178   196.17022035 -211.19209677\n",
      "   213.63577115 -372.88945875   68.77542236 -139.68264849 -278.62716864]\n",
      " [  14.11937565 -284.56836886  284.21175107 -211.19209677  265.21492301\n",
      "  -227.50954453  383.31064869 -129.21373021  139.86306461  312.95382355]\n",
      " [ -57.41301359  286.59163043 -293.7493219   213.63577115 -227.50954453\n",
      "   236.6297281  -407.24562546   64.7253529  -161.39437959 -299.37255548]\n",
      " [ 136.15037623 -494.84357777  499.83357052 -372.88945875  383.31064869\n",
      "  -407.24562546  725.54038317 -106.52231207  265.54489296  528.35419801]\n",
      " [  31.06343827   91.62247553  -77.80685932   68.77542236 -129.21373021\n",
      "    64.7253529  -106.52231207  123.33989073  -12.11541287 -126.92334203]\n",
      " [  27.8254596  -191.70088881  207.42165216 -139.68264849  139.86306461\n",
      "  -161.39437959  265.54489296  -12.11541287  131.72234105  181.116976  ]\n",
      " [  76.76494197 -369.8259922   366.64082546 -278.62716864  312.95382355\n",
      "  -299.37255548  528.35419801 -126.92334203  181.116976    409.53892218]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 16:30<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1789 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    2424.720\n",
      "w[1]   -1552.749\n",
      "w[2]    1300.758\n",
      "w[3]   -1254.967\n",
      "w[4]     530.020\n",
      "w[5]   -1248.153\n",
      "w[6]    2750.095\n",
      "w[7]     272.558\n",
      "w[8]     703.253\n",
      "w[9]    1700.194\n",
      "Name: mean, dtype: float64\n",
      "[[  98.75970465  -63.02744083   57.02542461  -54.21085418   11.80429306\n",
      "   -55.97822219  134.69848022   32.17166903   26.18476879   75.42529705]\n",
      " [ -63.02744083  362.50909368 -368.23050152  269.51685191 -296.5699094\n",
      "   295.82564116 -509.07244009   98.45313267 -197.73577634 -382.38378618]\n",
      " [  57.02542461 -368.23050152  382.46248019 -272.61244225  296.07720708\n",
      "  -303.22613268  514.07778099  -83.88971222  214.21471588  378.85885755]\n",
      " [ -54.21085418  269.51685191 -272.61244225  202.39411662 -219.97699769\n",
      "   220.35851716 -383.43249032   73.92254532 -143.88957721 -287.96938546]\n",
      " [  11.80429306 -296.5699094   296.07720708 -219.97699769  278.31632301\n",
      "  -236.83846494  397.8776449  -137.66485146  145.35579554  326.41064652]\n",
      " [ -55.97822219  295.82564116 -303.22613268  220.35851716 -236.83846494\n",
      "   244.00656016 -418.6023811    69.73117992 -166.41575218 -309.19818459]\n",
      " [ 134.69848022 -509.07244009  514.07778099 -383.43249032  397.8776449\n",
      "  -418.6023811   743.5030449  -115.00152372  272.53204472  544.16905483]\n",
      " [  32.17166903   98.45313267  -83.88971222   73.92254532 -137.66485146\n",
      "    69.73117992 -115.00152372  130.35317173  -13.77910771 -135.67897345]\n",
      " [  26.18476879 -197.73577634  214.21471588 -143.88957721  145.35579554\n",
      "  -166.41575218  272.53204472  -13.77910771  136.27303816  186.49955575]\n",
      " [  75.42529705 -382.38378618  378.85885755 -287.96938546  326.41064652\n",
      "  -309.19818459  544.16905483 -135.67897345  186.49955575  424.07073717]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 15:51<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1720 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    2479.809\n",
      "w[1]   -1579.811\n",
      "w[2]    1323.981\n",
      "w[3]   -1279.284\n",
      "w[4]     529.332\n",
      "w[5]   -1272.738\n",
      "w[6]    2814.508\n",
      "w[7]     293.276\n",
      "w[8]     713.098\n",
      "w[9]    1733.881\n",
      "Name: mean, dtype: float64\n",
      "[[ 104.12532368  -64.92961478   58.71480393  -56.05562279   10.96676358\n",
      "   -57.8842348   140.14040201   34.91378437   27.0140392    77.75821183]\n",
      " [ -64.92961478  387.24622247 -394.3377552   287.58569777 -316.71960497\n",
      "   316.25394013 -542.62590064  103.75498513 -213.02208176 -406.84607878]\n",
      " [  58.71480393 -394.3377552   410.56669368 -291.53574408  316.56367203\n",
      "  -324.97741115  549.23873971  -87.6472699   231.56723617  403.66175626]\n",
      " [ -56.05562279  287.58569777 -291.53574408  215.64768471 -234.67677811\n",
      "   235.25309196 -408.19587808   77.9681579  -154.763681   -306.08762585]\n",
      " [  10.96676358 -316.71960497  316.56367203 -234.67677811  297.34214109\n",
      "  -252.93612389  424.00932526 -146.80109149  155.96093386  347.76647742]\n",
      " [ -57.8842348   316.25394013 -324.97741115  235.25309196 -252.93612389\n",
      "   260.97359089 -446.45200881   73.07103333 -179.50705076 -329.00768724]\n",
      " [ 140.14040201 -542.62590064  549.23873971 -408.19587808  424.00932526\n",
      "  -446.45200881  790.57980533 -120.73541887  292.94670958  577.69619943]\n",
      " [  34.91378437  103.75498513  -87.6472699    77.9681579  -146.80109149\n",
      "    73.07103333 -120.73541887  140.80582598  -12.84762326 -144.26831558]\n",
      " [  27.0140392  -213.02208176  231.56723617 -154.763681    155.96093386\n",
      "  -179.50705076  292.94670958  -12.84762326  148.3371454   199.43501709]\n",
      " [  77.75821183 -406.84607878  403.66175626 -306.08762585  347.76647742\n",
      "  -329.00768724  577.69619943 -144.26831558  199.43501709  450.04446485]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 16:46<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1793 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    2536.475\n",
      "w[1]   -1605.427\n",
      "w[2]    1345.661\n",
      "w[3]   -1302.677\n",
      "w[4]     526.570\n",
      "w[5]   -1296.277\n",
      "w[6]    2877.914\n",
      "w[7]     315.617\n",
      "w[8]     722.108\n",
      "w[9]    1766.144\n",
      "Name: mean, dtype: float64\n",
      "[[ 105.38872634  -63.83616748   57.26550294  -55.30232489    9.46860843\n",
      "   -56.87015426  139.42502407   35.72044672   25.93964726   76.8286576 ]\n",
      " [ -63.83616748  380.57840487 -387.02347702  282.55194243 -311.44975478\n",
      "   310.51258828 -533.17269301  102.93747696 -208.61409377 -400.18648376]\n",
      " [  57.26550294 -387.02347702  402.74347933 -285.95190362  310.59587014\n",
      "  -318.72395223  538.70963816  -86.21302411  227.16548926  396.00574173]\n",
      " [ -55.30232489  282.55194243 -285.95190362  211.85674336 -230.746079\n",
      "   230.88922349 -401.11330254   77.50733353 -151.29436647 -301.153124  ]\n",
      " [   9.46860843 -311.44975478  310.59587014 -230.746079    294.01404992\n",
      "  -248.3215866   416.2385498  -147.62192622  151.95131288  342.9863181 ]\n",
      " [ -56.87015426  310.51258828 -318.72395223  230.88922349 -248.3215866\n",
      "   256.02111654 -438.27301687   72.18072722 -175.84087716 -323.15286159]\n",
      " [ 139.42502407 -533.17269301  538.70963816 -401.11330254  416.2385498\n",
      "  -438.27301687  777.60953875 -119.30171483  286.42390757  568.399654  ]\n",
      " [  35.72044672  102.93747696  -86.21302411   77.50733353 -147.62192622\n",
      "    72.18072722 -119.30171483  143.52861417  -10.99454577 -144.57048802]\n",
      " [  25.93964726 -208.61409377  227.16548926 -151.29436647  151.95131288\n",
      "  -175.84087716  286.42390757  -10.99454577  146.34523109  194.28792976]\n",
      " [  76.8286576  -400.18648376  396.00574173 -301.153124    342.9863181\n",
      "  -323.15286159  568.399654   -144.57048802  194.28792976  443.95307226]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 15:36<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1836 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    2592.714\n",
      "w[1]   -1629.226\n",
      "w[2]    1365.391\n",
      "w[3]   -1324.694\n",
      "w[4]     522.456\n",
      "w[5]   -1318.230\n",
      "w[6]    2938.764\n",
      "w[7]     338.147\n",
      "w[8]     729.915\n",
      "w[9]    1796.571\n",
      "Name: mean, dtype: float64\n",
      "[[ 111.70095061  -63.09174515   55.43224533  -55.31627369    6.45998902\n",
      "   -56.34102565  141.73610426   38.1482923    24.02754336   77.3299717 ]\n",
      " [ -63.09174515  389.8056606  -396.98685965  289.08018794 -319.25189938\n",
      "   318.19813695 -544.77023086  104.9998009  -214.79980437 -408.85012682]\n",
      " [  55.43224533 -396.98685965  413.98914938 -292.80899134  318.7311839\n",
      "  -327.14380236  550.60421455  -87.42376083  234.89137165  404.47253476]\n",
      " [ -55.31627369  289.08018794 -292.80899134  216.55316618 -236.27568473\n",
      "   236.30046224 -409.62473228   79.22131371 -155.28650017 -307.60895096]\n",
      " [   6.45998902 -319.25189938  318.7311839  -236.27568473  302.84376211\n",
      "  -254.51243774  424.94867641 -152.98985766  156.09192503  351.21946539]\n",
      " [ -56.34102565  318.19813695 -327.14380236  236.30046224 -254.51243774\n",
      "   262.48271584 -447.95033644   73.31963924 -181.3019502  -330.12329134]\n",
      " [ 141.73610426 -544.77023086  550.60421455 -409.62473228  424.94867641\n",
      "  -447.95033644  793.85884359 -121.05390548  293.27053829  580.08697236]\n",
      " [  38.1482923   104.9998009   -87.42376083   79.22131371 -152.98985766\n",
      "    73.31963924 -121.05390548  150.52625016   -9.51719231 -148.90870618]\n",
      " [  24.02754336 -214.79980437  234.89137165 -155.28650017  156.09192503\n",
      "  -181.3019502   293.27053829   -9.51719231  152.7864308   198.15782753]\n",
      " [  77.3299717  -408.85012682  404.47253476 -307.60895096  351.21946539\n",
      "  -330.12329134  580.08697236 -148.90870618  198.15782753  453.7235451 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 17:32<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1849 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    2651.205\n",
      "w[1]   -1650.756\n",
      "w[2]    1382.239\n",
      "w[3]   -1345.266\n",
      "w[4]     515.661\n",
      "w[5]   -1338.295\n",
      "w[6]    2997.796\n",
      "w[7]     361.815\n",
      "w[8]     735.625\n",
      "w[9]    1825.314\n",
      "Name: mean, dtype: float64\n",
      "[[ 119.39589603  -62.88953847   54.443562    -55.95168341    3.05345805\n",
      "   -56.61441059  145.64279044   41.99333908   22.85663998   78.27240216]\n",
      " [ -62.88953847  408.31197064 -416.47096289  302.61852127 -335.71839295\n",
      "   333.43227663 -569.21274769  111.04436947 -225.89247745 -427.75852141]\n",
      " [  54.443562   -416.47096289  435.10707236 -306.83867367  335.41128046\n",
      "  -343.3608376   575.82497311  -92.0635448   247.93467503  423.24438163]\n",
      " [ -55.95168341  302.61852127 -306.83867367  226.55755146 -248.21048247\n",
      "   247.43781792 -427.94670445   83.74753405 -162.99931202 -321.7921591 ]\n",
      " [   3.05345805 -335.71839295  335.41128046 -248.21048247  320.5497913\n",
      "  -267.49333232  445.05683605 -163.63609139  164.21901963  369.34643016]\n",
      " [ -56.61441059  333.43227663 -343.3608376   247.43781792 -267.49333232\n",
      "   275.11754283 -468.27273102   77.24919144 -190.86063719 -345.34706757]\n",
      " [ 145.64279044 -569.21274769  575.82497311 -427.94670445  445.05683605\n",
      "  -468.27273102  828.40625836 -127.2763452   307.16877386  605.83392334]\n",
      " [  41.99333908  111.04436947  -92.0635448    83.74753405 -163.63609139\n",
      "    77.24919144 -127.2763452   162.19278604   -8.96393836 -158.34482712]\n",
      " [  22.85663998 -225.89247745  247.93467503 -162.99931202  164.21901963\n",
      "  -190.86063719  307.16877386   -8.96393836  162.36364867  207.05367631]\n",
      " [  78.27240216 -427.75852141  423.24438163 -321.7921591   369.34643016\n",
      "  -345.34706757  605.83392334 -158.34482712  207.05367631  475.09549615]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 16:41<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1829 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    2712.408\n",
      "w[1]   -1670.335\n",
      "w[2]    1396.763\n",
      "w[3]   -1364.725\n",
      "w[4]     506.046\n",
      "w[5]   -1356.946\n",
      "w[6]    3055.768\n",
      "w[7]     387.387\n",
      "w[8]     739.780\n",
      "w[9]    1852.521\n",
      "Name: mean, dtype: float64\n",
      "[[ 1.23552514e+02 -6.17436916e+01  5.31673617e+01 -5.54818770e+01\n",
      "  -2.51375406e-02 -5.60807079e+01  1.46534142e+02  4.50337786e+01\n",
      "   2.20716964e+01  7.74596808e+01]\n",
      " [-6.17436916e+01  4.15639929e+02 -4.24340829e+02  3.07823666e+02\n",
      "  -3.42731023e+02  3.39524189e+02 -5.78288148e+02  1.14064813e+02\n",
      "  -2.30412414e+02 -4.35180192e+02]\n",
      " [ 5.31673617e+01 -4.24340829e+02  4.44271651e+02 -3.12238515e+02\n",
      "   3.41661520e+02 -3.50166023e+02  5.85407159e+02 -9.25189288e+01\n",
      "   2.54433677e+02  4.29828604e+02]\n",
      " [-5.54818770e+01  3.07823666e+02 -3.12238515e+02  2.30329194e+02\n",
      "  -2.53363460e+02  2.51733120e+02 -4.34620055e+02  8.63832675e+01\n",
      "  -1.65784638e+02 -3.27451678e+02]\n",
      " [-2.51375406e-02 -3.42731023e+02  3.41661520e+02 -2.53363460e+02\n",
      "   3.30539758e+02 -2.72631817e+02  4.52771920e+02 -1.72734603e+02\n",
      "   1.65677622e+02  3.78696821e+02]\n",
      " [-5.60807079e+01  3.39524189e+02 -3.50166023e+02  2.51733120e+02\n",
      "  -2.72631817e+02  2.80312854e+02 -4.76012565e+02  7.84398359e+01\n",
      "  -1.95229000e+02 -3.51052152e+02]\n",
      " [ 1.46534142e+02 -5.78288148e+02  5.85407159e+02 -4.34620055e+02\n",
      "   4.52771920e+02 -4.76012565e+02  8.40911490e+02 -1.29916613e+02\n",
      "   3.12477840e+02  6.15403999e+02]\n",
      " [ 4.50337786e+01  1.14064813e+02 -9.25189288e+01  8.63832675e+01\n",
      "  -1.72734603e+02  7.84398359e+01 -1.29916613e+02  1.75638125e+02\n",
      "  -4.63899465e+00 -1.66339363e+02]\n",
      " [ 2.20716964e+01 -2.30412414e+02  2.54433677e+02 -1.65784638e+02\n",
      "   1.65677622e+02 -1.95229000e+02  3.12477840e+02 -4.63899465e+00\n",
      "   1.68820626e+02  2.08582076e+02]\n",
      " [ 7.74596808e+01 -4.35180192e+02  4.29828604e+02 -3.27451678e+02\n",
      "   3.78696821e+02 -3.51052152e+02  6.15403999e+02 -1.66339363e+02\n",
      "   2.08582076e+02  4.85175982e+02]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 17:17<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1858 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    2774.151\n",
      "w[1]   -1686.969\n",
      "w[2]    1408.325\n",
      "w[3]   -1382.080\n",
      "w[4]     493.445\n",
      "w[5]   -1373.322\n",
      "w[6]    3110.249\n",
      "w[7]     414.503\n",
      "w[8]     742.359\n",
      "w[9]    1876.707\n",
      "Name: mean, dtype: float64\n",
      "[[ 126.59851643  -61.57194826   52.88853993  -55.6795729    -1.66682483\n",
      "   -56.15541054  148.07868579   47.31001411   21.91183406   77.3749919 ]\n",
      " [ -61.57194826  444.41069677 -454.35193656  328.80353431 -368.54606663\n",
      "   362.90690373 -616.11614588  124.34752648 -247.0074688  -464.9532028 ]\n",
      " [  52.88853993 -454.35193656  476.18321537 -333.95601291  367.56088097\n",
      "  -374.80934771  624.7492739  -101.02582205  273.12015881  459.76416988]\n",
      " [ -55.6795729   328.80353431 -333.95601291  245.70412487 -272.31333203\n",
      "   268.74433437 -462.41290899   94.26342643 -177.51178634 -349.47154493]\n",
      " [  -1.66682483 -368.54606663  367.56088097 -272.31333203  356.35016015\n",
      "  -293.04185272  485.98036043 -187.12288938  178.12580721  407.37682476]\n",
      " [ -56.15541054  362.90690373 -374.80934771  268.74433437 -293.04185272\n",
      "   299.43804941 -506.82310272   85.65891173 -209.3037172  -374.76815943]\n",
      " [ 148.07868579 -616.11614588  624.7492739  -462.41290899  485.98036043\n",
      "  -506.82310272  891.65675665 -142.4337439   334.08853779  654.73730154]\n",
      " [  47.31001411  124.34752648 -101.02582205   94.26342643 -187.12288938\n",
      "    85.65891173 -142.4337439   189.55846866   -5.38063763 -181.15307577]\n",
      " [  21.91183406 -247.0074688   273.12015881 -177.51178634  178.12580721\n",
      "  -209.3037172   334.08853779   -5.38063763  181.54335147  223.18182707]\n",
      " [  77.3749919  -464.9532028   459.76416988 -349.47154493  407.37682476\n",
      "  -374.76815943  654.73730154 -181.15307577  223.18182707  518.09752173]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 05:03<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 911 seconds.\n",
      "The acceptance probability does not match the target. It is 0.6925426656501852, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    2836.139\n",
      "w[1]   -1701.192\n",
      "w[2]    1417.421\n",
      "w[3]   -1397.735\n",
      "w[4]     478.557\n",
      "w[5]   -1387.772\n",
      "w[6]    3161.750\n",
      "w[7]     442.791\n",
      "w[8]     743.595\n",
      "w[9]    1898.333\n",
      "Name: mean, dtype: float64\n",
      "[[ 133.30726912  -63.30198604   53.40742434  -57.6839245    -2.0512807\n",
      "   -57.59694665  153.87730523   48.08249242   20.80640182   80.95431786]\n",
      " [ -63.30198604  462.21801784 -472.20585776  341.98857311 -384.27797472\n",
      "   377.28042186 -640.4738566   131.23049241 -256.0298888  -484.2060633 ]\n",
      " [  53.40742434 -472.20585776  494.8479383  -346.91867055  382.74416324\n",
      "  -389.4289705   648.4521136  -106.1851142   283.74499159  477.74938772]\n",
      " [ -57.6839245   341.98857311 -346.91867055  255.59637152 -283.99605401\n",
      "   279.33397274 -480.84042277   99.7192088  -183.67729536 -364.170072  ]\n",
      " [  -2.0512807  -384.27797472  382.74416324 -283.99605401  372.43541997\n",
      "  -305.35089627  506.62005712 -197.12892149  184.61058166  425.6116724 ]\n",
      " [ -57.59694665  377.28042186 -389.4289705   279.33397274 -305.35089627\n",
      "   311.10808978 -526.47365447   90.39558048 -217.04790167 -389.92153877]\n",
      " [ 153.87730523 -640.4738566   648.4521136  -480.84042277  506.62005712\n",
      "  -526.47365447  926.75753977 -151.38591023  345.23938966  682.10264198]\n",
      " [  48.08249242  131.23049241 -106.1851142    99.7192088  -197.12892149\n",
      "    90.39558048 -151.38591023  199.96621397   -4.89952683 -191.87402849]\n",
      " [  20.80640182 -256.0298888   283.74499159 -183.67729536  184.61058166\n",
      "  -217.04790167  345.23938966   -4.89952683  189.31209513  230.25046062]\n",
      " [  80.95431786 -484.2060633   477.74938772 -364.170072    425.6116724\n",
      "  -389.92153877  682.10264198 -191.87402849  230.25046062  541.15634085]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:50<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 510 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    2899.710\n",
      "w[1]   -1713.703\n",
      "w[2]    1424.302\n",
      "w[3]   -1412.353\n",
      "w[4]     461.918\n",
      "w[5]   -1400.784\n",
      "w[6]    3211.843\n",
      "w[7]     471.556\n",
      "w[8]     743.077\n",
      "w[9]    1918.828\n",
      "Name: mean, dtype: float64\n",
      "[[ 139.92122353  -62.97693225   52.50551238  -58.00798314   -5.25793295\n",
      "   -57.64972185  157.06123769   51.87090995   19.99361965   81.40820627]\n",
      " [ -62.97693225  487.52500434 -499.34443186  360.36852514 -405.92794671\n",
      "   398.02084148 -673.69535836  138.04994963 -272.03518857 -509.07150002]\n",
      " [  52.50551238 -499.34443186  524.54550767 -366.44955748  405.20332328\n",
      "  -411.86856853  683.73822648 -111.63863182  302.26434084  503.30464435]\n",
      " [ -58.00798314  360.36852514 -366.44955748  269.00755776 -299.67261702\n",
      "   294.35936276 -505.26898004  104.81220347 -194.97238408 -382.50866676]\n",
      " [  -5.25793295 -405.92794671  405.20332328 -299.67261702  393.90784607\n",
      "  -322.55372401  533.47879592 -208.23967807  196.37504886  448.29586016]\n",
      " [ -57.64972185  398.02084148 -411.86856853  294.35936276 -322.55372401\n",
      "   328.20636973 -553.85105084   94.93691629 -230.65949534 -409.92407241]\n",
      " [ 157.06123769 -673.69535836  683.73822648 -505.26898004  533.47879592\n",
      "  -553.85105084  972.27376313 -158.45588511  365.82937958  715.24271485]\n",
      " [  51.87090995  138.04994963 -111.63863182  104.81220347 -208.23967807\n",
      "    94.93691629 -158.45588511  211.82740706   -4.7452307  -201.97188013]\n",
      " [  19.99361965 -272.03518857  302.26434084 -194.97238408  196.37504886\n",
      "  -230.65949534  365.82937958   -4.7452307   202.37695259  243.59768813]\n",
      " [  81.40820627 -509.07150002  503.30464435 -382.50866676  448.29586016\n",
      "  -409.92407241  715.24271485 -201.97188013  243.59768813  567.50759077]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:14<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 466 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    2964.848\n",
      "w[1]   -1723.552\n",
      "w[2]    1428.239\n",
      "w[3]   -1425.174\n",
      "w[4]     442.299\n",
      "w[5]   -1411.698\n",
      "w[6]    3259.313\n",
      "w[7]     501.988\n",
      "w[8]     740.809\n",
      "w[9]    1936.876\n",
      "Name: mean, dtype: float64\n",
      "[[ 145.95250088  -59.48834767   48.16419382  -55.9797223   -11.06566579\n",
      "   -55.01596716  155.41445185   56.11235382   17.12162267   78.5247508 ]\n",
      " [ -59.48834767  502.87377589 -515.77709033  371.30281332 -421.41724686\n",
      "   410.43472639 -692.19501169  145.50946332 -281.27506996 -524.48152368]\n",
      " [  48.16419382 -515.77709033  543.03051831 -377.87164136  420.52662389\n",
      "  -425.49332902  703.0865183  -116.71207597  314.12649109  518.13209716]\n",
      " [ -55.9797223   371.30281332 -377.87164136  276.85987504 -310.85157009\n",
      "   303.13314347 -518.68195997  110.6846113  -201.01447202 -393.91541553]\n",
      " [ -11.06566579 -421.41724686  420.52662389 -310.85157009  413.09153729\n",
      "  -334.35260224  551.17584842 -222.4970698   202.66719581  466.32765669]\n",
      " [ -55.01596716  410.43472639 -425.49332902  303.13314347 -334.35260224\n",
      "   338.41112233 -568.84646355   99.52219239 -238.91360092 -421.73017395]\n",
      " [ 155.41445185 -692.19501169  703.0865183  -518.68195997  551.17584842\n",
      "  -568.84646355  995.76394135 -166.61874014  376.31822197  734.29157285]\n",
      " [  56.11235382  145.50946332 -116.71207597  110.6846113  -222.4970698\n",
      "    99.52219239 -166.61874014  228.77273488   -2.42031195 -215.14026333]\n",
      " [  17.12162267 -281.27506996  314.12649109 -201.01447202  202.66719581\n",
      "  -238.91360092  376.31822197   -2.42031195  212.31618474  249.2157382 ]\n",
      " [  78.5247508  -524.48152368  518.13209716 -393.91541553  466.32765669\n",
      "  -421.73017395  734.29157285 -215.14026333  249.2157382   585.97136495]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:07<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 471 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    3031.141\n",
      "w[1]   -1729.160\n",
      "w[2]    1427.524\n",
      "w[3]   -1435.018\n",
      "w[4]     418.445\n",
      "w[5]   -1419.163\n",
      "w[6]    3301.694\n",
      "w[7]     534.269\n",
      "w[8]     735.791\n",
      "w[9]    1950.770\n",
      "Name: mean, dtype: float64\n",
      "[[ 152.06929579  -58.70398421   46.11555169  -56.12589144  -13.44459942\n",
      "   -54.30294144  157.81213526   57.04409513   14.3640961    79.59549833]\n",
      " [ -58.70398421  511.57612208 -525.13075674  377.61698968 -429.34186177\n",
      "   417.65584222 -703.52318811  148.44019075 -286.70831912 -533.19461703]\n",
      " [  46.11555169 -525.13075674  554.04827897 -384.32180255  428.0327093\n",
      "  -433.5306893   714.46085166 -117.23416553  322.04070545  525.72744418]\n",
      " [ -56.12589144  377.61698968 -384.32180255  281.56301749 -316.72765011\n",
      "   308.28958062 -527.3193638   113.42964508 -204.26187713 -400.80306541]\n",
      " [ -13.44459942 -429.34186177  428.0327093  -316.72765011  423.13503723\n",
      "  -340.42660718  560.7103528  -230.30315683  205.29496846  476.21124004]\n",
      " [ -54.30294144  417.65584222 -433.5306893   308.28958062 -340.42660718\n",
      "   344.49856887 -578.15945291  100.8988308  -244.06486883 -428.39936728]\n",
      " [ 157.81213526 -703.52318811  714.46085166 -527.3193638   560.7103528\n",
      "  -578.15945291 1012.37413406 -170.40125078  381.89679534  746.83328925]\n",
      " [  57.04409513  148.44019075 -117.23416553  113.42964508 -230.30315683\n",
      "   100.8988308  -170.40125078  240.07423697    1.58386757 -222.96969641]\n",
      " [  14.3640961  -286.70831912  322.04070545 -204.26187713  205.29496846\n",
      "  -244.06486883  381.89679534    1.58386757  220.14912006  250.90969344]\n",
      " [  79.59549833 -533.19461703  525.72744418 -400.80306541  476.21124004\n",
      "  -428.39936728  746.83328925 -222.96969641  250.90969344  597.79999994]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:20<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 475 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    3098.312\n",
      "w[1]   -1733.094\n",
      "w[2]    1424.690\n",
      "w[3]   -1443.808\n",
      "w[4]     393.206\n",
      "w[5]   -1425.144\n",
      "w[6]    3342.418\n",
      "w[7]     566.376\n",
      "w[8]     728.954\n",
      "w[9]    1963.602\n",
      "Name: mean, dtype: float64\n",
      "[[ 150.31598735  -59.51928073   47.49445824  -56.4916409   -12.70343844\n",
      "   -55.05712953  157.87848193   57.28684827   15.91631971   79.51325659]\n",
      " [ -59.51928073  511.9304244  -526.89287844  377.55674963 -426.95799539\n",
      "   418.42381392 -704.37074367  142.87281221 -289.96853146 -531.0961137 ]\n",
      " [  47.49445824 -526.89287844  557.38674179 -385.25919148  426.2495088\n",
      "  -435.51792979  717.38321472 -111.04148292  326.52535175  524.68195318]\n",
      " [ -56.4916409   377.55674963 -385.25919148  281.2744331  -314.84571941\n",
      "   308.56475316 -527.39156925  109.49995975 -206.40458995 -398.97961184]\n",
      " [ -12.70343844 -426.95799539  426.2495088  -314.84571941  419.55513819\n",
      "  -338.70755752  558.01781741 -226.43536519  205.4159511   472.61505205]\n",
      " [ -55.05712953  418.42381392 -435.51792979  308.56475316 -338.70755752\n",
      "   345.53545499 -579.50028018   96.15987025 -247.17522259 -427.00488413]\n",
      " [ 157.87848193 -704.37074367  717.38321472 -527.39156925  558.01781741\n",
      "  -579.50028018 1013.33776509 -163.16100815  386.86623782  744.02135942]\n",
      " [  57.28684827  142.87281221 -111.04148292  109.49995975 -226.43536519\n",
      "    96.15987025 -163.16100815  240.14711835    5.90719467 -218.29843924]\n",
      " [  15.91631971 -289.96853146  326.52535175 -206.40458995  205.4159511\n",
      "  -247.17522259  386.86623782    5.90719467  224.61698392  252.0827851 ]\n",
      " [  79.51325659 -531.0961137   524.68195318 -398.97961184  472.61505205\n",
      "  -427.00488413  744.02135942 -218.29843924  252.0827851   593.74608331]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:29<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 498 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    3162.919\n",
      "w[1]   -1735.612\n",
      "w[2]    1420.713\n",
      "w[3]   -1451.333\n",
      "w[4]     367.618\n",
      "w[5]   -1429.909\n",
      "w[6]    3379.901\n",
      "w[7]     597.982\n",
      "w[8]     721.822\n",
      "w[9]    1974.503\n",
      "Name: mean, dtype: float64\n",
      "[[ 157.89621028  -55.26148972   41.71473405  -54.20077259  -18.7035067\n",
      "   -51.62932135  156.57556435   60.20403962   11.11369231   77.33218964]\n",
      " [ -55.26148972  518.63763667 -533.78976297  382.30100795 -435.41648613\n",
      "   423.56286738 -710.99413469  149.0024964  -293.46884701 -538.30056699]\n",
      " [  41.71473405 -533.78976297  565.48209278 -389.80912258  434.05859028\n",
      "  -441.08548311  723.29969962 -114.80502913  332.20411131  530.33738891]\n",
      " [ -54.20077259  382.30100795 -389.80912258  284.7637656  -320.9704126\n",
      "   312.12524843 -532.5233145   114.46948093 -208.20699951 -404.66186874]\n",
      " [ -18.7035067  -435.41648613  434.05859028 -320.9704126   432.21368414\n",
      "  -344.79161999  566.1739426  -238.05797505  207.78943058  483.30597227]\n",
      " [ -51.62932135  423.56286738 -441.08548311  312.12524843 -344.79161999\n",
      "   349.56525912 -584.44587014   99.94244812 -250.46289047 -432.03966578]\n",
      " [ 156.57556435 -710.99413469  723.29969962 -532.5233145   566.1739426\n",
      "  -584.44587014 1021.62728089 -170.12372878  388.58406994  752.74316979]\n",
      " [  60.20403962  149.0024964  -114.80502913  114.46948093 -238.05797505\n",
      "    99.94244812 -170.12372878  254.41492061    8.24862851 -229.36846467]\n",
      " [  11.11369231 -293.46884701  332.20411131 -208.20699951  207.78943058\n",
      "  -250.46289047  388.58406994    8.24862851  230.77486464  252.20830686]\n",
      " [  77.33218964 -538.30056699  530.33738891 -404.66186874  483.30597227\n",
      "  -432.03966578  752.74316979 -229.36846467  252.20830686  604.5509311 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:17<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 473 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    3229.307\n",
      "w[1]   -1734.977\n",
      "w[2]    1413.017\n",
      "w[3]   -1456.761\n",
      "w[4]     338.924\n",
      "w[5]   -1432.052\n",
      "w[6]    3414.294\n",
      "w[7]     630.549\n",
      "w[8]     712.052\n",
      "w[9]    1982.918\n",
      "Name: mean, dtype: float64\n",
      "[[ 169.45097875  -58.51703461   43.92083243  -57.69241957  -20.51880758\n",
      "   -54.70609296  167.18182774   64.47559744   11.24569165   82.50250819]\n",
      " [ -58.51703461  551.82131364 -569.23441999  406.69053644 -461.71693806\n",
      "   451.24063532 -756.43759858  154.70105898 -314.65205404 -571.05303258]\n",
      " [  43.92083243 -569.23441999  604.56820352 -415.43241706  460.66225499\n",
      "  -471.02277824  770.96811059 -117.28726984  357.48735294  563.00836589]\n",
      " [ -57.69241957  406.69053644 -415.43241706  302.86440688 -340.38346051\n",
      "   332.38206205 -566.55734274  119.29946085 -222.92647873 -429.46637049]\n",
      " [ -20.51880758 -461.71693806  460.66225499 -340.38346051  458.25145885\n",
      "  -365.81281617  600.02201369 -251.88952425  220.96369585  512.18380983]\n",
      " [ -54.70609296  451.24063532 -471.02277824  332.38206205 -365.81281617\n",
      "   372.80545212 -622.46480176  102.93632605 -268.99898557 -458.60724385]\n",
      " [ 167.18182774 -756.43759858  770.96811059 -566.55734274  600.02201369\n",
      "  -622.46480176 1087.16438984 -175.85554294  416.17868377  798.93232278]\n",
      " [  64.47559744  154.70105898 -117.28726984  119.29946085 -251.88952425\n",
      "   102.93632605 -175.85554294  273.15915609   13.01594999 -241.97367916]\n",
      " [  11.24569165 -314.65205404  357.48735294 -222.92647873  220.96369585\n",
      "  -268.99898557  416.17868377   13.01594999  250.05944472  268.15794361]\n",
      " [  82.50250819 -571.05303258  563.00836589 -429.46637049  512.18380983\n",
      "  -458.60724385  798.93232278 -241.97367916  268.15794361  641.08727909]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:08<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 448 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    3298.254\n",
      "w[1]   -1732.479\n",
      "w[2]    1403.048\n",
      "w[3]   -1461.108\n",
      "w[4]     307.701\n",
      "w[5]   -1432.734\n",
      "w[6]    3447.674\n",
      "w[7]     664.614\n",
      "w[8]     700.617\n",
      "w[9]    1990.009\n",
      "Name: mean, dtype: float64\n",
      "[[ 172.9314454   -58.72358238   43.39238758  -58.18224654  -21.20269241\n",
      "   -54.91554879  169.34061959   64.6347802    10.01983044   83.88499332]\n",
      " [ -58.72358238  564.75761906 -582.292317    416.5182957  -474.61058127\n",
      "   461.77015073 -773.99360832  161.46791626 -320.94380191 -585.8105174 ]\n",
      " [  43.39238758 -582.292317    618.41112139 -425.13646714  472.89934766\n",
      "  -481.85333975  788.2051496  -122.10273253  365.33117899  576.60273312]\n",
      " [ -58.18224654  416.5182957  -425.13646714  310.38405801 -350.33730425\n",
      "   340.32786336 -580.07573851  124.93947456 -227.26119441 -441.05198039]\n",
      " [ -21.20269241 -474.61058127  472.89934766 -350.33730425  472.96499589\n",
      "  -375.91020562  617.11500067 -262.29937609  225.41822143  528.41999641]\n",
      " [ -54.91554879  461.77015073 -481.85333975  340.32786336 -375.91020562\n",
      "   381.45969887 -636.74991476  107.59451902 -274.60228728 -470.20126141]\n",
      " [ 169.34061959 -773.99360832  788.2051496  -580.07573851  617.11500067\n",
      "  -636.74991476 1111.95433251 -185.11065009  423.85169934  819.68045695]\n",
      " [  64.6347802   161.46791626 -122.10273253  124.93947456 -262.29937609\n",
      "   107.59451902 -185.11065009  284.54829531   14.30538907 -253.5932355 ]\n",
      " [  10.01983044 -320.94380191  365.33117899 -227.26119441  225.41822143\n",
      "  -274.60228728  423.85169934   14.30538907  256.3969357   272.51106541]\n",
      " [  83.88499332 -585.8105174   576.60273312 -441.05198039  528.41999641\n",
      "  -470.20126141  819.68045695 -253.5932355   272.51106541  660.29330269]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 03:58<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 455 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    3366.575\n",
      "w[1]   -1727.688\n",
      "w[2]    1390.578\n",
      "w[3]   -1463.726\n",
      "w[4]     274.940\n",
      "w[5]   -1431.471\n",
      "w[6]    3477.700\n",
      "w[7]     698.541\n",
      "w[8]     687.564\n",
      "w[9]    1994.936\n",
      "Name: mean, dtype: float64\n",
      "[[ 177.93654665  -52.87430534   36.04414567  -54.54393911  -27.19673529\n",
      "   -50.0474267   164.44968393   66.24782294    4.20322465   80.03843561]\n",
      " [ -52.87430534  554.48301309 -572.3600913   408.60641669 -467.86244391\n",
      "   453.08001308 -757.34889642  160.50047986 -316.08964698 -574.4605752 ]\n",
      " [  36.04414567 -572.3600913   609.9744867  -417.08900949  465.25144849\n",
      "  -473.80076279  771.07902945 -118.06811414  363.21994139  563.47386636]\n",
      " [ -54.54393911  408.60641669 -417.08900949  304.42783379 -345.29066337\n",
      "   333.54495461 -567.74318886  124.9063144  -222.71503847 -432.97652825]\n",
      " [ -27.19673529 -467.86244391  465.25144849 -345.29066337  471.87652146\n",
      "  -369.50971598  605.12524103 -267.96581784  219.42450699  523.20878008]\n",
      " [ -50.0474267   453.08001308 -473.80076279  333.54495461 -369.50971598\n",
      "   374.25426137 -622.66608367  105.3330184  -271.29849663 -459.92225407]\n",
      " [ 164.44968393 -757.34889642  771.07902945 -567.74318886  605.12524103\n",
      "  -622.66608367 1087.49219711 -183.30114349  414.09552184  802.88017501]\n",
      " [  66.24782294  160.50047986 -118.06811414  124.9063144  -267.96581784\n",
      "   105.3330184  -183.30114349  297.51709286   22.06212983 -258.48302847]\n",
      " [   4.20322465 -316.08964698  363.21994139 -222.71503847  219.42450699\n",
      "  -271.29849663  414.09552184   22.06212983  259.7688825   262.45307643]\n",
      " [  80.03843561 -574.4605752   563.47386636 -432.97652825  523.20878008\n",
      "  -459.92225407  802.88017501 -258.48302847  262.45307643  651.61594169]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:03<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 459 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    3435.081\n",
      "w[1]   -1720.184\n",
      "w[2]    1374.944\n",
      "w[3]   -1464.458\n",
      "w[4]     240.267\n",
      "w[5]   -1427.875\n",
      "w[6]    3504.295\n",
      "w[7]     732.253\n",
      "w[8]     672.150\n",
      "w[9]    1997.732\n",
      "Name: mean, dtype: float64\n",
      "[[ 188.72691579  -53.2122536    34.56374695  -55.85270243  -30.14995701\n",
      "   -50.45290212  170.81702182   68.56193779    1.26210677   83.35302082]\n",
      " [ -53.2122536   595.74787922 -615.97730111  438.59400509 -503.02956475\n",
      "   486.7874252  -811.70110478  171.54700555 -341.64700259 -615.35771471]\n",
      " [  34.56374695 -615.97730111  657.9714241  -448.19547933  500.17245438\n",
      "  -510.04658523  827.34195779 -124.08160229  394.36968905  603.24598422]\n",
      " [ -55.85270243  438.59400509 -448.19547933  326.41889023 -371.21510585\n",
      "   357.88664753 -607.83590988  134.20646199 -240.08418693 -463.71609416]\n",
      " [ -30.14995701 -503.02956475  500.17245438 -371.21510585  507.622597\n",
      "  -397.06195821  649.91473638 -288.61968966  235.89121902  562.27216529]\n",
      " [ -50.45290212  486.7874252  -510.04658523  357.88664753 -397.06195821\n",
      "   402.03762459 -667.04464597  111.87654243 -293.59029029 -492.16879327]\n",
      " [ 170.81702182 -811.70110478  827.34195779 -607.83590988  649.91473638\n",
      "  -667.04464597 1162.30774289 -197.11901254  445.66564529  858.65930407]\n",
      " [  68.56193779  171.54700555 -124.08160229  134.20646199 -288.61968966\n",
      "   111.87654243 -197.11901254  323.945344     28.16052756 -279.89910631]\n",
      " [   1.26210677 -341.64700259  394.36968905 -240.08418693  235.89121902\n",
      "  -293.59029029  445.66564529   28.16052756  284.63226691  280.28653679]\n",
      " [  83.35302082 -615.35771471  603.24598422 -463.71609416  562.27216529\n",
      "  -492.16879327  858.65930407 -279.89910631  280.28653679  698.37002759]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:08<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 456 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    3505.375\n",
      "w[1]   -1709.347\n",
      "w[2]    1355.385\n",
      "w[3]   -1462.944\n",
      "w[4]     202.357\n",
      "w[5]   -1421.527\n",
      "w[6]    3527.532\n",
      "w[7]     766.922\n",
      "w[8]     653.953\n",
      "w[9]    1997.899\n",
      "Name: mean, dtype: float64\n",
      "[[ 191.5925764   -47.02098728   28.09770066  -51.51215947  -37.47038949\n",
      "   -45.57808211  164.06236901   73.23325756   -2.00290948   76.63146179]\n",
      " [ -47.02098728  611.57506728 -632.87113958  449.62345926 -520.31536535\n",
      "   499.29153336 -829.38354648  181.30924211 -351.06576791 -631.37417424]\n",
      " [  28.09770066 -632.87113958  676.73166561 -459.79099531  517.24264743\n",
      "  -523.74005215  846.14258211 -131.54309735  406.11970766  618.96581346]\n",
      " [ -51.51215947  449.62345926 -459.79099531  334.10369676 -383.51387753\n",
      "   366.49957717 -620.1302637   141.58789777 -246.30197855 -475.12125541]\n",
      " [ -37.47038949 -520.31536535  517.24264743 -383.51387753  529.18086794\n",
      "  -410.09282057  669.1594862  -304.85330358  243.02665666  582.36319737]\n",
      " [ -45.57808211  499.29153336 -523.74005215  366.49957717 -410.09282057\n",
      "   412.04885779 -680.95256939  118.24536182 -301.81712126 -504.15946582]\n",
      " [ 164.06236901 -829.38354648  846.14258211 -620.1302637   669.1594862\n",
      "  -680.95256939 1182.05147297 -208.08103997  456.11696897  876.516704  ]\n",
      " [  73.23325756  181.30924211 -131.54309735  141.58789777 -304.85330358\n",
      "   118.24536182 -208.08103997  341.70869924   29.1102284  -295.27498396]\n",
      " [  -2.00290948 -351.06576791  406.11970766 -246.30197855  243.02665666\n",
      "  -301.81712126  456.11696897   29.1102284   294.07824524  286.70742507]\n",
      " [  76.63146179 -631.37417424  618.96581346 -475.12125541  582.36319737\n",
      "  -504.15946582  876.516704   -295.27498396  286.70742507  717.0312642 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:01<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 454 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    3574.894\n",
      "w[1]   -1694.077\n",
      "w[2]    1331.395\n",
      "w[3]   -1458.119\n",
      "w[4]     160.648\n",
      "w[5]   -1411.568\n",
      "w[6]    3544.483\n",
      "w[7]     803.119\n",
      "w[8]     633.549\n",
      "w[9]    1993.159\n",
      "Name: mean, dtype: float64\n",
      "[[ 199.0210123   -42.30897541   23.07148386  -48.56448437  -46.00688238\n",
      "   -42.25866733  161.74656546   80.81587918   -4.38195631   71.56372252]\n",
      " [ -42.30897541  621.84875892 -643.1210363   457.01073607 -532.71676967\n",
      "   507.03619165 -840.21963827  190.1782091  -355.6977686  -642.5903921 ]\n",
      " [  23.07148386 -643.1210363   688.41713349 -466.83621389  527.35726925\n",
      "  -532.00763652  856.63935769 -135.29175112  413.89991611  627.53776476]\n",
      " [ -48.56448437  457.01073607 -466.83621389  339.50482238 -392.69517051\n",
      "   371.96416204 -628.15144818  148.77351517 -248.95088941 -483.73912121]\n",
      " [ -46.00688238 -532.71676967  527.35726925 -392.69517051  549.78979448\n",
      "  -418.36202135  681.03502309 -326.45165888  243.39736613  600.25333364]\n",
      " [ -42.25866733  507.03619165 -532.00763652  371.96416204 -418.36202135\n",
      "   418.09479574 -689.16385058  122.71986702 -306.50576185 -511.60174356]\n",
      " [ 161.74656546 -840.21963827  856.63935769 -628.15144818  681.03502309\n",
      "  -689.16385058 1194.79564588 -216.22007079  460.52475778  888.63979409]\n",
      " [  80.81587918  190.1782091  -135.29175112  148.77351517 -326.45165888\n",
      "   122.71986702 -216.22007079  371.35399503   36.60879524 -314.52218042]\n",
      " [  -4.38195631 -355.6977686   413.89991611 -248.95088941  243.39736613\n",
      "  -306.50576185  460.52475778   36.60879524  303.09495261  286.02885545]\n",
      " [  71.56372252 -642.5903921   627.53776476 -483.73912121  600.25333364\n",
      "  -511.60174356  888.63979409 -314.52218042  286.02885545  733.96438911]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:12<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 479 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    3644.869\n",
      "w[1]   -1675.561\n",
      "w[2]    1304.251\n",
      "w[3]   -1450.887\n",
      "w[4]     115.368\n",
      "w[5]   -1399.085\n",
      "w[6]    3557.387\n",
      "w[7]     841.621\n",
      "w[8]     611.789\n",
      "w[9]    1984.642\n",
      "Name: mean, dtype: float64\n",
      "[[ 206.19236101  -37.72717893   17.91760189  -45.79033445  -53.65025049\n",
      "   -39.01202167  159.5248324    87.27117825   -7.231429     67.15773127]\n",
      " [ -37.72717893  634.59305143 -657.85743035  465.50607678 -543.91911402\n",
      "   517.79844583 -854.30472895  192.67112288 -366.15214547 -653.25310016]\n",
      " [  17.91760189 -657.85743035  706.66859108 -476.4022499   538.12759362\n",
      "  -544.94061282  872.83531997 -133.52719291  428.74146402  637.60977958]\n",
      " [ -45.79033445  465.50607678 -476.4022499   345.24663938 -400.44224993\n",
      "   379.06865026 -637.74641105  151.16415367 -255.36461049 -491.33819801]\n",
      " [ -53.65025049 -543.91911402  538.12759362 -400.44224993  565.57743107\n",
      "  -426.61998964  691.88894365 -340.05914376  247.3116114   613.8906785 ]\n",
      " [ -39.01202167  517.79844583 -544.94061282  379.06865026 -426.61998964\n",
      "   427.41313109 -701.32390883  122.47399951 -316.47066401 -519.67280105]\n",
      " [ 159.5248324  -854.30472895  872.83531997 -637.74641105  691.88894365\n",
      "  -701.32390883 1211.86268244 -216.84288339  472.12355595  900.50593755]\n",
      " [  87.27117825  192.67112288 -133.52719291  151.16415367 -340.05914376\n",
      "   122.47399951 -216.84288339  394.22296835   45.59595853 -325.57871561]\n",
      " [  -7.231429   -366.15214547  428.74146402 -255.36461049  247.3116114\n",
      "  -316.47066401  472.12355595   45.59595853  317.91131183  289.63446668]\n",
      " [  67.15773127 -653.25310016  637.60977958 -491.33819801  613.8906785\n",
      "  -519.67280105  900.50593755 -325.57871561  289.63446668  747.14413646]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:17<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 476 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    3715.376\n",
      "w[1]   -1655.079\n",
      "w[2]    1274.911\n",
      "w[3]   -1442.308\n",
      "w[4]      68.311\n",
      "w[5]   -1384.985\n",
      "w[6]    3568.025\n",
      "w[7]     880.745\n",
      "w[8]     588.609\n",
      "w[9]    1974.325\n",
      "Name: mean, dtype: float64\n",
      "[[ 211.32418719  -35.66508844   16.05852974  -44.40144145  -59.5581488\n",
      "   -37.81203428  159.19515424   94.45104417   -6.9228403    63.67360795]\n",
      " [ -35.66508844  629.35334466 -653.80296586  461.2644671  -538.4830323\n",
      "   514.01361198 -845.99905891  188.06993898 -365.87813072 -645.74120619]\n",
      " [  16.05852974 -653.80296586  705.85623816 -472.59972976  530.29786836\n",
      "  -542.96419348  866.00264172 -121.9356189   433.52269128  627.7863953 ]\n",
      " [ -44.40144145  461.2644671  -472.59972976  341.91779952 -396.6412904\n",
      "   375.80712186 -631.200899    148.87981177 -254.11938905 -486.04825944]\n",
      " [ -59.5581488  -538.4830323   530.29786836 -396.6412904   568.36708814\n",
      "  -420.94002804  681.81751778 -351.89678297  238.72854985  612.85421251]\n",
      " [ -37.81203428  514.01361198 -542.96419348  375.80712186 -420.94002804\n",
      "   425.09439926 -695.35495907  115.45819148 -318.37761066 -512.55126121]\n",
      " [ 159.19515424 -845.99905891  866.00264172 -631.200899    681.81751778\n",
      "  -695.35495907 1200.15978948 -207.79195149  471.35258263  888.7622128 ]\n",
      " [  94.45104417  188.06993898 -121.9356189   148.87981177 -351.89678297\n",
      "   115.45819148 -207.79195149  423.91159726   63.78866634 -333.4834829 ]\n",
      " [  -6.9228403  -365.87813072  433.52269128 -254.11938905  238.72854985\n",
      "  -318.37761066  471.35258263   63.78866634  328.61276755  280.65983693]\n",
      " [  63.67360795 -645.74120619  627.7863953  -486.04825944  612.85421251\n",
      "  -512.55126121  888.7622128  -333.4834829   280.65983693  743.22021497]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:24<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 451 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    3785.147\n",
      "w[1]   -1633.080\n",
      "w[2]    1244.245\n",
      "w[3]   -1432.459\n",
      "w[4]      19.720\n",
      "w[5]   -1369.672\n",
      "w[6]    3576.167\n",
      "w[7]     921.048\n",
      "w[8]     565.206\n",
      "w[9]    1961.807\n",
      "Name: mean, dtype: float64\n",
      "[[ 215.06104391  -29.23921974    7.9319754   -40.30698625  -65.06075607\n",
      "   -32.34434771  152.85540362   94.49691815  -13.53710657   59.61200272]\n",
      " [ -29.23921974  615.42498976 -638.81932893  451.04904408 -530.62582133\n",
      "   501.94833666 -824.39091968  190.54489634 -356.11096415 -632.71189694]\n",
      " [   7.9319754  -638.81932893  690.93488254 -461.23399858  520.44215937\n",
      "  -530.35422275  841.96384168 -121.08123665  425.62476364  611.5371389 ]\n",
      " [ -40.30698625  451.04904408 -461.23399858  334.55031605 -391.14479724\n",
      "   366.86425203 -615.70919327  151.54178385 -246.18109681 -477.14605868]\n",
      " [ -65.06075607 -530.62582133  520.44215937 -391.14479724  567.4443824\n",
      "  -413.41274083  668.79778577 -360.05319693  229.95507768  608.16557855]\n",
      " [ -32.34434771  501.94833666 -530.35422275  366.86425203 -413.41274083\n",
      "   414.77760347 -676.62538113  116.12302684 -310.75732955 -500.54756351]\n",
      " [ 152.85540362 -824.39091968  841.96384168 -615.70919327  668.79778577\n",
      "  -676.62538113 1168.56435185 -211.40788605  454.80274064  869.78957875]\n",
      " [  94.49691815  190.54489634 -121.08123665  151.54178385 -360.05319693\n",
      "   116.12302684 -211.40788605  437.49325174   69.96732708 -342.3524821 ]\n",
      " [ -13.53710657 -356.11096415  425.62476364 -246.18109681  229.95507768\n",
      "  -310.75732955  454.80274064   69.96732708  327.37875553  266.77962465]\n",
      " [  59.61200272 -632.71189694  611.5371389  -477.14605868  608.16557855\n",
      "  -500.54756351  869.78957875 -342.3524821   266.77962465  735.01376254]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:24<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 470 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    3853.895\n",
      "w[1]   -1609.165\n",
      "w[2]    1211.356\n",
      "w[3]   -1421.186\n",
      "w[4]     -29.563\n",
      "w[5]   -1352.636\n",
      "w[6]    3581.273\n",
      "w[7]     960.219\n",
      "w[8]     540.077\n",
      "w[9]    1947.814\n",
      "Name: mean, dtype: float64\n",
      "[[ 220.71687343  -17.12552496   -4.75710299  -31.88770786  -79.0765821\n",
      "   -22.97907437  139.71016733  103.28885066  -20.30818186   47.04826957]\n",
      " [ -17.12552496  637.41769515 -663.34268972  466.03104134 -555.21579132\n",
      "   519.63920088 -847.10119632  203.32938771 -370.95161884 -653.28806619]\n",
      " [  -4.75710299 -663.34268972  719.37451133 -477.71812622  545.35414782\n",
      "  -550.58443402  867.59089512 -130.37224914  444.78119356  632.38758524]\n",
      " [ -31.88770786  466.03104134 -477.71812622  344.79349842 -408.41646364\n",
      "   378.82765144 -631.10265093  161.25581582 -255.7584264  -491.59116463]\n",
      " [ -79.0765821  -555.21579132  545.35414782 -408.41646364  599.43631278\n",
      "  -432.0993819   694.18322667 -383.8772138   241.09455255  635.61349694]\n",
      " [ -22.97907437  519.63920088 -550.58443402  378.82765144 -432.0993819\n",
      "   429.23212452 -695.03631227  124.22194246 -323.83160074 -516.19075733]\n",
      " [ 139.71016733 -847.10119632  867.59089512 -631.10265093  694.18322667\n",
      "  -695.03631227 1191.58022399 -224.16546974  470.6048891   890.58871885]\n",
      " [ 103.28885066  203.32938771 -130.37224914  161.25581582 -383.8772138\n",
      "   124.22194246 -224.16546974  464.66993823   72.34780773 -363.20539565]\n",
      " [ -20.30818186 -370.95161884  444.78119356 -255.7584264   241.09455255\n",
      "  -323.83160074  470.6048891    72.34780773  343.36166689  275.87596033]\n",
      " [  47.04826957 -653.28806619  632.38758524 -491.59116463  635.61349694\n",
      "  -516.19075733  890.58871885 -363.20539565  275.87596033  758.1182987 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:18<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 480 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    3922.918\n",
      "w[1]   -1580.046\n",
      "w[2]    1173.061\n",
      "w[3]   -1406.143\n",
      "w[4]     -83.661\n",
      "w[5]   -1331.400\n",
      "w[6]    3579.622\n",
      "w[7]    1001.478\n",
      "w[8]     511.968\n",
      "w[9]    1928.444\n",
      "Name: mean, dtype: float64\n",
      "[[ 222.25426645  -16.01866486   -6.62822048  -31.34954479  -79.90063091\n",
      "   -21.89123581  139.1109789   102.55081526  -22.32342077   46.90072086]\n",
      " [ -16.01866486  643.73879035 -669.25899775  470.75721737 -562.67648371\n",
      "   524.55730235 -855.03206464  209.11435842 -372.8792852  -661.2668913 ]\n",
      " [  -6.62822048 -669.25899775  725.32360115 -481.95890079  551.95844832\n",
      "  -555.26890922  874.49880484 -134.70029108  447.54947086  639.00117106]\n",
      " [ -31.34954479  470.75721737 -481.95890079  348.35425463 -414.06711959\n",
      "   382.4535675  -637.19107898  165.91385352 -256.86733542 -497.80211401]\n",
      " [ -79.90063091 -562.67648371  551.95844832 -414.06711959  608.66582864\n",
      "  -437.81059063  703.80198495 -391.7486631   242.59613728  645.7369447 ]\n",
      " [ -21.89123581  524.55730235 -555.26890922  382.4535675  -437.81059063\n",
      "   433.05090101 -701.0671128   128.47130137 -325.54390562 -522.17307805]\n",
      " [ 139.1109789  -855.03206464  874.49880484 -637.19107898  703.80198495\n",
      "  -701.0671128  1201.92477547 -232.43325678  472.04008442  901.29687207]\n",
      " [ 102.55081526  209.11435842 -134.70029108  165.91385352 -391.7486631\n",
      "   128.47130137 -232.43325678  472.76057447   72.88032054 -372.55334724]\n",
      " [ -22.32342077 -372.8792852   447.54947086 -256.86733542  242.59613728\n",
      "  -325.54390562  472.04008442   72.88032054  345.97535743  276.58084804]\n",
      " [  46.90072086 -661.2668913   639.00117106 -497.80211401  645.7369447\n",
      "  -522.17307805  901.29687207 -372.55334724  276.58084804  769.5803168 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:16<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 509 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    3989.755\n",
      "w[1]   -1549.891\n",
      "w[2]    1133.784\n",
      "w[3]   -1390.187\n",
      "w[4]    -137.550\n",
      "w[5]   -1309.166\n",
      "w[6]    3575.446\n",
      "w[7]    1041.572\n",
      "w[8]     483.299\n",
      "w[9]    1907.901\n",
      "Name: mean, dtype: float64\n",
      "[[ 236.92997343  -10.56063703  -13.66548051  -28.6601279   -91.1972753\n",
      "   -18.05746305  139.74525864  112.09196878  -27.22067774   42.97640149]\n",
      " [ -10.56063703  661.2582427  -687.92542186  482.96027264 -580.71887347\n",
      "   538.42360458 -875.26854251  218.68399055 -383.30631366 -678.76326252]\n",
      " [ -13.66548051 -687.92542186  748.04820228 -494.20741755  566.98320671\n",
      "  -571.09943934  895.03450305 -135.33272219  464.8739434   652.45150215]\n",
      " [ -28.6601279   482.96027264 -494.20741755  357.09336164 -427.28125289\n",
      "   391.87765615 -651.96519612  174.45489403 -262.53395884 -511.32664618]\n",
      " [ -91.1972753  -580.71887347  566.98320671 -427.28125289  637.93388941\n",
      "  -449.94659635  722.241622   -422.1552462   243.53724075  671.84945857]\n",
      " [ -18.05746305  538.42360458 -571.09943934  391.87765615 -449.94659635\n",
      "   444.47329044 -717.18589129  131.65710125 -336.18460575 -534.02422751]\n",
      " [ 139.74525864 -875.26854251  895.03450305 -651.96519612  722.241622\n",
      "  -717.18589129 1229.05630484 -241.35056659  482.3852582   923.01056604]\n",
      " [ 112.09196878  218.68399055 -135.33272219  174.45489403 -422.1552462\n",
      "   131.65710125 -241.35056659  519.34012385   88.98348028 -400.18531676]\n",
      " [ -27.22067774 -383.30631366  464.8739434  -262.53395884  243.53724075\n",
      "  -336.18460575  482.3852582    88.98348028  365.84714041  275.58907893]\n",
      " [  42.97640149 -678.76326252  652.45150215 -511.32664618  671.84945857\n",
      "  -534.02422751  923.01056604 -400.18531676  275.58907893  796.55523895]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:26<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 498 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    4058.805\n",
      "w[1]   -1517.194\n",
      "w[2]    1091.601\n",
      "w[3]   -1372.593\n",
      "w[4]    -194.540\n",
      "w[5]   -1284.940\n",
      "w[6]    3569.130\n",
      "w[7]    1083.468\n",
      "w[8]     452.757\n",
      "w[9]    1885.109\n",
      "Name: mean, dtype: float64\n",
      "[[ 244.89487907   -2.45351126  -21.78802553  -23.09593062 -104.02601176\n",
      "   -12.18364654  132.92021768  123.55375897  -30.13587877   33.3916735 ]\n",
      " [  -2.45351126  680.30361461 -709.44479581  496.07665658 -599.80068005\n",
      "   554.23032605 -896.01303325  226.51240808 -397.13125439 -695.84422318]\n",
      " [ -21.78802553 -709.44479581  773.38518597 -508.84351728  586.18841676\n",
      "  -589.44780131  918.9495742  -139.50060012  482.86036873  669.91041162]\n",
      " [ -23.09593062  496.07665658 -508.84351728  366.15584314 -440.66927865\n",
      "   402.69491263 -666.25016391  180.42081076 -271.70337337 -523.36615542]\n",
      " [-104.02601176 -599.80068005  586.18841676 -440.66927865  663.9405842\n",
      "  -464.4291734   740.89552423 -442.90581159  251.6436423   693.42794041]\n",
      " [ -12.18364654  554.23032605 -589.44780131  402.69491263 -464.4291734\n",
      "   457.85084536 -734.79202576  135.56345894 -348.84443791 -547.28265008]\n",
      " [ 132.92021768 -896.01303325  918.9495742  -666.25016391  740.89552423\n",
      "  -734.79202576 1252.45516924 -246.17465929  498.81733292  940.54023367]\n",
      " [ 123.55375897  226.51240808 -139.50060012  180.42081076 -442.90581159\n",
      "   135.56345894 -246.17465929  547.06191566   94.55390219 -415.96025366]\n",
      " [ -30.13587877 -397.13125439  482.86036873 -271.70337337  251.6436423\n",
      "  -348.84443791  498.81733292   94.55390219  381.37123508  283.73490353]\n",
      " [  33.3916735  -695.84422318  669.91041162 -523.36615542  693.42794041\n",
      "  -547.28265008  940.54023367 -415.96025366  283.73490353  815.18341928]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 05:13<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 526 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    4127.487\n",
      "w[1]   -1481.554\n",
      "w[2]    1046.538\n",
      "w[3]   -1352.757\n",
      "w[4]    -254.332\n",
      "w[5]   -1258.331\n",
      "w[6]    3558.651\n",
      "w[7]    1126.912\n",
      "w[8]     420.999\n",
      "w[9]    1858.894\n",
      "Name: mean, dtype: float64\n",
      "[[ 248.20719234    1.62494415  -26.25290515  -20.37573986 -109.05323219\n",
      "    -9.03588849  129.37942607  126.72530385  -32.87983534   29.64042688]\n",
      " [   1.62494415  674.51194024 -705.28766223  491.01294777 -593.6270297\n",
      "   549.67962888 -885.82553425  221.0938812  -397.65505355 -686.64511574]\n",
      " [ -26.25290515 -705.28766223  772.39877148 -504.57310563  579.05467358\n",
      "  -586.79803118  910.449284   -129.35962457  487.64580005  659.61090184]\n",
      " [ -20.37573986  491.01294777 -504.57310563  361.91548209 -435.85807202\n",
      "   398.55772805 -657.88601189  177.26440331 -270.83552352 -516.41035794]\n",
      " [-109.05323219 -593.6270297   579.05467358 -435.85807202  662.29599646\n",
      "  -458.45173401  730.04038192 -447.52870453  246.26833257  688.42585039]\n",
      " [  -9.03588849  549.67962888 -586.79803118  398.55772805 -458.45173401\n",
      "   454.50797994 -726.69840724  128.93975985 -350.63840144 -538.90035926]\n",
      " [ 129.37942607 -885.82553425  910.449284   -657.88601189  730.04038192\n",
      "  -726.69840724 1236.64235982 -237.97214741  497.33848199  926.40465578]\n",
      " [ 126.72530385  221.0938812  -129.35962457  177.26440331 -447.52870453\n",
      "   128.93975985 -237.97214741  564.42647488  107.77805679 -418.61559317]\n",
      " [ -32.87983534 -397.65505355  487.64580005 -270.83552352  246.26833257\n",
      "  -350.63840144  497.33848199  107.77805679  390.9015033   276.61668526]\n",
      " [  29.64042688 -686.64511574  659.61090184 -516.41035794  688.42585039\n",
      "  -538.90035926  926.40465578 -418.61559317  276.61668526  807.12490809]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:56<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 536 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    4194.611\n",
      "w[1]   -1445.870\n",
      "w[2]    1001.633\n",
      "w[3]   -1332.759\n",
      "w[4]    -313.454\n",
      "w[5]   -1231.651\n",
      "w[6]    3547.343\n",
      "w[7]    1169.596\n",
      "w[8]     389.429\n",
      "w[9]    1832.469\n",
      "Name: mean, dtype: float64\n",
      "[[ 258.4007426     1.56221656  -25.84037463  -20.9716234  -115.93052176\n",
      "   -10.02440537  134.54295568  137.09286065  -31.13091617   28.37915198]\n",
      " [   1.56221656  677.56695138 -709.94470697  492.69105899 -593.43233799\n",
      "   552.78025915 -889.58278912  216.01695515 -402.96305075 -686.75066926]\n",
      " [ -25.84037463 -709.94470697  779.98431326 -507.09370193  577.70272498\n",
      "  -591.71367096  916.28931743 -119.56263717  496.82792793  658.9207605 ]\n",
      " [ -20.9716234   492.69105899 -507.09370193  362.84719468 -435.40319048\n",
      "   400.29181173 -660.22057517  173.99530388 -273.77172872 -516.42609658]\n",
      " [-115.93052176 -593.43233799  577.70272498 -435.40319048  668.06386177\n",
      "  -457.33271586  726.3379564  -457.28972772  243.24807618  690.38571669]\n",
      " [ -10.02440537  552.78025915 -591.71367096  400.29181173 -457.33271586\n",
      "   457.79018499 -730.9497458   122.25362219 -356.52854272 -538.60810116]\n",
      " [ 134.54295568 -889.58278912  916.28931743 -660.22057517  726.3379564\n",
      "  -730.9497458  1243.69329208 -226.589954    504.66352804  925.86625159]\n",
      " [ 137.09286065  216.01695515 -119.56263717  173.99530388 -457.28972772\n",
      "   122.25362219 -226.589954    588.62000577  121.61327744 -422.14899431]\n",
      " [ -31.13091617 -402.96305075  496.82792793 -273.77172872  243.24807618\n",
      "  -356.52854272  504.66352804  121.61327744  402.44215637  275.07183127]\n",
      " [  28.37915198 -686.75066926  658.9207605  -516.42609658  690.38571669\n",
      "  -538.60810116  925.86625159 -422.14899431  275.07183127  808.33715043]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 05:00<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 543 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    4261.534\n",
      "w[1]   -1409.060\n",
      "w[2]     955.785\n",
      "w[3]   -1311.875\n",
      "w[4]    -373.891\n",
      "w[5]   -1204.116\n",
      "w[6]    3534.369\n",
      "w[7]    1213.361\n",
      "w[8]     357.685\n",
      "w[9]    1804.452\n",
      "Name: mean, dtype: float64\n",
      "[[ 261.73876773    4.99065142  -28.35975459  -18.47224118 -122.52322059\n",
      "    -7.99438667  131.55579125  144.62447992  -30.79912413   23.11446032]\n",
      " [   4.99065142  677.49256233 -711.2864946   491.9993484  -592.75501966\n",
      "   552.99256765 -887.47141365  213.27890558 -405.98826864 -684.04852247]\n",
      " [ -28.35975459 -711.2864946   783.47054219 -507.28837637  576.44457471\n",
      "  -593.4006484   916.41475376 -113.72513662  502.35753994  656.2302167 ]\n",
      " [ -18.47224118  491.9993484  -507.28837637  361.90407719 -434.57169329\n",
      "   399.8829425  -657.83721329  172.27048468 -275.30806477 -514.03859484]\n",
      " [-122.52322059 -592.75501966  576.44457471 -434.57169329  672.15983646\n",
      "  -455.99284269  722.063925   -464.50171265  241.3055309   690.78353044]\n",
      " [  -7.99438667  552.99256765 -593.4006484   399.8829425  -455.99284269\n",
      "   458.36277217 -729.92310539  118.20194304 -359.93715663 -536.02869886]\n",
      " [ 131.55579125 -887.47141365  916.41475376 -657.83721329  722.063925\n",
      "  -729.92310539 1238.8850969  -219.45102026  508.46062216  919.45444517]\n",
      " [ 144.62447992  213.27890558 -113.72513662  172.27048468 -464.50171265\n",
      "   118.20194304 -219.45102026  605.49309273  130.42612424 -425.14853932]\n",
      " [ -30.79912413 -405.98826864  502.35753994 -275.30806477  241.3055309\n",
      "  -359.93715663  508.46062216  130.42612424  409.79308904  273.45389196]\n",
      " [  23.11446032 -684.04852247  656.2302167  -514.03859484  690.78353044\n",
      "  -536.02869886  919.45444517 -425.14853932  273.45389196  805.46993656]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 05:39<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 623 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    4326.666\n",
      "w[1]   -1372.487\n",
      "w[2]     910.512\n",
      "w[3]   -1290.989\n",
      "w[4]    -433.515\n",
      "w[5]   -1176.783\n",
      "w[6]    3520.730\n",
      "w[7]    1256.575\n",
      "w[8]     326.570\n",
      "w[9]    1776.270\n",
      "Name: mean, dtype: float64\n",
      "[[ 260.39952255    9.87019451  -34.16913399  -14.97169415 -124.96120486\n",
      "    -3.59884785  124.31968249  142.76436842  -35.03269723   19.21891345]\n",
      " [   9.87019451  702.57529331 -740.37764469  509.41711035 -613.31199457\n",
      "   574.31841021 -917.58801201  215.60113202 -426.43114588 -704.88706139]\n",
      " [ -34.16913399 -740.37764469  818.75726141 -527.10307549  597.63005449\n",
      "  -618.75140168  951.10220991 -110.70529575  529.54235355  677.52908172]\n",
      " [ -14.97169415  509.41711035 -527.10307549  374.06874003 -449.59067609\n",
      "   414.52132996 -678.70454941  175.43517407 -288.6334366  -529.21028875]\n",
      " [-124.96120486 -613.31199457  597.63005449 -449.59067609  692.83835612\n",
      "  -472.49653255  747.96791837 -475.31736105  251.99012311  712.88165627]\n",
      " [  -3.59884785  574.31841021 -618.75140168  414.52132996 -472.49653255\n",
      "   476.71158582 -755.30028906  118.01080937 -378.71344174 -552.56668192]\n",
      " [ 124.31968249 -917.58801201  951.10220991 -678.70454941  747.96791837\n",
      "  -755.30028906 1274.20283188 -224.25753816  532.45797961  944.86680331]\n",
      " [ 142.76436842  215.60113202 -110.70529575  175.43517407 -475.31736105\n",
      "   118.01080937 -224.25753816  625.73410691  141.57417961 -437.8841904 ]\n",
      " [ -35.03269723 -426.43114588  529.54235355 -288.6334366   251.99012311\n",
      "  -378.71344174  532.45797961  141.57417961  434.33350879  283.91602554]\n",
      " [  19.21891345 -704.88706139  677.52908172 -529.21028875  712.88165627\n",
      "  -552.56668192  944.86680331 -437.8841904   283.91602554  828.12608289]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 05:03<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 564 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    4388.472\n",
      "w[1]   -1334.360\n",
      "w[2]     863.437\n",
      "w[3]   -1268.788\n",
      "w[4]    -492.254\n",
      "w[5]   -1147.820\n",
      "w[6]    3503.300\n",
      "w[7]    1296.822\n",
      "w[8]     293.937\n",
      "w[9]    1746.929\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.68570224e+02  1.31944361e+01 -4.00153912e+01 -1.36371031e+01\n",
      "  -1.28557116e+02 -5.97208596e-01  1.24373510e+02  1.41822934e+02\n",
      "  -4.16859572e+01  1.98897579e+01]\n",
      " [ 1.31944361e+01  7.23510263e+02 -7.63562674e+02  5.24321201e+02\n",
      "  -6.32240347e+02  5.91471357e+02 -9.43489417e+02  2.21468696e+02\n",
      "  -4.40843655e+02 -7.24714906e+02]\n",
      " [-4.00153912e+01 -7.63562674e+02  8.46582416e+02 -5.42907176e+02\n",
      "   6.15925453e+02 -6.38421662e+02  9.78363482e+02 -1.10693810e+02\n",
      "   5.50289068e+02  6.95408904e+02]\n",
      " [-1.36371031e+01  5.24321201e+02 -5.42907176e+02  3.84920226e+02\n",
      "  -4.63707095e+02  4.26536581e+02 -6.97757279e+02  1.81412148e+02\n",
      "  -2.97385654e+02 -5.44597424e+02]\n",
      " [-1.28557116e+02 -6.32240347e+02  6.15925453e+02 -4.63707095e+02\n",
      "   7.15022337e+02 -4.86927898e+02  7.71434858e+02 -4.91185284e+02\n",
      "   2.58974355e+02  7.35808444e+02]\n",
      " [-5.97208596e-01  5.91471357e+02 -6.38421662e+02  4.26536581e+02\n",
      "  -4.86927898e+02  4.91005377e+02 -7.76284378e+02  1.20438381e+02\n",
      "  -3.92054893e+02 -5.67510491e+02]\n",
      " [ 1.24373510e+02 -9.43489417e+02  9.78363482e+02 -6.97757279e+02\n",
      "   7.71434858e+02 -7.76284378e+02  1.30850047e+03 -2.33365529e+02\n",
      "   5.47416642e+02  9.71867015e+02]\n",
      " [ 1.41822934e+02  2.21468696e+02 -1.10693810e+02  1.81412148e+02\n",
      "  -4.91185284e+02  1.20438381e+02 -2.33365529e+02  6.50599609e+02\n",
      "   1.52158024e+02 -4.55660293e+02]\n",
      " [-4.16859572e+01 -4.40843655e+02  5.50289068e+02 -2.97385654e+02\n",
      "   2.58974355e+02 -3.92054893e+02  5.47416642e+02  1.52158024e+02\n",
      "   4.54809628e+02  2.88651875e+02]\n",
      " [ 1.98897579e+01 -7.24714906e+02  6.95408904e+02 -5.44597424e+02\n",
      "   7.35808444e+02 -5.67510491e+02  9.71867015e+02 -4.55660293e+02\n",
      "   2.88651875e+02  8.54378043e+02]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:59<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 553 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    4450.266\n",
      "w[1]   -1294.778\n",
      "w[2]     814.474\n",
      "w[3]   -1245.610\n",
      "w[4]    -551.624\n",
      "w[5]   -1117.544\n",
      "w[6]    3483.975\n",
      "w[7]    1336.124\n",
      "w[8]     259.614\n",
      "w[9]    1716.788\n",
      "Name: mean, dtype: float64\n",
      "[[ 280.46796039   25.1618444   -54.9734641    -6.26631961 -141.98975153\n",
      "     9.13558547  115.25334541  147.08929429  -53.10597646   11.55241737]\n",
      " [  25.1618444   713.28645636 -751.99067998  516.48804052 -632.40458668\n",
      "   581.78161835 -924.34047105  232.22252459 -431.72804566 -716.6568387 ]\n",
      " [ -54.9734641  -751.99067998  835.63511584 -533.39524852  613.05653961\n",
      "  -628.17880345  955.62726153 -115.77450436  544.76542895  682.25822218]\n",
      " [  -6.26631961  516.48804052 -533.39524852  379.18663336 -463.8913551\n",
      "   419.01340075 -684.10858548  190.54996998 -289.09131018 -539.55897826]\n",
      " [-141.98975153 -632.40458668  613.05653961 -463.8913551   729.08295116\n",
      "  -484.77707762  765.37677425 -515.09356029  250.86866614  742.59389858]\n",
      " [   9.13558547  581.78161835 -628.17880345  419.01340075 -484.77707762\n",
      "   482.2384742  -758.83698478  126.42045975 -385.19993749 -558.40578039]\n",
      " [ 115.25334541 -924.34047105  955.62726153 -684.10858548  765.37677425\n",
      "  -758.83698478 1279.51368895 -245.66993628  529.19064446  957.98519826]\n",
      " [ 147.08929429  232.22252459 -115.77450436  190.54996998 -515.09356029\n",
      "   126.42045975 -245.66993628  682.8520367   160.45254478 -478.79106918]\n",
      " [ -53.10597646 -431.72804566  544.76542895 -289.09131018  250.86866614\n",
      "  -385.19993749  529.19064446  160.45254478  457.53066645  272.36714002]\n",
      " [  11.55241737 -716.6568387   682.25822218 -539.55897826  742.59389858\n",
      "  -558.40578039  957.98519826 -478.79106918  272.36714002  855.66886935]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:49<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 558 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    4512.745\n",
      "w[1]   -1253.744\n",
      "w[2]     763.527\n",
      "w[3]   -1221.523\n",
      "w[4]    -611.867\n",
      "w[5]   -1085.951\n",
      "w[6]    3463.170\n",
      "w[7]    1374.765\n",
      "w[8]     223.442\n",
      "w[9]    1686.003\n",
      "Name: mean, dtype: float64\n",
      "[[ 288.73841912   31.23486336  -63.01817636   -2.72048762 -149.67978629\n",
      "    14.12872866  111.82188647  150.49869882  -59.45403151    7.8013109 ]\n",
      " [  31.23486336  735.44435245 -776.30973426  532.07444879 -653.78574522\n",
      "   599.70362228 -950.66198396  241.0745058  -446.27298997 -737.72801147]\n",
      " [ -63.01817636 -776.30973426  864.49371407 -549.86878896  633.53220761\n",
      "  -648.58501216  983.48231141 -118.46051612  565.50369946  701.41766618]\n",
      " [  -2.72048762  532.07444879 -549.86878896  390.31542095 -479.50993096\n",
      "   431.42008011 -703.05995652  198.37623609 -298.04671748 -555.42112884]\n",
      " [-149.67978629 -653.78574522  633.53220761 -479.50993096  756.01589292\n",
      "  -500.77329571  790.09758414 -536.48013439  258.10528828  768.46793558]\n",
      " [  14.12872866  599.70362228 -648.58501216  431.42008011 -500.77329571\n",
      "   496.9873578  -779.97126364  130.78403245 -398.64790257 -574.0517328 ]\n",
      " [ 111.82188647 -950.66198396  983.48231141 -703.05995652  790.09758414\n",
      "  -779.97126364 1312.8937587  -256.44577272  544.62810156  984.55685955]\n",
      " [ 150.49869882  241.0745058  -118.46051612  198.37623609 -536.48013439\n",
      "   130.78403245 -256.44577272  713.67727907  170.37281061 -500.10177029]\n",
      " [ -59.45403151 -446.27298997  565.50369946 -298.04671748  258.10528828\n",
      "  -398.64790257  544.62810156  170.37281061  477.45557203  277.65570739]\n",
      " [   7.8013109  -737.72801147  701.41766618 -555.42112884  768.46793558\n",
      "  -574.0517328   984.55685955 -500.10177029  277.65570739  882.71491472]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 03:58<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 416 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    4574.054\n",
      "w[1]   -1211.112\n",
      "w[2]     710.810\n",
      "w[3]   -1196.212\n",
      "w[4]    -672.707\n",
      "w[5]   -1052.925\n",
      "w[6]    3439.666\n",
      "w[7]    1412.650\n",
      "w[8]     186.071\n",
      "w[9]    1653.787\n",
      "Name: mean, dtype: float64\n",
      "[[ 290.89258926   32.49452151  -64.5318545    -2.09775535 -151.67834349\n",
      "    14.99051433  111.42784717  152.05116405  -60.50993063    6.81989567]\n",
      " [  32.49452151  750.74250315 -792.82882086  542.98039927 -666.91844746\n",
      "   612.34883046 -970.14450103  244.92018929 -456.28205236 -752.21632766]\n",
      " [ -64.5318545  -792.82882086  884.43768644 -561.10850787  644.14823202\n",
      "  -663.06720632 1004.15472562 -114.94894197  580.96694369  713.24715917]\n",
      " [  -2.09775535  542.98039927 -561.10850787  398.25055893 -489.62444141\n",
      "   440.24508582 -717.16781226  202.84580899 -304.02309021 -566.70387516]\n",
      " [-151.67834349 -666.91844746  644.14823202 -489.62444141  773.83285742\n",
      "  -510.10552464  806.73014585 -553.54117646  258.89622505  787.27129019]\n",
      " [  14.99051433  612.34883046 -663.06720632  440.24508582 -510.10552464\n",
      "   507.7710521  -796.05496123  130.78674551 -408.7421919  -584.54188034]\n",
      " [ 111.42784717 -970.14450103 1004.15472562 -717.16781226  806.73014585\n",
      "  -796.05496123 1338.42169679 -261.60863873  556.63834277 1003.61236255]\n",
      " [ 152.05116405  244.92018929 -114.94894197  202.84580899 -553.54117646\n",
      "   130.78674551 -261.60863873  743.73227313  184.67746836 -517.47932628]\n",
      " [ -60.50993063 -456.28205236  580.96694369 -304.02309021  258.89622505\n",
      "  -408.7421919   556.63834277  184.67746836  494.17316905  278.81515063]\n",
      " [   6.81989567 -752.21632766  713.24715917 -566.70387516  787.27129019\n",
      "  -584.54188034 1003.61236255 -517.47932628  278.81515063  903.23684684]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:07<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 464 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    4633.083\n",
      "w[1]   -1168.860\n",
      "w[2]     658.714\n",
      "w[3]   -1170.996\n",
      "w[4]    -732.180\n",
      "w[5]   -1020.115\n",
      "w[6]    3415.472\n",
      "w[7]    1449.196\n",
      "w[8]     149.191\n",
      "w[9]    1621.705\n",
      "Name: mean, dtype: float64\n",
      "[[ 297.15203597   38.99442752  -73.38531547    1.76872087 -157.8431318\n",
      "    20.71186819  106.27487917  152.37198165  -68.01064212    3.24878536]\n",
      " [  38.99442752  764.90992155 -807.9083824   552.63840822 -682.61586707\n",
      "   623.54857191 -985.15008311  253.97256467 -464.79574962 -766.43170201]\n",
      " [ -73.38531547 -807.9083824   903.28040711 -570.64681729  657.17397523\n",
      "  -675.95341532 1018.79526592 -115.84265807  596.03296318  723.41555695]\n",
      " [   1.76872087  552.63840822 -570.64681729  405.03676188 -501.26727792\n",
      "   447.63524044 -727.76832838  211.26884707 -308.26188377 -577.69794692]\n",
      " [-157.8431318  -682.61586707  657.17397523 -501.26727792  797.23723658\n",
      "  -521.17063904  824.4722466  -576.75591322  260.06477207  809.92505212]\n",
      " [  20.71186819  623.54857191 -675.95341532  447.63524044 -521.17063904\n",
      "   516.95211389 -807.49698921  134.83138864 -417.56848746 -594.04021371]\n",
      " [ 106.27487917 -985.15008311 1018.79526592 -727.76832838  824.4722466\n",
      "  -807.49698921 1355.24682239 -274.38612121  563.0767647  1020.80633713]\n",
      " [ 152.37198165  253.97256467 -115.84265807  211.26884707 -576.75591322\n",
      "   134.83138864 -274.38612121  779.1933123   198.46476592 -542.55672875]\n",
      " [ -68.01064212 -464.79574962  596.03296318 -308.26188377  260.06477207\n",
      "  -417.56848746  563.0767647   198.46476592  512.19019199  276.65470787]\n",
      " [   3.24878536 -766.43170201  723.41555695 -577.69794692  809.92505212\n",
      "  -594.04021371 1020.80633713 -542.55672875  276.65470787  926.40571253]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:05<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 524 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    4690.893\n",
      "w[1]   -1126.230\n",
      "w[2]     605.923\n",
      "w[3]   -1145.505\n",
      "w[4]    -790.745\n",
      "w[5]    -986.763\n",
      "w[6]    3390.200\n",
      "w[7]    1483.722\n",
      "w[8]     111.355\n",
      "w[9]    1589.796\n",
      "Name: mean, dtype: float64\n",
      "[[ 289.52052447   39.91165595  -74.00652233    3.04416992 -154.792315\n",
      "    22.10527633  100.97762111  147.69211109  -68.32484909    1.69915009]\n",
      " [  39.91165595  758.08533313 -800.43391511  547.69848425 -678.27568\n",
      "   617.63761722 -975.54650767  254.46880817 -459.61265527 -760.51383817]\n",
      " [ -74.00652233 -800.43391511  896.25117792 -564.96702521  650.07459016\n",
      "  -670.00150889 1008.28444091 -111.5741403   593.05006865  714.67842758]\n",
      " [   3.04416992  547.69848425 -564.96702521  401.48305401 -498.98637864\n",
      "   443.1882638  -720.53220768  213.19252321 -303.83964095 -573.94201424]\n",
      " [-154.792315   -678.27568     650.07459016 -498.98637864  796.73179285\n",
      "  -516.80929363  820.65044441 -583.32242209  251.57806137  810.77431123]\n",
      " [  22.10527633  617.63761722 -670.00150889  443.1882638  -516.80929363\n",
      "   511.98593202 -798.78677965  133.7356066  -414.23648867 -587.91254386]\n",
      " [ 100.97762111 -975.54650767 1008.28444091 -720.53220768  820.65044441\n",
      "  -798.78677965 1339.60474378 -278.28396906  555.554254   1012.45683424]\n",
      " [ 147.69211109  254.46880817 -111.5741403   213.19252321 -583.32242209\n",
      "   133.7356066  -278.28396906  794.25118926  208.89740916 -552.43902603]\n",
      " [ -68.32484909 -459.61265527  593.05006865 -303.83964095  251.57806137\n",
      "  -414.23648867  555.554254    208.89740916  514.47626295  266.90466848]\n",
      " [   1.69915009 -760.51383817  714.67842758 -573.94201424  810.77431123\n",
      "  -587.91254386 1012.45683424 -552.43902603  266.90466848  925.68788639]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 05:31<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 618 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    4744.926\n",
      "w[1]   -1084.099\n",
      "w[2]     553.917\n",
      "w[3]   -1120.066\n",
      "w[4]    -847.097\n",
      "w[5]    -953.583\n",
      "w[6]    3363.572\n",
      "w[7]    1515.848\n",
      "w[8]      74.094\n",
      "w[9]    1558.033\n",
      "Name: mean, dtype: float64\n",
      "[[ 287.53035928   45.05865188  -78.06216314    7.12042735 -160.1632701\n",
      "    25.96330215   93.17004232  152.10094303  -68.91965956   -5.60632344]\n",
      " [  45.05865188  769.2883729  -809.46018194  556.04516189 -695.70676624\n",
      "   625.14424449 -987.90447851  272.20816957 -459.79969789 -777.14959761]\n",
      " [ -78.06216314 -809.46018194  905.25668344 -571.21841423  660.90824304\n",
      "  -676.70668365 1018.0025853  -119.0753861   597.12732812  724.82420058]\n",
      " [   7.12042735  556.04516189 -571.21841423  407.78822194 -512.94912393\n",
      "   448.56793275 -729.67697991  228.40626273 -302.89311306 -587.21477602]\n",
      " [-160.1632701  -695.70676624  660.90824304 -512.94912393  827.88048477\n",
      "  -527.54058451  841.59567689 -620.6824854   245.14981934  842.24833814]\n",
      " [  25.96330215  625.14424449 -676.70668365  448.56793275 -527.54058451\n",
      "   517.20710301 -806.7489013   143.44601676 -415.78458765 -597.86290753]\n",
      " [  93.17004232 -987.90447851 1018.0025853  -729.67697991  841.59567689\n",
      "  -806.7489013  1352.1502813  -300.63553165  554.92936615 1031.41242424]\n",
      " [ 152.10094303  272.20816957 -119.0753861   228.40626273 -620.6824854\n",
      "   143.44601676 -300.63553165  844.79961047  223.14701802 -590.88088853]\n",
      " [ -68.91965956 -459.79969789  597.12732812 -302.89311306  245.14981934\n",
      "  -415.78458765  554.92936615  223.14701802  523.1744167   259.98121807]\n",
      " [  -5.60632344 -777.14959761  724.82420058 -587.21477602  842.24833814\n",
      "  -597.86290753 1031.41242424 -590.88088853  259.98121807  956.3280642 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 04:30<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 729 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    4796.168\n",
      "w[1]   -1041.899\n",
      "w[2]     502.356\n",
      "w[3]   -1094.299\n",
      "w[4]    -902.670\n",
      "w[5]    -920.335\n",
      "w[6]    3335.382\n",
      "w[7]    1547.395\n",
      "w[8]      37.642\n",
      "w[9]    1525.445\n",
      "Name: mean, dtype: float64\n",
      "[[ 295.71549039   50.14776654  -84.66345977    9.96789451 -167.44852774\n",
      "    29.89805085   90.92444066  156.41862164  -74.016116     -9.11909967]\n",
      " [  50.14776654  774.6374061  -818.7248592   558.64823373 -696.65042519\n",
      "   630.48667877 -991.60393079  264.12838342 -470.84142838 -775.68046713]\n",
      " [ -84.66345977 -818.7248592   922.23766246 -575.67033797  659.94013442\n",
      "  -686.51308896 1025.64015447 -100.04172656  618.39568164  720.78396722]\n",
      " [   9.96789451  558.64823373 -575.67033797  409.01589721 -513.57725668\n",
      "   451.11838926 -731.22756549  224.79083972 -308.1906005  -586.47075469]\n",
      " [-167.44852774 -696.65042519  659.94013442 -513.57725668  836.04580898\n",
      "  -526.93083853  839.01955909 -634.26259143  240.89890632  846.87404814]\n",
      " [  29.89805085  630.48667877 -686.51308896  451.11838926 -526.93083853\n",
      "   522.85336551 -811.02005576  132.39132579 -428.1072245  -595.4025997 ]\n",
      " [  90.92444066 -991.60393079 1025.64015447 -731.22756549  839.01955909\n",
      "  -811.02005576 1355.06752191 -288.84637325  565.53500204 1027.68957215]\n",
      " [ 156.41862164  264.12838342 -100.04172656  224.79083972 -634.26259143\n",
      "   132.39132579 -288.84637325  885.39700679  251.69852554 -602.21364785]\n",
      " [ -74.016116   -470.84142838  618.39568164 -308.1906005   240.89890632\n",
      "  -428.1072245   565.53500204  251.69852554  550.89567651  253.45679166]\n",
      " [  -9.11909967 -775.68046713  720.78396722 -586.47075469  846.87404814\n",
      "  -595.4025997  1027.68957215 -602.21364785  253.45679166  959.11696031]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 05:44<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 703 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    4846.696\n",
      "w[1]   -1000.458\n",
      "w[2]     451.465\n",
      "w[3]   -1069.076\n",
      "w[4]    -956.935\n",
      "w[5]    -887.618\n",
      "w[6]    3307.856\n",
      "w[7]    1577.649\n",
      "w[8]       1.295\n",
      "w[9]    1493.870\n",
      "Name: mean, dtype: float64\n",
      "[[  295.01962923    53.17157997   -86.74588704    12.45753264\n",
      "   -171.71522451    31.92550094    86.40893386   161.12221509\n",
      "    -73.35476706   -14.42244735]\n",
      " [   53.17157997   786.978777    -830.47147625   567.65706301\n",
      "   -711.40743262   639.78590101 -1006.13826053   274.93565204\n",
      "   -475.3775087   -790.55063695]\n",
      " [  -86.74588704  -830.47147625   935.25416484  -583.86776649\n",
      "    670.38658302  -696.154194    1039.61326326  -102.89126225\n",
      "    626.81752535   731.58308814]\n",
      " [   12.45753264   567.65706301  -583.86776649   415.6503208\n",
      "   -525.13618402   457.72801485  -741.72374194   234.26148942\n",
      "   -310.66715601  -597.9767905 ]\n",
      " [ -171.71522451  -711.40743262   670.38658302  -525.13618402\n",
      "    860.25974997  -536.52774843   856.65094267  -661.1633889\n",
      "    238.28656553   871.31479981]\n",
      " [   31.92550094   639.78590101  -696.154194     457.72801485\n",
      "   -536.52774843   530.18513802  -821.96041899   137.35401879\n",
      "   -433.3057724   -605.13034394]\n",
      " [   86.40893386 -1006.13826053  1039.61326326  -741.72374194\n",
      "    856.65094267  -821.96041899  1371.6058671   -301.69754165\n",
      "    571.17364514  1044.83106323]\n",
      " [  161.12221509   274.93565204  -102.89126225   234.26148942\n",
      "   -661.1633889    137.35401879  -301.69754165   924.22507991\n",
      "    264.34319515  -628.94237618]\n",
      " [  -73.35476706  -475.3775087    626.81752535  -310.66715601\n",
      "    238.28656553  -433.3057724    571.17364514   264.34319515\n",
      "    561.71359051   251.43053887]\n",
      " [  -14.42244735  -790.55063695   731.58308814  -597.9767905\n",
      "    871.31479981  -605.13034394  1044.83106323  -628.94237618\n",
      "    251.43053887   983.10186079]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 05:42<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 607 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    4894.841\n",
      "w[1]    -958.673\n",
      "w[2]     400.430\n",
      "w[3]   -1043.412\n",
      "w[4]   -1010.433\n",
      "w[5]    -854.524\n",
      "w[6]    3278.642\n",
      "w[7]    1606.708\n",
      "w[8]     -35.007\n",
      "w[9]    1461.688\n",
      "Name: mean, dtype: float64\n",
      "[[ 297.67603671   52.56028924  -87.08571575   11.51671726 -170.79110288\n",
      "    31.62933845   88.90071302  159.18779846  -75.05873466  -11.94560809]\n",
      " [  52.56028924  775.52454339 -817.34181821  559.39781831 -702.39611972\n",
      "   629.97945609 -991.3396044   273.99915822 -466.59337738 -780.41321702]\n",
      " [ -87.08571575 -817.34181821  922.84137765 -573.65515336  656.00240365\n",
      "  -685.86354965 1021.69993925  -92.76745286  622.5794963   715.10030674]\n",
      " [  11.51671726  559.39781831 -573.65515336  409.90242687 -519.65211397\n",
      "   450.40600829 -731.43855319  235.93908586 -302.71785621 -592.00701824]\n",
      " [-170.79110288 -702.39611972  656.00240365 -519.65211397  859.86283606\n",
      "  -527.28781843  845.76006726 -675.00902661  222.43318419  870.69020069]\n",
      " [  31.62933845  629.97945609 -685.86354965  450.40600829 -527.28781843\n",
      "   522.13759687 -809.04690868  133.2012318  -427.88556593 -594.70823372]\n",
      " [  88.90071302 -991.3396044  1021.69993925 -731.43855319  845.76006726\n",
      "  -809.04690868 1353.56286301 -302.70671646  557.81744102 1033.4532226 ]\n",
      " [ 159.18779846  273.99915822  -92.76745286  235.93908586 -675.00902661\n",
      "   133.2012318  -302.70671646  956.1705581   285.02029172 -644.59435838]\n",
      " [ -75.05873466 -466.59337738  622.5794963  -302.71785621  222.43318419\n",
      "  -427.88556593  557.81744102  285.02029172  567.79825618  233.0026485 ]\n",
      " [ -11.94560809 -780.41321702  715.10030674 -592.00701824  870.69020069\n",
      "  -594.70823372 1033.4532226  -644.59435838  233.0026485   982.94138689]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 05:13<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 547 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    4941.177\n",
      "w[1]    -919.360\n",
      "w[2]     352.105\n",
      "w[3]   -1019.428\n",
      "w[4]   -1060.790\n",
      "w[5]    -823.350\n",
      "w[6]    3251.756\n",
      "w[7]    1633.715\n",
      "w[8]     -69.785\n",
      "w[9]    1431.957\n",
      "Name: mean, dtype: float64\n",
      "[[  301.35028361    53.95671948   -88.13601381    12.40632065\n",
      "   -174.85902402    32.46900842    88.96622647   164.25023458\n",
      "    -74.71086072   -14.11391189]\n",
      " [   53.95671948   810.2808679   -855.83906214   584.18061814\n",
      "   -729.86862939   659.0498397  -1035.90514501   278.35940614\n",
      "   -491.80396098  -812.07335485]\n",
      " [  -88.13601381  -855.83906214   968.0335654   -600.54467092\n",
      "    681.78345154  -719.10160478  1071.06428582   -87.74332763\n",
      "    656.17938956   745.46198728]\n",
      " [   12.40632065   584.18061814  -600.54467092   427.69658563\n",
      "   -540.14246133   470.9008244   -763.32263733   241.05109776\n",
      "   -319.45271281  -615.63452849]\n",
      " [ -174.85902402  -729.86862939   681.78345154  -540.14246133\n",
      "    891.2973255   -548.28573607   879.90335229  -698.23530108\n",
      "    231.83646548   904.3527597 ]\n",
      " [   32.46900842   659.0498397   -719.10160478   470.9008244\n",
      "   -548.28573607   546.86104803  -846.37778679   132.71287026\n",
      "   -451.29141669  -619.26957448]\n",
      " [   88.96622647 -1035.90514501  1071.06428582  -763.32263733\n",
      "    879.90335229  -846.37778679  1411.65460481  -306.75065022\n",
      "    590.27459077  1074.08438492]\n",
      " [  164.25023458   278.35940614   -87.74332763   241.05109776\n",
      "   -698.23530108   132.71287026  -306.75065022   997.42708532\n",
      "    304.02549777  -666.8430967 ]\n",
      " [  -74.71086072  -491.80396098   656.17938956  -319.45271281\n",
      "    231.83646548  -451.29141669   590.27459077   304.02549777\n",
      "    598.72898391   245.45805601]\n",
      " [  -14.11391189  -812.07335485   745.46198728  -615.63452849\n",
      "    904.3527597   -619.26957448  1074.08438492  -666.8430967\n",
      "    245.45805601  1020.52859818]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 05:25<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 609 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    4985.596\n",
      "w[1]    -879.378\n",
      "w[2]     303.155\n",
      "w[3]    -994.807\n",
      "w[4]   -1110.704\n",
      "w[5]    -791.477\n",
      "w[6]    3222.992\n",
      "w[7]    1659.535\n",
      "w[8]    -104.973\n",
      "w[9]    1401.527\n",
      "Name: mean, dtype: float64\n",
      "[[  306.51562369    54.78637474   -89.76782118    12.47551832\n",
      "   -177.41573786    33.0099881     90.82864688   166.14965387\n",
      "    -76.43991693   -13.74016576]\n",
      " [   54.78637474   798.75677258  -845.08404164   575.31597236\n",
      "   -717.85084168   650.0588146  -1020.05459043   270.22101318\n",
      "   -488.01742664  -797.53765704]\n",
      " [  -89.76782118  -845.08404164   961.22300836  -591.44594421\n",
      "    665.55905702  -711.91588657  1055.38531477   -69.0277103\n",
      "    659.71017342   726.08849264]\n",
      " [   12.47551832   575.31597236  -591.44594421   421.08948012\n",
      "   -531.93638864   463.70525823  -751.53278475   237.29447589\n",
      "   -314.78635842  -605.90399788]\n",
      " [ -177.41573786  -717.85084168   665.55905702  -531.93638864\n",
      "    888.29772817  -536.75878744   863.07986403  -709.4955022\n",
      "    216.71101563   898.23667642]\n",
      " [   33.0099881    650.0588146   -711.91588657   463.70525823\n",
      "   -536.75878744   540.32443988  -833.90474427   121.8183429\n",
      "   -451.02747043  -605.72746517]\n",
      " [   90.82864688 -1020.05459043  1055.38531477  -751.53278475\n",
      "    863.07986403  -833.90474427  1391.60064683  -296.23273549\n",
      "    583.36373581  1055.59223476]\n",
      " [  166.14965387   270.22101318   -69.0277103    237.29447589\n",
      "   -709.4955022    121.8183429   -296.23273549  1033.46691334\n",
      "    331.32560602  -676.6137541 ]\n",
      " [  -76.43991693  -488.01742664   659.71017342  -314.78635842\n",
      "    216.71101563  -451.02747043   583.36373581   331.32560602\n",
      "    612.94781564   227.98488006]\n",
      " [  -13.74016576  -797.53765704   726.08849264  -605.90399788\n",
      "    898.23667642  -605.72746517  1055.59223476  -676.6137541\n",
      "    227.98488006  1012.59834824]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 05:32<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 568 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5028.464\n",
      "w[1]    -840.984\n",
      "w[2]     255.700\n",
      "w[3]    -971.292\n",
      "w[4]   -1157.986\n",
      "w[5]    -760.726\n",
      "w[6]    3195.564\n",
      "w[7]    1682.831\n",
      "w[8]    -139.743\n",
      "w[9]    1373.142\n",
      "Name: mean, dtype: float64\n",
      "[[  307.28266243    48.43103271   -81.86280007     8.07098242\n",
      "   -174.31243935    27.10561074    99.26321721   169.4529743\n",
      "    -69.87729928    -9.60220171]\n",
      " [   48.43103271   787.00933899  -835.98347647   566.41119368\n",
      "   -698.22372868   642.08171701 -1007.59860566   249.16030291\n",
      "   -488.48615445  -779.48209176]\n",
      " [  -81.86280007  -835.98347647   956.88108278  -584.03328037\n",
      "    643.76734391  -706.98577831  1046.95311114   -39.79173955\n",
      "    666.42962626   706.83479469]\n",
      " [    8.07098242   566.41119368  -584.03328037   414.43439788\n",
      "   -518.19121179   457.44608547  -741.92479055   223.5991935\n",
      "   -313.97290501  -593.17538516]\n",
      " [ -174.31243935  -698.22372868   643.76734391  -518.19121179\n",
      "    871.29520712  -520.29439417   839.21359666  -705.40770064\n",
      "    202.35417684   880.54503242]\n",
      " [   27.10561074   642.08171701  -706.98577831   457.44608547\n",
      "   -520.29439417   535.50808859  -826.11437056   101.40375528\n",
      "   -454.2756587   -591.04966634]\n",
      " [   99.26321721 -1007.59860566  1046.95311114  -741.92479055\n",
      "    839.21359666  -826.11437056  1379.00429787  -267.89868918\n",
      "    586.64529404  1034.12351483]\n",
      " [  169.4529743    249.16030291   -39.79173955   223.5991935\n",
      "   -705.40770064   101.40375528  -267.89868918  1056.86846308\n",
      "    360.31187849  -668.83848368]\n",
      " [  -69.87729928  -488.48615445   666.42962626  -313.97290501\n",
      "    202.35417684  -454.2756587    586.64529404   360.31187849\n",
      "    627.64844884   216.56249439]\n",
      " [   -9.60220171  -779.48209176   706.83479469  -593.17538516\n",
      "    880.54503242  -591.04966634  1034.12351483  -668.83848368\n",
      "    216.56249439   994.83139501]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 05:13<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 550 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5069.566\n",
      "w[1]    -804.617\n",
      "w[2]     210.642\n",
      "w[3]    -949.086\n",
      "w[4]   -1202.855\n",
      "w[5]    -731.621\n",
      "w[6]    3169.854\n",
      "w[7]    1704.913\n",
      "w[8]    -172.881\n",
      "w[9]    1346.447\n",
      "Name: mean, dtype: float64\n",
      "[[  303.51777965    54.12187016   -89.48907576    12.12116241\n",
      "   -174.29364523    32.67709522    89.93679653   162.02818655\n",
      "    -77.19125923   -12.25950724]\n",
      " [   54.12187016   789.88497036  -839.69314694   568.01494784\n",
      "   -703.03407486   644.16036795 -1008.57407301   252.52798463\n",
      "   -491.13188637  -781.68139376]\n",
      " [  -89.48907576  -839.69314694   964.46035549  -585.38649707\n",
      "    645.27616418  -710.78451868  1047.59470892   -34.02429028\n",
      "    676.0440738    704.56064516]\n",
      " [   12.12116241   568.01494784  -585.38649707   415.43760483\n",
      "   -522.61608565   458.23080136  -742.13229327   228.85574854\n",
      "   -313.78233171  -595.75054264]\n",
      " [ -174.29364523  -703.03407486   645.27616418  -522.61608565\n",
      "    881.66422483  -522.69003104   846.35668913  -720.02664013\n",
      "    197.28876139   891.98574373]\n",
      " [   32.67709522   644.16036795  -710.78451868   458.23080136\n",
      "   -522.69003104   537.31878031  -825.90082277   100.94876373\n",
      "   -458.53662012  -590.68977646]\n",
      " [   89.93679653 -1008.57407301  1047.59470892  -742.13229327\n",
      "    846.35668913  -825.90082277  1375.74809151  -277.73777894\n",
      "    585.45446937  1036.5554837 ]\n",
      " [  162.02818655   252.52798463   -34.02429028   228.85574854\n",
      "   -720.02664013   100.94876373  -277.73777894  1085.87945855\n",
      "    378.32244012  -688.71331067]\n",
      " [  -77.19125923  -491.13188637   676.0440738   -313.78233171\n",
      "    197.28876139  -458.53662012   585.45446937   378.32244012\n",
      "    643.6734731    207.43129865]\n",
      " [  -12.25950724  -781.68139376   704.56064516  -595.75054264\n",
      "    891.98574373  -590.68977646  1036.5554837   -688.71331067\n",
      "    207.43129865  1005.62028168]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 05:20<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 587 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5108.185\n",
      "w[1]    -768.923\n",
      "w[2]     166.107\n",
      "w[3]    -927.242\n",
      "w[4]   -1245.355\n",
      "w[5]    -702.792\n",
      "w[6]    3143.731\n",
      "w[7]    1723.987\n",
      "w[8]    -206.225\n",
      "w[9]    1320.851\n",
      "Name: mean, dtype: float64\n",
      "[[  299.08520697    59.05564396   -94.7511954     15.8892748\n",
      "   -175.63756719    37.04025517    81.19650944   158.97376717\n",
      "    -80.91875003   -16.57082081]\n",
      " [   59.05564396   796.18498524  -847.20307751   571.97831109\n",
      "   -709.66235235   649.2388152  -1014.04413455   255.1556342\n",
      "   -496.76639193  -786.49825208]\n",
      " [  -94.7511954   -847.20307751   974.52946503  -589.82347316\n",
      "    650.72081511  -717.2578706   1054.25863842   -32.14827451\n",
      "    685.35255572   708.08531772]\n",
      " [   15.8892748    571.97831109  -589.82347316   417.95241401\n",
      "   -527.67793727   461.27012097  -745.24541648   232.20587991\n",
      "   -316.63458454  -599.35019071]\n",
      " [ -175.63756719  -709.66235235   650.72081511  -527.67793727\n",
      "    890.74722137  -527.46087085   854.43688996  -728.82837261\n",
      "    198.06504496   901.36328521]\n",
      " [   37.04025517   649.2388152   -717.2578706    461.27012097\n",
      "   -527.46087085   541.51156888  -830.02627941   101.71651886\n",
      "   -464.01282386  -593.76727148]\n",
      " [   81.19650944 -1014.04413455  1054.25863842  -745.24541648\n",
      "    854.43688996  -830.02627941  1378.04800413  -283.37019454\n",
      "    590.34726433  1040.71357036]\n",
      " [  158.97376717   255.1556342    -32.14827451   232.20587991\n",
      "   -728.82837261   101.71651886  -283.37019454  1101.89887817\n",
      "    386.76698578  -699.81685425]\n",
      " [  -80.91875003  -496.76639193   685.35255572  -316.63458454\n",
      "    198.06504496  -464.01282386   590.34726433   386.76698578\n",
      "    654.59340706   206.74987777]\n",
      " [  -16.57082081  -786.49825208   708.08531772  -599.35019071\n",
      "    901.36328521  -593.76727148  1040.71357036  -699.81685425\n",
      "    206.74987777  1013.48452282]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 05:38<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 593 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5144.800\n",
      "w[1]    -733.398\n",
      "w[2]     121.906\n",
      "w[3]    -905.369\n",
      "w[4]   -1286.730\n",
      "w[5]    -674.011\n",
      "w[6]    3116.786\n",
      "w[7]    1741.765\n",
      "w[8]    -239.331\n",
      "w[9]    1295.301\n",
      "Name: mean, dtype: float64\n",
      "[[  306.14593808    64.72035584  -100.45158165    19.60069644\n",
      "   -185.11859777    40.9789276     77.29170154   167.69810822\n",
      "    -83.21791226   -23.05217115]\n",
      " [   64.72035584   818.74467689  -875.09613081   586.90917183\n",
      "   -725.36971415   668.73301038 -1040.10146446   251.68917998\n",
      "   -519.01637989  -802.00650561]\n",
      " [ -100.45158165  -875.09613081  1011.67137539  -607.7257323\n",
      "    664.62089111  -742.59260139  1086.81529073   -16.52382814\n",
      "    719.0454365    722.21345925]\n",
      " [   19.60069644   586.90917183  -607.7257323    427.94947085\n",
      "   -539.02589329   473.93681817  -762.55098141   231.97928622\n",
      "   -330.10303913  -610.63105979]\n",
      " [ -185.11859777  -725.36971415   664.62089111  -539.02589329\n",
      "    914.62837822  -538.29423234   870.42730102  -752.0468418\n",
      "    200.67036045   922.58231183]\n",
      " [   40.9789276    668.73301038  -742.59260139   473.93681817\n",
      "   -538.29423234   558.9369274   -852.87525753    93.21350622\n",
      "   -486.10654413  -604.83525964]\n",
      " [   77.29170154 -1040.10146446  1086.81529073  -762.55098141\n",
      "    870.42730102  -852.87525753  1409.3847215   -275.86037786\n",
      "    616.9889857   1057.87914947]\n",
      " [  167.69810822   251.68917998   -16.52382814   231.97928622\n",
      "   -752.0468418     93.21350622  -275.86037786  1153.69768251\n",
      "    416.59677993  -718.84865182]\n",
      " [  -83.21791226  -519.01637989   719.0454365   -330.10303913\n",
      "    200.67036045  -486.10654413   616.9889857    416.59677993\n",
      "    690.84518431   210.39642265]\n",
      " [  -23.05217115  -802.00650561   722.21345925  -610.63105979\n",
      "    922.58231183  -604.83525964  1057.87914947  -718.84865182\n",
      "    210.39642265  1033.59192513]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 05:30<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 582 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5180.454\n",
      "w[1]    -697.933\n",
      "w[2]      77.631\n",
      "w[3]    -883.529\n",
      "w[4]   -1327.167\n",
      "w[5]    -645.156\n",
      "w[6]    3089.455\n",
      "w[7]    1758.076\n",
      "w[8]    -272.846\n",
      "w[9]    1270.174\n",
      "Name: mean, dtype: float64\n",
      "[[  302.55267546    62.60984079   -97.44445095    18.44043582\n",
      "   -182.47847719    39.23869677    78.09460345   167.11407322\n",
      "    -80.41666275   -22.3336733 ]\n",
      " [   62.60984079   803.1874227   -856.94997034   576.04303969\n",
      "   -713.40970182   655.4926327  -1021.17316348   251.25973634\n",
      "   -506.02044524  -789.15534794]\n",
      " [  -97.44445095  -856.94997034   992.33481738  -594.61895775\n",
      "    647.12877389  -727.93758966  1064.7365938     -8.70177781\n",
      "    708.0390558    703.84888249]\n",
      " [   18.44043582   576.04303969  -594.61895775   420.43013\n",
      "   -531.57865438   464.48605767  -749.21377081   233.49393652\n",
      "   -320.06184527  -602.41551175]\n",
      " [ -182.47847719  -713.40970182   647.12877389  -531.57865438\n",
      "    910.85799473  -526.75754481   856.85320322  -763.98126732\n",
      "    182.90627163   919.0716171 ]\n",
      " [   39.23869677   655.4926327   -727.93758966   464.48605767\n",
      "   -526.75754481   547.96773707  -836.60536857    89.91987257\n",
      "   -476.81340759  -592.44065108]\n",
      " [   78.09460345 -1021.17316348  1064.7365938   -749.21377081\n",
      "    856.85320322  -836.60536857  1385.37740695  -276.60097277\n",
      "    601.12339626  1042.15791293]\n",
      " [  167.11407322   251.25973634    -8.70177781   233.49393652\n",
      "   -763.98126732    89.91987257  -276.60097277  1180.41200147\n",
      "    433.18053924  -731.75609771]\n",
      " [  -80.41666275  -506.02044524   708.0390558   -320.06184527\n",
      "    182.90627163  -476.81340759   601.12339626   433.18053924\n",
      "    689.27518903   192.13012073]\n",
      " [  -22.3336733   -789.15534794   703.84888249  -602.41551175\n",
      "    919.0716171   -592.44065108  1042.15791293  -731.75609771\n",
      "    192.13012073  1029.05254407]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 05:22<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 614 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5214.049\n",
      "w[1]    -664.854\n",
      "w[2]      36.038\n",
      "w[3]    -863.253\n",
      "w[4]   -1364.590\n",
      "w[5]    -618.146\n",
      "w[6]    3064.158\n",
      "w[7]    1772.531\n",
      "w[8]    -304.710\n",
      "w[9]    1247.221\n",
      "Name: mean, dtype: float64\n",
      "[[  296.88820911    63.8671994    -98.51928482    19.81311332\n",
      "   -180.63044194    40.64514037    73.48219518   163.60980025\n",
      "    -81.07781101   -23.77882301]\n",
      " [   63.8671994    811.27561879  -865.47712486   581.66902466\n",
      "   -720.83262363   662.01878594 -1031.18466531   253.8740209\n",
      "   -511.19014917  -796.83977156]\n",
      " [  -98.51928482  -865.47712486  1001.86703289  -600.44240628\n",
      "    653.90430025  -735.12289009  1075.46008157    -9.15207118\n",
      "    714.73726464   710.91864944]\n",
      " [   19.81311332   581.66902466  -600.44240628   424.29958394\n",
      "   -537.17556372   468.92166226  -755.8920004    236.08600837\n",
      "   -323.40643514  -607.93910497]\n",
      " [ -180.63044194  -720.83262363   653.90430025  -537.17556372\n",
      "    917.66496054  -532.45942463   867.51871999  -767.91677698\n",
      "    185.49649621   927.95820335]\n",
      " [   40.64514037   662.01878594  -735.12289009   468.92166226\n",
      "   -532.45942463   553.33887244  -844.48022083    91.18938125\n",
      "   -481.64050301  -598.08636549]\n",
      " [   73.48219518 -1031.18466531  1075.46008157  -755.8920004\n",
      "    867.51871999  -844.48022083  1396.14642693  -281.70047321\n",
      "    607.69910109  1051.44604235]\n",
      " [  163.60980025   253.8740209     -9.15207118   236.08600837\n",
      "   -767.91677698    91.18938125  -281.70047321  1186.80148955\n",
      "    436.39548607  -738.33893374]\n",
      " [  -81.07781101  -511.19014917   714.73726464  -323.40643514\n",
      "    185.49649621  -481.64050301   607.69910109   436.39548607\n",
      "    695.38976696   194.7312828 ]\n",
      " [  -23.77882301  -796.83977156   710.91864944  -607.93910497\n",
      "    927.95820335  -598.08636549  1051.44604235  -738.33893374\n",
      "    194.7312828   1038.22334944]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 05:37<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 599 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5245.846\n",
      "w[1]    -632.030\n",
      "w[2]      -5.056\n",
      "w[3]    -842.987\n",
      "w[4]   -1401.109\n",
      "w[5]    -591.288\n",
      "w[6]    3038.231\n",
      "w[7]    1786.195\n",
      "w[8]    -336.068\n",
      "w[9]    1224.215\n",
      "Name: mean, dtype: float64\n",
      "[[  291.10845116    59.36641196   -92.551249      17.27746557\n",
      "   -175.41038583    37.02472006    76.17762981   161.8665241\n",
      "    -76.04148921   -21.2460961 ]\n",
      " [   59.36641196   810.71936645  -867.12135206   581.11460392\n",
      "   -713.79242744   662.84468886 -1032.56483564   241.43377753\n",
      "   -516.20524948  -792.07965949]\n",
      " [  -92.551249    -867.12135206  1009.74809672  -600.6838256\n",
      "    641.21776614  -739.48208331  1080.05262799    18.26110791\n",
      "    729.7493784    701.24921877]\n",
      " [   17.27746557   581.11460392  -600.6838256    423.90620111\n",
      "   -533.70456093   469.00506231  -756.38502679   230.51364236\n",
      "   -325.18710758  -605.77685791]\n",
      " [ -175.41038583  -713.79242744   641.21776614  -533.70456093\n",
      "    917.31728864  -525.01149929   861.59102411  -780.37331659\n",
      "    170.27440257   930.10954855]\n",
      " [   37.02472006   662.84468886  -739.48208331   469.00506231\n",
      "   -525.01149929   555.72307378  -847.07187178    75.35545506\n",
      "   -490.14105465  -592.48253049]\n",
      " [   76.17762981 -1032.56483564  1080.05262799  -756.38502679\n",
      "    861.59102411  -847.07187178  1398.9465902   -267.88438413\n",
      "    615.83901974  1047.01690502]\n",
      " [  161.8665241    241.43377753    18.26110791   230.51364236\n",
      "   -780.37331659    75.35545506  -267.88438413  1233.80767528\n",
      "    474.91483783  -751.43639066]\n",
      " [  -76.04148921  -516.20524948   729.7493784   -325.18710758\n",
      "    170.27440257  -490.14105465   615.83901974   474.91483783\n",
      "    720.06421952   182.09312074]\n",
      " [  -21.2460961   -792.07965949   701.24921877  -605.77685791\n",
      "    930.10954855  -592.48253049  1047.01690502  -751.43639066\n",
      "    182.09312074  1041.6390497 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 05:42<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 593 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5275.142\n",
      "w[1]    -600.174\n",
      "w[2]     -45.027\n",
      "w[3]    -823.230\n",
      "w[4]   -1435.456\n",
      "w[5]    -565.051\n",
      "w[6]    3012.262\n",
      "w[7]    1797.755\n",
      "w[8]    -366.833\n",
      "w[9]    1202.126\n",
      "Name: mean, dtype: float64\n",
      "[[  287.13552414    61.21103666   -95.72753547    18.52131279\n",
      "   -172.27246144    39.31142532    71.89907778   153.69338939\n",
      "    -80.54693843   -20.25909964]\n",
      " [   61.21103666   811.37227415  -872.24331101   580.48003706\n",
      "   -707.9604839    665.12234513 -1032.12224718   226.36798587\n",
      "   -526.43554461  -784.59412113]\n",
      " [  -95.72753547  -872.24331101  1023.78729952  -602.18748807\n",
      "    632.80523586  -746.91010491  1084.23431078    46.54181713\n",
      "    751.89544431   690.6113572 ]\n",
      " [   18.52131279   580.48003706  -602.18748807   422.88000919\n",
      "   -530.22296524   469.35977923  -754.77403063   223.03202481\n",
      "   -329.64939678  -601.11422097]\n",
      " [ -172.27246144  -707.9604839    632.80523586  -530.22296524\n",
      "    914.13044291  -519.80413632   855.99819737  -783.42591206\n",
      "    162.44494526   927.77338711]\n",
      " [   39.31142532   665.12234513  -746.91010491   469.35977923\n",
      "   -519.80413632   559.47406111  -848.40679702    59.03866995\n",
      "   -502.57445775  -585.59567374]\n",
      " [   71.89907778 -1032.12224718  1084.23431078  -754.77403063\n",
      "    855.99819737  -848.40679702  1395.81302764  -253.95241596\n",
      "    625.60040891  1038.24919803]\n",
      " [  153.69338939   226.36798587    46.54181713   223.03202481\n",
      "   -783.42591206    59.03866995  -253.95241596  1267.36093466\n",
      "    510.26772423  -758.00033256]\n",
      " [  -80.54693843  -526.43554461   751.89544431  -329.64939678\n",
      "    162.44494526  -502.57445775   625.60040891   510.26772423\n",
      "    751.01780862   171.85332921]\n",
      " [  -20.25909964  -784.59412113   690.6113572   -601.11422097\n",
      "    927.77338711  -585.59567374  1038.24919803  -758.00033256\n",
      "    171.85332921  1038.81377876]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 05:36<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 601 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5303.102\n",
      "w[1]    -569.261\n",
      "w[2]     -84.458\n",
      "w[3]    -804.183\n",
      "w[4]   -1467.389\n",
      "w[5]    -539.294\n",
      "w[6]    2986.881\n",
      "w[7]    1806.121\n",
      "w[8]    -398.179\n",
      "w[9]    1181.929\n",
      "Name: mean, dtype: float64\n",
      "[[  284.65743585    64.97192265  -100.25949238    21.31563701\n",
      "   -173.19835287    42.85845518    65.68046992   150.80567421\n",
      "    -84.27087682   -22.98333465]\n",
      " [   64.97192265   837.9704215   -901.32013055   599.4488124\n",
      "   -731.75987277   687.12124405 -1065.328239     234.07509982\n",
      "   -544.20582692  -809.99929714]\n",
      " [ -100.25949238  -901.32013055  1057.76623983  -622.31297563\n",
      "    655.25664806  -771.77554064  1120.02244182    45.90353694\n",
      "    776.14625576   714.38422552]\n",
      " [   21.31563701   599.4488124   -622.31297563   436.55555566\n",
      "   -548.30200844   484.79951988  -778.47186818   230.8648311\n",
      "   -340.96999311  -620.34323034]\n",
      " [ -173.19835287  -731.75987277   655.25664806  -548.30200844\n",
      "    940.09645755  -538.34055675   887.43926126  -801.35059668\n",
      "    170.78597817   956.8340741 ]\n",
      " [   42.85845518   687.12124405  -771.77554064   484.79951988\n",
      "   -538.34055675   577.93319734  -875.53117824    62.77630659\n",
      "   -519.02040892  -605.14256845]\n",
      " [   65.68046992 -1065.328239    1120.02244182  -778.47186818\n",
      "    887.43926126  -875.53117824  1436.51266853  -266.67544191\n",
      "    646.51833097  1070.92871061]\n",
      " [  150.80567421   234.07509982    45.90353694   230.8648311\n",
      "   -801.35059668    62.77630659  -266.67544191  1294.85039963\n",
      "    521.79533521  -779.28986061]\n",
      " [  -84.27087682  -544.20582692   776.14625576  -340.96999311\n",
      "    170.78597817  -519.02040892   646.51833097   521.79533521\n",
      "    773.34754155   180.14234477]\n",
      " [  -22.98333465  -809.99929714   714.38422552  -620.34323034\n",
      "    956.8340741   -605.14256845  1070.92871061  -779.28986061\n",
      "    180.14234477  1070.27554721]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 05:58<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 607 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5329.542\n",
      "w[1]    -538.357\n",
      "w[2]    -123.915\n",
      "w[3]    -785.047\n",
      "w[4]   -1498.348\n",
      "w[5]    -513.402\n",
      "w[6]    2960.727\n",
      "w[7]    1813.045\n",
      "w[8]    -429.721\n",
      "w[9]    1161.867\n",
      "Name: mean, dtype: float64\n",
      "[[  287.78389633    62.81343081   -98.0543999     19.48234989\n",
      "   -173.19697205    40.86315522    70.15537674   152.91211871\n",
      "    -82.73927894   -21.01007101]\n",
      " [   62.81343081   857.43677734  -921.10520901   613.92564239\n",
      "   -748.78461899   702.96683632 -1092.26842895   240.8073645\n",
      "   -554.33283947  -830.92304393]\n",
      " [  -98.0543999   -921.10520901  1081.13983623  -636.19849958\n",
      "    666.78639644  -789.18702226  1147.01008624    51.42412103\n",
      "    793.80217798   729.59878657]\n",
      " [   19.48234989   613.92564239  -636.19849958   447.52661094\n",
      "   -562.25165544   496.2653029   -798.71307935   238.73259469\n",
      "   -346.68258616  -637.3744782 ]\n",
      " [ -173.19697205  -748.78461899   666.78639644  -562.25165544\n",
      "    966.26059253  -549.73575792   910.66838741  -830.64826738\n",
      "    166.50206369   985.87853099]\n",
      " [   40.86315522   702.96683632  -789.18702226   496.2653029\n",
      "   -549.73575792   591.36800299  -897.42095237    63.08279249\n",
      "   -530.23086646  -619.72448479]\n",
      " [   70.15537674 -1092.26842895  1147.01008624  -798.71307935\n",
      "    910.66838741  -897.42095237  1474.56792947  -275.90753037\n",
      "    659.90132259  1100.3685614 ]\n",
      " [  152.91211871   240.8073645     51.42412103   238.73259469\n",
      "   -830.64826738    63.08279249  -275.90753037  1346.223799\n",
      "    546.29315427  -809.44349395]\n",
      " [  -82.73927894  -554.33283947   793.80217798  -346.68258616\n",
      "    166.50206369  -530.23086646   659.90132259   546.29315427\n",
      "    795.12257103   177.48472547]\n",
      " [  -21.01007101  -830.92304393   729.59878657  -637.3744782\n",
      "    985.87853099  -619.72448479  1100.3685614   -809.44349395\n",
      "    177.48472547  1103.81248679]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 06:19<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 660 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5354.974\n",
      "w[1]    -508.256\n",
      "w[2]    -162.167\n",
      "w[3]    -766.344\n",
      "w[4]   -1528.647\n",
      "w[5]    -488.232\n",
      "w[6]    2935.064\n",
      "w[7]    1820.223\n",
      "w[8]    -460.054\n",
      "w[9]    1141.983\n",
      "Name: mean, dtype: float64\n",
      "[[  279.39147665    63.80926843   -97.16113683    21.04311328\n",
      "   -171.92585491    41.53689601    64.59937546   152.38771175\n",
      "    -80.07939658   -24.64930877]\n",
      " [   63.80926843   866.11488292  -930.74694573   620.24805126\n",
      "   -756.0877242    710.16786263 -1103.40396241   242.94774799\n",
      "   -560.35723852  -838.97744855]\n",
      " [  -97.16113683  -930.74694573  1094.06792273  -642.78197535\n",
      "    669.7046136   -798.21255804  1159.9656267     59.338009\n",
      "    805.74811996   734.225303  ]\n",
      " [   21.04311328   620.24805126  -642.78197535   452.19196448\n",
      "   -568.8962706    501.26463739  -806.4903492    242.76437829\n",
      "   -349.96275963  -644.14991654]\n",
      " [ -171.92585491  -756.0877242    669.7046136   -568.8962706\n",
      "    980.1126658   -553.86966536   921.81161438  -849.96059386\n",
      "    160.15098506  1002.02057309]\n",
      " [   41.53689601   710.16786263  -798.21255804   501.26463739\n",
      "   -553.86966536   597.74387436  -906.55450038    60.80251281\n",
      "   -537.57214515  -624.4561957 ]\n",
      " [   64.59937546 -1103.40396241  1159.9656267   -806.4903492\n",
      "    921.81161438  -906.55450038  1486.70353249  -280.57668774\n",
      "    668.3841795   1110.07302762]\n",
      " [  152.38771175   242.94774799    59.338009     242.76437829\n",
      "   -849.96059386    60.80251281  -280.57668774  1384.73454924\n",
      "    567.86596698  -830.36325145]\n",
      " [  -80.07939658  -560.35723852   805.74811996  -349.96275963\n",
      "    160.15098506  -537.57214515   668.3841795    567.86596698\n",
      "    811.5876084    172.96190869]\n",
      " [  -24.64930877  -838.97744855   734.225303    -644.14991654\n",
      "   1002.02057309  -624.4561957   1110.07302762  -830.36325145\n",
      "    172.96190869  1119.59089162]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 06:03<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 648 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5378.684\n",
      "w[1]    -478.978\n",
      "w[2]    -199.395\n",
      "w[3]    -748.102\n",
      "w[4]   -1557.414\n",
      "w[5]    -463.660\n",
      "w[6]    2909.603\n",
      "w[7]    1826.162\n",
      "w[8]    -489.719\n",
      "w[9]    1122.777\n",
      "Name: mean, dtype: float64\n",
      "[[  286.29720528    63.22540507   -98.52165409    19.6583966\n",
      "   -171.95623027    41.16196022    69.31051769   150.63003636\n",
      "    -83.61897927   -20.63199348]\n",
      " [   63.22540507   854.1892031   -916.21146524   612.19838164\n",
      "   -748.80193471   699.6793789  -1088.26413246   246.01929184\n",
      "   -548.89981548  -830.45328432]\n",
      " [  -98.52165409  -916.21146524  1081.76682139  -631.53999333\n",
      "    652.7250045   -787.37377071  1139.68563164    73.87239071\n",
      "    803.55291161   714.04384819]\n",
      " [   19.6583966    612.19838164  -631.53999333   447.16054073\n",
      "   -565.84406095   493.71594916  -796.99603363   249.26845609\n",
      "   -339.15982692  -640.95483922]\n",
      " [ -171.95623027  -748.80193471   652.7250045   -565.84406095\n",
      "    989.67572537  -544.22343683   913.4280956   -881.95064308\n",
      "    135.3748057   1011.46713801]\n",
      " [   41.16196022   699.6793789   -787.37377071   493.71594916\n",
      "   -544.22343683   589.27622581  -892.91134357    56.45960584\n",
      "   -531.74956741  -613.44216507]\n",
      " [   69.31051769 -1088.26413246  1139.68563164  -796.99603363\n",
      "    913.4280956   -892.91134357  1469.84216473  -287.94070391\n",
      "    650.08420627  1102.47170739]\n",
      " [  150.63003636   246.01929184    73.87239071   249.26845609\n",
      "   -881.95064308    56.45960584  -287.94070391  1449.72413929\n",
      "    604.9077983   -865.61988374]\n",
      " [  -83.61897927  -548.89981548   803.55291161  -339.15982692\n",
      "    135.3748057   -531.74956741   650.08420627   604.9077983\n",
      "    826.14200054   143.53571652]\n",
      " [  -20.63199348  -830.45328432   714.04384819  -640.95483922\n",
      "   1011.46713801  -613.44216507  1102.47170739  -865.61988374\n",
      "    143.53571652  1131.12806742]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 06:00<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 615 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5401.800\n",
      "w[1]    -451.822\n",
      "w[2]    -234.633\n",
      "w[3]    -731.419\n",
      "w[4]   -1583.552\n",
      "w[5]    -440.685\n",
      "w[6]    2886.657\n",
      "w[7]    1830.015\n",
      "w[8]    -518.712\n",
      "w[9]    1106.205\n",
      "Name: mean, dtype: float64\n",
      "[[  286.03043953    58.21541899   -93.177761      16.17052491\n",
      "   -167.9303679     37.02243684    75.70078805   149.62588492\n",
      "    -80.2647845    -16.04605881]\n",
      " [   58.21541899   813.72277955  -874.90952131   582.96811044\n",
      "   -708.43612132   667.67234085 -1037.50779747   224.78647187\n",
      "   -527.8534751   -787.08352014]\n",
      " [  -93.177761    -874.90952131  1041.66964961  -601.23746301\n",
      "    607.87703011  -755.56515337  1087.67463559   103.38921275\n",
      "    786.68237497   666.0162693 ]\n",
      " [   16.17052491   582.96811044  -601.23746301   426.12371431\n",
      "   -537.51395908   470.39286422  -760.3281086    235.72868135\n",
      "   -322.92322767  -610.43918153]\n",
      " [ -167.9303679   -708.43612132   607.87703011  -537.51395908\n",
      "    956.40168597  -510.69993628   862.88956126  -875.41152394\n",
      "    106.0340676    975.08521792]\n",
      " [   37.02243684   667.67234085  -755.56515337   470.39286422\n",
      "   -510.69993628   564.31175516  -852.71680064    36.3007664\n",
      "   -517.03552313  -577.54313412]\n",
      " [   75.70078805 -1037.50779747  1087.67463559  -760.3281086\n",
      "    862.88956126  -852.71680064  1406.23344855  -261.76231839\n",
      "    623.32711332  1048.26405875]\n",
      " [  149.62588492   224.78647187   103.38921275   235.72868135\n",
      "   -875.41152394    36.3007664   -261.76231839  1469.49508448\n",
      "    633.7598619   -857.51613003]\n",
      " [  -80.2647845   -527.8534751    786.68237497  -322.92322767\n",
      "    106.0340676   -517.03552313   623.32711332   633.7598619\n",
      "    825.55446475   112.50900352]\n",
      " [  -16.04605881  -787.08352014   666.0162693   -610.43918153\n",
      "    975.08521792  -577.54313412  1048.26405875  -857.51613003\n",
      "    112.50900352  1091.51987195]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 05:57<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 611 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5424.031\n",
      "w[1]    -426.247\n",
      "w[2]    -268.308\n",
      "w[3]    -715.850\n",
      "w[4]   -1607.617\n",
      "w[5]    -418.892\n",
      "w[6]    2865.355\n",
      "w[7]    1832.248\n",
      "w[8]    -547.051\n",
      "w[9]    1091.455\n",
      "Name: mean, dtype: float64\n",
      "[[  289.57259659    61.0045956    -98.41145445    17.44855584\n",
      "   -168.56628326    39.98405588    74.22317497   145.3072287\n",
      "    -86.72005631   -14.98420561]\n",
      " [   61.0045956    830.41525697  -894.61602245   594.45026194\n",
      "   -721.07103179   681.94568597 -1057.70855779   224.62106494\n",
      "   -542.42452681  -800.14636675]\n",
      " [  -98.41145445  -894.61602245  1070.22622932  -613.32980637\n",
      "    614.63758198  -774.3502448   1109.74986898   121.91161219\n",
      "    815.58675058   671.73945875]\n",
      " [   17.44855584   594.45026194  -613.32980637   434.41580345\n",
      "   -548.36063265   479.68793046  -774.75730418   240.50282645\n",
      "   -329.76179503  -622.03994611]\n",
      " [ -168.56628326  -721.07103179   614.63758198  -548.36063265\n",
      "    979.45241492  -518.4431096    880.08129841  -904.97743914\n",
      "     98.9167008   1000.03417451]\n",
      " [   39.98405588   681.94568597  -774.3502448    479.68793046\n",
      "   -518.4431096    577.23537959  -869.41031492    29.32657821\n",
      "   -533.78624873  -585.15154713]\n",
      " [   74.22317497 -1057.70855779  1109.74986898  -774.75730418\n",
      "    880.08129841  -869.41031492  1431.89651927  -266.3635706\n",
      "    637.2140732   1067.11139614]\n",
      " [  145.3072287    224.62106494   121.91161219   240.50282645\n",
      "   -904.97743914    29.32657821  -266.3635706   1535.17191116\n",
      "    674.56683691  -891.10355612]\n",
      " [  -86.72005631  -542.42452681   815.58675058  -329.76179503\n",
      "     98.9167008   -533.78624873   637.2140732    674.56683691\n",
      "    864.10180732   102.52574903]\n",
      " [  -14.98420561  -800.14636675   671.73945875  -622.03994611\n",
      "   1000.03417451  -585.15154713  1067.11139614  -891.10355612\n",
      "    102.52574903  1119.4206126 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 05:49<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 595 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5445.488\n",
      "w[1]    -400.568\n",
      "w[2]    -302.228\n",
      "w[3]    -700.186\n",
      "w[4]   -1631.076\n",
      "w[5]    -396.894\n",
      "w[6]    2843.530\n",
      "w[7]    1833.350\n",
      "w[8]    -575.823\n",
      "w[9]    1076.882\n",
      "Name: mean, dtype: float64\n",
      "[[  289.19337354    54.73028097   -90.0391388     13.33540001\n",
      "   -165.82023815    34.25828772    82.03214002   149.54718656\n",
      "    -79.34113465   -11.72112784]\n",
      " [   54.73028097   821.41532967  -886.16741928   588.15061907\n",
      "   -707.47185213   675.66131007 -1049.06400253   212.20549005\n",
      "   -540.06895574  -788.68054369]\n",
      " [  -90.0391388   -886.16741928  1068.27914993  -606.09168331\n",
      "    589.82740737  -771.09084979  1102.08828136   158.38571717\n",
      "    827.11654023   649.66522264]\n",
      " [   13.33540001   588.15061907  -606.09168331   430.31682894\n",
      "   -541.3254518    474.72573179  -768.73260923   237.03022268\n",
      "   -325.10300778  -616.49361243]\n",
      " [ -165.82023815  -707.47185213   589.82740737  -541.3254518\n",
      "    984.09737238  -503.4798394    865.11003917  -937.58045059\n",
      "     67.75472908  1005.4286142 ]\n",
      " [   34.25828772   675.66131007  -771.09084979   474.72573179\n",
      "   -503.4798394    574.02442862  -863.70370493     9.48447331\n",
      "   -538.21041555  -572.15841313]\n",
      " [   82.03214002 -1049.06400253  1102.08828136  -768.73260923\n",
      "    865.11003917  -863.70370493  1424.41568081  -251.07643722\n",
      "    636.06234176  1055.16959955]\n",
      " [  149.54718656   212.20549005   158.38571717   237.03022268\n",
      "   -937.58045059     9.48447331  -251.07643722  1623.03700693\n",
      "    734.70905232  -922.11011517]\n",
      " [  -79.34113465  -540.06895574   827.11654023  -325.10300778\n",
      "     67.75472908  -538.21041555   636.06234176   734.70905232\n",
      "    894.95231841    73.64082641]\n",
      " [  -11.72112784  -788.68054369   649.66522264  -616.49361243\n",
      "   1005.4286142   -572.15841313  1055.16959955  -922.11011517\n",
      "     73.64082641  1126.12360313]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 05:55<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 611 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5465.688\n",
      "w[1]    -376.415\n",
      "w[2]    -334.502\n",
      "w[3]    -685.528\n",
      "w[4]   -1652.512\n",
      "w[5]    -376.050\n",
      "w[6]    2823.065\n",
      "w[7]    1833.039\n",
      "w[8]    -603.719\n",
      "w[9]    1063.844\n",
      "Name: mean, dtype: float64\n",
      "[[  292.76527143    62.47952549   -99.95524433    18.31639967\n",
      "   -171.44498322    40.99377317    74.16458786   148.06825649\n",
      "    -87.8090753    -16.2143444 ]\n",
      " [   62.47952549   792.38891138  -855.60826635   566.65247699\n",
      "   -687.1995114    651.29218153 -1007.05344677   210.82378799\n",
      "   -521.56481595  -760.17426828]\n",
      " [  -99.95524433  -855.60826635  1039.06527825  -582.66260401\n",
      "    564.45373974  -746.46405122  1056.54054342   169.37515147\n",
      "    814.12848596   614.3353277 ]\n",
      " [   18.31639967   566.65247699  -582.66260401   414.62698214\n",
      "   -527.21494124   456.43394128  -738.11617006   238.30747015\n",
      "   -309.68690401  -596.78897112]\n",
      " [ -171.44498322  -687.1995114    564.45373974  -527.21494124\n",
      "    976.8164074   -484.85842282   836.03913406  -951.62883404\n",
      "     45.8722618    992.69536562]\n",
      " [   40.99377317   651.29218153  -746.46405122   456.43394128\n",
      "   -484.85842282   553.95334007  -828.19270457     4.7180625\n",
      "   -524.95038944  -546.38831795]\n",
      " [   74.16458786 -1007.05344677  1056.54054342  -738.11617006\n",
      "    836.03913406  -828.19270457  1365.55278092  -251.08829071\n",
      "    606.62536653  1016.18262145]\n",
      " [  148.06825649   210.82378799   169.37515147   238.30747015\n",
      "   -951.62883404     4.7180625   -251.08829071  1656.6548417\n",
      "    756.68819935  -937.78754569]\n",
      " [  -87.8090753   -521.56481595   814.12848596  -309.68690401\n",
      "     45.8722618   -524.95038944   606.62536653   756.68819935\n",
      "    897.38105435    43.86226781]\n",
      " [  -16.2143444   -760.17426828   614.3353277   -596.78897112\n",
      "    992.69536562  -546.38831795  1016.18262145  -937.78754569\n",
      "     43.86226781  1107.58056097]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 06:04<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 610 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5485.419\n",
      "w[1]    -353.176\n",
      "w[2]    -365.826\n",
      "w[3]    -671.516\n",
      "w[4]   -1672.831\n",
      "w[5]    -355.909\n",
      "w[6]    2803.577\n",
      "w[7]    1831.941\n",
      "w[8]    -631.166\n",
      "w[9]    1051.807\n",
      "Name: mean, dtype: float64\n",
      "[[  290.01675366    64.1488262   -101.59348545    19.70602505\n",
      "   -171.38798819    42.46062688    70.58111905   146.75969725\n",
      "    -88.68294629   -17.93792669]\n",
      " [   64.1488262    788.02885048  -851.12298666   563.42255655\n",
      "   -684.34084951   647.64232148 -1000.31792063   210.86689089\n",
      "   -518.82871726  -755.85256387]\n",
      " [ -101.59348545  -851.12298666  1035.4569532   -579.10080184\n",
      "    559.62916077  -743.16699982  1049.53130215   173.34054181\n",
      "    813.6234702    607.95602233]\n",
      " [   19.70602505   563.42255655  -579.10080184   412.2611272\n",
      "   -525.56827383   453.61193748  -733.05623467   239.29509621\n",
      "   -307.15435209  -593.98629279]\n",
      " [ -171.38798819  -684.34084951   559.62916077  -525.56827383\n",
      "    977.46569956  -481.68020617   832.32455957  -957.83808431\n",
      "     39.91245781   993.23567407]\n",
      " [   42.46062688   647.64232148  -743.16699982   453.61193748\n",
      "   -481.68020617   551.09024976  -822.46437608     3.01000986\n",
      "   -523.70854108  -541.89185   ]\n",
      " [   70.58111905 -1000.31792063  1049.53130215  -733.05623467\n",
      "    832.32455957  -822.46437608  1354.61112567  -252.11583982\n",
      "    602.26446844  1009.62734014]\n",
      " [  146.75969725   210.86689089   173.34054181   239.29509621\n",
      "   -957.83808431     3.01000986  -252.11583982  1670.84392378\n",
      "    765.61666895  -945.14410067]\n",
      " [  -88.68294629  -518.82871726   813.6234702   -307.15435209\n",
      "     39.91245781  -523.70854108   602.26446844   765.61666895\n",
      "    900.86000164    36.85311298]\n",
      " [  -17.93792669  -755.85256387   607.95602233  -593.98629279\n",
      "    993.23567407  -541.89185     1009.62734014  -945.14410067\n",
      "     36.85311298  1106.80449264]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 05:52<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 615 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5504.235\n",
      "w[1]    -330.633\n",
      "w[2]    -396.452\n",
      "w[3]    -657.959\n",
      "w[4]   -1691.923\n",
      "w[5]    -336.255\n",
      "w[6]    2784.532\n",
      "w[7]    1829.708\n",
      "w[8]    -658.339\n",
      "w[9]    1040.590\n",
      "Name: mean, dtype: float64\n",
      "[[ 290.67284675   67.78938099 -107.5056075    21.80791761 -171.19351082\n",
      "    46.07060152   66.5637377   140.46660609  -95.55292619  -17.69692105]\n",
      " [  67.78938099  786.59952134 -851.62541965  561.86899806 -682.28963089\n",
      "   646.93728507 -996.27145361  207.23772155 -521.66741781 -751.45518215]\n",
      " [-107.5056075  -851.62541965 1041.33076044 -578.01759846  554.75763006\n",
      "  -745.15271258 1046.34664695  187.02833078  824.9364539   599.43436956]\n",
      " [  21.80791761  561.86899806 -578.01759846  410.99919116 -524.88907409\n",
      "   452.37289981 -729.85204062  239.45451105 -306.91650827 -591.9144099 ]\n",
      " [-171.19351082 -682.28963089  554.75763006 -524.88907409  980.69693985\n",
      "  -478.86137828  830.04130498 -968.273764     32.21583138  996.57739416]\n",
      " [  46.07060152  646.93728507 -745.15271258  452.37289981 -478.86137828\n",
      "   551.26100531 -819.27865352   -3.4088622  -528.7058405  -536.76908089]\n",
      " [  66.5637377  -996.27145361 1046.34664695 -729.85204062  830.04130498\n",
      "  -819.27865352 1347.09360567 -251.92189552  601.24485944 1004.52005404]\n",
      " [ 140.46660609  207.23772155  187.02833078  239.45451105 -968.273764\n",
      "    -3.4088622  -251.92189552 1701.84314712  789.51920256 -959.48650757]\n",
      " [ -95.55292619 -521.66741781  824.9364539  -306.91650827   32.21583138\n",
      "  -528.7058405   601.24485944  789.51920256  920.37083444   25.0125558 ]\n",
      " [ -17.69692105 -751.45518215  599.43436956 -591.9144099   996.57739416\n",
      "  -536.76908089 1004.52005404 -959.48650757   25.0125558  1110.063601  ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 05:47<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 602 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5522.273\n",
      "w[1]    -309.476\n",
      "w[2]    -425.719\n",
      "w[3]    -645.383\n",
      "w[4]   -1709.162\n",
      "w[5]    -317.637\n",
      "w[6]    2766.931\n",
      "w[7]    1825.996\n",
      "w[8]    -684.975\n",
      "w[9]    1030.998\n",
      "Name: mean, dtype: float64\n",
      "[[ 290.97613199   71.03375768 -110.5027258    24.32821815 -174.92267797\n",
      "    48.58528018   62.3085864   143.40335463  -96.50986194  -21.92837178]\n",
      " [  71.03375768  759.82108922 -822.62285237  542.50074214 -662.7349437\n",
      "   624.39733286 -959.50809859  205.55991916 -503.0592655  -726.56095192]\n",
      " [-110.5027258  -822.62285237 1013.12300568 -556.21605805  527.53225296\n",
      "  -722.00697946 1006.27651011  201.55597758  812.06956697  566.29647738]\n",
      " [  24.32821815  542.50074214 -556.21605805  397.18266935 -512.30239708\n",
      "   435.73609847 -703.30072941  241.49638555 -291.60349094 -575.46220581]\n",
      " [-174.92267797 -662.7349437   527.53225296 -512.30239708  977.97117185\n",
      "  -460.00940513  803.52735727 -991.29123355    4.88752065  990.08526004]\n",
      " [  48.58528018  624.39733286 -722.00697946  435.73609847 -460.00940513\n",
      "   532.78575906 -788.23091908   -9.85924609 -515.92443568 -513.36216378]\n",
      " [  62.3085864  -959.50809859 1006.27651011 -703.30072941  803.52735727\n",
      "  -788.23091908 1296.70226552 -250.36540292  575.16593001  970.71685153]\n",
      " [ 143.40335463  205.55991916  201.55597758  241.49638555 -991.29123355\n",
      "    -9.85924609 -250.36540292 1752.5989868   819.56468857 -982.45388974]\n",
      " [ -96.50986194 -503.0592655   812.06956697 -291.60349094    4.88752065\n",
      "  -515.92443568  575.16593001  819.56468857  923.9496529    -6.26163434]\n",
      " [ -21.92837178 -726.56095192  566.29647738 -575.46220581  990.08526004\n",
      "  -513.36216378  970.71685153 -982.45388974   -6.26163434 1098.73828998]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 06:15<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 626 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5539.744\n",
      "w[1]    -288.964\n",
      "w[2]    -454.383\n",
      "w[3]    -633.251\n",
      "w[4]   -1725.381\n",
      "w[5]    -299.466\n",
      "w[6]    2749.890\n",
      "w[7]    1821.344\n",
      "w[8]    -711.423\n",
      "w[9]    1022.202\n",
      "Name: mean, dtype: float64\n",
      "[[  284.92830366    72.36224105  -111.32649431    25.85053486\n",
      "   -173.52313158    49.85878226    57.34891888   140.89804087\n",
      "    -96.44883463   -24.11176226]\n",
      " [   72.36224105   755.37812859  -820.28961639   538.66412053\n",
      "   -655.88756668   621.62838995  -952.75333367   197.24767261\n",
      "   -505.15603293  -718.22639423]\n",
      " [ -111.32649431  -820.28961639  1016.45454302  -553.08408349\n",
      "    516.15273311  -722.35840494  1002.01110647   222.76604906\n",
      "    823.21893841   553.59848763]\n",
      " [   25.85053486   538.66412053  -553.08408349   394.11537578\n",
      "   -508.54411179   432.87546768  -697.43368541   238.78060999\n",
      "   -290.92665018  -570.31995172]\n",
      " [ -173.52313158  -655.88756668   516.15273311  -508.54411179\n",
      "    978.90058395  -452.88455077   796.04871027 -1004.68822912\n",
      "     -8.91303555   991.42891933]\n",
      " [   49.85878226   621.62838995  -722.35840494   432.87546768\n",
      "   -452.88455077   531.75208452  -783.53381021   -21.41178795\n",
      "   -521.20197873  -504.87726693]\n",
      " [   57.34891888  -952.75333367  1002.01110647  -697.43368541\n",
      "    796.04871027  -783.53381021  1284.99333009  -242.75111293\n",
      "    576.61657677   959.40315932]\n",
      " [  140.89804087   197.24767261   222.76604906   238.78060999\n",
      "  -1004.68822912   -21.41178795  -242.75111293  1795.71395414\n",
      "    852.60101396  -997.56195572]\n",
      " [  -96.44883463  -505.15603293   823.21893841  -290.92665018\n",
      "     -8.91303555  -521.20197873   576.61657677   852.60101396\n",
      "    945.15177603   -20.69654147]\n",
      " [  -24.11176226  -718.22639423   553.59848763  -570.31995172\n",
      "    991.42891933  -504.87726693   959.40315932  -997.56195572\n",
      "    -20.69654147  1098.28669761]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 06:09<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 632 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5556.335\n",
      "w[1]    -268.891\n",
      "w[2]    -482.509\n",
      "w[3]    -621.362\n",
      "w[4]   -1740.825\n",
      "w[5]    -281.623\n",
      "w[6]    2732.960\n",
      "w[7]    1816.090\n",
      "w[8]    -737.497\n",
      "w[9]    1013.748\n",
      "Name: mean, dtype: float64\n",
      "[[  285.66254781    69.98353606  -108.38084308    24.18372241\n",
      "   -172.57224539    47.70052669    60.88500176   142.31489306\n",
      "    -94.05591722   -22.41389231]\n",
      " [   69.98353606   773.12952954  -837.51334939   552.10489783\n",
      "   -672.53185327   635.83665718  -977.58308495   206.13184168\n",
      "   -512.59246395  -738.88586371]\n",
      " [ -108.38084308  -837.51334939  1038.66370914  -564.82259391\n",
      "    522.46491437  -738.38731907  1025.75434221   235.21517599\n",
      "    842.69899438   563.56393438]\n",
      " [   24.18372241   552.10489783  -564.82259391   404.59170367\n",
      "   -523.45492446   443.09959226  -716.32364452   250.47380432\n",
      "   -293.65748946  -588.34516938]\n",
      " [ -172.57224539  -672.53185327   522.46491437  -523.45492446\n",
      "   1012.05681464  -462.20687868   819.82212756 -1050.64070664\n",
      "    -23.78906868  1028.69967233]\n",
      " [   47.70052669   635.83665718  -738.38731907   443.09959226\n",
      "   -462.20687868   544.0339144   -803.26752527   -22.86230768\n",
      "   -532.14313406  -517.32126737]\n",
      " [   60.88500176  -977.58308495  1025.75434221  -716.32364452\n",
      "    819.82212756  -803.26752527  1319.89876595  -256.34903214\n",
      "    586.24257348   988.97132198]\n",
      " [  142.31489306   206.13184168   235.21517599   250.47380432\n",
      "  -1050.64070664   -22.86230768  -256.34903214  1880.77488285\n",
      "    895.74050307 -1046.34497318]\n",
      " [  -94.05591722  -512.59246395   842.69899438  -293.65748946\n",
      "    -23.78906868  -532.14313406   586.24257348   895.74050307\n",
      "    975.54005586   -34.45700222]\n",
      " [  -22.41389231  -738.88586371   563.56393438  -588.34516938\n",
      "   1028.69967233  -517.32126737   988.97132198 -1046.34497318\n",
      "    -34.45700222  1140.73779826]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 06:01<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 645 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5571.841\n",
      "w[1]    -249.185\n",
      "w[2]    -510.106\n",
      "w[3]    -609.636\n",
      "w[4]   -1755.554\n",
      "w[5]    -264.044\n",
      "w[6]    2715.940\n",
      "w[7]    1810.311\n",
      "w[8]    -763.128\n",
      "w[9]    1005.457\n",
      "Name: mean, dtype: float64\n",
      "[[  288.37750515    70.47798761  -108.13910829    24.56756975\n",
      "   -175.97485167    47.48069443    61.51410399   147.82652034\n",
      "    -92.34260842   -24.48089371]\n",
      " [   70.47798761   746.27361938  -809.29920721   532.47769936\n",
      "   -649.4613426    613.66721605  -942.06241115   198.16979835\n",
      "   -496.55429936  -711.94843812]\n",
      " [ -108.13910829  -809.29920721  1010.38145471  -543.92634469\n",
      "    495.4224418   -715.7412072    988.72209966   249.31267982\n",
      "    828.96122419   532.72039753]\n",
      " [   24.56756975   532.47769936  -543.92634469   390.29892638\n",
      "   -507.06079978   426.77837051  -690.35474673   245.65847768\n",
      "   -281.33272602  -569.14171055]\n",
      " [ -175.97485167  -649.4613426    495.4224418   -507.06079978\n",
      "    998.78004526  -441.66556656   787.97298311 -1056.76105103\n",
      "    -44.06112012  1010.78352333]\n",
      " [   47.48069443   613.66721605  -715.7412072    426.77837051\n",
      "   -441.66556656   526.05365047  -774.20672376   -32.40559644\n",
      "   -520.40659424  -493.8520056 ]\n",
      " [   61.51410399  -942.06241115   988.72209966  -690.35474673\n",
      "    787.97298311  -774.20672376  1273.46932548  -243.4569348\n",
      "    565.86858934   952.67508029]\n",
      " [  147.82652034   198.16979835   249.31267982   245.65847768\n",
      "  -1056.76105103   -32.40559644  -243.4569348   1904.2776824\n",
      "    913.7114894  -1049.02310979]\n",
      " [  -92.34260842  -496.55429936   828.96122419  -281.33272602\n",
      "    -44.06112012  -520.40659424   565.86858934   913.7114894\n",
      "    973.03862133   -56.28910775]\n",
      " [  -24.48089371  -711.94843812   532.72039753  -569.14171055\n",
      "   1010.78352333  -493.8520056    952.67508029 -1049.02310979\n",
      "    -56.28910775  1118.36741593]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 06:07<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 646 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5586.898\n",
      "w[1]    -230.273\n",
      "w[2]    -536.795\n",
      "w[3]    -598.443\n",
      "w[4]   -1769.438\n",
      "w[5]    -247.114\n",
      "w[6]    2699.720\n",
      "w[7]    1804.150\n",
      "w[8]    -788.171\n",
      "w[9]     997.874\n",
      "Name: mean, dtype: float64\n",
      "[[  278.88480577    70.08731862  -110.28620235    24.26551013\n",
      "   -165.39558268    49.11823239    57.29419233   129.58512214\n",
      "    -98.85837596   -18.81569905]\n",
      " [   70.08731862   753.09664881  -816.46405539   537.45481\n",
      "   -655.2482837    619.37705241  -951.27690977   200.02982602\n",
      "   -500.63476788  -718.8803588 ]\n",
      " [ -110.28620235  -816.46405539  1020.40605911  -548.33717349\n",
      "    498.36392475  -722.61688733   996.61109373   255.09491814\n",
      "    838.93079976   535.19074691]\n",
      " [   24.26551013   537.45481     -548.33717349   394.14192728\n",
      "   -512.7791191    430.59364246  -697.22174866   250.2069328\n",
      "   -282.40755563  -575.77897888]\n",
      " [ -165.39558268  -655.2482837    498.36392475  -512.7791191\n",
      "   1003.49389567  -446.0486747    801.84107852 -1061.99341615\n",
      "    -47.12466664  1022.43664196]\n",
      " [   49.11823239   619.37705241  -722.61688733   430.59364246\n",
      "   -446.0486747    531.03532544  -780.7169539    -32.62869356\n",
      "   -525.72173287  -498.01057141]\n",
      " [   57.29419233  -951.27690977   996.61109373  -697.22174866\n",
      "    801.84107852  -780.7169539   1283.61616146  -257.0146051\n",
      "    566.82419291   965.64914749]\n",
      " [  129.58512214   200.02982602   255.09491814   250.2069328\n",
      "  -1061.99341615   -32.62869356  -257.0146051   1919.80427486\n",
      "    929.23637784 -1065.35766355]\n",
      " [  -98.85837596  -500.63476788   838.93079976  -282.40755563\n",
      "    -47.12466664  -525.72173287   566.82419291   929.23637784\n",
      "    988.24982951   -62.9788998 ]\n",
      " [  -18.81569905  -718.8803588    535.19074691  -575.77897888\n",
      "   1022.43664196  -498.01057141   965.64914749 -1065.35766355\n",
      "    -62.9788998   1134.57061323]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 06:00<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 651 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5601.154\n",
      "w[1]    -212.409\n",
      "w[2]    -562.485\n",
      "w[3]    -587.988\n",
      "w[4]   -1781.733\n",
      "w[5]    -230.920\n",
      "w[6]    2684.467\n",
      "w[7]    1796.545\n",
      "w[8]    -812.908\n",
      "w[9]     991.585\n",
      "Name: mean, dtype: float64\n",
      "[[  273.99028861    71.09439076  -109.13942962    25.79907769\n",
      "   -167.25479246    49.46798139    53.17064252   133.96646048\n",
      "    -94.97456054   -23.58145565]\n",
      " [   71.09439076   740.54744532  -807.47861813   527.29699852\n",
      "   -637.7202662    610.64723094  -933.69283086   181.51763116\n",
      "   -502.35823027  -698.71056223]\n",
      " [ -109.13942962  -807.47861813  1018.25327249  -540.15854456\n",
      "    477.26785512  -718.21101748   984.45089359   285.97995532\n",
      "    849.94745219   512.82173552]\n",
      " [   25.79907769   527.29699852  -540.15854456   386.08488949\n",
      "   -500.57117619   423.11312749  -682.72799412   239.2006195\n",
      "   -281.71635879  -561.12966502]\n",
      " [ -167.25479246  -637.7202662    477.26785512  -500.57117619\n",
      "    994.0493845   -430.44774392   778.09151709 -1068.32741027\n",
      "    -63.83470062  1009.77512593]\n",
      " [   49.46798139   610.64723094  -718.21101748   423.11312749\n",
      "   -430.44774392   525.71630141  -768.43760802   -52.69928574\n",
      "   -531.08314814  -480.60530505]\n",
      " [   53.17064252  -933.69283086   984.45089359  -682.72799412\n",
      "    778.09151709  -768.43760802  1257.50404539  -231.73768877\n",
      "    569.96998788   936.73223168]\n",
      " [  133.96646048   181.51763116   285.97995532   239.2006195\n",
      "  -1068.32741027   -52.69928574  -231.73768877  1960.62914598\n",
      "    966.333101   -1067.72802376]\n",
      " [  -94.97456054  -502.35823027   849.94745219  -281.71635879\n",
      "    -63.83470062  -531.08314814   569.96998788   966.333101\n",
      "   1010.21565938   -78.16768294]\n",
      " [  -23.58145565  -698.71056223   512.82173552  -561.12966502\n",
      "   1009.77512593  -480.60530505   936.73223168 -1067.72802376\n",
      "    -78.16768294  1116.65126224]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 05:57<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 662 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5614.557\n",
      "w[1]    -194.819\n",
      "w[2]    -587.783\n",
      "w[3]    -577.655\n",
      "w[4]   -1793.458\n",
      "w[5]    -214.920\n",
      "w[6]    2669.126\n",
      "w[7]    1788.497\n",
      "w[8]    -837.330\n",
      "w[9]     985.439\n",
      "Name: mean, dtype: float64\n",
      "[[  277.49808234    74.8656005   -113.45228109    28.28740298\n",
      "   -172.22070468    52.328055      50.04059002   137.11800561\n",
      "    -97.50396185   -27.05442596]\n",
      " [   74.8656005    737.28186602  -808.25117945   523.7959095\n",
      "   -629.98654229   609.34099778  -927.00879059   168.4056367\n",
      "   -509.24317625  -688.21575444]\n",
      " [ -113.45228109  -808.25117945  1026.37277969  -538.78464165\n",
      "    467.91508444  -721.42032922   982.35935006   309.11903046\n",
      "    866.14012596   500.6915007 ]\n",
      " [   28.28740298   523.7959095   -538.78464165   382.91270234\n",
      "   -495.11261878   420.95753371  -676.6130105    231.91755404\n",
      "   -284.41028016  -553.71604714]\n",
      " [ -172.22070468  -629.98654229   467.91508444  -495.11261878\n",
      "    992.71251016  -423.13227084   765.66820146 -1075.43947905\n",
      "    -71.92167002  1004.84654854]\n",
      " [   52.328055     609.34099778  -721.42032922   420.95753371\n",
      "   -423.13227084   526.24287325  -764.70782568   -67.56757917\n",
      "   -540.13064993  -471.23774868]\n",
      " [   50.04059002  -927.00879059   982.35935006  -676.6130105\n",
      "    765.66820146  -764.70782568  1246.55218251  -214.24959711\n",
      "    576.54134619   921.42011545]\n",
      " [  137.11800561   168.4056367    309.11903046   231.91755404\n",
      "  -1075.43947905   -67.56757917  -214.24959711  1995.06735119\n",
      "    995.58885945 -1072.1517536 ]\n",
      " [  -97.50396185  -509.24317625   866.14012596  -284.41028016\n",
      "    -71.92167002  -540.13064993   576.54134619   995.58885945\n",
      "   1034.00174896   -87.42329643]\n",
      " [  -27.05442596  -688.21575444   500.6915007   -553.71604714\n",
      "   1004.84654854  -471.23774868   921.42011545 -1072.1517536\n",
      "    -87.42329643  1108.59480045]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 06:17<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 653 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5627.460\n",
      "w[1]    -178.002\n",
      "w[2]    -612.489\n",
      "w[3]    -567.896\n",
      "w[4]   -1803.851\n",
      "w[5]    -199.428\n",
      "w[6]    2654.562\n",
      "w[7]    1778.992\n",
      "w[8]    -861.789\n",
      "w[9]     980.475\n",
      "Name: mean, dtype: float64\n",
      "[[  276.69634832    76.42464635  -116.83760397    28.96899707\n",
      "   -170.04548911    54.38531017    47.69154953   130.43069489\n",
      "   -102.43710258   -25.38063136]\n",
      " [   76.42464635   740.20513168  -815.13953508   525.04260781\n",
      "   -627.2443578    613.20995783  -929.77230172   157.12268026\n",
      "   -519.08067843  -684.74695306]\n",
      " [ -116.83760397  -815.13953508  1042.26285843  -541.66069841\n",
      "    461.48812726  -730.35470642   988.94064304   335.426286\n",
      "    888.92599038   492.56910412]\n",
      " [   28.96899707   525.04260781  -541.66069841   383.48863812\n",
      "   -494.1269125    422.58859943  -677.80081229   227.49876963\n",
      "   -288.39295119  -552.4597525 ]\n",
      " [ -170.04548911  -627.2443578    461.48812726  -494.1269125\n",
      "    995.14628194  -419.65477376   763.57341423 -1086.11500372\n",
      "    -81.36392892  1008.63099032]\n",
      " [   54.38531017   613.20995783  -730.35470642   422.58859943\n",
      "   -419.65477376   531.24659951  -768.3224752    -82.13217508\n",
      "   -552.8779635   -466.74721575]\n",
      " [   47.69154953  -929.77230172   988.94064304  -677.80081229\n",
      "    763.57341423  -768.3224752   1248.65265338  -204.25172197\n",
      "    585.82779656   918.18828119]\n",
      " [  130.43069489   157.12268026   335.426286     227.49876963\n",
      "  -1086.11500372   -82.13217508  -204.25172197  2039.0780466\n",
      "   1033.78206939 -1086.57534319]\n",
      " [ -102.43710258  -519.08067843   888.92599038  -288.39295119\n",
      "    -81.36392892  -552.8779635    585.82779656  1033.78206939\n",
      "   1066.88598566   -99.48011982]\n",
      " [  -25.38063136  -684.74695306   492.56910412  -552.4597525\n",
      "   1008.63099032  -466.74721575   918.18828119 -1086.57534319\n",
      "    -99.48011982  1113.44387903]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 06:35<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 657 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5639.830\n",
      "w[1]    -161.230\n",
      "w[2]    -637.230\n",
      "w[3]    -558.159\n",
      "w[4]   -1813.736\n",
      "w[5]    -183.890\n",
      "w[6]    2639.781\n",
      "w[7]    1768.679\n",
      "w[8]    -886.470\n",
      "w[9]     975.751\n",
      "Name: mean, dtype: float64\n",
      "[[  275.86369901    84.93121355  -123.97482099    35.68563813\n",
      "   -180.25012902    60.67187208    35.81229084   139.34310052\n",
      "   -103.41041881   -37.52146966]\n",
      " [   84.93121355   734.34770356  -812.58232822   519.37807949\n",
      "   -620.9802239    609.16396068  -917.39825018   149.1062604\n",
      "   -522.86135361  -672.69531407]\n",
      " [ -123.97482099  -812.58232822  1046.6684378   -537.69360243\n",
      "    451.21023008  -730.51706253   981.16791153   356.64813621\n",
      "    902.56553199   477.43718207]\n",
      " [   35.68563813   519.37807949  -537.69360243   378.44902335\n",
      "   -489.75206049   418.20113693  -666.75405011   224.03169334\n",
      "   -288.86672477  -543.42442897]\n",
      " [ -180.25012902  -620.9802239    451.21023008  -489.75206049\n",
      "   1002.25334078  -412.20684236   750.71091187 -1106.74750446\n",
      "    -94.23791239  1009.64021694]\n",
      " [   60.67187208   609.16396068  -730.51706253   418.20113693\n",
      "   -412.20684236   529.18250338  -759.32811669   -94.53897548\n",
      "   -559.75206449  -454.9126912 ]\n",
      " [   35.81229084  -917.39825018   981.16791153  -666.75405011\n",
      "    750.71091187  -759.32811669  1225.77340394  -190.83103764\n",
      "    589.16631129   896.56099632]\n",
      " [  139.34310052   149.1062604    356.64813621   224.03169334\n",
      "  -1106.74750446   -94.53897548  -190.83103764  2092.0449953\n",
      "   1067.81824464 -1102.3158011 ]\n",
      " [ -103.41041881  -522.86135361   902.56553199  -288.86672477\n",
      "    -94.23791239  -559.75206449   589.16631129  1067.81824464\n",
      "   1090.50859636  -113.132124  ]\n",
      " [  -37.52146966  -672.69531407   477.43718207  -543.42442897\n",
      "   1009.64021694  -454.9126912    896.56099632 -1102.3158011\n",
      "   -113.132124    1106.27282738]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 06:20<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 643 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5651.703\n",
      "w[1]    -144.994\n",
      "w[2]    -661.176\n",
      "w[3]    -548.727\n",
      "w[4]   -1823.236\n",
      "w[5]    -168.845\n",
      "w[6]    2625.417\n",
      "w[7]    1758.611\n",
      "w[8]    -910.367\n",
      "w[9]     971.172\n",
      "Name: mean, dtype: float64\n",
      "[[  273.91380029    81.34356155  -119.08019699    33.55844085\n",
      "   -178.25396601    57.53928236    39.38643708   141.09711094\n",
      "    -98.82242549   -36.05526055]\n",
      " [   81.34356155   717.49387786  -797.83578752   506.6913832\n",
      "   -599.20782077   596.91462574  -896.90638283   129.72070219\n",
      "   -519.79543909  -650.09154241]\n",
      " [ -119.08019699  -797.83578752  1038.36282713  -525.59172001\n",
      "    423.19708863  -721.81457503   963.64962724   392.31889318\n",
      "    910.29157971   449.21326989]\n",
      " [   33.55844085   506.6913832   -525.59172001   369.09279934\n",
      "   -475.39772063   408.51587952  -651.13462505   213.64096981\n",
      "   -284.29237228  -528.23374964]\n",
      " [ -178.25396601  -599.20782077   423.19708863  -475.39772063\n",
      "    991.32470951  -392.56917949   723.82288674 -1117.69921545\n",
      "   -118.48713674   996.99328621]\n",
      " [   57.53928236   596.91462574  -721.81457503   408.51587952\n",
      "   -392.56917949   521.13402067  -744.49126355  -116.65456028\n",
      "   -562.08254862  -434.7704742 ]\n",
      " [   39.38643708  -896.90638283   963.64962724  -651.13462505\n",
      "    723.82288674  -744.49126355  1200.39959545  -166.20918084\n",
      "    586.35851972   868.25251397]\n",
      " [  141.09711094   129.72070219   392.31889318   213.64096981\n",
      "  -1117.69921545  -116.65456028  -166.20918084  2145.07221601\n",
      "   1113.69506403 -1110.80812226]\n",
      " [  -98.82242549  -519.79543909   910.29157971  -284.29237228\n",
      "   -118.48713674  -562.08254862   586.35851972  1113.69506403\n",
      "   1113.52382042  -136.38132396]\n",
      " [  -36.05526055  -650.09154241   449.21326989  -528.23374964\n",
      "    996.99328621  -434.7704742    868.25251397 -1110.80812226\n",
      "   -136.38132396  1091.48743736]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 06:19<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 674 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5663.008\n",
      "w[1]    -129.367\n",
      "w[2]    -684.654\n",
      "w[3]    -539.738\n",
      "w[4]   -1831.585\n",
      "w[5]    -154.182\n",
      "w[6]    2611.588\n",
      "w[7]    1747.226\n",
      "w[8]    -934.329\n",
      "w[9]     967.543\n",
      "Name: mean, dtype: float64\n",
      "[[  272.21063346    86.9328661   -126.53740264    37.42736817\n",
      "   -179.49789386    62.94687785    31.27401421   135.75203954\n",
      "   -105.64540311   -38.93945078]\n",
      " [   86.9328661    715.32657151  -799.50123244   503.70819158\n",
      "   -593.86930948   596.29020001  -890.65151478   119.4664851\n",
      "   -526.77905866  -641.10723333]\n",
      " [ -126.53740264  -799.50123244  1045.50919857  -524.90239509\n",
      "    419.80864653  -724.78085003   961.39167491   404.9832513\n",
      "    922.520803     441.68883789]\n",
      " [   37.42736817   503.70819158  -524.90239509   365.99420585\n",
      "   -470.8563057    406.74226852  -644.83758391   207.03046411\n",
      "   -287.6758646   -520.95300577]\n",
      " [ -179.49789386  -593.86930948   419.80864653  -470.8563057\n",
      "    983.56392012  -388.99394233   715.66905732 -1108.77999507\n",
      "   -116.69067622   987.50243143]\n",
      " [   62.94687785   596.29020001  -724.78085003   406.74226852\n",
      "   -388.99394233   521.65174909  -740.43271023  -125.41548471\n",
      "   -569.27120778  -427.92663855]\n",
      " [   31.27401421  -890.65151478   961.39167491  -644.83758391\n",
      "    715.66905732  -740.43271023  1187.30672934  -155.30358948\n",
      "    591.65918464   854.4414394 ]\n",
      " [  135.75203954   119.4664851    404.9832513    207.03046411\n",
      "  -1108.77999507  -125.41548471  -155.30358948  2143.68542864\n",
      "   1123.17217009 -1103.18392068]\n",
      " [ -105.64540311  -526.77905866   922.520803    -287.6758646\n",
      "   -116.69067622  -569.27120778   591.65918464  1123.17217009\n",
      "   1127.67893693  -137.47172649]\n",
      " [  -38.93945078  -641.10723333   441.68883789  -520.95300577\n",
      "    987.50243143  -427.92663855   854.4414394  -1103.18392068\n",
      "   -137.47172649  1078.84248182]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 06:36<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 672 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5674.021\n",
      "w[1]    -113.762\n",
      "w[2]    -708.195\n",
      "w[3]    -530.763\n",
      "w[4]   -1839.616\n",
      "w[5]    -139.472\n",
      "w[6]    2597.630\n",
      "w[7]    1735.314\n",
      "w[8]    -958.463\n",
      "w[9]     964.076\n",
      "Name: mean, dtype: float64\n",
      "[[  269.15314117    78.11511329  -116.36309683    31.34234918\n",
      "   -171.3785039     55.63413128    41.20663318   133.50774605\n",
      "    -98.71426134   -31.39603456]\n",
      " [   78.11511329   687.8881258   -774.04682333   483.59162176\n",
      "   -558.90850892   576.01739188  -858.56795036    90.9254458\n",
      "   -518.62588402  -606.87110127]\n",
      " [ -116.36309683  -774.04682333  1023.29504386  -506.02291525\n",
      "    383.83824353  -706.66121721   932.49861431   438.25164151\n",
      "    918.10023416   407.3086403 ]\n",
      " [   31.34234918   483.59162176  -506.02291525   351.27774441\n",
      "   -445.80950165   391.76991474  -621.14340692   187.20894282\n",
      "   -281.2138155   -496.24907765]\n",
      " [ -171.3785039   -558.90850892   383.83824353  -445.80950165\n",
      "    946.69359     -361.54380459   673.60185351 -1087.76672329\n",
      "   -134.87258093   950.25289538]\n",
      " [   55.63413128   576.01739188  -706.66121721   391.76991474\n",
      "   -361.54380459   506.99340766  -717.05458513  -149.66250339\n",
      "   -564.77421922  -401.36582645]\n",
      " [   41.20663318  -858.56795036   932.49861431  -621.14340692\n",
      "    673.60185351  -717.05458513  1149.45721505  -119.16332501\n",
      "    583.99391023   812.91087844]\n",
      " [  133.50774605    90.9254458    438.25164151   187.20894282\n",
      "  -1087.76672329  -149.66250339  -119.16332501  2144.33253745\n",
      "   1146.6797667  -1079.90591351]\n",
      " [  -98.71426134  -518.62588402   918.10023416  -281.2138155\n",
      "   -134.87258093  -564.77421922   583.99391023  1146.6797667\n",
      "   1132.26491913  -153.45218366]\n",
      " [  -31.39603456  -606.87110127   407.3086403   -496.24907765\n",
      "    950.25289538  -401.36582645   812.91087844 -1079.90591351\n",
      "   -153.45218366  1040.89541268]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 07:06<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 724 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5684.018\n",
      "w[1]     -99.515\n",
      "w[2]    -730.013\n",
      "w[3]    -522.644\n",
      "w[4]   -1846.340\n",
      "w[5]    -125.909\n",
      "w[6]    2584.905\n",
      "w[7]    1723.156\n",
      "w[8]    -981.238\n",
      "w[9]     961.522\n",
      "Name: mean, dtype: float64\n",
      "[[  259.43800125    74.15494087  -113.27019138    28.80432035\n",
      "   -160.26562821    53.53594001    41.5371073    119.81513425\n",
      "    -99.55200512   -25.00703783]\n",
      " [   74.15494087   667.40535218  -754.26912692   468.46631245\n",
      "   -535.55682631   560.31111024  -833.57000493    74.652855\n",
      "   -510.56157739  -582.74052606]\n",
      " [ -113.27019138  -754.26912692  1006.02831297  -490.92607075\n",
      "    358.64697084  -692.1700351    907.81753667   459.98860024\n",
      "    914.2621274    380.79906278]\n",
      " [   28.80432035   468.46631245  -490.92607075   340.18715629\n",
      "   -429.6027462    379.93843225  -602.53314017   177.30089373\n",
      "   -274.15616088  -479.29834956]\n",
      " [ -160.26562821  -535.55682631   358.64697084  -429.6027462\n",
      "    920.51958188  -343.04246729   648.72992028 -1073.00454083\n",
      "   -149.26434228   927.08143847]\n",
      " [   53.53594001   560.31111024  -692.1700351    379.93843225\n",
      "   -343.04246729   495.14984778  -697.33743551  -163.79986834\n",
      "   -559.99787765  -381.68897119]\n",
      " [   41.5371073   -833.57000493   907.81753667  -602.53314017\n",
      "    648.72992028  -697.33743551  1116.69392892  -105.2901748\n",
      "    572.54230086   784.65124398]\n",
      " [  119.81513425    74.652855     459.98860024   177.30089373\n",
      "  -1073.00454083  -163.79986834  -105.2901748   2144.03327865\n",
      "   1165.33990094 -1070.88259251]\n",
      " [  -99.55200512  -510.56157739   914.2621274   -274.15616088\n",
      "   -149.26434228  -559.99787765   572.54230086  1165.33990094\n",
      "   1137.52256102  -169.83281799]\n",
      " [  -25.00703783  -582.74052606   380.79906278  -479.29834956\n",
      "    927.08143847  -381.68897119   784.65124398 -1070.88259251\n",
      "   -169.83281799  1018.03595077]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 08:45<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 883 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5693.474\n",
      "w[1]     -86.496\n",
      "w[2]    -750.295\n",
      "w[3]    -515.328\n",
      "w[4]   -1852.103\n",
      "w[5]    -113.403\n",
      "w[6]    2573.477\n",
      "w[7]    1711.086\n",
      "w[8]   -1002.761\n",
      "w[9]     959.775\n",
      "Name: mean, dtype: float64\n",
      "[[  250.43404456    66.59541638  -105.2233985     23.80660416\n",
      "   -148.01814177    48.10985036    46.99226458   109.22641106\n",
      "    -95.95735046   -16.72770802]\n",
      " [   66.59541638   646.93094636  -736.18198186   452.99312727\n",
      "   -506.50258527   545.63063356  -809.83900633    47.573905\n",
      "   -507.21172724  -554.67343941]\n",
      " [ -105.2233985   -736.18198186   988.76385744  -477.56500081\n",
      "    334.13461916  -678.84148428   887.6306189    480.79987286\n",
      "    908.8288329    358.03107555]\n",
      " [   23.80660416   452.99312727  -477.56500081   328.39567388\n",
      "   -407.62121335   368.89611316  -584.21583211   156.46057638\n",
      "   -272.16456524  -457.64005144]\n",
      " [ -148.01814177  -506.50258527   334.13461916  -407.62121335\n",
      "    876.75338039  -322.75198677   615.81936508 -1029.6873218\n",
      "   -151.72250574   885.4891593 ]\n",
      " [   48.10985036   545.63063356  -678.84148428   368.89611316\n",
      "   -322.75198677   484.4875587   -680.34015511  -182.02619614\n",
      "   -556.87540885  -362.14326626]\n",
      " [   46.99226458  -809.83900633   887.6306189   -584.21583211\n",
      "    615.81936508  -680.34015511  1087.4228068    -74.11760885\n",
      "    569.97984041   750.96843026]\n",
      " [  109.22641106    47.573905     480.79987286   156.46057638\n",
      "  -1029.6873218   -182.02619614   -74.11760885  2097.75177707\n",
      "   1163.70547946 -1028.9651497 ]\n",
      " [  -95.95735046  -507.21172724   908.8288329   -272.16456524\n",
      "   -151.72250574  -556.87540885   569.97984041  1163.70547946\n",
      "   1132.27294133  -170.60944261]\n",
      " [  -16.72770802  -554.67343941   358.03107555  -457.64005144\n",
      "    885.4891593   -362.14326626   750.96843026 -1028.9651497\n",
      "   -170.60944261   976.46574387]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 06:35<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 696 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5702.190\n",
      "w[1]     -73.956\n",
      "w[2]    -770.283\n",
      "w[3]    -508.372\n",
      "w[4]   -1856.614\n",
      "w[5]    -101.141\n",
      "w[6]    2562.332\n",
      "w[7]    1697.398\n",
      "w[8]   -1024.554\n",
      "w[9]     958.958\n",
      "Name: mean, dtype: float64\n",
      "[[  245.74686004    66.76488862  -105.850875      24.03309868\n",
      "   -144.46273304    48.74947277    44.53483338   103.48237141\n",
      "    -97.52065546   -15.60928001]\n",
      " [   66.76488862   640.53067103  -727.73361211   448.77846075\n",
      "   -503.92394071   539.72216917  -801.3806667     52.05550306\n",
      "   -499.59809486  -551.2720749 ]\n",
      " [ -105.850875    -727.73361211   979.23373538  -471.61721888\n",
      "    328.29512355  -671.6702204    876.10841183   480.32067553\n",
      "    902.25872531   350.67558518]\n",
      " [   24.03309868   448.77846075  -471.61721888   325.68660305\n",
      "   -406.59659022   364.83619585  -578.61372951   160.82366234\n",
      "   -266.32964083  -456.06854576]\n",
      " [ -144.46273304  -503.92394071   328.29512355  -406.59659022\n",
      "    877.36823396  -319.61629396   614.37711951 -1036.7751759\n",
      "   -159.63117136   888.00562573]\n",
      " [   48.74947277   539.72216917  -671.6702204    364.83619585\n",
      "   -319.61629396   479.25196419  -672.2312684   -179.73617732\n",
      "   -551.17442406  -357.91432415]\n",
      " [   44.53483338  -801.3806667    876.10841183  -578.61372951\n",
      "    614.37711951  -672.2312684   1075.16983357   -83.24737049\n",
      "    558.92848733   747.32173452]\n",
      " [  103.48237141    52.05550306   480.32067553   160.82366234\n",
      "  -1036.7751759   -179.73617732   -83.24737049  2108.67293986\n",
      "   1169.45105245 -1040.3067948 ]\n",
      " [  -97.52065546  -499.59809486   902.25872531  -266.32964083\n",
      "   -159.63117136  -551.17442406   558.92848733  1169.45105245\n",
      "   1130.5743134   -180.66953489]\n",
      " [  -15.60928001  -551.2720749    350.67558518  -456.06854576\n",
      "    888.00562573  -357.91432415   747.32173452 -1040.3067948\n",
      "   -180.66953489   979.55712384]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 06:25<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 699 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5710.482\n",
      "w[1]     -61.945\n",
      "w[2]    -789.498\n",
      "w[3]    -501.714\n",
      "w[4]   -1860.795\n",
      "w[5]     -89.361\n",
      "w[6]    2551.638\n",
      "w[7]    1683.999\n",
      "w[8]   -1045.580\n",
      "w[9]     958.290\n",
      "Name: mean, dtype: float64\n",
      "[[  240.27975378    68.02859595  -105.37862364    25.71773809\n",
      "   -145.3947247     49.46747011    39.81414051   105.78995799\n",
      "    -94.74862481   -19.70390115]\n",
      " [   68.02859595   653.69766332  -738.6679754    458.99642855\n",
      "   -521.32365641   549.11991041  -818.46341967    68.43812988\n",
      "   -500.70126274  -569.94495471]\n",
      " [ -105.37862364  -738.6679754    985.64633764  -480.85902074\n",
      "    346.43786724  -678.48337475   891.44719372   458.15745865\n",
      "    897.39529421   370.89463819]\n",
      " [   25.71773809   458.99642855  -480.85902074   333.37283038\n",
      "   -419.17394897   372.38302973  -591.3920069    171.27912287\n",
      "   -268.83426265  -469.20354399]\n",
      " [ -145.3947247   -521.32365641   346.43786724  -419.17394897\n",
      "    893.32685396  -333.62923707   636.76112514 -1043.73650443\n",
      "   -149.7532185    905.72973545]\n",
      " [   49.46747011   549.11991041  -678.48337475   372.38302973\n",
      "   -333.62923707   485.55058402  -684.65442269  -164.53259944\n",
      "   -549.77502774  -373.01444292]\n",
      " [   39.81414051  -818.46341967   891.44719372  -591.3920069\n",
      "    636.76112514  -684.65442269  1095.56191464  -102.83146007\n",
      "    562.69517971   769.65095478]\n",
      " [  105.78995799    68.43812988   458.15745865   171.27912287\n",
      "  -1043.73650443  -164.53259944  -102.83146007  2097.37943816\n",
      "   1148.87491343 -1047.75152671]\n",
      " [  -94.74862481  -500.70126274   897.39529421  -268.83426265\n",
      "   -149.7532185   -549.77502774   562.69517971  1148.87491343\n",
      "   1117.96106377  -168.70037109]\n",
      " [  -19.70390115  -569.94495471   370.89463819  -469.20354399\n",
      "    905.72973545  -373.01444292   769.65095478 -1047.75152671\n",
      "   -168.70037109   997.49057512]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 06:13<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 677 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5718.418\n",
      "w[1]     -49.613\n",
      "w[2]    -808.733\n",
      "w[3]    -494.729\n",
      "w[4]   -1865.574\n",
      "w[5]     -77.424\n",
      "w[6]    2540.298\n",
      "w[7]    1671.551\n",
      "w[8]   -1066.142\n",
      "w[9]     956.763\n",
      "Name: mean, dtype: float64\n",
      "[[  236.88791166    71.53555199  -109.05550769    28.47611494\n",
      "   -146.40776547    52.56733334    33.51559326   103.88259889\n",
      "    -97.1051596    -23.06482191]\n",
      " [   71.53555199   646.83613359  -735.48450455   452.80885726\n",
      "   -510.3201644    545.02074762  -807.08225273    54.05627273\n",
      "   -505.3989107   -555.73491797]\n",
      " [ -109.05550769  -735.48450455   989.0532056   -476.61129934\n",
      "    333.85587602  -678.43921226   884.4564448    481.81071601\n",
      "    910.4719304    355.22392751]\n",
      " [   28.47611494   452.80885726  -476.61129934   328.15704674\n",
      "   -411.42655211   368.15402549  -581.51477189   163.19035587\n",
      "   -270.01430014  -458.92421827]\n",
      " [ -146.40776547  -510.3201644    333.85587602  -411.42655211\n",
      "    886.12329119  -324.35122278   621.81241109 -1045.19127893\n",
      "   -158.69809514   896.67049402]\n",
      " [   52.56733334   545.02074762  -678.43921226   368.15402549\n",
      "   -324.35122278   483.78741047  -677.09184789  -179.38386889\n",
      "   -556.70627106  -361.08338462]\n",
      " [   33.51559326  -807.08225273   884.4564448   -581.51477189\n",
      "    621.81241109  -677.09184789  1076.67438299   -85.90105337\n",
      "    566.60508558   749.26499725]\n",
      " [  103.88259889    54.05627273   481.81071601   163.19035587\n",
      "  -1045.19127893  -179.38386889   -85.90105337  2124.07583067\n",
      "   1176.59099376 -1049.26229041]\n",
      " [  -97.1051596   -505.3989107    910.4719304   -270.01430014\n",
      "   -158.69809514  -556.70627106   566.60508558  1176.59099376\n",
      "   1138.95666555  -179.13652562]\n",
      " [  -23.06482191  -555.73491797   355.22392751  -458.92421827\n",
      "    896.67049402  -361.08338462   749.26499725 -1049.26229041\n",
      "   -179.13652562   984.82586139]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 06:24<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 705 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5725.990\n",
      "w[1]     -37.895\n",
      "w[2]    -827.183\n",
      "w[3]    -488.137\n",
      "w[4]   -1869.832\n",
      "w[5]     -66.011\n",
      "w[6]    2529.559\n",
      "w[7]    1659.096\n",
      "w[8]   -1086.054\n",
      "w[9]     955.632\n",
      "Name: mean, dtype: float64\n",
      "[[  228.09553187    62.91188634   -97.62345153    23.36393982\n",
      "   -137.68566063    45.3147584     39.95575893   102.36503061\n",
      "    -87.44839212   -18.13635302]\n",
      " [   62.91188634   638.87805254  -721.64174842   448.94895497\n",
      "   -507.57128304   537.16293627  -802.03231168    64.28988451\n",
      "   -489.32608369  -557.15098921]\n",
      " [  -97.62345153  -721.64174842   964.6272434   -469.67813163\n",
      "    331.78206164  -664.25920283   873.64698378   459.79184\n",
      "    881.43846757   358.39513248]\n",
      " [   23.36393982   448.94895497  -469.67813163   326.40586448\n",
      "   -409.87627306   364.36211021  -579.62902344   168.12473264\n",
      "   -261.85234823  -459.94490811]\n",
      " [ -137.68566063  -507.57128304   331.78206164  -409.87627306\n",
      "    877.01965072  -323.25559372   622.86349167 -1033.81711028\n",
      "   -157.68314867   891.96069316]\n",
      " [   45.3147584    537.16293627  -664.25920283   364.36211021\n",
      "   -323.25559372   475.69676088  -671.44954296  -166.35807405\n",
      "   -539.60359272  -363.43574746]\n",
      " [   39.95575893  -802.03231168   873.64698378  -579.62902344\n",
      "    622.86349167  -671.44954296  1074.33130971   -98.87693375\n",
      "    552.12687655   753.73159413]\n",
      " [  102.36503061    64.28988451   459.79184      168.12473264\n",
      "  -1033.81711028  -166.35807405   -98.87693375  2084.61883181\n",
      "   1145.32762641 -1039.23663298]\n",
      " [  -87.44839212  -489.32608369   881.43846757  -261.85234823\n",
      "   -157.68314867  -539.60359272   552.12687655  1145.32762641\n",
      "   1103.31574854  -174.00656782]\n",
      " [  -18.13635302  -557.15098921   358.39513248  -459.94490811\n",
      "    891.96069316  -363.43574746   753.73159413 -1039.23663298\n",
      "   -174.00656782   982.98005642]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 06:51<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 692 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5732.969\n",
      "w[1]     -27.141\n",
      "w[2]    -844.613\n",
      "w[3]    -482.206\n",
      "w[4]   -1872.903\n",
      "w[5]     -55.342\n",
      "w[6]    2519.786\n",
      "w[7]    1645.841\n",
      "w[8]   -1105.429\n",
      "w[9]     955.502\n",
      "Name: mean, dtype: float64\n",
      "[[  229.57766024    60.06227717   -93.32702102    21.41193322\n",
      "   -138.28294305    42.31740691    44.42990668   107.52425863\n",
      "    -82.75853165   -17.64428191]\n",
      " [   60.06227717   641.37816223  -720.216317     451.9161673\n",
      "   -515.13749565   537.83740949  -807.45993706    77.78309929\n",
      "   -482.03584679  -567.22570791]\n",
      " [  -93.32702102  -720.216317     958.09237093  -470.03020458\n",
      "    336.61486111  -661.37745366   874.80037615   445.32422324\n",
      "    869.81470828   366.09344219]\n",
      " [   21.41193322   451.9161673   -470.03020458   329.37102138\n",
      "   -416.15724152   365.86999425  -585.01056636   177.74835176\n",
      "   -257.62298001  -468.1303853 ]\n",
      " [ -138.28294305  -515.13749565   336.61486111  -416.15724152\n",
      "    889.58656046  -328.26005102   632.94079433 -1048.59472024\n",
      "   -160.22965707   905.7372413 ]\n",
      " [   42.31740691   537.83740949  -661.37745366   365.86999425\n",
      "   -328.26005102   475.03850793  -674.47158929  -155.3941102\n",
      "   -532.29646847  -370.69640033]\n",
      " [   44.42990668  -807.45993706   874.80037615  -585.01056636\n",
      "    632.94079433  -674.47158929  1084.62392696  -113.82093245\n",
      "    545.59283984   767.73672894]\n",
      " [  107.52425863    77.78309929   445.32422324   177.74835176\n",
      "  -1048.59472024  -155.3941102   -113.82093245  2092.79512663\n",
      "   1137.25466891 -1053.08323562]\n",
      " [  -82.75853165  -482.03584679   869.81470828  -257.62298001\n",
      "   -160.22965707  -532.29646847   545.59283984  1137.25466891\n",
      "   1090.68042612  -174.4821906 ]\n",
      " [  -17.64428191  -567.22570791   366.09344219  -468.1303853\n",
      "    905.7372413   -370.69640033   767.73672894 -1053.08323562\n",
      "   -174.4821906    998.90284172]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 06:49<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 691 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5739.541\n",
      "w[1]     -16.389\n",
      "w[2]    -861.546\n",
      "w[3]    -476.134\n",
      "w[4]   -1876.587\n",
      "w[5]     -44.835\n",
      "w[6]    2509.732\n",
      "w[7]    1634.076\n",
      "w[8]   -1123.739\n",
      "w[9]     954.477\n",
      "Name: mean, dtype: float64\n",
      "[[  231.2969567     64.37817017  -101.8990833     23.48825787\n",
      "   -136.23078167    47.28643396    40.12714353    95.62411874\n",
      "    -93.97649558   -14.93624851]\n",
      " [   64.37817017   645.46451795  -729.59616119   453.35382787\n",
      "   -512.24919095   542.88093035  -809.99971609    63.37796998\n",
      "   -495.71942942  -562.10306781]\n",
      " [ -101.8990833   -729.59616119   975.50641778  -474.42109562\n",
      "    336.49365917  -671.45584729   881.7761801    463.88679508\n",
      "    891.99630579   361.921923  ]\n",
      " [   23.48825787   453.35382787  -474.42109562   329.55762293\n",
      "   -413.50079548   368.02812697  -585.48229506   168.93223576\n",
      "   -264.91369719  -464.28564009]\n",
      " [ -136.23078167  -512.24919095   336.49365917  -413.50079548\n",
      "    880.84607587  -327.11975804   629.87575956 -1035.24458128\n",
      "   -155.4418039    897.50825838]\n",
      " [   47.28643396   542.88093035  -671.45584729   368.02812697\n",
      "   -327.11975804   480.70603682  -677.96123352  -167.82467612\n",
      "   -545.83908197  -367.12245023]\n",
      " [   40.12714353  -809.99971609   881.7761801   -585.48229506\n",
      "    629.87575956  -677.96123352  1085.21109369  -101.48968427\n",
      "    556.83546281   762.28468953]\n",
      " [   95.62411874    63.37796998   463.88679508   168.93223576\n",
      "  -1035.24458128  -167.82467612  -101.48968427  2091.75287211\n",
      "   1153.15167124 -1044.6036568 ]\n",
      " [  -93.97649558  -495.71942942   891.99630579  -264.91369719\n",
      "   -155.4418039   -545.83908197   556.83546281  1153.15167124\n",
      "   1115.81271008  -174.6267654 ]\n",
      " [  -14.93624851  -562.10306781   361.921923    -464.28564009\n",
      "    897.50825838  -367.12245023   762.28468953 -1044.6036568\n",
      "   -174.6267654    991.3506994 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 06:36<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 709 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5746.021\n",
      "w[1]      -6.142\n",
      "w[2]    -878.103\n",
      "w[3]    -470.470\n",
      "w[4]   -1879.470\n",
      "w[5]     -34.677\n",
      "w[6]    2500.323\n",
      "w[7]    1621.447\n",
      "w[8]   -1142.123\n",
      "w[9]     954.284\n",
      "Name: mean, dtype: float64\n",
      "[[  234.84733043    68.01803167  -105.56204552    25.96915321\n",
      "   -141.95855107    50.01308486    37.10129565   100.52580714\n",
      "    -95.60477823   -19.22692315]\n",
      " [   68.01803167   659.96117643  -741.58293486   464.48011555\n",
      "   -532.80793145   553.07566756  -827.52010617    83.18978257\n",
      "   -496.8091578   -582.91043607]\n",
      " [ -105.56204552  -741.58293486   988.9949498   -482.76624973\n",
      "    347.72183662  -681.2704416    895.47649614   460.3216105\n",
      "    900.88688348   372.67619102]\n",
      " [   25.96915321   464.48011555  -482.76624973   338.31495228\n",
      "   -430.56725319   375.52465885  -599.20460619   187.08539953\n",
      "   -263.82892836  -481.79869383]\n",
      " [ -141.95855107  -532.80793145   347.72183662  -430.56725319\n",
      "    920.34126532  -339.26732192   655.20620603 -1085.49319571\n",
      "   -166.87761031   937.5757398 ]\n",
      " [   50.01308486   553.07566756  -681.2704416    375.52465885\n",
      "   -339.26732192   488.40328762  -690.00507973  -158.96242475\n",
      "   -549.70423989  -379.22729778]\n",
      " [   37.10129565  -827.52010617   895.47649614  -599.20460619\n",
      "    655.20620603  -690.00507973  1107.14624521  -127.17714242\n",
      "    556.41751251   788.738922  ]\n",
      " [  100.52580714    83.18978257   460.3216105    187.08539953\n",
      "  -1085.49319571  -158.96242475  -127.17714242  2166.88822816\n",
      "   1180.44616889 -1096.41203586]\n",
      " [  -95.60477823  -496.8091578    900.88688348  -263.82892836\n",
      "   -166.87761031  -549.70423989   556.41751251  1180.44616889\n",
      "   1133.76609787  -187.5207625 ]\n",
      " [  -19.22692315  -582.91043607   372.67619102  -481.79869383\n",
      "    937.5757398   -379.22729778   788.738922   -1096.41203586\n",
      "   -187.5207625   1032.86699992]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 06:36<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 712 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5752.501\n",
      "w[1]       4.428\n",
      "w[2]    -894.655\n",
      "w[3]    -464.489\n",
      "w[4]   -1883.238\n",
      "w[5]     -24.391\n",
      "w[6]    2490.444\n",
      "w[7]    1610.186\n",
      "w[8]   -1159.947\n",
      "w[9]     953.135\n",
      "Name: mean, dtype: float64\n",
      "[[  232.10904176    60.77345115   -97.4212411     20.95254083\n",
      "   -134.88992371    44.00691221    45.20628985    97.82662035\n",
      "    -90.25814716   -12.71776955]\n",
      " [   60.77345115   648.359126    -732.4099841    455.74501093\n",
      "   -513.00252323   545.34058993  -815.38485707    61.84653995\n",
      "   -497.19777125  -565.14067687]\n",
      " [  -97.4212411   -732.4099841    981.75340439  -475.98594517\n",
      "    330.49679268  -675.30426516   887.03154397   479.55951034\n",
      "    901.50376724   358.32679254]\n",
      " [   20.95254083   455.74501093  -475.98594517   331.67477017\n",
      "   -415.70087936   369.73515666  -589.83602513   170.93950172\n",
      "   -264.36735874  -468.21648563]\n",
      " [ -134.88992371  -513.00252323   330.49679268  -415.70087936\n",
      "    892.54157166  -325.06716276   632.14283015 -1059.82160925\n",
      "   -170.26930698   910.61648795]\n",
      " [   44.00691221   545.34058993  -675.30426516   369.73515666\n",
      "   -325.06716276   483.38306087  -682.46254669  -174.84922283\n",
      "   -550.41784722  -366.99071297]\n",
      " [   45.20628985  -815.38485707   887.03154397  -589.83602513\n",
      "    632.14283015  -682.46254669  1094.52469721  -100.06391876\n",
      "    559.46587579   767.97801918]\n",
      " [   97.82662035    61.84653995   479.55951034   170.93950172\n",
      "  -1059.82160925  -174.84922283  -100.06391876  2146.41971414\n",
      "   1186.15456783 -1069.10916982]\n",
      " [  -90.25814716  -497.19777125   901.50376724  -264.36735874\n",
      "   -170.26930698  -550.41784722   559.46587579  1186.15456783\n",
      "   1135.04738211  -188.06529013]\n",
      " [  -12.71776955  -565.14067687   358.32679254  -468.21648563\n",
      "    910.61648795  -366.99071297   767.97801918 -1069.10916982\n",
      "   -188.06529013  1006.63005805]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 06:36<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 725 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5758.338\n",
      "w[1]      14.313\n",
      "w[2]    -910.709\n",
      "w[3]    -459.006\n",
      "w[4]   -1885.670\n",
      "w[5]     -14.527\n",
      "w[6]    2481.153\n",
      "w[7]    1597.378\n",
      "w[8]   -1177.880\n",
      "w[9]     953.092\n",
      "Name: mean, dtype: float64\n",
      "[[  228.55547959    59.68758206   -97.35900025    20.13710226\n",
      "   -129.95447133    43.83805975    45.03602844    90.13277556\n",
      "    -92.3457631     -9.44018369]\n",
      " [   59.68758206   645.73560532  -730.45716258   453.62031328\n",
      "   -508.29092749   543.58918101  -812.11997909    56.47710742\n",
      "   -497.82790604  -560.5861476 ]\n",
      " [  -97.35900025  -730.45716258   981.66842257  -473.9514495\n",
      "    324.82834122  -674.48087942   883.81181623   488.43881451\n",
      "    905.1278098    352.20472462]\n",
      " [   20.13710226   453.62031328  -473.9514495    330.05798246\n",
      "   -412.73304953   368.12203404  -587.25956996   168.40952853\n",
      "   -263.84194396  -465.39259471]\n",
      " [ -129.95447133  -508.29092749   324.82834122  -412.73304953\n",
      "    886.52169194  -321.28884538   628.49534125 -1056.38520943\n",
      "   -174.04894814   906.75315391]\n",
      " [   43.83805975   543.58918101  -674.48087942   368.12203404\n",
      "   -321.28884538   482.35352462  -679.83260214  -179.95840096\n",
      "   -551.96007272  -362.95738657]\n",
      " [   45.03602844  -812.11997909   883.81181623  -587.25956996\n",
      "    628.49534125  -679.83260214  1089.78410711   -97.69993408\n",
      "    558.38914457   763.78829278]\n",
      " [   90.13277556    56.47710742   488.43881451   168.40952853\n",
      "  -1056.38520943  -179.95840096   -97.69993408  2150.51875633\n",
      "   1196.02624663 -1069.53494584]\n",
      " [  -92.3457631   -497.82790604   905.1278098   -263.84194396\n",
      "   -174.04894814  -551.96007272   558.38914457  1196.02624663\n",
      "   1142.16876205  -193.24719498]\n",
      " [   -9.44018369  -560.5861476    352.20472462  -465.39259471\n",
      "    906.75315391  -362.95738657   763.78829278 -1069.53494584\n",
      "   -193.24719498  1004.09730924]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 07:04<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 716 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5764.123\n",
      "w[1]      24.239\n",
      "w[2]    -926.749\n",
      "w[3]    -453.483\n",
      "w[4]   -1888.177\n",
      "w[5]      -4.646\n",
      "w[6]    2471.785\n",
      "w[7]    1584.697\n",
      "w[8]   -1195.742\n",
      "w[9]     952.932\n",
      "Name: mean, dtype: float64\n",
      "[[  228.69429696    61.78397388  -101.99785109    21.0589638\n",
      "   -127.54381721    46.47433062    42.64417322    81.59750524\n",
      "    -99.04399845    -6.96857078]\n",
      " [   61.78397388   639.22280671  -717.72774366   450.07549803\n",
      "   -513.84540776   535.84201468  -803.19073526    78.01637596\n",
      "   -480.8933449   -564.84640141]\n",
      " [ -101.99785109  -717.72774366   966.74299791  -464.59658977\n",
      "    318.89244102  -663.14420167   864.7818165    482.92838249\n",
      "    893.84725404   342.25028463]\n",
      " [   21.0589638    450.07549803  -464.59658977   328.72006926\n",
      "   -419.79998806   362.97807183  -582.82063116   188.9756889\n",
      "   -249.30760428  -472.15653696]\n",
      " [ -127.54381721  -513.84540776   318.89244102  -419.79998806\n",
      "    910.14271223  -321.43716848   638.60535034 -1099.7624197\n",
      "   -196.35134506   933.84030453]\n",
      " [   46.47433062   535.84201468  -663.14420167   362.97807183\n",
      "   -321.43716848   474.58642251  -668.62840178  -168.37524524\n",
      "   -540.15332995  -361.03071191]\n",
      " [   42.64417322  -803.19073526   864.7818165   -582.82063116\n",
      "    638.60535034  -668.62840178  1077.96816939  -132.80648116\n",
      "    531.69178727   772.55520912]\n",
      " [   81.59750524    78.01637596   482.92838249   188.9756889\n",
      "  -1099.7624197   -168.37524524  -132.80648116  2213.7624459\n",
      "   1220.11425302 -1122.45037712]\n",
      " [  -99.04399845  -480.8933449    893.84725404  -249.30760428\n",
      "   -196.35134506  -540.15332995   531.69178727  1220.11425302\n",
      "   1145.94087002  -222.20221597]\n",
      " [   -6.96857078  -564.84640141   342.25028463  -472.15653696\n",
      "    933.84030453  -361.03071191   772.55520912 -1122.45037712\n",
      "   -222.20221597  1034.80599013]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 06:56<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 709 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5769.730\n",
      "w[1]      33.235\n",
      "w[2]    -941.571\n",
      "w[3]    -448.567\n",
      "w[4]   -1890.198\n",
      "w[5]       4.391\n",
      "w[6]    2463.517\n",
      "w[7]    1572.501\n",
      "w[8]   -1212.508\n",
      "w[9]     953.266\n",
      "Name: mean, dtype: float64\n",
      "[[  229.5725601     65.35483347  -106.61972512    23.3499045\n",
      "   -129.59358647    49.65524968    38.57729519    80.10424414\n",
      "   -103.20732443    -8.94116707]\n",
      " [   65.35483347   639.55723489  -718.11011793   450.0042713\n",
      "   -516.14388851   535.89140354  -801.71947457    80.67785818\n",
      "   -481.03671873  -565.1981103 ]\n",
      " [ -106.61972512  -718.11011793   968.92978188  -464.05933179\n",
      "    318.816363    -663.81780938   862.56951896   485.83985549\n",
      "    897.77696987   339.54277113]\n",
      " [   23.3499045    450.0042713   -464.05933179   328.57097721\n",
      "   -421.82894638   362.59653009  -581.55681823   192.30444714\n",
      "   -248.19993159  -472.93294275]\n",
      " [ -129.59358647  -516.14388851   318.816363    -421.82894638\n",
      "    917.47595921  -322.24853977   640.80676402 -1110.8536104\n",
      "   -200.24854884   940.5076228 ]\n",
      " [   49.65524968   535.89140354  -663.81780938   362.59653009\n",
      "   -322.24853977   474.64217527  -666.91211536  -168.23182124\n",
      "   -541.39906582  -360.0354137 ]\n",
      " [   38.57729519  -801.71947457   862.56951896  -581.55681823\n",
      "    640.80676402  -666.91211536  1073.95041237  -137.80009477\n",
      "    529.16971908   772.34763224]\n",
      " [   80.10424414    80.67785818   485.83985549   192.30444714\n",
      "  -1110.8536104   -168.23182124  -137.80009477  2233.92450634\n",
      "   1230.537883   -1135.10157488]\n",
      " [ -103.20732443  -481.03671873   897.77696987  -248.19993159\n",
      "   -200.24854884  -541.39906582   529.16971908  1230.537883\n",
      "   1153.95743419  -228.64776844]\n",
      " [   -8.94116707  -565.1981103    339.54277113  -472.93294275\n",
      "    940.5076228   -360.0354137    772.34763224 -1135.10157488\n",
      "   -228.64776844  1040.62238707]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 07:29<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 876 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5775.429\n",
      "w[1]      42.141\n",
      "w[2]    -956.400\n",
      "w[3]    -443.758\n",
      "w[4]   -1891.990\n",
      "w[5]      13.391\n",
      "w[6]    2455.444\n",
      "w[7]    1559.924\n",
      "w[8]   -1229.460\n",
      "w[9]     953.903\n",
      "Name: mean, dtype: float64\n",
      "[[  223.60525431    70.53344495  -110.32621482    27.91570084\n",
      "   -133.53659619    53.72755397    28.4102024     83.06947836\n",
      "   -102.90451326   -17.16478695]\n",
      " [   70.53344495   640.15517909  -718.4319813    450.23773609\n",
      "   -520.46534024   535.92236525  -800.06295165    87.04738876\n",
      "   -480.10547608  -566.84612815]\n",
      " [ -110.32621482  -718.4319813    970.34252368  -463.81399621\n",
      "    319.53306753  -664.28327641   861.1615606    485.96166469\n",
      "    899.81785568   338.3635126 ]\n",
      " [   27.91570084   450.23773609  -463.81399621   328.61706766\n",
      "   -425.75767352   362.27978899  -579.69926068   198.54071834\n",
      "   -246.76441231  -474.42737385]\n",
      " [ -133.53659619  -520.46534024   319.53306753  -425.75767352\n",
      "    930.46262298  -324.06764226   645.10015003 -1130.2322861\n",
      "   -206.50510354   952.17609762]\n",
      " [   53.72755397   535.92236525  -664.28327641   362.27978899\n",
      "   -324.06764226   474.56332571  -664.95258514  -165.85556672\n",
      "   -541.87895009  -359.6691552 ]\n",
      " [   28.4102024   -800.06295165   861.1615606   -579.69926068\n",
      "    645.10015003  -664.95258514  1066.67848956  -145.52493725\n",
      "    527.88233097   770.78516654]\n",
      " [   83.06947836    87.04738876   485.96166469   198.54071834\n",
      "  -1130.2322861   -165.85556672  -145.52493725  2263.80789674\n",
      "   1241.87512051 -1153.99818126]\n",
      " [ -102.90451326  -480.10547608   899.81785568  -246.76441231\n",
      "   -206.50510354  -541.87895009   527.88233097  1241.87512051\n",
      "   1159.84494708  -234.82394005]\n",
      " [  -17.16478695  -566.84612815   338.3635126   -474.42737385\n",
      "    952.17609762  -359.6691552    770.78516654 -1153.99818126\n",
      "   -234.82394005  1048.08574521]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 07:31<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 887 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5780.780\n",
      "w[1]      50.792\n",
      "w[2]    -970.720\n",
      "w[3]    -439.047\n",
      "w[4]   -1893.779\n",
      "w[5]      22.115\n",
      "w[6]    2447.487\n",
      "w[7]    1547.899\n",
      "w[8]   -1245.745\n",
      "w[9]     954.352\n",
      "Name: mean, dtype: float64\n",
      "[[  231.03419175    72.90674672  -116.99145321    28.22218651\n",
      "   -133.01514636    56.63810602    29.77177921    75.03776351\n",
      "   -112.83082784   -12.41931726]\n",
      " [   72.90674672   652.65579323  -731.8843361    459.18689073\n",
      "   -532.44986037   546.03330938  -815.26588273    91.86248556\n",
      "   -488.08485555  -579.18432637]\n",
      " [ -116.99145321  -731.8843361    990.19299731  -471.93940714\n",
      "    325.60802618  -677.00506159   874.68031328   497.11662891\n",
      "    920.03500152   342.03525874]\n",
      " [   28.22218651   459.18689073  -471.93940714   335.44692641\n",
      "   -436.07169481   369.02186279  -591.50617843   206.30096663\n",
      "   -249.26643972  -485.91383963]\n",
      " [ -133.01514636  -532.44986037   325.60802618  -436.07169481\n",
      "    952.07289589  -331.14474618   661.96313438 -1157.73492528\n",
      "   -213.87759851   976.28707333]\n",
      " [   56.63810602   546.03330938  -677.00506159   369.02186279\n",
      "   -331.14474618   483.41062441  -676.49001283  -167.96843438\n",
      "   -552.37589932  -366.3170696 ]\n",
      " [   29.77177921  -815.26588273   874.68031328  -591.50617843\n",
      "    661.96313438  -676.49001283  1087.78672446  -158.08157474\n",
      "    531.7055945    790.717264  ]\n",
      " [   75.03776351    91.86248556   497.11662891   206.30096663\n",
      "  -1157.73492528  -167.96843438  -158.08157474  2318.45962135\n",
      "   1274.51814499 -1188.07831068]\n",
      " [ -112.83082784  -488.08485555   920.03500152  -249.26643972\n",
      "   -213.87759851  -552.37589932   531.7055945   1274.51814499\n",
      "   1190.11782736  -247.7076196 ]\n",
      " [  -12.41931726  -579.18432637   342.03525874  -485.91383963\n",
      "    976.28707333  -366.3170696    790.717264   -1188.07831068\n",
      "   -247.7076196   1077.37364242]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 08:19<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 888 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5786.068\n",
      "w[1]      59.231\n",
      "w[2]    -984.953\n",
      "w[3]    -434.520\n",
      "w[4]   -1895.105\n",
      "w[5]      30.719\n",
      "w[6]    2439.801\n",
      "w[7]    1535.234\n",
      "w[8]   -1262.217\n",
      "w[9]     955.283\n",
      "Name: mean, dtype: float64\n",
      "[[  228.6871105     78.03585615  -126.18215699    31.20774546\n",
      "   -129.50210342    62.56972098    22.24371982    60.35636973\n",
      "   -124.58259352   -10.47175787]\n",
      " [   78.03585615   641.90638358  -725.94698407   449.70140786\n",
      "   -516.6887962    538.93690361  -797.48873593    72.64649782\n",
      "   -493.35567772  -558.52064756]\n",
      " [ -126.18215699  -725.94698407   995.3051916   -464.2151775\n",
      "    306.01008902  -675.92520631   860.37257669   533.88210373\n",
      "    941.28692648   315.2841751 ]\n",
      " [   31.20774546   449.70140786  -464.2151775    327.77623864\n",
      "   -425.57093297   361.88493301  -576.96225937   197.3434012\n",
      "   -248.47458455  -472.2110728 ]\n",
      " [ -129.50210342  -516.6887962    306.01008902  -425.57093297\n",
      "    941.40236627  -317.28070057   643.15069046 -1161.03061037\n",
      "   -229.69404819   965.7252935 ]\n",
      " [   62.56972098   538.93690361  -675.92520631   361.88493301\n",
      "   -317.28070057   479.63788532  -663.02142693  -189.17831659\n",
      "   -562.02910252  -347.49175205]\n",
      " [   22.24371982  -797.48873593   860.37257669  -576.96225937\n",
      "    643.15069046  -663.02142693  1059.51319747  -142.34839488\n",
      "    530.43294825   764.82046968]\n",
      " [   60.35636973    72.64649782   533.88210373   197.3434012\n",
      "  -1161.03061037  -189.17831659  -142.34839488  2361.99960929\n",
      "   1321.85998232 -1198.66709155]\n",
      " [ -124.58259352  -493.35567772   941.28692648  -248.47458455\n",
      "   -229.69404819  -562.02910252   530.43294825  1321.85998232\n",
      "   1227.54910248  -271.03354893]\n",
      " [  -10.47175787  -558.52064756   315.2841751   -472.2110728\n",
      "    965.7252935   -347.49175205   764.82046968 -1198.66709155\n",
      "   -271.03354893  1065.59937392]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 07:04<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 837 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5791.165\n",
      "w[1]      67.655\n",
      "w[2]    -999.230\n",
      "w[3]    -430.006\n",
      "w[4]   -1896.207\n",
      "w[5]      39.353\n",
      "w[6]    2432.033\n",
      "w[7]    1522.180\n",
      "w[8]   -1278.825\n",
      "w[9]     956.341\n",
      "Name: mean, dtype: float64\n",
      "[[  236.32901514    80.33068269  -128.29148359    32.43508839\n",
      "   -136.58402077    63.59613808    23.2127795     68.72704373\n",
      "   -124.65916259   -13.61565085]\n",
      " [   80.33068269   639.46124189  -722.2481151    448.00445598\n",
      "   -517.65437901   536.21451983  -793.04363375    77.73482336\n",
      "   -489.46681762  -557.8296909 ]\n",
      " [ -128.29148359  -722.2481151    994.25340826  -460.58456733\n",
      "    298.63612002  -673.70965799   853.75314673   544.69459782\n",
      "    945.73407204   305.73023267]\n",
      " [   32.43508839   448.00445598  -460.58456733   326.89112762\n",
      "   -427.90207596   359.61527719  -574.21899932   204.62308558\n",
      "   -243.40412906  -473.71103775]\n",
      " [ -136.58402077  -517.65437901   298.63612002  -427.90207596\n",
      "    961.17208516  -314.10699608   641.78577155 -1199.22210097\n",
      "   -248.4656175    982.45879805]\n",
      " [   63.59613808   536.21451983  -673.70965799   359.61527719\n",
      "   -314.10699608   477.4910729   -658.63214217  -192.04609268\n",
      "   -562.0694671   -343.16075667]\n",
      " [   23.2127795   -793.04363375   853.75314673  -574.21899932\n",
      "    641.78577155  -658.63214217  1054.20077687  -147.00912731\n",
      "    523.87010518   763.38931615]\n",
      " [   68.72704373    77.73482336   544.69459782   204.62308558\n",
      "  -1199.22210097  -192.04609268  -147.00912731  2432.75728031\n",
      "   1356.14616767 -1234.629972  ]\n",
      " [ -124.65916259  -489.46681762   945.73407204  -243.40412906\n",
      "   -248.4656175   -562.0694671    523.87010518  1356.14616767\n",
      "   1244.83124896  -291.43833785]\n",
      " [  -13.61565085  -557.8296909    305.73023267  -473.71103775\n",
      "    982.45879805  -343.16075667   763.38931615 -1234.629972\n",
      "   -291.43833785  1081.29231755]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 07:22<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 790 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5796.522\n",
      "w[1]      75.664\n",
      "w[2]   -1013.126\n",
      "w[3]    -425.830\n",
      "w[4]   -1896.978\n",
      "w[5]      47.641\n",
      "w[6]    2424.965\n",
      "w[7]    1508.976\n",
      "w[8]   -1295.300\n",
      "w[9]     957.937\n",
      "Name: mean, dtype: float64\n",
      "[[  236.8486995     82.92856766  -131.45992996    34.16607708\n",
      "   -138.40486928    65.88668625    20.1025388     68.04684509\n",
      "   -127.23225883   -15.45476632]\n",
      " [   82.92856766   617.28918312  -698.12482984   432.07137589\n",
      "   -501.77169734   517.62673534  -762.87136911    76.96036496\n",
      "   -473.86178676  -537.5446696 ]\n",
      " [ -131.45992996  -698.12482984   967.24970501  -443.43786516\n",
      "    282.91342528  -653.21645616   820.97581565   542.4097838\n",
      "    927.02197275   285.16555322]\n",
      " [   34.16607708   432.07137589  -443.43786516   315.39400033\n",
      "   -416.04820435   346.33181519  -552.5501313    203.22847059\n",
      "   -232.64013941  -458.73715908]\n",
      " [ -138.40486928  -501.77169734   282.91342528  -416.04820435\n",
      "    946.94022015  -301.35260806   619.77056161 -1192.53086305\n",
      "   -256.02308222   964.82978358]\n",
      " [   65.88668625   517.62673534  -653.21645616   346.33181519\n",
      "   -301.35260806   461.80530637  -633.36582401  -191.54579652\n",
      "   -548.35289701  -326.70690347]\n",
      " [   20.1025388   -762.87136911   820.97581565  -552.5501313\n",
      "    619.77056161  -633.36582401  1013.29194796  -145.47579378\n",
      "    502.77676748   735.61776618]\n",
      " [   68.04684509    76.96036496   542.4097838    203.22847059\n",
      "  -1192.53086305  -191.54579652  -145.47579378  2419.90603745\n",
      "   1349.38905804 -1227.6479347 ]\n",
      " [ -127.23225883  -473.86178676   927.02197275  -232.64013941\n",
      "   -256.02308222  -548.35289701   502.77676748  1349.38905804\n",
      "   1229.78792623  -302.1901671 ]\n",
      " [  -15.45476632  -537.5446696    285.16555322  -458.73715908\n",
      "    964.82978358  -326.70690347   735.61776618 -1227.6479347\n",
      "   -302.1901671   1059.65399572]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 07:18<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 799 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5801.736\n",
      "w[1]      83.575\n",
      "w[2]   -1026.957\n",
      "w[3]    -421.719\n",
      "w[4]   -1897.528\n",
      "w[5]      55.883\n",
      "w[6]    2417.944\n",
      "w[7]    1495.490\n",
      "w[8]   -1311.812\n",
      "w[9]     959.689\n",
      "Name: mean, dtype: float64\n",
      "[[  241.4569574     90.99954375  -142.77384255    39.01113942\n",
      "   -142.95337002    73.23368231    12.39869943    63.36156446\n",
      "   -138.2041078    -18.42179998]\n",
      " [   90.99954375   623.34750028  -709.75232888   434.7009539\n",
      "   -502.72715839   524.04246337  -765.95931736    66.00105238\n",
      "   -488.46757012  -534.46631871]\n",
      " [ -142.77384255  -709.75232888   988.91755436  -448.84335849\n",
      "    283.25734327  -665.5836282    829.17316765   564.75216195\n",
      "    954.06057999   280.14660174]\n",
      " [   39.01113942   434.7009539   -448.84335849   316.37082666\n",
      "   -416.68041096   349.15422915  -553.13911079   198.32465795\n",
      "   -239.63016017  -456.83504993]\n",
      " [ -142.95337002  -502.72715839   283.25734327  -416.68041096\n",
      "    951.64191253  -301.52833685   618.62163063 -1199.15460004\n",
      "   -257.30264127   967.20654055]\n",
      " [   73.23368231   524.04246337  -665.5836282    349.15422915\n",
      "   -301.52833685   468.69549944  -637.26045357  -204.40597865\n",
      "   -564.04901729  -323.27076472]\n",
      " [   12.39869943  -765.95931736   829.17316765  -553.13911079\n",
      "    618.62163063  -637.26045357  1012.75074496  -134.70057857\n",
      "    514.81062775   730.20555915]\n",
      " [   63.36156446    66.00105238   564.75216195   198.32465795\n",
      "  -1199.15460004  -204.40597865  -134.70057857  2453.24382621\n",
      "   1379.64151359 -1236.16666016]\n",
      " [ -138.2041078   -488.46757012   954.06057999  -239.63016017\n",
      "   -257.30264127  -564.04901729   514.81062775  1379.64151359\n",
      "   1263.68417597  -308.37651862]\n",
      " [  -18.42179998  -534.46631871   280.14660174  -456.83504993\n",
      "    967.20654055  -323.27076472   730.20555915 -1236.16666016\n",
      "   -308.37651862  1060.06059345]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 07:17<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 786 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5806.689\n",
      "w[1]      91.720\n",
      "w[2]   -1040.867\n",
      "w[3]    -417.380\n",
      "w[4]   -1898.414\n",
      "w[5]      64.276\n",
      "w[6]    2410.457\n",
      "w[7]    1482.470\n",
      "w[8]   -1328.112\n",
      "w[9]     960.906\n",
      "Name: mean, dtype: float64\n",
      "[[  235.91262049    95.77834498  -149.24214071    42.50794135\n",
      "   -141.19781169    78.22678716     3.31207511    54.37018643\n",
      "   -144.8568977    -20.25060624]\n",
      " [   95.77834498   629.54660857  -715.43074509   439.0857347\n",
      "   -512.61761726   528.44400786  -771.74189021    75.42607714\n",
      "   -489.83679586  -542.55920852]\n",
      " [ -149.24214071  -715.43074509   992.97988507  -453.0254058\n",
      "    295.55684216  -669.06342035   833.61530338   549.90903766\n",
      "    952.6229779    289.74265015]\n",
      " [   42.50794135   439.0857347   -453.0254058    319.41486973\n",
      "   -423.47277818   352.30643323  -557.12537793   204.48193909\n",
      "   -240.93512722  -462.2779633 ]\n",
      " [ -141.19781169  -512.61761726   295.55684216  -423.47277818\n",
      "    956.00313294  -310.50449797   632.22223374 -1193.3999341\n",
      "   -247.02809024   973.63312557]\n",
      " [   78.22678716   528.44400786  -669.06342035   352.30643323\n",
      "   -310.50449797   471.49251495  -640.63912911  -194.13502177\n",
      "   -563.62860398  -330.1370615 ]\n",
      " [    3.31207511  -771.74189021   833.61530338  -557.12537793\n",
      "    632.22223374  -640.63912911  1015.79026828  -150.92719948\n",
      "    513.70404528   739.62602966]\n",
      " [   54.37018643    75.42607714   549.90903766   204.48193909\n",
      "  -1193.3999341   -194.13502177  -150.92719948  2429.28241203\n",
      "   1362.246001   -1236.17847733]\n",
      " [ -144.8568977   -489.83679586   952.6229779   -240.93512722\n",
      "   -247.02809024  -563.62860398   513.70404528  1362.246001\n",
      "   1257.51330998  -301.36448559]\n",
      " [  -20.25060624  -542.55920852   289.74265015  -462.2779633\n",
      "    973.63312557  -330.1370615    739.62602966 -1236.17847733\n",
      "   -301.36448559  1066.38817885]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 07:21<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 774 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5811.530\n",
      "w[1]      99.105\n",
      "w[2]   -1053.988\n",
      "w[3]    -413.598\n",
      "w[4]   -1898.532\n",
      "w[5]      72.058\n",
      "w[6]    2403.914\n",
      "w[7]    1469.048\n",
      "w[8]   -1344.000\n",
      "w[9]     962.939\n",
      "Name: mean, dtype: float64\n",
      "[[  235.19081095    91.73518898  -148.00626627    38.9268907\n",
      "   -132.21854598    76.12166735     8.56655694    41.68073833\n",
      "   -149.01676085   -10.78887188]\n",
      " [   91.73518898   640.59967501  -728.44387735   447.05429047\n",
      "   -517.78491288   538.29104982  -788.28831362    70.95971212\n",
      "   -499.69109026  -551.41771867]\n",
      " [ -148.00626627  -728.44387735  1005.61962047  -462.83212776\n",
      "    308.52546848  -679.3030888    851.62329205   541.92170762\n",
      "    957.80270495   305.34762354]\n",
      " [   38.9268907    447.05429047  -462.83212776   325.09217091\n",
      "   -426.01146204   359.62984018  -569.33623666   199.01257436\n",
      "   -249.09678284  -467.81193861]\n",
      " [ -132.21854598  -517.78491288   308.52546848  -426.01146204\n",
      "    942.18688781  -318.35947677   642.80066798 -1159.53221884\n",
      "   -226.36045872   964.83099572]\n",
      " [   76.12166735   538.29104982  -679.3030888    359.62984018\n",
      "   -318.35947677   479.60432572  -654.76453901  -191.76793445\n",
      "   -569.23378412  -340.57826403]\n",
      " [    8.56655694  -788.28831362   851.62329205  -569.33623666\n",
      "    642.80066798  -654.76453901  1040.26493168  -150.04162771\n",
      "    525.26403489   755.44000272]\n",
      " [   41.68073833    70.95971212   541.92170762   199.01257436\n",
      "  -1159.53221884  -191.76793445  -150.04162771  2369.0666657\n",
      "   1335.11982323 -1207.53365087]\n",
      " [ -149.01676085  -499.69109026   957.80270495  -249.09678284\n",
      "   -226.36045872  -569.23378412   525.26403489  1335.11982323\n",
      "   1250.99251264  -281.12389129]\n",
      " [  -10.78887188  -551.41771867   305.34762354  -467.81193861\n",
      "    964.83099572  -340.57826403   755.44000272 -1207.53365087\n",
      "   -281.12389129  1063.52236215]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 11:36<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1065 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5816.055\n",
      "w[1]     106.517\n",
      "w[2]   -1066.599\n",
      "w[3]    -409.642\n",
      "w[4]   -1899.432\n",
      "w[5]      79.669\n",
      "w[6]    2397.103\n",
      "w[7]    1457.406\n",
      "w[8]   -1358.716\n",
      "w[9]     963.962\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.35515896e+02  9.73867371e+01 -1.53719462e+02  4.31243603e+01\n",
      "  -1.37827725e+02  8.06129270e+01  1.23235121e+00  4.47994685e+01\n",
      "  -1.51713834e+02 -1.70789765e+01]\n",
      " [ 9.73867371e+01  6.57018027e+02 -7.46848140e+02  4.58324512e+02\n",
      "  -5.33588202e+02  5.51722102e+02 -8.06837072e+02  7.68793452e+01\n",
      "  -5.11453818e+02 -5.66275040e+02]\n",
      " [-1.53719462e+02 -7.46848140e+02  1.02798276e+03 -4.75056563e+02\n",
      "   3.22773529e+02 -6.95104618e+02  8.72499719e+02  5.42399053e+02\n",
      "   9.74945460e+02  3.18734999e+02]\n",
      " [ 4.31243603e+01  4.58324512e+02 -4.75056563e+02  3.32904727e+02\n",
      "  -4.37770210e+02  3.68660026e+02 -5.81950152e+02  2.04877983e+02\n",
      "  -2.56232397e+02 -4.78772510e+02]\n",
      " [-1.37827725e+02 -5.33588202e+02  3.22773529e+02 -4.37770210e+02\n",
      "   9.63658933e+02 -3.29872034e+02  6.61036925e+02 -1.17852044e+03\n",
      "  -2.22887039e+02  9.85621872e+02]\n",
      " [ 8.06129270e+01  5.51722102e+02 -6.95104618e+02  3.68660026e+02\n",
      "  -3.29872034e+02  4.90893560e+02 -6.69897595e+02 -1.89883587e+02\n",
      "  -5.80556595e+02 -3.51317868e+02]\n",
      " [ 1.23235121e+00 -8.06837072e+02  8.72499719e+02 -5.81950152e+02\n",
      "   6.61036925e+02 -6.69897595e+02  1.06067857e+03 -1.57125695e+02\n",
      "   5.38724594e+02  7.72042524e+02]\n",
      " [ 4.47994685e+01  7.68793452e+01  5.42399053e+02  2.04877983e+02\n",
      "  -1.17852044e+03 -1.89883587e+02 -1.57125695e+02  2.39909515e+03\n",
      "   1.34701826e+03 -1.22622553e+03]\n",
      " [-1.51713834e+02 -5.11453818e+02  9.74945460e+02 -2.56232397e+02\n",
      "  -2.22887039e+02 -5.80556595e+02  5.38724594e+02  1.34701826e+03\n",
      "   1.26844388e+03 -2.77925824e+02]\n",
      " [-1.70789765e+01 -5.66275040e+02  3.18734999e+02 -4.78772510e+02\n",
      "   9.85621872e+02 -3.51317868e+02  7.72042524e+02 -1.22622553e+03\n",
      "  -2.77925824e+02  1.08308556e+03]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 10:05<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1127 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5820.548\n",
      "w[1]     113.949\n",
      "w[2]   -1079.422\n",
      "w[3]    -405.711\n",
      "w[4]   -1900.016\n",
      "w[5]      87.381\n",
      "w[6]    2390.267\n",
      "w[7]    1445.036\n",
      "w[8]   -1373.872\n",
      "w[9]     965.298\n",
      "Name: mean, dtype: float64\n",
      "[[  235.1043679     93.90225242  -149.90593464    40.62310858\n",
      "   -134.64974099    77.71818226     5.63787262    43.80331391\n",
      "   -149.38330319   -13.7842074 ]\n",
      " [   93.90225242   635.19409371  -723.55773218   442.78262203\n",
      "   -513.27201863   534.13160096  -779.87853781    68.73425536\n",
      "   -497.82609581  -544.7843691 ]\n",
      " [ -149.90593464  -723.55773218  1001.50524039  -458.86058558\n",
      "    303.93003778  -675.69487161   843.95545816   545.01219634\n",
      "    956.72063383   298.82564587]\n",
      " [   40.62310858   442.78262203  -458.86058558   321.74688814\n",
      "   -422.60991946   356.29352601  -562.72050565   197.60147938\n",
      "   -247.40444655  -462.74337626]\n",
      " [ -134.64974099  -513.27201863   303.93003778  -422.60991946\n",
      "    939.61160003  -314.60114979   635.58051085 -1160.12489462\n",
      "   -229.09477336   960.29354925]\n",
      " [   77.71818226   534.13160096  -675.69487161   356.29352601\n",
      "   -314.60114979   476.47393925  -648.28531361  -194.09385467\n",
      "   -568.12869423  -335.18131546]\n",
      " [    5.63787262  -779.87853781   843.95545816  -562.72050565\n",
      "    635.58051085  -648.28531361  1027.41251297  -146.21769203\n",
      "    522.36994356   745.08875861]\n",
      " [   43.80331391    68.73425536   545.01219634   197.60147938\n",
      "  -1160.12489462  -194.09385467  -146.21769203  2373.1579968\n",
      "   1338.29417143 -1206.85060454]\n",
      " [ -149.38330319  -497.82609581   956.72063383  -247.40444655\n",
      "   -229.09477336  -568.12869423   522.36994356  1338.29417143\n",
      "   1251.6127428   -284.49730153]\n",
      " [  -13.7842074   -544.7843691    298.82564587  -462.74337626\n",
      "    960.29354925  -335.18131546   745.08875861 -1206.85060454\n",
      "   -284.49730153  1056.28187991]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 10:00<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1122 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5824.868\n",
      "w[1]     120.847\n",
      "w[2]   -1091.435\n",
      "w[3]    -402.101\n",
      "w[4]   -1900.450\n",
      "w[5]      94.572\n",
      "w[6]    2384.019\n",
      "w[7]    1433.274\n",
      "w[8]   -1388.171\n",
      "w[9]     966.744\n",
      "Name: mean, dtype: float64\n",
      "[[  235.85392084    95.162626    -148.4785516     42.20832401\n",
      "   -141.00172562    77.57767429     3.88682655    55.26295564\n",
      "   -143.94241563   -20.2016619 ]\n",
      " [   95.162626     608.41863259  -688.39871363   424.88870493\n",
      "   -502.83739181   509.35811562  -744.82252681    87.91501056\n",
      "   -465.92862351  -530.64759579]\n",
      " [ -148.4785516   -688.39871363   956.17813844  -435.34628945\n",
      "    286.81781793  -643.7402857    799.36433617   525.89451873\n",
      "    917.12435787   278.38384059]\n",
      " [   42.20832401   424.88870493  -435.34628945   309.73697753\n",
      "   -416.13198197   339.6697626   -538.91529676   211.17056368\n",
      "   -225.9496059   -453.3980087 ]\n",
      " [ -141.00172562  -502.83739181   286.81781793  -416.13198197\n",
      "    945.1423389   -303.11360609   619.47863716 -1185.91536302\n",
      "   -249.8786843    961.65938832]\n",
      " [   77.57767429   509.35811562  -643.7402857    339.6697626\n",
      "   -303.11360609   453.88102259  -616.41792466  -179.76308577\n",
      "   -540.0773832   -320.89257999]\n",
      " [    3.88682655  -744.82252681   799.36433617  -538.91529676\n",
      "    619.47863716  -616.41792466   981.20746535  -165.98364266\n",
      "    483.79491393   723.9315132 ]\n",
      " [   55.26295564    87.91501056   525.89451873   211.17056368\n",
      "  -1185.91536302  -179.76308577  -165.98364266  2393.86424889\n",
      "   1330.58850905 -1229.40722455]\n",
      " [ -143.94241563  -465.92862351   917.12435787  -225.9496059\n",
      "   -249.8786843   -540.0773832    483.79491393  1330.58850905\n",
      "   1219.63976771  -306.2722829 ]\n",
      " [  -20.2016619   -530.64759579   278.38384059  -453.3980087\n",
      "    961.65938832  -320.89257999   723.9315132  -1229.40722455\n",
      "   -306.2722829   1052.84266585]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 10:03<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1119 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5828.955\n",
      "w[1]     127.549\n",
      "w[2]   -1102.848\n",
      "w[3]    -398.521\n",
      "w[4]   -1901.255\n",
      "w[5]     101.469\n",
      "w[6]    2377.852\n",
      "w[7]    1422.737\n",
      "w[8]   -1401.492\n",
      "w[9]     967.670\n",
      "Name: mean, dtype: float64\n",
      "[[  242.45152607    98.89175735  -152.828167      44.26139052\n",
      "   -147.14895502    80.20132055     2.51073485    60.12521948\n",
      "   -146.86183634   -23.19970107]\n",
      " [   98.89175735   604.58604659  -685.63054759   421.51470738\n",
      "   -499.43707211   506.38271805  -737.69163944    85.12258447\n",
      "   -466.27205137  -524.61276654]\n",
      " [ -152.828167    -685.63054759   954.34177111  -432.68621358\n",
      "    284.93928003  -641.53196828   793.25128391   527.45112152\n",
      "    917.76087046   273.60919651]\n",
      " [   44.26139052   421.51470738  -432.68621358   306.91207232\n",
      "   -412.80856989   337.06105066  -533.30627192   208.54239977\n",
      "   -225.81655557  -448.46727983]\n",
      " [ -147.14895502  -499.43707211   284.93928003  -412.80856989\n",
      "    942.69734412  -300.38734715   611.67250141 -1183.91325122\n",
      "   -248.49803193   955.43710547]\n",
      " [   80.20132055   506.38271805  -641.53196828   337.06105066\n",
      "   -300.38734715   451.579536    -610.99327823  -182.06535138\n",
      "   -540.27241422  -316.2378466 ]\n",
      " [    2.51073485  -737.69163944   793.25128391  -533.30627192\n",
      "    611.67250141  -610.99327823   970.94307166  -159.80899453\n",
      "    482.55059252   714.34501352]\n",
      " [   60.12521948    85.12258447   527.45112152   208.54239977\n",
      "  -1183.91325122  -182.06535138  -159.80899453  2392.66612677\n",
      "   1329.64091865 -1224.58774362]\n",
      " [ -146.86183634  -466.27205137   917.76087046  -225.81655557\n",
      "   -248.49803193  -540.27241422   482.55059252  1329.64091865\n",
      "   1220.48477975  -306.64368799]\n",
      " [  -23.19970107  -524.61276654   273.60919651  -448.46727983\n",
      "    955.43710547  -316.2378466    714.34501352 -1224.58774362\n",
      "   -306.64368799  1044.22210499]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 38:25<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 2844 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5832.960\n",
      "w[1]     133.549\n",
      "w[2]   -1113.471\n",
      "w[3]    -395.438\n",
      "w[4]   -1901.486\n",
      "w[5]     107.774\n",
      "w[6]    2372.566\n",
      "w[7]    1412.083\n",
      "w[8]   -1414.294\n",
      "w[9]     969.223\n",
      "Name: mean, dtype: float64\n",
      "[[  242.89244924    98.41993375  -155.32345692    43.17999921\n",
      "   -141.93574448    80.92412122     3.83121028    49.40941146\n",
      "   -153.00367806   -17.35272237]\n",
      " [   98.41993375   609.22708963  -693.99832943   424.09318723\n",
      "   -497.33487701   511.58647203  -743.78466574    73.46943715\n",
      "   -476.62572303  -522.9508387 ]\n",
      " [ -155.32345692  -693.99832943   971.28382956  -436.63602617\n",
      "    279.71562409  -651.35489395   802.10704486   552.84461551\n",
      "    940.47663378   267.26899078]\n",
      " [   43.17999921   424.09318723  -436.63602617   308.57023676\n",
      "   -412.39090996   339.74935057  -537.24796813   204.0136677\n",
      "   -230.0609244   -448.79492956]\n",
      " [ -141.93574448  -497.33487701   279.71562409  -412.39090996\n",
      "    943.29118724  -297.91219707   612.12931501 -1190.51748198\n",
      "   -256.35294329   958.75520509]\n",
      " [   80.92412122   511.58647203  -651.35489395   339.74935057\n",
      "   -297.91219707   457.4784918   -617.06660517  -195.85861528\n",
      "   -552.86000965  -313.57296682]\n",
      " [    3.83121028  -743.78466574   802.10704486  -537.24796813\n",
      "    612.12931501  -617.06660517   979.6281394   -151.73128368\n",
      "    491.57280719   715.97973522]\n",
      " [   49.40941146    73.46943715   552.84461551   204.0136677\n",
      "  -1190.51748198  -195.85861528  -151.73128368  2429.35622938\n",
      "   1365.24689643 -1236.62945375]\n",
      " [ -153.00367806  -476.62572303   940.47663378  -230.0609244\n",
      "   -256.35294329  -552.86000965   491.57280719  1365.24689643\n",
      "   1252.40831695  -317.62629958]\n",
      " [  -17.35272237  -522.9508387    267.26899078  -448.79492956\n",
      "    958.75520509  -313.57296682   715.97973522 -1236.62945375\n",
      "   -317.62629958  1050.81555103]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 56:16<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 4846 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5836.812\n",
      "w[1]     139.632\n",
      "w[2]   -1124.283\n",
      "w[3]    -392.307\n",
      "w[4]   -1901.520\n",
      "w[5]     114.196\n",
      "w[6]    2367.109\n",
      "w[7]    1400.947\n",
      "w[8]   -1427.379\n",
      "w[9]     970.885\n",
      "Name: mean, dtype: float64\n",
      "[[  248.36322732   101.3189231   -159.12634717    44.67552416\n",
      "   -146.34202514    83.14278777     2.98457344    51.95923408\n",
      "   -156.01600156   -19.04741287]\n",
      " [  101.3189231    627.49200331  -712.59787539   437.45931839\n",
      "   -516.28881344   526.08056765  -766.45808812    84.11222217\n",
      "   -485.84227952  -542.89225624]\n",
      " [ -159.12634717  -712.59787539   991.36791233  -449.89064189\n",
      "    297.49978653  -666.51282344   824.6134673    545.64645678\n",
      "    952.33010362   285.51297283]\n",
      " [   44.67552416   437.45931839  -449.89064189   318.48109021\n",
      "   -426.51129078   350.26013091  -554.20718914   212.61885339\n",
      "   -236.06667201  -464.01039   ]\n",
      " [ -146.34202514  -516.28881344   297.49978653  -426.51129078\n",
      "    966.41458857  -312.20072265   635.08283812 -1208.42961149\n",
      "   -250.22736879   982.20337267]\n",
      " [   83.14278777   526.08056765  -666.51282344   350.26013091\n",
      "   -312.20072265   469.14692303  -635.04840905  -188.99884\n",
      "   -561.06494656  -328.66421211]\n",
      " [    2.98457344  -766.45808812   824.6134673   -554.20718914\n",
      "    635.08283812  -635.04840905  1009.28790726  -164.90136813\n",
      "    501.90972382   741.74414785]\n",
      " [   51.95923408    84.11222217   545.64645678   212.61885339\n",
      "  -1208.42961149  -188.99884     -164.90136813  2450.01400559\n",
      "   1367.96939057 -1254.84271017]\n",
      " [ -156.01600156  -485.84227952   952.33010362  -236.06667201\n",
      "   -250.22736879  -561.06494656   501.90972382  1367.96939057\n",
      "   1262.42073568  -312.0235268 ]\n",
      " [  -19.04741287  -542.89225624   285.51297283  -464.01039\n",
      "    982.20337267  -328.66421211   741.74414785 -1254.84271017\n",
      "   -312.0235268   1076.27949871]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 26:41<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 2924 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5840.579\n",
      "w[1]     145.669\n",
      "w[2]   -1134.999\n",
      "w[3]    -389.196\n",
      "w[4]   -1901.548\n",
      "w[5]     120.565\n",
      "w[6]    2361.654\n",
      "w[7]    1389.908\n",
      "w[8]   -1440.330\n",
      "w[9]     972.516\n",
      "Name: mean, dtype: float64\n",
      "[[  247.46819156    97.05231675  -154.70035921    41.59721045\n",
      "   -141.95417695    79.74940292     8.16030024    49.801068\n",
      "   -153.6097549    -14.62162479]\n",
      " [   97.05231675   611.74032251  -698.50649373   425.65709047\n",
      "   -495.73393561   514.47824369  -747.57896395    66.50466393\n",
      "   -482.23276981  -522.2103774 ]\n",
      " [ -154.70035921  -698.50649373   980.14617651  -439.00843005\n",
      "    276.29653585  -656.72988324   807.81119129   567.07515371\n",
      "    952.18001786   264.45916028]\n",
      " [   41.59721045   425.65709047  -439.00843005   309.70546812\n",
      "   -411.73272251   341.4221933   -540.04293726   200.68493259\n",
      "   -232.66565893  -449.08093581]\n",
      " [ -141.95417695  -495.73393561   276.29653585  -411.73272251\n",
      "    945.16845028  -295.83539256   610.24842984 -1196.90910669\n",
      "   -261.19557726   960.36255903]\n",
      " [   79.74940292   514.47824369  -656.72988324   341.4221933\n",
      "   -295.83539256   460.85064405  -621.16343697  -204.45294132\n",
      "   -559.75325469  -312.30350715]\n",
      " [    8.16030024  -747.57896395   807.81119129  -540.04293726\n",
      "    610.24842984  -621.16343697   986.65942209  -143.29823574\n",
      "    497.84204665   716.72785926]\n",
      " [   49.801068      66.50466393   567.07515371   200.68493259\n",
      "  -1196.90910669  -204.45294132  -143.29823574  2453.65206026\n",
      "   1384.64880109 -1242.12961031]\n",
      " [ -153.6097549   -482.23276981   952.18001786  -232.66565893\n",
      "   -261.19557726  -559.75325469   497.84204665  1384.64880109\n",
      "   1268.4336401   -322.40449379]\n",
      " [  -14.62162479  -522.2103774    264.45916028  -449.08093581\n",
      "    960.36255903  -312.30350715   716.72785926 -1242.12961031\n",
      "   -322.40449379  1053.75397452]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 07:24<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 825 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5844.178\n",
      "w[1]     151.346\n",
      "w[2]   -1145.086\n",
      "w[3]    -386.273\n",
      "w[4]   -1901.603\n",
      "w[5]     126.552\n",
      "w[6]    2356.560\n",
      "w[7]    1379.560\n",
      "w[8]   -1452.520\n",
      "w[9]     974.049\n",
      "Name: mean, dtype: float64\n",
      "[[  257.4132245     96.50411338  -156.92251217    39.85668865\n",
      "   -142.61233803    79.59428723    14.41314844    47.77596734\n",
      "   -158.70233827    -9.37682948]\n",
      " [   96.50411338   627.63870933  -713.99438897   437.57135349\n",
      "   -511.71741128   527.05043076  -768.99250435    76.10610736\n",
      "   -488.88089788  -540.82888326]\n",
      " [ -156.92251217  -713.99438897  1001.07175079  -449.00433523\n",
      "    283.46410979  -671.08787812   826.48673075   577.0703798\n",
      "    971.39458498   272.11236578]\n",
      " [   39.85668865   437.57135349  -449.00433523   319.11102927\n",
      "   -425.6743621    350.30797456  -556.98102711   212.7012293\n",
      "   -234.19549449  -465.89064455]\n",
      " [ -142.61233803  -511.71741128   283.46410979  -425.6743621\n",
      "    976.37280845  -305.00951487   632.20129737 -1238.75318784\n",
      "   -273.20087732   994.31650211]\n",
      " [   79.59428723   527.05043076  -671.08787812   350.30797456\n",
      "   -305.00951487   471.6124483   -637.67794473  -204.47066773\n",
      "   -569.67035738  -323.20796998]\n",
      " [   14.41314844  -768.99250435   826.48673075  -556.98102711\n",
      "    632.20129737  -637.67794473  1018.62883213  -159.55241632\n",
      "    502.40791439   745.51515847]\n",
      " [   47.77596734    76.10610736   577.0703798    212.7012293\n",
      "  -1238.75318784  -204.47066773  -159.55241632  2529.7347745\n",
      "   1423.32344232 -1288.28734128]\n",
      " [ -158.70233827  -488.88089788   971.39458498  -234.19549449\n",
      "   -273.20087732  -569.67035738   502.40791439  1423.32344232\n",
      "   1298.99580203  -337.46117104]\n",
      " [   -9.37682948  -540.82888326   272.11236578  -465.89064455\n",
      "    994.31650211  -323.20796998   745.51515847 -1288.28734128\n",
      "   -337.46117104  1094.33059974]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:00<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 942 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5847.983\n",
      "w[1]     156.791\n",
      "w[2]   -1154.997\n",
      "w[3]    -383.549\n",
      "w[4]   -1901.455\n",
      "w[5]     132.362\n",
      "w[6]    2351.888\n",
      "w[7]    1369.061\n",
      "w[8]   -1464.708\n",
      "w[9]     975.930\n",
      "Name: mean, dtype: float64\n",
      "[[  253.16324039    99.34868274  -158.64699408    42.47406439\n",
      "   -144.65953341    81.72129113     8.28643918    49.65450066\n",
      "   -157.90683602   -14.33942211]\n",
      " [   99.34868274   628.2931509   -714.70741114   437.79738088\n",
      "   -514.0177419    527.28628937  -768.37874173    78.69422594\n",
      "   -489.02038065  -541.58584308]\n",
      " [ -158.64699408  -714.70741114  1000.75682379  -449.58867124\n",
      "    286.94336267  -671.02158565   826.6178542    571.56798373\n",
      "    969.32697583   274.86404306]\n",
      " [   42.47406439   437.79738088  -449.58867124   318.97668457\n",
      "   -426.89432083   350.36398953  -555.87888235   213.77216267\n",
      "   -234.82819216  -465.59405244]\n",
      " [ -144.65953341  -514.0177419    286.94336267  -426.89432083\n",
      "    977.84135682  -307.06566125   634.10207066 -1237.4558154\n",
      "   -269.80202872   994.70666329]\n",
      " [   81.72129113   527.28628937  -671.02158565   350.36398953\n",
      "   -307.06566125   471.43706296  -636.90172561  -201.43627394\n",
      "   -568.90709739  -324.12822255]\n",
      " [    8.28643918  -768.37874173   826.6178542   -555.87888235\n",
      "    634.10207066  -636.90172561  1014.52463826  -161.80070552\n",
      "    503.18949016   743.7585287 ]\n",
      " [   49.65450066    78.69422594   571.56798373   213.77216267\n",
      "  -1237.4558154   -201.43627394  -161.80070552  2522.23503087\n",
      "   1416.01378104 -1285.75300893]\n",
      " [ -157.90683602  -489.02038065   969.32697583  -234.82819216\n",
      "   -269.80202872  -568.90709739   503.18949016  1416.01378104\n",
      "   1294.32325066  -333.2478047 ]\n",
      " [  -14.33942211  -541.58584308   274.86404306  -465.59405244\n",
      "    994.70666329  -324.12822255   743.7585287  -1285.75300893\n",
      "   -333.2478047   1091.66861751]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 08:36<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 907 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5851.513\n",
      "w[1]     162.365\n",
      "w[2]   -1164.946\n",
      "w[3]    -380.692\n",
      "w[4]   -1901.420\n",
      "w[5]     138.268\n",
      "w[6]    2346.888\n",
      "w[7]    1358.700\n",
      "w[8]   -1476.796\n",
      "w[9]     977.529\n",
      "Name: mean, dtype: float64\n",
      "[[  253.58045663    90.1492652   -149.92206995    35.48820964\n",
      "   -135.22312097    74.48678942    20.71107536    43.71433112\n",
      "   -154.45409729    -3.35834783]\n",
      " [   90.1492652    622.57778881  -708.18887244   434.23384837\n",
      "   -504.10023956   523.19530169  -765.59352347    70.21518733\n",
      "   -485.57088129  -535.83383823]\n",
      " [ -149.92206995  -708.18887244   997.56795451  -444.3919933\n",
      "    269.42453903  -667.82005764   821.93350503   595.4100849\n",
      "    974.63190672   260.66507345]\n",
      " [   35.48820964   434.23384837  -444.3919933    317.09332735\n",
      "   -421.86612291   347.48771955  -554.93370495   211.52032425\n",
      "   -230.31120444  -463.95661041]\n",
      " [ -135.22312097  -504.10023956   269.42453903  -421.86612291\n",
      "    975.42571845  -297.02926151   626.86613048 -1252.00549193\n",
      "   -290.40401827   996.79776153]\n",
      " [   74.48678942   523.19530169  -667.82005764   347.48771955\n",
      "   -297.02926151   469.11330339  -635.01735602  -213.5808556\n",
      "   -569.77871764  -317.24617033]\n",
      " [   20.71107536  -765.59352347   821.93350503  -554.93370495\n",
      "    626.86613048  -635.01735602  1017.38165553  -155.8292106\n",
      "    499.11108743   742.92363727]\n",
      " [   43.71433112    70.21518733   595.4100849    211.52032425\n",
      "  -1252.00549193  -213.5808556   -155.8292106   2569.7040783\n",
      "   1453.61693537 -1304.06469337]\n",
      " [ -154.45409729  -485.57088129   974.63190672  -230.31120444\n",
      "   -290.40401827  -569.77871764   499.11108743  1453.61693537\n",
      "   1312.56383393  -353.52049301]\n",
      " [   -3.35834783  -535.83383823   260.66507345  -463.95661041\n",
      "    996.79776153  -317.24617033   742.92363727 -1304.06469337\n",
      "   -353.52049301  1099.75319765]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 07:49<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 878 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5854.695\n",
      "w[1]     167.948\n",
      "w[2]   -1174.927\n",
      "w[3]    -377.818\n",
      "w[4]   -1901.130\n",
      "w[5]     144.213\n",
      "w[6]    2341.701\n",
      "w[7]    1347.931\n",
      "w[8]   -1488.975\n",
      "w[9]     979.192\n",
      "Name: mean, dtype: float64\n",
      "[[  257.60381433    92.94217153  -150.93818437    37.73760581\n",
      "   -143.39529218    75.63921348    18.92826821    55.28248643\n",
      "   -151.49949177    -9.90017737]\n",
      " [   92.94217153   633.09683148  -724.14715941   440.51313823\n",
      "   -506.1559695    533.56850565  -777.17751428    57.10100176\n",
      "   -502.75671969  -537.28042982]\n",
      " [ -150.93818437  -724.14715941  1014.46347321  -455.94105749\n",
      "    283.54922642  -680.91525155   842.19794352   590.40707057\n",
      "    984.53004363   276.32548014]\n",
      " [   37.73760581   440.51313823  -455.94105749   320.29865252\n",
      "   -419.86124961   354.43764095  -561.26607667   196.53170028\n",
      "   -245.06970236  -461.07723117]\n",
      " [ -143.39529218  -506.1559695    283.54922642  -419.86124961\n",
      "    960.87460906  -302.77335115   623.59886222 -1214.34041254\n",
      "   -262.9311598    976.92303185]\n",
      " [   75.63921348   533.56850565  -680.91525155   354.43764095\n",
      "   -302.77335115   478.42290796  -647.63941655  -217.88999915\n",
      "   -580.91431583  -323.5190138 ]\n",
      " [   18.92826821  -777.17751428   842.19794352  -561.26607667\n",
      "    623.59886222  -647.63941655  1030.43864054  -130.0589125\n",
      "    524.19550674   739.4294943 ]\n",
      " [   55.28248643    57.10100176   590.40707057   196.53170028\n",
      "  -1214.34041254  -217.88999915  -130.0589125   2504.74934553\n",
      "   1420.30251685 -1256.56543732]\n",
      " [ -151.49949177  -502.75671969   984.53004363  -245.06970236\n",
      "   -262.9311598   -580.91431583   524.19550674  1420.30251685\n",
      "   1304.90417396  -321.38739333]\n",
      " [   -9.90017737  -537.28042982   276.32548014  -461.07723117\n",
      "    976.92303185  -323.5190138    739.4294943  -1256.56543732\n",
      "   -321.38739333  1075.14290627]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 10:16<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1063 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5857.861\n",
      "w[1]     172.636\n",
      "w[2]   -1183.727\n",
      "w[3]    -375.531\n",
      "w[4]   -1900.479\n",
      "w[5]     149.327\n",
      "w[6]    2337.654\n",
      "w[7]    1337.796\n",
      "w[8]   -1500.073\n",
      "w[9]     981.307\n",
      "Name: mean, dtype: float64\n",
      "[[  254.47536914    89.99880589  -148.52183512    35.61421288\n",
      "   -137.74379778    73.78599754    21.2859864     49.00265226\n",
      "   -151.56674896    -5.44214285]\n",
      " [   89.99880589   627.05747822  -719.99260741   435.87488957\n",
      "   -495.39285897   529.8185861   -770.51909313    44.40969393\n",
      "   -504.40001378  -526.98600074]\n",
      " [ -148.52183512  -719.99260741  1017.18887636  -451.44281421\n",
      "    266.16181499  -680.65997435   837.17421589   620.58808767\n",
      "    998.36240545   258.86384951]\n",
      " [   35.61421288   435.87488957  -451.44281421   317.0414198\n",
      "   -413.95270235   351.01248128  -556.23101534   191.82244631\n",
      "   -243.37257011  -455.59452843]\n",
      " [ -137.74379778  -495.39285897   266.16181499  -413.95270235\n",
      "    958.75078947  -292.02919166   613.0537192  -1228.88015589\n",
      "   -282.51276847   976.93865879]\n",
      " [   73.78599754   529.8185861   -680.65997435   351.01248128\n",
      "   -292.02919166   477.04590709  -643.24996294  -234.55696178\n",
      "   -587.19757687  -312.82776626]\n",
      " [   21.2859864   -770.51909313   837.17421589  -556.23101534\n",
      "    613.0537192   -643.24996294  1022.68787097  -118.51858914\n",
      "    524.94560639   728.9644982 ]\n",
      " [   49.00265226    44.40969393   620.58808767   191.82244631\n",
      "  -1228.88015589  -234.55696178  -118.51858914  2558.65579538\n",
      "   1465.31155286 -1274.46719014]\n",
      " [ -151.56674896  -504.40001378   998.36240545  -243.37257011\n",
      "   -282.51276847  -587.19757687   524.94560639  1465.31155286\n",
      "   1333.22645693  -342.07065008]\n",
      " [   -5.44214285  -526.98600074   258.86384951  -455.59452843\n",
      "    976.93865879  -312.82776626   728.9644982  -1274.46719014\n",
      "   -342.07065008  1076.77397848]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:44<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1080 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5860.709\n",
      "w[1]     177.711\n",
      "w[2]   -1192.973\n",
      "w[3]    -372.955\n",
      "w[4]   -1899.904\n",
      "w[5]     154.798\n",
      "w[6]    2332.936\n",
      "w[7]    1327.342\n",
      "w[8]   -1511.521\n",
      "w[9]     983.128\n",
      "Name: mean, dtype: float64\n",
      "[[  255.69485642    94.02707282  -156.43454584    37.58860386\n",
      "   -135.79828538    78.4218572     17.12879672    37.72254161\n",
      "   -161.92848428    -2.99006042]\n",
      " [   94.02707282   627.9528014   -723.75403891   435.50403114\n",
      "   -493.75045323   531.39505513  -769.14231127    37.64452625\n",
      "   -510.81422279  -522.8241645 ]\n",
      " [ -156.43454584  -723.75403891  1023.56003839  -452.97672081\n",
      "    270.08354246  -684.13249931   837.52115409   621.51521515\n",
      "   1005.24975206   258.56629142]\n",
      " [   37.58860386   435.50403114  -452.97672081   316.1258775\n",
      "   -411.49076464   351.34423705  -554.41795685   186.20344485\n",
      "   -247.23880262  -451.69786224]\n",
      " [ -135.79828538  -493.75045323   270.08354246  -411.49076464\n",
      "    946.43092609  -293.06933405   611.19937227 -1205.51584403\n",
      "   -270.8404331    964.74332099]\n",
      " [   78.4218572    531.39505513  -684.13249931   351.34423705\n",
      "   -293.06933405   478.72645127  -642.57375795  -236.81602144\n",
      "   -591.74726073  -311.24424747]\n",
      " [   17.12879672  -769.14231127   837.52115409  -554.41795685\n",
      "    611.19937227  -642.57375795  1018.38515865  -114.91439771\n",
      "    527.75860667   724.27549884]\n",
      " [   37.72254161    37.64452625   621.51521515   186.20344485\n",
      "  -1205.51584403  -236.81602144  -114.91439771  2523.45246603\n",
      "   1454.65874091 -1255.64329788]\n",
      " [ -161.92848428  -510.81422279  1005.24975206  -247.23880262\n",
      "   -270.8404331   -591.74726073   527.75860667  1454.65874091\n",
      "   1336.40387772  -335.28038619]\n",
      " [   -2.99006042  -522.8241645    258.56629142  -451.69786224\n",
      "    964.74332099  -311.24424747   724.27549884 -1255.64329788\n",
      "   -335.28038619  1064.77506509]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:57<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1162 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5863.560\n",
      "w[1]     182.637\n",
      "w[2]   -1201.876\n",
      "w[3]    -370.433\n",
      "w[4]   -1899.537\n",
      "w[5]     160.083\n",
      "w[6]    2328.387\n",
      "w[7]    1317.567\n",
      "w[8]   -1522.454\n",
      "w[9]     984.745\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.56923653e+02  9.42339204e+01 -1.58487523e+02  3.71485952e+01\n",
      "  -1.33594190e+02  7.92100521e+01  1.78246392e+01  3.19223425e+01\n",
      "  -1.65997565e+02  8.06657564e-02]\n",
      " [ 9.42339204e+01  6.27262028e+02 -7.21864661e+02  4.35205506e+02\n",
      "  -4.95364638e+02  5.30407907e+02 -7.68180269e+02  4.21323220e+01\n",
      "  -5.07736192e+02 -5.24314546e+02]\n",
      " [-1.58487523e+02 -7.21864661e+02  1.02343294e+03 -4.50871152e+02\n",
      "   2.66434280e+02 -6.83212908e+02  8.33534311e+02  6.27343469e+02\n",
      "   1.00802055e+03  2.53287569e+02]\n",
      " [ 3.71485952e+01  4.35205506e+02 -4.50871152e+02  3.16337044e+02\n",
      "  -4.14131814e+02  3.50467717e+02 -5.54438184e+02  1.92596646e+02\n",
      "  -2.43078671e+02 -4.54697394e+02]\n",
      " [-1.33594190e+02 -4.95364638e+02  2.66434280e+02 -4.14131814e+02\n",
      "   9.56017515e+02 -2.92500628e+02  6.15167880e+02 -1.22459723e+03\n",
      "  -2.81636062e+02  9.76273530e+02]\n",
      " [ 7.92100521e+01  5.30407907e+02 -6.83212908e+02  3.50467717e+02\n",
      "  -2.92500628e+02  4.77939914e+02 -6.40741106e+02 -2.36821906e+02\n",
      "  -5.91296452e+02 -3.10065942e+02]\n",
      " [ 1.78246392e+01 -7.68180269e+02  8.33534311e+02 -5.54438184e+02\n",
      "   6.15167880e+02 -6.40741106e+02  1.01778876e+03 -1.25415649e+02\n",
      "   5.20568415e+02  7.28774103e+02]\n",
      " [ 3.19223425e+01  4.21323220e+01  6.27343469e+02  1.92596646e+02\n",
      "  -1.22459723e+03 -2.36821906e+02 -1.25415649e+02  2.56006166e+03\n",
      "   1.47493806e+03 -1.27959398e+03]\n",
      " [-1.65997565e+02 -5.07736192e+02  1.00802055e+03 -2.43078671e+02\n",
      "  -2.81636062e+02 -5.91296452e+02  5.20568415e+02  1.47493806e+03\n",
      "   1.34751760e+03 -3.49385437e+02]\n",
      " [ 8.06657564e-02 -5.24314546e+02  2.53287569e+02 -4.54697394e+02\n",
      "   9.76273530e+02 -3.10065942e+02  7.28774103e+02 -1.27959398e+03\n",
      "  -3.49385437e+02  1.07887391e+03]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 08:51<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1009 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5866.188\n",
      "w[1]     187.525\n",
      "w[2]   -1210.641\n",
      "w[3]    -367.914\n",
      "w[4]   -1899.147\n",
      "w[5]     165.312\n",
      "w[6]    2323.773\n",
      "w[7]    1307.900\n",
      "w[8]   -1533.189\n",
      "w[9]     986.260\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.54033151e+02  8.93840459e+01 -1.51177442e+02  3.43192108e+01\n",
      "  -1.31465470e+02  7.45709040e+01  2.24779719e+01  3.60781431e+01\n",
      "  -1.58336851e+02  1.06500575e+00]\n",
      " [ 8.93840459e+01  6.29514992e+02 -7.22675396e+02  4.37556671e+02\n",
      "  -4.97172617e+02  5.32057574e+02 -7.73987524e+02  4.44586686e+01\n",
      "  -5.05926345e+02 -5.29168609e+02]\n",
      " [-1.51177442e+02 -7.22675396e+02  1.01935916e+03 -4.53086373e+02\n",
      "   2.70981794e+02 -6.82515932e+02  8.39051516e+02  6.15608019e+02\n",
      "   9.98394730e+02  2.62355628e+02]\n",
      " [ 3.43192108e+01  4.37556671e+02 -4.53086373e+02  3.18323215e+02\n",
      "  -4.15049899e+02  3.52549681e+02 -5.59148657e+02  1.91980371e+02\n",
      "  -2.44010056e+02 -4.57460503e+02]\n",
      " [-1.31465470e+02 -4.97172617e+02  2.70981794e+02 -4.15049899e+02\n",
      "   9.52366667e+02 -2.95267377e+02  6.18551572e+02 -1.21434110e+03\n",
      "  -2.75172442e+02  9.73728068e+02]\n",
      " [ 7.45709040e+01  5.32057574e+02 -6.82515932e+02  3.52549681e+02\n",
      "  -2.95267377e+02  4.78710397e+02 -6.45693748e+02 -2.31464851e+02\n",
      "  -5.87319971e+02 -3.15775554e+02]\n",
      " [ 2.24779719e+01 -7.73987524e+02  8.39051516e+02 -5.59148657e+02\n",
      "   6.18551572e+02 -6.45693748e+02  1.02810729e+03 -1.25482555e+02\n",
      "   5.23009495e+02  7.35460635e+02]\n",
      " [ 3.60781431e+01  4.44586686e+01  6.15608019e+02  1.91980371e+02\n",
      "  -1.21434110e+03 -2.31464851e+02 -1.25482555e+02  2.53171995e+03\n",
      "   1.45453493e+03 -1.26646769e+03]\n",
      " [-1.58336851e+02 -5.05926345e+02  9.98394730e+02 -2.44010056e+02\n",
      "  -2.75172442e+02 -5.87319971e+02  5.23009495e+02  1.45453493e+03\n",
      "   1.33055767e+03 -3.38266190e+02]\n",
      " [ 1.06500575e+00 -5.29168609e+02  2.62355628e+02 -4.57460503e+02\n",
      "   9.73728068e+02 -3.15775554e+02  7.35460635e+02 -1.26646769e+03\n",
      "  -3.38266190e+02  1.07706455e+03]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 08:27<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 948 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5868.966\n",
      "w[1]     192.836\n",
      "w[2]   -1219.682\n",
      "w[3]    -365.054\n",
      "w[4]   -1899.497\n",
      "w[5]     170.809\n",
      "w[6]    2318.663\n",
      "w[7]    1299.121\n",
      "w[8]   -1543.795\n",
      "w[9]     987.032\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.49923013e+02  9.02376551e+01 -1.51827483e+02  3.53353821e+01\n",
      "  -1.30318394e+02  7.54969722e+01  1.90853426e+01  3.39377115e+01\n",
      "  -1.58495344e+02 -2.21210453e-01]\n",
      " [ 9.02376551e+01  6.37527979e+02 -7.30709637e+02  4.43478678e+02\n",
      "  -5.05597979e+02  5.38363578e+02 -7.84175061e+02  4.94511092e+01\n",
      "  -5.09583282e+02 -5.38233204e+02]\n",
      " [-1.51827483e+02 -7.30709637e+02  1.02945601e+03 -4.58550012e+02\n",
      "   2.75847590e+02 -6.89652862e+02  8.49180388e+02  6.18167042e+02\n",
      "   1.00646980e+03  2.67799849e+02]\n",
      " [ 3.53353821e+01  4.43478678e+02 -4.58550012e+02  3.22776694e+02\n",
      "  -4.22283095e+02  3.56995834e+02 -5.66510750e+02  1.97674611e+02\n",
      "  -2.45685489e+02 -4.64994038e+02]\n",
      " [-1.30318394e+02 -5.05597979e+02  2.75847590e+02 -4.22283095e+02\n",
      "   9.66086386e+02 -3.00659627e+02  6.30708401e+02 -1.23082138e+03\n",
      "  -2.78893800e+02  9.89580107e+02]\n",
      " [ 7.54969722e+01  5.38363578e+02 -6.89652862e+02  3.56995834e+02\n",
      "  -3.00659627e+02  4.83966908e+02 -6.53494156e+02 -2.30275244e+02\n",
      "  -5.91934095e+02 -3.21462146e+02]\n",
      " [ 1.90853426e+01 -7.84175061e+02  8.49180388e+02 -5.66510750e+02\n",
      "   6.30708401e+02 -6.53494156e+02  1.03979798e+03 -1.33995485e+02\n",
      "   5.27366116e+02  7.47153170e+02]\n",
      " [ 3.39377115e+01  4.94511092e+01  6.18167042e+02  1.97674611e+02\n",
      "  -1.23082138e+03 -2.30275244e+02 -1.33995485e+02  2.55990131e+03\n",
      "   1.46833534e+03 -1.28549621e+03]\n",
      " [-1.58495344e+02 -5.09583282e+02  1.00646980e+03 -2.45685489e+02\n",
      "  -2.78893800e+02 -5.91934095e+02  5.27366116e+02  1.46833534e+03\n",
      "   1.34168737e+03 -3.41953835e+02]\n",
      " [-2.21210453e-01 -5.38233204e+02  2.67799849e+02 -4.64994038e+02\n",
      "   9.89580107e+02 -3.21462146e+02  7.47153170e+02 -1.28549621e+03\n",
      "  -3.41953835e+02  1.09377821e+03]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 08:50<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 981 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5871.266\n",
      "w[1]     197.321\n",
      "w[2]   -1227.961\n",
      "w[3]    -362.786\n",
      "w[4]   -1898.677\n",
      "w[5]     175.710\n",
      "w[6]    2314.397\n",
      "w[7]    1289.299\n",
      "w[8]   -1554.167\n",
      "w[9]     988.853\n",
      "Name: mean, dtype: float64\n",
      "[[  247.64083768    85.84691231  -146.45915863    32.39199726\n",
      "   -126.21363989    71.81357178    23.65128457    32.99182664\n",
      "   -154.54044279     3.14823969]\n",
      " [   85.84691231   625.93568431  -716.24618832   435.88961523\n",
      "   -496.48696034   528.36192894  -771.41933501    49.94228159\n",
      "   -498.2361861   -530.23343813]\n",
      " [ -146.45915863  -716.24618832  1017.84636932  -447.47823944\n",
      "    253.30454183  -679.77033402   832.37365675   641.61636676\n",
      "   1006.56881882   245.91853653]\n",
      " [   32.39199726   435.88961523  -447.47823944   318.20574318\n",
      "   -419.06018583   349.8002683   -558.38621966   203.92403437\n",
      "   -234.72523538  -462.69637235]\n",
      " [ -126.21363989  -496.48696034   253.30454183  -419.06018583\n",
      "    977.92323441  -288.32619406   622.39878834 -1272.34554376\n",
      "   -312.43288538  1003.77861769]\n",
      " [   71.81357178   528.36192894  -679.77033402   349.8002683\n",
      "   -288.32619406   476.37380309  -642.09489248  -239.49857223\n",
      "   -587.89265143  -309.76433396]\n",
      " [   23.65128457  -771.41933501   832.37365675  -558.38621966\n",
      "    622.39878834  -642.09489248  1025.71649646  -138.11959657\n",
      "    512.8997507    740.00496809]\n",
      " [   32.99182664    49.94228159   641.61636676   203.92403437\n",
      "  -1272.34554376  -239.49857223  -138.11959657  2648.83058115\n",
      "   1520.93473646 -1330.03916926]\n",
      " [ -154.54044279  -498.2361861   1006.56881882  -234.72523538\n",
      "   -312.43288538  -587.89265143   512.8997507   1520.93473646\n",
      "   1362.07773548  -376.0511586 ]\n",
      " [    3.14823969  -530.23343813   245.91853653  -462.69637235\n",
      "   1003.77861769  -309.76433396   740.00496809 -1330.03916926\n",
      "   -376.0511586   1110.13643609]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:25<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1018 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5873.790\n",
      "w[1]     201.706\n",
      "w[2]   -1235.961\n",
      "w[3]    -360.566\n",
      "w[4]   -1898.199\n",
      "w[5]     180.439\n",
      "w[6]    2310.360\n",
      "w[7]    1280.296\n",
      "w[8]   -1564.067\n",
      "w[9]     990.437\n",
      "Name: mean, dtype: float64\n",
      "[[  252.93066777    84.80674253  -151.84944293    29.72225092\n",
      "   -117.28385668    73.18714622    28.54617963    13.15876797\n",
      "   -167.81545543    15.82338855]\n",
      " [   84.80674253   634.53265203  -725.71039919   442.14803738\n",
      "   -502.52259904   535.63904602  -783.21794987    49.94767108\n",
      "   -504.4794812   -537.84346508]\n",
      " [ -151.84944293  -725.71039919  1034.44020769  -452.42909943\n",
      "    253.12891179  -689.69129205   841.11395979   658.90359608\n",
      "   1026.58978789   243.31956862]\n",
      " [   29.72225092   442.14803738  -452.42909943   323.35575951\n",
      "   -425.66911671   354.47970817  -568.22973627   209.47483935\n",
      "   -235.13888472  -471.68643599]\n",
      " [ -117.28385668  -502.52259904   253.12891179  -425.66911671\n",
      "    989.12574225  -291.45616647   635.9542522  -1290.56754422\n",
      "   -322.48340973  1021.14386827]\n",
      " [   73.18714622   535.63904602  -689.69129205   354.47970817\n",
      "   -291.45616647   483.08959899  -650.63961457  -244.64690409\n",
      "   -597.22993496  -312.81935447]\n",
      " [   28.54617963  -783.21794987   841.11395979  -568.22973627\n",
      "    635.9542522   -650.63961457  1044.22940529  -150.93162666\n",
      "    512.35569052   758.06955826]\n",
      " [   13.15876797    49.94767108   658.90359608   209.47483935\n",
      "  -1290.56754422  -244.64690409  -150.93162666  2695.87578472\n",
      "   1557.61076916 -1360.62229099]\n",
      " [ -167.81545543  -504.4794812   1026.58978789  -235.13888472\n",
      "   -322.48340973  -597.22993496   512.35569052  1557.61076916\n",
      "   1394.56909726  -393.8578765 ]\n",
      " [   15.82338855  -537.84346508   243.31956862  -471.68643599\n",
      "   1021.14386827  -312.81935447   758.06955826 -1360.62229099\n",
      "   -393.8578765   1136.3347094 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 08:12<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 934 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5876.066\n",
      "w[1]     206.181\n",
      "w[2]   -1244.201\n",
      "w[3]    -358.301\n",
      "w[4]   -1897.383\n",
      "w[5]     185.323\n",
      "w[6]    2306.097\n",
      "w[7]    1270.524\n",
      "w[8]   -1574.386\n",
      "w[9]     992.226\n",
      "Name: mean, dtype: float64\n",
      "[[  257.74100531    86.10515065  -152.22967134    30.58988844\n",
      "   -123.04088968    73.45324386    29.24449717    21.41621942\n",
      "   -166.05307842    12.35841607]\n",
      " [   86.10515065   636.15400524  -730.27192216   442.61514633\n",
      "   -499.78173055   538.01520519  -784.43479341    41.0077801\n",
      "   -511.62658797  -534.41012437]\n",
      " [ -152.22967134  -730.27192216  1044.2290173   -454.60608606\n",
      "    248.72697339  -695.37405622   846.43418637   675.55245417\n",
      "   1040.23592068   238.99747039]\n",
      " [   30.58988844   442.61514633  -454.60608606   323.26229938\n",
      "   -423.65477986   355.4820501   -568.25639725   204.06702908\n",
      "   -239.08472208  -469.12472348]\n",
      " [ -123.04088968  -499.78173055   248.72697339  -423.65477986\n",
      "    992.73928653  -288.18945097   629.57135584 -1300.09359201\n",
      "   -327.80553214  1021.35304533]\n",
      " [   73.45324386   538.01520519  -695.37405622   355.4820501\n",
      "   -288.18945097   486.28147873  -653.33205858  -255.42655123\n",
      "   -605.61151816  -309.50899998]\n",
      " [   29.24449717  -784.43479341   846.43418637  -568.25639725\n",
      "    629.57135584  -653.33205858  1045.84186047  -135.67886726\n",
      "    522.04342207   751.89114574]\n",
      " [   21.41621942    41.0077801    675.55245417   204.06702908\n",
      "  -1300.09359201  -255.42655123  -135.67886726  2726.56707825\n",
      "   1579.30903569 -1364.89716455]\n",
      " [ -166.05307842  -511.62658797  1040.23592068  -239.08472208\n",
      "   -327.80553214  -605.61151816   522.04342207  1579.30903569\n",
      "   1412.3358744   -397.62321409]\n",
      " [   12.35841607  -534.41012437   238.99747039  -469.12472348\n",
      "   1021.35304533  -309.50899998   751.89114574 -1364.89716455\n",
      "   -397.62321409  1134.16763705]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:10<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 990 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5878.258\n",
      "w[1]     210.101\n",
      "w[2]   -1251.573\n",
      "w[3]    -356.361\n",
      "w[4]   -1896.553\n",
      "w[5]     189.644\n",
      "w[6]    2302.480\n",
      "w[7]    1261.617\n",
      "w[8]   -1583.722\n",
      "w[9]     994.040\n",
      "Name: mean, dtype: float64\n",
      "[[  255.02256715    80.03507065  -144.64530673    26.63852314\n",
      "   -118.27838035    68.25790793    35.71293911    21.88291927\n",
      "   -159.87685843    16.39690032]\n",
      " [   80.03507065   638.05086762  -734.2009932    443.88868267\n",
      "   -494.20072318   540.91581381  -789.68165863    28.54917556\n",
      "   -517.80822637  -532.2453041 ]\n",
      " [ -144.64530673  -734.2009932   1051.42284228  -457.16869894\n",
      "    241.91636672  -700.53018426   855.02633451   693.19775333\n",
      "   1050.44406353   236.61832577]\n",
      " [   26.63852314   443.88868267  -457.16869894   324.12418235\n",
      "   -420.1124228    357.38512368  -571.70044017   196.08503088\n",
      "   -243.0461842   -467.81136184]\n",
      " [ -118.27838035  -494.20072318   241.91636672  -420.1124228\n",
      "    986.67482723  -283.68836009   624.56845487 -1297.80408692\n",
      "   -332.96093726  1017.17305708]\n",
      " [   68.25790793   540.91581381  -700.53018426   357.38512368\n",
      "   -283.68836009   489.98470298  -659.468935    -267.49612082\n",
      "   -612.74162967  -308.07416524]\n",
      " [   35.71293911  -789.68165863   855.02633451  -571.70044017\n",
      "    624.56845487  -659.468935    1055.50801124  -119.34727792\n",
      "    532.92488715   750.89761013]\n",
      " [   21.88291927    28.54917556   693.19775333   196.08503088\n",
      "  -1297.80408692  -267.49612082  -119.34727792  2740.98462751\n",
      "   1597.49417564 -1360.95611057]\n",
      " [ -159.87685843  -517.80822637  1050.44406353  -243.0461842\n",
      "   -332.96093726  -612.74162967   532.92488715  1597.49417564\n",
      "   1425.30229191  -398.8461998 ]\n",
      " [   16.39690032  -532.2453041    236.61832577  -467.81136184\n",
      "   1017.17305708  -308.07416524   750.89761013 -1360.95611057\n",
      "   -398.8461998   1131.88364013]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 10:02<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1029 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5880.494\n",
      "w[1]     213.701\n",
      "w[2]   -1258.544\n",
      "w[3]    -354.635\n",
      "w[4]   -1895.577\n",
      "w[5]     193.678\n",
      "w[6]    2299.297\n",
      "w[7]    1252.876\n",
      "w[8]   -1592.728\n",
      "w[9]     996.054\n",
      "Name: mean, dtype: float64\n",
      "[[  255.13798589    77.9433659   -141.86839628    25.21078403\n",
      "   -117.42860822    66.28184004    38.51364282    23.39779235\n",
      "   -157.41091722    17.55599933]\n",
      " [   77.9433659    633.87925055  -727.29825251   441.67639492\n",
      "   -493.70076896   536.63461257  -785.54510491    34.84934311\n",
      "   -509.8513267   -532.56227067]\n",
      " [ -141.86839628  -727.29825251  1044.23670866  -452.37999202\n",
      "    234.10569599  -695.11347365   847.33038567   698.0667421\n",
      "   1046.73416199   229.26265931]\n",
      " [   25.21078403   441.67639492  -452.37999202   323.26202263\n",
      "   -421.62079139   354.68364937  -569.79798518   203.3637949\n",
      "   -236.32354593  -470.06306309]\n",
      " [ -117.42860822  -493.70076896   234.10569599  -421.62079139\n",
      "    998.33284259  -280.38337593   625.15125862 -1324.09268498\n",
      "   -349.45665869  1030.1171122 ]\n",
      " [   66.28184004   536.63461257  -695.11347365   354.68364937\n",
      "   -280.38337593   486.25468308  -654.94378216  -267.11874426\n",
      "   -608.29313047  -305.30897719]\n",
      " [   38.51364282  -785.54510491   847.33038567  -569.79798518\n",
      "    625.15125862  -654.94378216  1051.88371417  -128.15773788\n",
      "    523.15735238   752.78865204]\n",
      " [   23.39779235    34.84934311   698.0667421    203.3637949\n",
      "  -1324.09268498  -267.11874426  -128.15773788  2787.18051319\n",
      "   1619.54340518 -1388.80353597]\n",
      " [ -157.41091722  -509.8513267   1046.73416199  -236.32354593\n",
      "   -349.45665869  -608.29313047   523.15735238  1619.54340518\n",
      "   1431.19138981  -415.78388429]\n",
      " [   17.55599933  -532.56227067   229.26265931  -470.06306309\n",
      "   1030.1171122   -305.30897719   752.78865204 -1388.80353597\n",
      "   -415.78388429  1146.45146154]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 10:34<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1105 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5882.490\n",
      "w[1]     216.700\n",
      "w[2]   -1264.943\n",
      "w[3]    -353.349\n",
      "w[4]   -1893.820\n",
      "w[5]     197.263\n",
      "w[6]    2296.789\n",
      "w[7]    1243.504\n",
      "w[8]   -1601.537\n",
      "w[9]     998.813\n",
      "Name: mean, dtype: float64\n",
      "[[  260.64158252    78.25892499  -142.70886929    24.92125416\n",
      "   -120.12843467    66.24048645    41.06146143    26.38081861\n",
      "   -158.1521105     17.89402247]\n",
      " [   78.25892499   649.76568702  -746.22265762   452.63128096\n",
      "   -503.87602159   550.47584209  -805.95798398    31.70864733\n",
      "   -524.38606713  -544.57749191]\n",
      " [ -142.70886929  -746.22265762  1070.46835893  -464.46104177\n",
      "    239.95304371  -713.00462087   870.77633585   715.36284592\n",
      "   1072.27271884   236.66899641]\n",
      " [   24.92125416   452.63128096  -464.46104177   331.09285869\n",
      "   -430.04600031   363.89391202  -584.30347255   204.41226893\n",
      "   -244.22948767  -480.13667042]\n",
      " [ -120.12843467  -503.87602159   239.95304371  -430.04600031\n",
      "   1017.48971556  -286.56526121   637.98700814 -1347.9790079\n",
      "   -354.47346075  1049.72304669]\n",
      " [   66.24048645   550.47584209  -713.00462087   363.89391202\n",
      "   -286.56526121   498.89091965  -672.65110584  -275.43905435\n",
      "   -624.13233703  -313.12523173]\n",
      " [   41.06146143  -805.95798398   870.77633585  -584.30347255\n",
      "    637.98700814  -672.65110584  1079.79173595  -124.83882983\n",
      "    540.19070599   769.69961167]\n",
      " [   26.38081861    31.70864733   715.36284592   204.41226893\n",
      "  -1347.9790079   -275.43905435  -124.83882983  2841.70390109\n",
      "   1653.11304948 -1412.03696418]\n",
      " [ -158.1521105   -524.38606713  1072.27271884  -244.22948767\n",
      "   -354.47346075  -624.13233703   540.19070599  1653.11304948\n",
      "   1462.86009571  -420.20755539]\n",
      " [   17.89402247  -544.57749191   236.66899641  -480.13667042\n",
      "   1049.72304669  -313.12523173   769.69961167 -1412.03696418\n",
      "   -420.20755539  1168.47431174]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 08:36<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 952 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5884.243\n",
      "w[1]     220.691\n",
      "w[2]   -1272.477\n",
      "w[3]    -351.351\n",
      "w[4]   -1892.627\n",
      "w[5]     201.714\n",
      "w[6]    2292.859\n",
      "w[7]    1233.892\n",
      "w[8]   -1611.165\n",
      "w[9]    1000.749\n",
      "Name: mean, dtype: float64\n",
      "[[  264.41335989    79.58360095  -143.81221169    25.7443212\n",
      "   -124.16584131    66.91767889    41.15530111    31.37104766\n",
      "   -157.9248087     15.74741247]\n",
      " [   79.58360095   653.40813396  -754.89582412   454.00443773\n",
      "   -499.38823781   555.29564713  -809.35749067    15.70415577\n",
      "   -537.51755514  -539.38838972]\n",
      " [ -143.81221169  -754.89582412  1084.36732435  -469.50441264\n",
      "    239.7666834   -721.93417891   880.90226544   729.85745742\n",
      "   1088.38117855   236.59981893]\n",
      " [   25.7443212    454.00443773  -469.50441264   331.149444\n",
      "   -425.44659837   366.39511006  -585.15260438   191.95586337\n",
      "   -253.19138325  -474.92558956]\n",
      " [ -124.16584131  -499.38823781   239.7666834   -425.44659837\n",
      "   1008.23548404  -284.39494162   629.37951584 -1333.25582633\n",
      "   -347.32007553  1037.17878424]\n",
      " [   66.91767889   555.29564713  -721.93417891   366.39511006\n",
      "   -284.39494162   504.32905971  -678.06724579  -287.99391259\n",
      "   -635.8180844   -310.86806592]\n",
      " [   41.15530111  -809.35749067   880.90226544  -585.15260438\n",
      "    629.37951584  -678.06724579  1083.31196784  -100.94990261\n",
      "    557.2244191    760.98746032]\n",
      " [   31.37104766    15.70415577   729.85745742   191.95586337\n",
      "  -1333.25582633  -287.99391259  -100.94990261  2832.76943729\n",
      "   1658.14090497 -1392.11643608]\n",
      " [ -157.9248087   -537.51755514  1088.38117855  -253.19138325\n",
      "   -347.32007553  -635.8180844    557.2244191   1658.14090497\n",
      "   1476.18939875  -411.34837089]\n",
      " [   15.74741247  -539.38838972   236.59981893  -474.92558956\n",
      "   1037.17878424  -310.86806592   760.98746032 -1392.11643608\n",
      "   -411.34837089  1153.5097852 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:37<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1072 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5886.075\n",
      "w[1]     224.157\n",
      "w[2]   -1279.249\n",
      "w[3]    -349.691\n",
      "w[4]   -1891.370\n",
      "w[5]     205.648\n",
      "w[6]    2289.635\n",
      "w[7]    1224.951\n",
      "w[8]   -1620.008\n",
      "w[9]    1002.836\n",
      "Name: mean, dtype: float64\n",
      "[[  269.65818186    75.29363275  -139.63124969    22.14014094\n",
      "   -122.93540677    63.06070469    49.68542705    33.27927211\n",
      "   -155.57793637    20.46616015]\n",
      " [   75.29363275   644.78092187  -743.74794593   448.54658385\n",
      "   -492.80650918   547.72905669  -800.45909883    16.89576113\n",
      "   -528.10902727  -534.24866272]\n",
      " [ -139.63124969  -743.74794593  1072.71996668  -461.61184207\n",
      "    227.29456498  -713.09077947   868.24319631   737.51875321\n",
      "   1082.23460994   224.92905093]\n",
      " [   22.14014094   448.54658385  -461.61184207   327.97816061\n",
      "   -422.1976743    361.35992373  -580.12199266   195.07914185\n",
      "   -245.46037078  -473.17224853]\n",
      " [ -122.93540677  -492.80650918   227.29456498  -422.1976743\n",
      "   1011.25839224  -276.94522187   622.14212245 -1350.83133195\n",
      "   -363.48810617  1040.63335821]\n",
      " [   63.06070469   547.72905669  -713.09077947   361.35992373\n",
      "   -276.94522187   498.05400001  -670.15942863  -290.55340543\n",
      "   -629.65801796  -304.62746277]\n",
      " [   49.68542705  -800.45909883   868.24319631  -580.12199266\n",
      "    622.14212245  -670.15942863  1076.46732271  -102.9526648\n",
      "    545.32995806   757.62282149]\n",
      " [   33.27927211    16.89576113   737.51875321   195.07914185\n",
      "  -1350.83133195  -290.55340543  -102.9526648   2868.31168319\n",
      "   1677.3854746  -1409.80951172]\n",
      " [ -155.57793637  -528.10902727  1082.23460994  -245.46037078\n",
      "   -363.48810617  -629.65801796   545.32995806  1677.3854746\n",
      "   1479.05284942  -427.90701925]\n",
      " [   20.46616015  -534.24866272   224.92905093  -473.17224853\n",
      "   1040.63335821  -304.62746277   757.62282149 -1409.80951172\n",
      "   -427.90701925  1159.5808248 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 07:16<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 833 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5887.809\n",
      "w[1]     227.430\n",
      "w[2]   -1285.819\n",
      "w[3]    -348.168\n",
      "w[4]   -1889.896\n",
      "w[5]     209.428\n",
      "w[6]    2286.613\n",
      "w[7]    1215.884\n",
      "w[8]   -1628.731\n",
      "w[9]    1005.117\n",
      "Name: mean, dtype: float64\n",
      "[[  266.83160451    75.92258233  -140.53497205    22.67109918\n",
      "   -121.24100134    63.89215797    47.49187739    30.00652767\n",
      "   -156.80073722    20.5133896 ]\n",
      " [   75.92258233   646.5823186   -748.30050311   449.26441788\n",
      "   -490.40335829   550.15238162  -802.16739136     8.6968288\n",
      "   -534.81059602  -531.52983197]\n",
      " [ -140.53497205  -748.30050311  1085.20893167  -463.05787712\n",
      "    218.52411055  -719.78379668   872.75885781   763.802473\n",
      "   1101.90749498   215.56555419]\n",
      " [   22.67109918   449.26441788  -463.05787712   328.37397297\n",
      "   -422.17547541   362.13030012  -580.71590813   193.71555386\n",
      "   -247.18001165  -472.92392322]\n",
      " [ -121.24100134  -490.40335829   218.52411055  -422.17547541\n",
      "   1019.4178926   -272.51876892   620.65152122 -1372.97521698\n",
      "   -379.03860803  1050.09331565]\n",
      " [   63.89215797   550.15238162  -719.78379668   362.13030012\n",
      "   -272.51876892   501.58312441  -672.38931405  -304.17304855\n",
      "   -640.10700904  -299.69949897]\n",
      " [   47.49187739  -802.16739136   872.75885781  -580.71590813\n",
      "    620.65152122  -672.38931405  1077.26689842   -96.13948276\n",
      "    551.86824918   754.9387236 ]\n",
      " [   30.00652767     8.6968288    763.802473     193.71555386\n",
      "  -1372.97521698  -304.17304855   -96.13948276  2930.21426419\n",
      "   1721.77079599 -1434.45498851]\n",
      " [ -156.80073722  -534.81059602  1101.90749498  -247.18001165\n",
      "   -379.03860803  -640.10700904   551.86824918  1721.77079599\n",
      "   1511.16715222  -444.45474297]\n",
      " [   20.5133896   -531.52983197   215.56555419  -472.92392322\n",
      "   1050.09331565  -299.69949897   754.9387236  -1434.45498851\n",
      "   -444.45474297  1169.40014939]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 06:42<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 742 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5889.425\n",
      "w[1]     231.346\n",
      "w[2]   -1293.277\n",
      "w[3]    -346.218\n",
      "w[4]   -1888.535\n",
      "w[5]     213.835\n",
      "w[6]    2282.721\n",
      "w[7]    1206.086\n",
      "w[8]   -1638.341\n",
      "w[9]    1007.154\n",
      "Name: mean, dtype: float64\n",
      "[[  269.36617706    72.66616211  -134.07634683    20.83847585\n",
      "   -125.16963582    59.71288754    52.72845704    42.50101937\n",
      "   -147.91069524    18.14584325]\n",
      " [   72.66616211   660.52618178  -759.32485222   460.49076606\n",
      "   -506.90308756   560.4198361   -822.55075161    23.69714214\n",
      "   -535.3323476   -552.01783616]\n",
      " [ -134.07634683  -759.32485222  1096.17842912  -471.63905181\n",
      "    225.42125325  -729.1234977    890.52220342   763.74483477\n",
      "   1107.59038243   227.48443782]\n",
      " [   20.83847585   460.49076606  -471.63905181   337.42906271\n",
      "   -436.41728539   370.21860317  -596.77337325   207.57189962\n",
      "   -246.89913826  -489.98316693]\n",
      " [ -125.16963582  -506.90308756   225.42125325  -436.41728539\n",
      "   1054.07292931  -281.51786409   641.62768102 -1420.38517043\n",
      "   -392.59027938  1085.85735417]\n",
      " [   59.71288754   560.4198361   -729.1234977    370.21860317\n",
      "   -281.51786409   509.78346994  -688.1341607   -299.23547629\n",
      "   -643.32866424  -312.48001986]\n",
      " [   52.72845704  -822.55075161   890.52220342  -596.77337325\n",
      "    641.62768102  -688.1341607   1107.13366409  -111.52728002\n",
      "    556.33229187   781.86917672]\n",
      " [   42.50101937    23.69714214   763.74483477   207.57189962\n",
      "  -1420.38517043  -299.23547629  -111.52728002  3004.22461456\n",
      "   1748.47115089 -1478.67081807]\n",
      " [ -147.91069524  -535.3323476   1107.59038243  -246.89913826\n",
      "   -392.59027938  -643.32866424   556.33229187  1748.47115089\n",
      "   1523.45890592  -453.65694192]\n",
      " [   18.14584325  -552.01783616   227.48443782  -489.98316693\n",
      "   1085.85735417  -312.48001986   781.86917672 -1478.67081807\n",
      "   -453.65694192  1207.60296498]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 08:43<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1197 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5891.015\n",
      "w[1]     235.080\n",
      "w[2]   -1300.272\n",
      "w[3]    -344.335\n",
      "w[4]   -1887.484\n",
      "w[5]     217.982\n",
      "w[6]    2279.016\n",
      "w[7]    1197.251\n",
      "w[8]   -1647.228\n",
      "w[9]    1008.866\n",
      "Name: mean, dtype: float64\n",
      "[[  260.30501077    74.86771761  -135.63359621    23.23190472\n",
      "   -122.80881956    62.03641813    44.99408403    37.87789569\n",
      "   -148.50581452    15.16187493]\n",
      " [   74.86771761   653.89468944  -752.66188671   455.23474493\n",
      "   -501.45607057   554.8021737   -812.30107282    21.85772212\n",
      "   -532.0824592   -544.40031763]\n",
      " [ -135.63359621  -752.66188671  1093.76630554  -465.27382772\n",
      "    211.8970126   -725.24839546   879.9106603    782.56963851\n",
      "   1114.03801713   211.71554704]\n",
      " [   23.23190472   455.23474493  -465.27382772   333.50955879\n",
      "   -434.44928425   365.27997637  -588.48948088   210.85810256\n",
      "   -241.8085393   -486.04333089]\n",
      " [ -122.80881956  -501.45607057   211.8970126   -434.44928425\n",
      "   1061.27636531  -274.05756745   636.55492145 -1445.75825165\n",
      "   -412.87533917  1094.35601008]\n",
      " [   62.03641813   554.8021737   -725.24839546   365.27997637\n",
      "   -274.05756745   505.69519622  -678.95762347  -307.11258212\n",
      "   -644.49549106  -302.75633194]\n",
      " [   44.99408403  -812.30107282   879.9106603   -588.48948088\n",
      "    636.55492145  -678.95762347  1089.15152633  -113.9219419\n",
      "    550.08130325   771.10243082]\n",
      " [   37.87789569    21.85772212   782.56963851   210.85810256\n",
      "  -1445.75825165  -307.11258212  -113.9219419   3063.67770721\n",
      "   1786.92644044 -1507.97503847]\n",
      " [ -148.50581452  -532.0824592   1114.03801713  -241.8085393\n",
      "   -412.87533917  -644.49549106   550.08130325  1786.92644044\n",
      "   1543.76970489  -475.69820411]\n",
      " [   15.16187493  -544.40031763   211.71554704  -486.04333089\n",
      "   1094.35601008  -302.75633194   771.10243082 -1507.97503847\n",
      "   -475.69820411  1214.15331771]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:51<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1070 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5892.650\n",
      "w[1]     238.305\n",
      "w[2]   -1306.549\n",
      "w[3]    -342.785\n",
      "w[4]   -1886.310\n",
      "w[5]     221.635\n",
      "w[6]    2275.988\n",
      "w[7]    1188.949\n",
      "w[8]   -1655.415\n",
      "w[9]    1010.770\n",
      "Name: mean, dtype: float64\n",
      "[[  266.18416496    70.83487497  -128.65079972    20.56907718\n",
      "   -127.78908108    57.13820484    52.88513303    52.25173152\n",
      "   -139.29425121    13.68112217]\n",
      " [   70.83487497   661.94478272  -762.5114507    461.14702118\n",
      "   -503.94612789   562.32000033  -824.95606761    15.85251105\n",
      "   -540.36049618  -549.95589833]\n",
      " [ -128.65079972  -762.5114507   1108.4334322   -472.03066095\n",
      "    209.17793174  -735.66176665   896.13696246   801.65207647\n",
      "   1130.19268874   213.59479726]\n",
      " [   20.56907718   461.14702118  -472.03066095   337.9333847\n",
      "   -437.2510076    370.58229811  -597.66544934   208.49824461\n",
      "   -246.80884546  -490.989278  ]\n",
      " [ -127.78908108  -503.94612789   209.17793174  -437.2510076\n",
      "   1075.97707373  -273.55459168   638.04194772 -1471.36314864\n",
      "   -423.83683786  1107.15434915]\n",
      " [   57.13820484   562.32000033  -735.66176665   370.58229811\n",
      "   -273.55459168   513.29184234  -691.18832938  -318.36236931\n",
      "   -655.06289871  -305.6165803 ]\n",
      " [   52.88513303  -824.95606761   896.13696246  -597.66544934\n",
      "    638.04194772  -691.18832938  1109.63251521  -100.17099633\n",
      "    564.97585282   778.21819578]\n",
      " [   52.25173152    15.85251105   801.65207647   208.49824461\n",
      "  -1471.36314864  -318.36236931  -100.17099633  3122.83497851\n",
      "   1820.45195368 -1526.22346077]\n",
      " [ -139.29425121  -540.36049618  1130.19268874  -246.80884546\n",
      "   -423.83683786  -655.06289871   564.97585282  1820.45195368\n",
      "   1566.20761899  -481.34758059]\n",
      " [   13.68112217  -549.95589833   213.59479726  -490.989278\n",
      "   1107.15434915  -305.6165803    778.21819578 -1526.22346077\n",
      "   -481.34758059  1227.2357021 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:37<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 984 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5893.915\n",
      "w[1]     241.225\n",
      "w[2]   -1312.327\n",
      "w[3]    -341.386\n",
      "w[4]   -1884.972\n",
      "w[5]     224.993\n",
      "w[6]    2273.147\n",
      "w[7]    1180.923\n",
      "w[8]   -1663.035\n",
      "w[9]    1012.664\n",
      "Name: mean, dtype: float64\n",
      "[[  267.42518369    69.0192641   -127.35145119    18.98922998\n",
      "   -125.763044      55.79809057    56.14242858    50.30323131\n",
      "   -139.55488711    16.68545288]\n",
      " [   69.0192641    643.94840911  -739.23454283   449.19777853\n",
      "   -494.62496052   546.08194001  -802.82927435    24.90969805\n",
      "   -520.13369605  -539.61577707]\n",
      " [ -127.35145119  -739.23454283  1077.76781044  -456.68795785\n",
      "    198.69995058  -714.27871664   867.05277215   786.76859505\n",
      "   1102.70988045   201.37610197]\n",
      " [   18.98922998   449.19777853  -456.68795785   329.97893862\n",
      "   -430.63781635   359.89308263  -583.15521046   213.71021071\n",
      "   -233.66323253  -483.87029928]\n",
      " [ -125.763044    -494.62496052   198.69995058  -430.63781635\n",
      "   1067.65480597  -265.98654419   626.82240242 -1468.69181112\n",
      "   -430.6195928   1098.59235175]\n",
      " [   55.79809057   546.08194001  -714.27871664   359.89308263\n",
      "   -265.98654419   498.43758604  -671.13564691  -308.42464834\n",
      "   -635.93716127  -297.04315917]\n",
      " [   56.14242858  -802.82927435   867.05277215  -583.15521046\n",
      "    626.82240242  -671.13564691  1083.08191276  -112.19215026\n",
      "    539.12437653   766.3368252 ]\n",
      " [   50.30323131    24.90969805   786.76859505   213.71021071\n",
      "  -1468.69181112  -308.42464834  -112.19215026  3102.9403905\n",
      "   1802.83374676 -1524.97395346]\n",
      " [ -139.55488711  -520.13369605  1102.70988045  -233.66323253\n",
      "   -430.6195928   -635.93716127   539.12437653  1802.83374676\n",
      "   1540.30297994  -490.19554956]\n",
      " [   16.68545288  -539.61577707   201.37610197  -483.87029928\n",
      "   1098.59235175  -297.04315917   766.3368252  -1524.97395346\n",
      "   -490.19554956  1218.87671468]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:42<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1042 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5895.117\n",
      "w[1]     244.015\n",
      "w[2]   -1317.829\n",
      "w[3]    -340.043\n",
      "w[4]   -1883.722\n",
      "w[5]     228.199\n",
      "w[6]    2270.421\n",
      "w[7]    1173.314\n",
      "w[8]   -1670.287\n",
      "w[9]    1014.440\n",
      "Name: mean, dtype: float64\n",
      "[[  264.24157612    68.44631264  -123.70919724    19.53520692\n",
      "   -128.64995589    54.41196862    54.89452865    58.63421841\n",
      "   -132.71577662    11.97929527]\n",
      " [   68.44631264   658.68774344  -756.70482442   459.41722971\n",
      "   -503.52130031   558.98310065  -822.33475698    21.06214208\n",
      "   -533.61298795  -550.69182695]\n",
      " [ -123.70919724  -756.70482442  1100.68133164  -468.48152107\n",
      "    203.630492    -730.75359203   891.42617178   802.19148517\n",
      "   1123.90667804   210.31914344]\n",
      " [   19.53520692   459.41722971  -468.48152107   337.07258997\n",
      "   -437.92916128   368.61620943  -596.23187403   213.08294784\n",
      "   -242.19514271  -492.19444158]\n",
      " [ -128.64995589  -503.52130031   203.630492    -437.92916128\n",
      "   1084.72588464  -271.18242444   637.60980366 -1490.17969298\n",
      "   -435.356375    1115.63680221]\n",
      " [   54.41196862   558.98310065  -730.75359203   368.61620943\n",
      "   -271.18242444   510.28912309  -688.51328176  -316.99823928\n",
      "   -650.47007307  -304.53203755]\n",
      " [   54.89452865  -822.33475698   891.42617178  -596.23187403\n",
      "    637.60980366  -688.51328176  1107.69655353  -104.21637619\n",
      "    559.57207887   778.85626142]\n",
      " [   58.63421841    21.06214208   802.19148517   213.08294784\n",
      "  -1490.17969298  -316.99823928  -104.21637619  3151.761522\n",
      "   1831.46293234 -1542.28190816]\n",
      " [ -132.71577662  -533.61298795  1123.90667804  -242.19514271\n",
      "   -435.356375    -650.47007307   559.57207887  1831.46293234\n",
      "   1564.93463617  -489.93900627]\n",
      " [   11.97929527  -550.69182695   210.31914344  -492.19444158\n",
      "   1115.63680221  -304.53203755   778.85626142 -1542.28190816\n",
      "   -489.93900627  1235.1121686 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 08:47<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 940 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5896.334\n",
      "w[1]     246.497\n",
      "w[2]   -1323.313\n",
      "w[3]    -338.996\n",
      "w[4]   -1881.690\n",
      "w[5]     231.278\n",
      "w[6]    2268.146\n",
      "w[7]    1164.488\n",
      "w[8]   -1678.025\n",
      "w[9]    1017.076\n",
      "Name: mean, dtype: float64\n",
      "[[  267.87345594    73.2495926   -126.98006502    23.27982939\n",
      "   -138.23147934    57.42027891    50.19004288    70.04534396\n",
      "   -131.25946968     3.51943133]\n",
      " [   73.2495926    682.69453655  -779.86393654   477.13882924\n",
      "   -531.28076674   577.4730208   -851.75852745    40.97550212\n",
      "   -542.81325481  -579.29114547]\n",
      " [ -126.98006502  -779.86393654  1123.83890468  -485.37905156\n",
      "    227.98942063  -749.11112538   920.36781231   787.69642532\n",
      "   1134.99270493   236.10954638]\n",
      " [   23.27982939   477.13882924  -485.37905156   350.2088355\n",
      "   -458.92415105   382.14538129  -617.88295057   228.80934339\n",
      "   -248.46489936  -513.72923869]\n",
      " [ -138.23147934  -531.28076674   227.98942063  -458.92415105\n",
      "   1123.78871501  -291.16643182   669.94378536 -1526.57499225\n",
      "   -430.95471867  1153.81272863]\n",
      " [   57.42027891   577.4730208   -749.11112538   382.14538129\n",
      "   -291.16643182   524.82044195  -711.44439975  -304.39657385\n",
      "   -658.88679619  -325.47012885]\n",
      " [   50.19004288  -851.75852745   920.36781231  -617.88295057\n",
      "    669.94378536  -711.44439975  1144.28931893  -125.54982401\n",
      "    572.17977574   812.79737236]\n",
      " [   70.04534396    40.97550212   787.69642532   228.80934339\n",
      "  -1526.57499225  -304.39657385  -125.54982401  3194.12384268\n",
      "   1836.03424169 -1575.97610698]\n",
      " [ -131.25946968  -542.81325481  1134.99270493  -248.46489936\n",
      "   -430.95471867  -658.88679619   572.17977574  1836.03424169\n",
      "   1574.29203228  -483.73189488]\n",
      " [    3.51943133  -579.29114547   236.10954638  -513.72923869\n",
      "   1153.81272863  -325.47012885   812.79737236 -1575.97610698\n",
      "   -483.73189488  1273.04561635]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:37<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1017 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5897.647\n",
      "w[1]     249.779\n",
      "w[2]   -1329.502\n",
      "w[3]    -337.345\n",
      "w[4]   -1880.636\n",
      "w[5]     234.947\n",
      "w[6]    2264.857\n",
      "w[7]    1156.482\n",
      "w[8]   -1685.942\n",
      "w[9]    1018.663\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.66353811e+02  7.69514197e+01 -1.32211099e+02  2.57318415e+01\n",
      "  -1.38169330e+02  6.11215003e+01  4.46616301e+01  6.48439552e+01\n",
      "  -1.36574903e+02  2.33053438e+00]\n",
      " [ 7.69514197e+01  6.77682573e+02 -7.79014982e+02  4.72241203e+02\n",
      "  -5.21673439e+02  5.74787682e+02 -8.42755027e+02  2.64485392e+01\n",
      "  -5.49124996e+02 -5.66494278e+02]\n",
      " [-1.32211099e+02 -7.79014982e+02  1.13236634e+03 -4.82186663e+02\n",
      "   2.14221250e+02 -7.51752378e+02  9.15395271e+02  8.18380653e+02\n",
      "   1.15479913e+03  2.18387958e+02]\n",
      " [ 2.57318415e+01  4.72241203e+02 -4.82186663e+02  3.46052617e+02\n",
      "  -4.52882309e+02  3.78669188e+02 -6.09963152e+02  2.22345125e+02\n",
      "  -2.49536352e+02 -5.05446597e+02]\n",
      " [-1.38169330e+02 -5.21673439e+02  2.14221250e+02 -4.52882309e+02\n",
      "   1.12194267e+03 -2.81718169e+02  6.57904125e+02 -1.53765343e+03\n",
      "  -4.45061145e+02  1.15103774e+03]\n",
      " [ 6.11215003e+01  5.74787682e+02 -7.51752378e+02  3.78669188e+02\n",
      "  -2.81718169e+02  5.24481727e+02 -7.05338224e+02 -3.22214820e+02\n",
      "  -6.68963917e+02 -3.13050688e+02]\n",
      " [ 4.46616301e+01 -8.42755027e+02  9.15395271e+02 -6.09963152e+02\n",
      "   6.57904125e+02 -7.05338224e+02  1.12905524e+03 -1.11186976e+02\n",
      "   5.76062728e+02  7.95974090e+02]\n",
      " [ 6.48439552e+01  2.64485392e+01  8.18380653e+02  2.22345125e+02\n",
      "  -1.53765343e+03 -3.22214820e+02 -1.11186976e+02  3.24305035e+03\n",
      "   1.87867135e+03 -1.58945799e+03]\n",
      " [-1.36574903e+02 -5.49124996e+02  1.15479913e+03 -2.49536352e+02\n",
      "  -4.45061145e+02 -6.68963917e+02  5.76062728e+02  1.87867135e+03\n",
      "   1.60682239e+03 -5.01204924e+02]\n",
      " [ 2.33053438e+00 -5.66494278e+02  2.18387958e+02 -5.05446597e+02\n",
      "   1.15103774e+03 -3.13050688e+02  7.95974090e+02 -1.58945799e+03\n",
      "  -5.01204924e+02  1.26824517e+03]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 08:42<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 962 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5898.891\n",
      "w[1]     252.651\n",
      "w[2]   -1334.895\n",
      "w[3]    -335.895\n",
      "w[4]   -1879.827\n",
      "w[5]     238.143\n",
      "w[6]    2262.019\n",
      "w[7]    1149.673\n",
      "w[8]   -1692.798\n",
      "w[9]    1019.989\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.75688826e+02  8.04670919e+01 -1.36969878e+02  2.73592237e+01\n",
      "  -1.44768548e+02  6.35912794e+01  4.51235786e+01  6.97232820e+01\n",
      "  -1.40433139e+02  5.36300459e-01]\n",
      " [ 8.04670919e+01  6.94974566e+02 -7.96849682e+02  4.84714411e+02\n",
      "  -5.39365930e+02  5.88501521e+02 -8.63721101e+02  3.61460497e+01\n",
      "  -5.58457919e+02 -5.84824717e+02]\n",
      " [-1.36969878e+02 -7.96849682e+02  1.15389529e+03 -4.94201326e+02\n",
      "   2.27653659e+02 -7.67106861e+02  9.36006141e+02  8.19367760e+02\n",
      "   1.17151225e+03  2.31528792e+02]\n",
      " [ 2.73592237e+01  4.84714411e+02 -4.94201326e+02  3.55317842e+02\n",
      "  -4.66591950e+02  3.88284880e+02 -6.25673532e+02  2.31798508e+02\n",
      "  -2.54398789e+02 -5.20205598e+02]\n",
      " [-1.44768548e+02 -5.39365930e+02  2.27653659e+02 -4.66591950e+02\n",
      "   1.15015316e+03 -2.93449589e+02  6.78384079e+02 -1.56837141e+03\n",
      "  -4.46717599e+02  1.17869430e+03]\n",
      " [ 6.35912794e+01  5.88501521e+02 -7.67106861e+02  3.88284880e+02\n",
      "  -2.93449589e+02  5.35889383e+02 -7.21973924e+02 -3.19399585e+02\n",
      "  -6.79155528e+02 -3.25343005e+02]\n",
      " [ 4.51235786e+01 -8.63721101e+02  9.36006141e+02 -6.25673532e+02\n",
      "   6.78384079e+02 -7.21973924e+02  1.15711295e+03 -1.22827755e+02\n",
      "   5.85416703e+02  8.19969140e+02]\n",
      " [ 6.97232820e+01  3.61460497e+01  8.19367760e+02  2.31798508e+02\n",
      "  -1.56837141e+03 -3.19399585e+02 -1.22827755e+02  3.29264387e+03\n",
      "   1.89872181e+03 -1.61999268e+03]\n",
      " [-1.40433139e+02 -5.58457919e+02  1.17151225e+03 -2.54398789e+02\n",
      "  -4.46717599e+02 -6.79155528e+02  5.85416703e+02  1.89872181e+03\n",
      "   1.62789613e+03 -5.04320426e+02]\n",
      " [ 5.36300459e-01 -5.84824717e+02  2.31528792e+02 -5.20205598e+02\n",
      "   1.17869430e+03 -3.25343005e+02  8.19969140e+02 -1.61999268e+03\n",
      "  -5.04320426e+02  1.29822153e+03]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 08:49<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 966 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5900.273\n",
      "w[1]     255.759\n",
      "w[2]   -1340.810\n",
      "w[3]    -334.354\n",
      "w[4]   -1878.820\n",
      "w[5]     241.626\n",
      "w[6]    2258.984\n",
      "w[7]    1142.010\n",
      "w[8]   -1700.401\n",
      "w[9]    1021.587\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.73076707e+02  8.03341534e+01 -1.36927473e+02  2.73947325e+01\n",
      "  -1.42899178e+02  6.37240941e+01  4.38971326e+01  6.69237505e+01\n",
      "  -1.40838585e+02  1.00199507e+00]\n",
      " [ 8.03341534e+01  7.05928293e+02 -8.08688377e+02  4.92640613e+02\n",
      "  -5.48231698e+02  5.97622088e+02 -8.78047617e+02  3.77893442e+01\n",
      "  -5.66034832e+02 -5.95056518e+02]\n",
      " [-1.36927473e+02 -8.08688377e+02  1.17031357e+03 -5.01947831e+02\n",
      "   2.31294523e+02 -7.78363544e+02  9.51075201e+02  8.30466531e+02\n",
      "   1.18753594e+03  2.36284266e+02]\n",
      " [ 2.73947325e+01  4.92640613e+02 -5.01947831e+02  3.61224054e+02\n",
      "  -4.74435294e+02  3.94555769e+02 -6.36045911e+02  2.36026819e+02\n",
      "  -2.58095260e+02 -5.29034819e+02]\n",
      " [-1.42899178e+02 -5.48231698e+02  2.31294523e+02 -4.74435294e+02\n",
      "   1.16603957e+03 -2.98663219e+02  6.91502522e+02 -1.58924061e+03\n",
      "  -4.53231440e+02  1.19714947e+03]\n",
      " [ 6.37240941e+01  5.97622088e+02 -7.78363544e+02  3.94555769e+02\n",
      "  -2.98663219e+02  5.44003856e+02 -7.33630084e+02 -3.22810623e+02\n",
      "  -6.88465703e+02 -3.31446661e+02]\n",
      " [ 4.38971326e+01 -8.78047617e+02  9.51075201e+02 -6.36045911e+02\n",
      "   6.91502522e+02 -7.33630084e+02  1.17512474e+03 -1.27718811e+02\n",
      "   5.94286633e+02  8.34140520e+02]\n",
      " [ 6.69237505e+01  3.77893442e+01  8.30466531e+02  2.36026819e+02\n",
      "  -1.58924061e+03 -3.22810623e+02 -1.27718811e+02  3.33622263e+03\n",
      "   1.92510168e+03 -1.64365456e+03]\n",
      " [-1.40838585e+02 -5.66034832e+02  1.18753594e+03 -2.58095260e+02\n",
      "  -4.53231440e+02 -6.88465703e+02  5.94286633e+02  1.92510168e+03\n",
      "   1.65001611e+03 -5.10803721e+02]\n",
      " [ 1.00199507e+00 -5.95056518e+02  2.36284266e+02 -5.29034819e+02\n",
      "   1.19714947e+03 -3.31446661e+02  8.34140520e+02 -1.64365456e+03\n",
      "  -5.10803721e+02  1.31865721e+03]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 10:14<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1044 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5901.358\n",
      "w[1]     259.082\n",
      "w[2]   -1346.528\n",
      "w[3]    -332.538\n",
      "w[4]   -1878.555\n",
      "w[5]     245.144\n",
      "w[6]    2255.457\n",
      "w[7]    1135.731\n",
      "w[8]   -1707.227\n",
      "w[9]    1022.210\n",
      "Name: mean, dtype: float64\n",
      "[[  269.4171363     80.45378144  -138.95307515    27.24419101\n",
      "   -137.53816259    64.87530426    41.93234609    56.6787503\n",
      "   -145.4242481      4.53897339]\n",
      " [   80.45378144   721.60650721  -819.28216798   505.58142091\n",
      "   -572.43446872   608.15973569  -899.53598474    65.45259809\n",
      "   -562.03256338  -622.0552968 ]\n",
      " [ -138.95307515  -819.28216798  1172.52626159  -511.80528708\n",
      "    257.38216098  -783.34704574   965.29278796   791.34195755\n",
      "   1173.49712213   263.6959223 ]\n",
      " [   27.24419101   505.58142091  -511.80528708   371.63121239\n",
      "   -492.30198372   403.71954367  -653.72703747   254.36348562\n",
      "   -257.36076918  -549.23384763]\n",
      " [ -137.53816259  -572.43446872   257.38216098  -492.30198372\n",
      "   1183.12547583  -319.27510981   726.22776206 -1590.10985248\n",
      "   -436.91789499  1220.59934272]\n",
      " [   64.87530426   608.15973569  -783.34704574   403.71954367\n",
      "   -319.27510981   550.14309047  -747.80515286  -295.19553911\n",
      "   -680.86839806  -353.56693203]\n",
      " [   41.93234609  -899.53598474   965.29278796  -653.72703747\n",
      "    726.22776206  -747.80515286  1203.56810116  -168.23085096\n",
      "    588.03864456   871.74434271]\n",
      " [   56.6787503     65.45259809   791.34195755   254.36348562\n",
      "  -1590.10985248  -295.19553911  -168.23085096  3298.24461605\n",
      "   1885.04494394 -1653.10521204]\n",
      " [ -145.4242481   -562.03256338  1173.49712213  -257.36076918\n",
      "   -436.91789499  -680.86839806   588.03864456  1885.04494394\n",
      "   1624.98181169  -496.57911644]\n",
      " [    4.53897339  -622.0552968    263.6959223   -549.23384763\n",
      "   1220.59934272  -353.56693203   871.74434271 -1653.10521204\n",
      "   -496.57911644  1348.03630206]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 11:37<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1154 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5902.539\n",
      "w[1]     261.823\n",
      "w[2]   -1351.755\n",
      "w[3]    -331.173\n",
      "w[4]   -1877.640\n",
      "w[5]     248.225\n",
      "w[6]    2252.751\n",
      "w[7]    1128.934\n",
      "w[8]   -1713.953\n",
      "w[9]    1023.619\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.67122097e+02  7.68962699e+01 -1.30962210e+02  2.58652569e+01\n",
      "  -1.40500231e+02  6.04760947e+01  4.49077848e+01  6.95302006e+01\n",
      "  -1.33960507e+02  4.11443081e-01]\n",
      " [ 7.68962699e+01  7.22521648e+02 -8.19700251e+02  5.06749058e+02\n",
      "  -5.72288874e+02  6.08941498e+02 -9.02665130e+02  6.49576112e+01\n",
      "  -5.61474344e+02 -6.23892626e+02]\n",
      " [-1.30962210e+02 -8.19700251e+02  1.17434121e+03 -5.12461445e+02\n",
      "   2.50811516e+02 -7.84871566e+02  9.69801124e+02  8.02957373e+02\n",
      "   1.17734542e+03  2.61282226e+02]\n",
      " [ 2.58652569e+01  5.06749058e+02 -5.12461445e+02  3.72799952e+02\n",
      "  -4.93669163e+02  4.04523473e+02 -6.56066220e+02  2.55857074e+02\n",
      "  -2.56744896e+02 -5.51465677e+02]\n",
      " [-1.40500231e+02 -5.72288874e+02  2.50811516e+02 -4.93669163e+02\n",
      "   1.19620064e+03 -3.16294852e+02  7.25358857e+02 -1.61683075e+03\n",
      "  -4.51871410e+02  1.23250736e+03]\n",
      " [ 6.04760947e+01  6.08941498e+02 -7.84871566e+02  4.04523473e+02\n",
      "  -3.16294852e+02  5.51394201e+02 -7.51030077e+02 -3.01149393e+02\n",
      "  -6.83138006e+02 -3.52920348e+02]\n",
      " [ 4.49077848e+01 -9.02665130e+02  9.69801124e+02 -6.56066220e+02\n",
      "   7.25358857e+02 -7.51030077e+02  1.20909848e+03 -1.62408729e+02\n",
      "   5.92633575e+02  8.72636650e+02]\n",
      " [ 6.95302006e+01  6.49576112e+01  8.02957373e+02  2.55857074e+02\n",
      "  -1.61683075e+03 -3.01149393e+02 -1.62408729e+02  3.35066532e+03\n",
      "   1.91148957e+03 -1.67371286e+03]\n",
      " [-1.33960507e+02 -5.61474344e+02  1.17734542e+03 -2.56744896e+02\n",
      "  -4.51871410e+02 -6.83138006e+02  5.92633575e+02  1.91148957e+03\n",
      "   1.63552701e+03 -5.05833240e+02]\n",
      " [ 4.11443081e-01 -6.23892626e+02  2.61282226e+02 -5.51465677e+02\n",
      "   1.23250736e+03 -3.52920348e+02  8.72636650e+02 -1.67371286e+03\n",
      "  -5.05833240e+02  1.35820040e+03]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 10:04<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1103 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5903.572\n",
      "w[1]     264.327\n",
      "w[2]   -1356.591\n",
      "w[3]    -329.941\n",
      "w[4]   -1876.657\n",
      "w[5]     251.071\n",
      "w[6]    2250.266\n",
      "w[7]    1122.435\n",
      "w[8]   -1720.242\n",
      "w[9]    1025.036\n",
      "Name: mean, dtype: float64\n",
      "[[  269.47581586    72.60425746  -128.60474899    22.04019176\n",
      "   -134.27771646    57.59901199    52.10942196    61.96280546\n",
      "   -136.1309026      8.67582788]\n",
      " [   72.60425746   721.29861861  -813.81961524   507.44760035\n",
      "   -577.22164808   606.52046736  -904.11549382    79.14699397\n",
      "   -550.29785145  -631.55067641]\n",
      " [ -128.60474899  -813.81961524  1168.65542102  -508.4048877\n",
      "    244.08333848  -780.47006211   963.41796877   807.4255886\n",
      "   1174.44373042   255.09286808]\n",
      " [   22.04019176   507.44760035  -508.4048877    374.86271587\n",
      "   -500.73214243   403.55423242  -659.77572582   271.46800503\n",
      "   -246.40677465  -561.24906649]\n",
      " [ -134.27771646  -577.22164808   244.08333848  -500.73214243\n",
      "   1217.7963452   -316.20680586   736.89057359 -1658.19435361\n",
      "   -475.21645024  1259.45207298]\n",
      " [   57.59901199   606.52046736  -780.47006211   403.55423242\n",
      "   -316.20680586   548.93628997  -749.75338583  -296.48145835\n",
      "   -677.2730802   -354.32911842]\n",
      " [   52.10942196  -904.11549382   963.41796877  -659.77572582\n",
      "    736.89057359  -749.75338583  1216.10687083  -187.74767504\n",
      "    575.67770417   889.17864756]\n",
      " [   61.96280546    79.14699397   807.4255886    271.46800503\n",
      "  -1658.19435361  -296.48145835  -187.74767504  3420.80858805\n",
      "   1945.30034531 -1723.11742492]\n",
      " [ -136.1309026   -550.29785145  1174.44373042  -246.40677465\n",
      "   -475.21645024  -677.2730802    575.67770417  1945.30034531\n",
      "   1647.8340703   -532.69701279]\n",
      " [    8.67582788  -631.55067641   255.09286808  -561.24906649\n",
      "   1259.45207298  -354.32911842   889.17864756 -1723.11742492\n",
      "   -532.69701279  1392.19575676]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 10:10<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1046 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5904.568\n",
      "w[1]     267.216\n",
      "w[2]   -1361.952\n",
      "w[3]    -328.452\n",
      "w[4]   -1875.790\n",
      "w[5]     254.279\n",
      "w[6]    2247.274\n",
      "w[7]    1115.582\n",
      "w[8]   -1727.027\n",
      "w[9]    1026.281\n",
      "Name: mean, dtype: float64\n",
      "[[ 2.66989979e+02  7.59114782e+01 -1.30579008e+02  2.50110473e+01\n",
      "  -1.38391839e+02  5.99401527e+01  4.61883238e+01  6.64073643e+01\n",
      "  -1.34973121e+02  2.66091073e+00]\n",
      " [ 7.59114782e+01  7.11919055e+02 -8.05359922e+02  5.00097334e+02\n",
      "  -5.68811270e+02  5.99101575e+02 -8.89959384e+02  7.41008077e+01\n",
      "  -5.47368480e+02 -6.19890220e+02]\n",
      " [-1.30579008e+02 -8.05359922e+02  1.15944841e+03 -5.02248049e+02\n",
      "   2.38814571e+02 -7.73264925e+02  9.51395686e+02  8.06751640e+02\n",
      "   1.16821381e+03  2.47581404e+02]\n",
      " [ 2.50110473e+01  5.00097334e+02 -5.02248049e+02  3.68951150e+02\n",
      "  -4.93483162e+02  3.97887720e+02 -6.48409475e+02  2.66010785e+02\n",
      "  -2.45180284e+02 -5.51209068e+02]\n",
      " [-1.38391839e+02 -5.68811270e+02  2.38814571e+02 -4.93483162e+02\n",
      "   1.20668307e+03 -3.10340675e+02  7.23330546e+02 -1.64561198e+03\n",
      "  -4.72508674e+02  1.24455863e+03]\n",
      " [ 5.99401527e+01  5.99101575e+02 -7.73264925e+02  3.97887720e+02\n",
      "  -3.10340675e+02  5.42895233e+02 -7.38763356e+02 -2.98702992e+02\n",
      "  -6.73771924e+02 -3.46091738e+02]\n",
      " [ 4.61883238e+01 -8.89959384e+02  9.51395686e+02 -6.48409475e+02\n",
      "   7.23330546e+02 -7.38763356e+02  1.19409253e+03 -1.78088436e+02\n",
      "   5.72898403e+02  8.70167045e+02]\n",
      " [ 6.64073643e+01  7.41008077e+01  8.06751640e+02  2.66010785e+02\n",
      "  -1.64561198e+03 -2.98702992e+02 -1.78088436e+02  3.40002917e+03\n",
      "   1.93485857e+03 -1.70681539e+03]\n",
      " [-1.34973121e+02 -5.47368480e+02  1.16821381e+03 -2.45180284e+02\n",
      "  -4.72508674e+02 -6.73771924e+02  5.72898403e+02  1.93485857e+03\n",
      "   1.63873859e+03 -5.29482548e+02]\n",
      " [ 2.66091073e+00 -6.19890220e+02  2.47581404e+02 -5.51209068e+02\n",
      "   1.24455863e+03 -3.46091738e+02  8.70167045e+02 -1.70681539e+03\n",
      "  -5.29482548e+02  1.37194367e+03]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:41<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1007 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5905.510\n",
      "w[1]     270.308\n",
      "w[2]   -1367.552\n",
      "w[3]    -326.819\n",
      "w[4]   -1875.026\n",
      "w[5]     257.670\n",
      "w[6]    2243.987\n",
      "w[7]    1108.659\n",
      "w[8]   -1733.991\n",
      "w[9]    1027.365\n",
      "Name: mean, dtype: float64\n",
      "[[  272.28124916    73.33833174  -129.57423025    22.37131737\n",
      "   -136.39163823    58.06576427    52.54814094    64.01282179\n",
      "   -136.66389599     8.08782223]\n",
      " [   73.33833174   735.36723645  -825.09708406   518.7293782\n",
      "   -596.62262464   616.64160628  -922.86612407    98.21790722\n",
      "   -550.3787044   -652.84152455]\n",
      " [ -129.57423025  -825.09708406  1173.56516911  -518.50613234\n",
      "    267.26050213  -786.93566565   978.8271971    775.98381545\n",
      "   1165.04876153   280.02515419]\n",
      " [   22.37131737   518.7293782   -518.50613234   383.64180674\n",
      "   -514.2171481    412.10202428  -674.7860856    282.45471907\n",
      "   -248.92769984  -576.28275445]\n",
      " [ -136.39163823  -596.62262464   267.26050213  -514.2171481\n",
      "   1231.54877551  -333.06823744   761.14179937 -1656.16485576\n",
      "   -457.78563082  1274.34892136]\n",
      " [   58.06576427   616.64160628  -786.93566565   412.10202428\n",
      "   -333.06823744   555.57117453  -763.49576671  -276.50141744\n",
      "   -673.58089204  -372.76975509]\n",
      " [   52.54814094  -922.86612407   978.8271971   -674.7860856\n",
      "    761.14179937  -763.49576671  1241.72923269  -210.40265301\n",
      "    576.84248958   916.71979581]\n",
      " [   64.01282179    98.21790722   775.98381545   282.45471907\n",
      "  -1656.16485576  -276.50141744  -210.40265301  3385.51717615\n",
      "   1908.36150999 -1721.25234442]\n",
      " [ -136.66389599  -550.3787044   1165.04876153  -248.92769984\n",
      "   -457.78563082  -673.58089204   576.84248958  1908.36150999\n",
      "   1626.14247676  -514.50833357]\n",
      " [    8.08782223  -652.84152455   280.02515419  -576.28275445\n",
      "   1274.34892136  -372.76975509   916.71979581 -1721.25234442\n",
      "   -514.50833357  1409.37395042]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:18<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 977 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5906.350\n",
      "w[1]     272.423\n",
      "w[2]   -1371.934\n",
      "w[3]    -325.840\n",
      "w[4]   -1873.689\n",
      "w[5]     260.195\n",
      "w[6]    2241.902\n",
      "w[7]    1102.080\n",
      "w[8]   -1739.942\n",
      "w[9]    1029.080\n",
      "Name: mean, dtype: float64\n",
      "[[  268.81566459    68.57732331  -125.63393294    18.91441492\n",
      "   -128.30062935    54.93118725    57.10451288    55.59939936\n",
      "   -136.4788244     14.95599841]\n",
      " [   68.57732331   730.06480707  -819.24141745   515.27028936\n",
      "   -589.60972736   612.56558395  -918.51323026    93.53917124\n",
      "   -547.04448318  -647.61398126]\n",
      " [ -125.63393294  -819.24141745  1171.4314602   -513.54101363\n",
      "    252.61790409  -784.03328951   972.71485046   796.4474139\n",
      "   1170.97217494   266.20244321]\n",
      " [   18.91441492   515.27028936  -513.54101363   381.68541057\n",
      "   -511.45809888   409.01581282  -672.2929512    283.43492872\n",
      "   -244.21740918  -574.98152646]\n",
      " [ -128.30062935  -589.60972736   252.61790409  -511.45809888\n",
      "   1233.4400773   -325.14860494   757.26327732 -1674.60422877\n",
      "   -477.5427233   1280.39463583]\n",
      " [   54.93118725   612.56558395  -784.03328951   409.01581282\n",
      "   -325.14860494   553.01489691  -759.64883858  -285.71829306\n",
      "   -674.56446543  -365.75940865]\n",
      " [   57.10451288  -918.51323026   972.71485046  -672.2929512\n",
      "    757.26327732  -759.64883858  1238.69194883  -210.88518772\n",
      "    571.28495678   914.6901509 ]\n",
      " [   55.59939936    93.53917124   796.4474139    283.43492872\n",
      "  -1674.60422877  -285.71829306  -210.88518772  3435.77928791\n",
      "   1945.28614488 -1745.26553063]\n",
      " [ -136.4788244   -547.04448318  1170.97217494  -244.21740918\n",
      "   -477.5427233   -674.56446543   571.28495678  1945.28614488\n",
      "   1645.33696161  -535.6537985 ]\n",
      " [   14.95599841  -647.61398126   266.20244321  -574.98152646\n",
      "   1280.39463583  -365.75940865   914.6901509  -1745.26553063\n",
      "   -535.6537985   1419.18668559]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:43<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1030 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5907.199\n",
      "w[1]     274.825\n",
      "w[2]   -1376.465\n",
      "w[3]    -324.618\n",
      "w[4]   -1872.863\n",
      "w[5]     262.895\n",
      "w[6]    2239.433\n",
      "w[7]    1096.150\n",
      "w[8]   -1745.730\n",
      "w[9]    1030.231\n",
      "Name: mean, dtype: float64\n",
      "[[  273.34665839    66.22855418  -126.39958208    16.08794161\n",
      "   -123.37946073    53.89084034    62.97138705    46.71030947\n",
      "   -141.86607496    23.11582179]\n",
      " [   66.22855418   740.0280544   -836.02802758   521.24335559\n",
      "   -585.97976523   623.43311001  -932.03652598    71.06849111\n",
      "   -567.30022899  -646.05440321]\n",
      " [ -126.39958208  -836.02802758  1206.02385694  -521.7185306\n",
      "    238.40189844  -804.43198524   992.24330619   853.85127626\n",
      "   1218.69204267   252.18069885]\n",
      " [   16.08794161   521.24335559  -521.7185306    385.82656826\n",
      "   -511.68971496   414.90678929  -681.37780132   275.78664006\n",
      "   -252.30429014  -577.446319  ]\n",
      " [ -123.37946073  -585.97976523   238.40189844  -511.68971496\n",
      "   1245.31722504  -318.4796771    756.34867092 -1708.13365969\n",
      "   -502.35685239  1295.56275537]\n",
      " [   53.89084034   623.43311001  -804.43198524   414.90678929\n",
      "   -318.4796771    565.56294384  -773.34389184  -316.74250556\n",
      "   -701.16038153  -360.28683451]\n",
      " [   62.97138705  -932.03652598   992.24330619  -681.37780132\n",
      "    756.34867092  -773.34389184  1258.85181171  -190.21456315\n",
      "    591.78043665   918.44133088]\n",
      " [   46.71030947    71.06849111   853.85127626   275.78664006\n",
      "  -1708.13365969  -316.74250556  -190.21456315  3547.38379253\n",
      "   2033.05585164 -1784.03623819]\n",
      " [ -141.86607496  -567.30022899  1218.69204267  -252.30429014\n",
      "   -502.35685239  -701.16038153   591.78043665  2033.05585164\n",
      "   1715.77015255  -563.3416552 ]\n",
      " [   23.11582179  -646.05440321   252.18069885  -577.446319\n",
      "   1295.56275537  -360.28683451   918.44133088 -1784.03623819\n",
      "   -563.3416552   1439.96174155]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:46<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1006 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5908.010\n",
      "w[1]     276.455\n",
      "w[2]   -1380.295\n",
      "w[3]    -323.985\n",
      "w[4]   -1871.145\n",
      "w[5]     265.007\n",
      "w[6]    2237.972\n",
      "w[7]    1089.522\n",
      "w[8]   -1751.316\n",
      "w[9]    1032.378\n",
      "Name: mean, dtype: float64\n",
      "[[  276.65893049    61.3640047   -119.77014941    12.74824125\n",
      "   -123.93344426    49.10314721    70.91610266    54.01440228\n",
      "   -135.2071502     24.95213326]\n",
      " [   61.3640047    722.27019369  -811.25886297   510.17613406\n",
      "   -578.40949104   606.89297457  -911.99727469    84.34777476\n",
      "   -543.38068639  -639.18025979]\n",
      " [ -119.77014941  -811.25886297  1171.95262035  -506.21138439\n",
      "    227.19078929  -781.52672097   964.25772353   836.67791098\n",
      "   1186.21819197   241.88068136]\n",
      " [   12.74824125   510.17613406  -506.21138439   378.95072192\n",
      "   -506.88319247   404.59749028  -669.03629684   283.97231873\n",
      "   -237.30923429  -573.23460188]\n",
      " [ -123.93344426  -578.40949104   227.19078929  -506.88319247\n",
      "   1244.70879934  -311.01995407   746.32675073 -1718.09372086\n",
      "   -513.96577884  1293.74294578]\n",
      " [   49.10314721   606.89297457  -781.52672097   404.59749028\n",
      "   -311.01995407   550.23427438  -754.83905553  -305.10209952\n",
      "   -679.20653133  -353.62783534]\n",
      " [   70.91610266  -911.99727469   964.25772353  -669.03629684\n",
      "    746.32675073  -754.83905553  1237.51527786  -203.04739725\n",
      "    564.97137402   910.55858834]\n",
      " [   54.01440228    84.34777476   836.67791098   283.97231873\n",
      "  -1718.09372086  -305.10209952  -203.04739725  3544.68055999\n",
      "   2017.89415509 -1791.32351172]\n",
      " [ -135.2071502   -543.38068639  1186.21819197  -237.30923429\n",
      "   -513.96577884  -679.20653133   564.97137402  2017.89415509\n",
      "   1685.16738807  -573.88426819]\n",
      " [   24.95213326  -639.18025979   241.88068136  -573.23460188\n",
      "   1293.74294578  -353.62783534   910.55858834 -1791.32351172\n",
      "   -573.88426819  1438.32605747]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 10:07<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1018 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5908.941\n",
      "w[1]     278.029\n",
      "w[2]   -1384.065\n",
      "w[3]    -323.397\n",
      "w[4]   -1869.458\n",
      "w[5]     267.063\n",
      "w[6]    2236.644\n",
      "w[7]    1083.002\n",
      "w[8]   -1756.843\n",
      "w[9]    1034.562\n",
      "Name: mean, dtype: float64\n",
      "[[  276.98624193    55.3357905   -113.93207335     8.16706149\n",
      "   -117.77919146    44.37456859    79.0956503     50.16090014\n",
      "   -132.87216254    32.16459678]\n",
      " [   55.3357905    719.58216528  -815.52341844   507.04664811\n",
      "   -560.62101786   607.98015947  -910.91439377    52.61128637\n",
      "   -557.55127595  -623.78704964]\n",
      " [ -113.93207335  -815.52341844  1183.3321737   -508.22283743\n",
      "    216.06168081  -788.25606685   972.34970786   865.29122092\n",
      "   1204.10577965   233.95960077]\n",
      " [    8.16706149   507.04664811  -508.22283743   375.79012604\n",
      "   -492.53639415   404.48531822  -666.76606998   259.83056715\n",
      "   -247.23394331  -560.58200282]\n",
      " [ -117.77919146  -560.62101786   216.06168081  -492.53639415\n",
      "   1212.40933653  -299.89036493   725.18355146 -1679.32781773\n",
      "   -507.60251064  1261.89912501]\n",
      " [   44.37456859   607.98015947  -788.25606685   404.48531822\n",
      "   -299.89036493   553.72228349  -758.23484971  -329.0270203\n",
      "   -692.26740131  -344.79326614]\n",
      " [   79.0956503   -910.91439377   972.34970786  -666.76606998\n",
      "    725.18355146  -758.23484971  1239.45603622  -162.40638898\n",
      "    584.79110194   893.06225861]\n",
      " [   50.16090014    52.61128637   865.29122092   259.83056715\n",
      "  -1679.32781773  -329.0270203   -162.40638898  3513.47007081\n",
      "   2026.05535803 -1750.157824  ]\n",
      " [ -132.87216254  -557.55127595  1204.10577965  -247.23394331\n",
      "   -507.60251064  -692.26740131   584.79110194  2026.05535803\n",
      "   1700.21270133  -564.64926369]\n",
      " [   32.16459678  -623.78704964   233.95960077  -560.58200282\n",
      "   1261.89912501  -344.79326614   893.06225861 -1750.157824\n",
      "   -564.64926369  1407.79911532]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:10<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 943 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5909.617\n",
      "w[1]     280.192\n",
      "w[2]   -1388.537\n",
      "w[3]    -322.385\n",
      "w[4]   -1867.985\n",
      "w[5]     269.652\n",
      "w[6]    2234.422\n",
      "w[7]    1076.118\n",
      "w[8]   -1762.940\n",
      "w[9]    1036.323\n",
      "Name: mean, dtype: float64\n",
      "[[  271.67333052    63.1221932   -123.76321325    13.8231038\n",
      "   -118.54685105    51.83475823    66.26882327    41.9171119\n",
      "   -141.63062612    27.50582262]\n",
      " [   63.1221932    716.09446478  -805.27831483   505.62450033\n",
      "   -573.86545109   601.91591784  -903.14775826    83.26021933\n",
      "   -539.86529605  -633.0198764 ]\n",
      " [ -123.76321325  -805.27831483  1164.10216971  -502.24534235\n",
      "    228.0240015   -775.76851998   954.99297035   827.70812794\n",
      "   1177.95977744   240.06986043]\n",
      " [   13.8231038    505.62450033  -502.24534235   375.47885048\n",
      "   -502.5766376    401.10236056  -662.51426092   281.26347015\n",
      "   -235.7246421   -567.81935598]\n",
      " [ -118.54685105  -573.86545109   228.0240015   -502.5766376\n",
      "   1227.78343328  -309.89229869   742.2813737  -1691.41527303\n",
      "   -504.27791323  1278.94476457]\n",
      " [   51.83475823   601.91591784  -775.76851998   401.10236056\n",
      "   -309.89229869   545.75736171  -747.22762328  -301.1931486\n",
      "   -674.13791047  -350.54737604]\n",
      " [   66.26882327  -903.14775826   954.99297035  -662.51426092\n",
      "    742.2813737   -747.22762328  1223.74320651  -205.89092445\n",
      "    558.22964645   903.03987015]\n",
      " [   41.9171119     83.26021933   827.70812794   281.26347015\n",
      "  -1691.41527303  -301.1931486   -205.89092445  3495.12183928\n",
      "   1994.99210535 -1770.45333825]\n",
      " [ -141.63062612  -539.86529605  1177.95977744  -235.7246421\n",
      "   -504.27791323  -674.13791047   558.22964645  1994.99210535\n",
      "   1671.78939098  -567.71534958]\n",
      " [   27.50582262  -633.0198764    240.06986043  -567.81935598\n",
      "   1278.94476457  -350.54737604   903.03987015 -1770.45333825\n",
      "   -567.71534958  1423.95991291]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:32<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 958 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5910.476\n",
      "w[1]     281.997\n",
      "w[2]   -1392.259\n",
      "w[3]    -321.554\n",
      "w[4]   -1866.959\n",
      "w[5]     271.783\n",
      "w[6]    2232.716\n",
      "w[7]    1070.684\n",
      "w[8]   -1767.977\n",
      "w[9]    1037.751\n",
      "Name: mean, dtype: float64\n",
      "[[  269.27347131    62.89007479  -123.21024191    13.82988342\n",
      "   -117.44892396    51.70566933    65.32982736    40.92345691\n",
      "   -140.9411708     27.29065094]\n",
      " [   62.89007479   716.17273305  -800.24287291   506.99285751\n",
      "   -582.72746844   599.92476065  -904.04399734   102.5184224\n",
      "   -528.55406186  -642.62484823]\n",
      " [ -123.21024191  -800.24287291  1155.72225276  -499.38610879\n",
      "    228.60918951  -770.46582454   949.06374753   818.07658753\n",
      "   1168.2567829    240.67922047]\n",
      " [   13.82988342   506.99285751  -499.38610879   377.56437407\n",
      "   -511.28400254   400.47501834  -664.87242684   298.00486936\n",
      "   -226.97333468  -577.20564528]\n",
      " [ -117.44892396  -582.72746844   228.60918951  -511.28400254\n",
      "   1250.18923417  -313.6547431    755.61168547 -1726.35192198\n",
      "   -518.49790301  1304.10687157]\n",
      " [   51.70566933   599.92476065  -770.46582454   400.47501834\n",
      "   -313.6547431    542.84374601  -745.09869187  -289.73692806\n",
      "   -665.86914631  -354.50878146]\n",
      " [   65.32982736  -904.04399734   949.06374753  -664.87242684\n",
      "    755.61168547  -745.09869187  1225.34100452  -233.05297994\n",
      "    543.4482937    916.78075572]\n",
      " [   40.92345691   102.5184224    818.07658753   298.00486936\n",
      "  -1726.35192198  -289.73692806  -233.05297994  3540.49844036\n",
      "   2007.38271022 -1809.62698346]\n",
      " [ -140.9411708   -528.55406186  1168.2567829   -226.97333468\n",
      "   -518.49790301  -665.86914631   543.4482937   2007.38271022\n",
      "   1670.16039576  -583.24638002]\n",
      " [   27.29065094  -642.62484823   240.67922047  -577.20564528\n",
      "   1304.10687157  -354.50878146   916.78075572 -1809.62698346\n",
      "   -583.24638002  1451.34356296]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:26<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 942 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5911.172\n",
      "w[1]     282.955\n",
      "w[2]   -1395.104\n",
      "w[3]    -321.332\n",
      "w[4]   -1865.070\n",
      "w[5]     273.243\n",
      "w[6]    2232.041\n",
      "w[7]    1064.792\n",
      "w[8]   -1772.548\n",
      "w[9]    1040.067\n",
      "Name: mean, dtype: float64\n",
      "[[  274.50717798    65.08738125  -125.71972652    15.02549651\n",
      "   -122.17531446    53.17256771    65.15124809    45.58945\n",
      "   -142.16718034    25.15495521]\n",
      " [   65.08738125   738.31359442  -828.03497791   522.05801828\n",
      "   -595.96282517   619.72578672  -931.63538562    94.95545441\n",
      "   -551.44677689  -657.28367938]\n",
      " [ -125.71972652  -828.03497791  1190.40986737  -518.28062956\n",
      "    245.23232168  -795.25138859   983.75899023   827.35395478\n",
      "   1196.68368427   259.24516745]\n",
      " [   15.02549651   522.05801828  -518.28062956   387.85277373\n",
      "   -520.16332816   413.9671616   -683.81821575   292.68239343\n",
      "   -242.53833723  -587.22193231]\n",
      " [ -122.17531446  -595.96282517   245.23232168  -520.16332816\n",
      "   1260.3641841   -325.23563238   770.47828986 -1725.23921377\n",
      "   -505.25274681  1313.26519293]\n",
      " [   53.17256771   619.72578672  -795.25138859   413.9671616\n",
      "   -325.23563238   560.55828766  -770.00219381  -296.81515744\n",
      "   -686.28569071  -367.64522843]\n",
      " [   65.15124809  -931.63538562   983.75899023  -683.81821575\n",
      "    770.47828986  -770.00219381  1261.04228382  -221.09593745\n",
      "    572.37369318   934.82111868]\n",
      " [   45.58945       94.95545441   827.35395478   292.68239343\n",
      "  -1725.23921377  -296.81515744  -221.09593745  3547.98474593\n",
      "   2015.52884553 -1805.03870676]\n",
      " [ -142.16718034  -551.44677689  1196.68368427  -242.53833723\n",
      "   -505.25274681  -686.28569071   572.37369318  2015.52884553\n",
      "   1693.42028272  -567.92595062]\n",
      " [   25.15495521  -657.28367938   259.24516745  -587.22193231\n",
      "   1313.26519293  -367.64522843   934.82111868 -1805.03870676\n",
      "   -567.92595062  1461.06068121]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:28<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 968 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5911.854\n",
      "w[1]     284.480\n",
      "w[2]   -1398.369\n",
      "w[3]    -320.653\n",
      "w[4]   -1863.975\n",
      "w[5]     275.098\n",
      "w[6]    2230.585\n",
      "w[7]    1059.723\n",
      "w[8]   -1777.072\n",
      "w[9]    1041.491\n",
      "Name: mean, dtype: float64\n",
      "[[  281.48848588    63.62616903  -123.59919338    13.67956083\n",
      "   -126.20374794    51.11277365    70.68445133    53.71032395\n",
      "   -139.11458623    25.06290948]\n",
      " [   63.62616903   742.1416657   -830.41311142   525.44740398\n",
      "   -601.24664415   622.39422958  -937.58281098   101.0064966\n",
      "   -550.23406766  -664.14333635]\n",
      " [ -123.59919338  -830.41311142  1193.8901859   -520.03751807\n",
      "    244.31946525  -797.87399214   987.77871484   832.26222959\n",
      "   1200.49630439   259.71257208]\n",
      " [   13.67956083   525.44740398  -520.03751807   390.91907305\n",
      "   -525.39892848   416.18078984  -689.16866009   299.28964621\n",
      "   -240.7159796   -593.9237719 ]\n",
      " [ -126.20374794  -601.24664415   244.31946525  -525.39892848\n",
      "   1278.55763313  -326.62095191   776.10214252 -1754.85494841\n",
      "   -516.90469554  1330.87920635]\n",
      " [   51.11277365   622.39422958  -797.87399214   416.18078984\n",
      "   -326.62095191   562.9134863   -774.55255194  -297.18092927\n",
      "   -687.69410044  -370.56815343]\n",
      " [   70.68445133  -937.58281098   987.77871484  -689.16866009\n",
      "    776.10214252  -774.55255194  1271.9715982   -226.26501888\n",
      "    571.64298322   944.61892512]\n",
      " [   53.71032395   101.0064966    832.26222959   299.28964621\n",
      "  -1754.85494841  -297.18092927  -226.26501888  3599.62093495\n",
      "   2037.7976891  -1832.5771549 ]\n",
      " [ -139.11458623  -550.23406766  1200.49630439  -240.7159796\n",
      "   -516.90469554  -687.69410044   571.64298322  2037.7976891\n",
      "   1704.24650566  -578.75041383]\n",
      " [   25.06290948  -664.14333635   259.71257208  -593.9237719\n",
      "   1330.87920635  -370.56815343   944.61892512 -1832.5771549\n",
      "   -578.75041383  1480.49873863]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:48<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 975 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5912.361\n",
      "w[1]     285.916\n",
      "w[2]   -1401.339\n",
      "w[3]    -319.982\n",
      "w[4]   -1863.045\n",
      "w[5]     276.816\n",
      "w[6]    2229.133\n",
      "w[7]    1055.221\n",
      "w[8]   -1781.108\n",
      "w[9]    1042.647\n",
      "Name: mean, dtype: float64\n",
      "[[  293.79615068    67.15525926  -126.3753332     15.6863157\n",
      "   -138.31477483    52.62482823    72.33703854    69.07514816\n",
      "   -137.98434368    19.13432625]\n",
      " [   67.15525926   755.54741631  -837.81378922   536.65352629\n",
      "   -626.8456467    630.38741766  -954.37124171   133.47008391\n",
      "   -543.12085764  -690.3494485 ]\n",
      " [ -126.3753332   -837.81378922  1197.42895324  -526.36822293\n",
      "    260.06514332  -802.01563628   996.82047703   811.27728133\n",
      "   1195.18158078   275.46720024]\n",
      " [   15.6863157    536.65352629  -526.36822293   400.29470351\n",
      "   -545.93773862   422.99350887  -703.64533013   324.98643081\n",
      "   -235.2096108   -615.45500484]\n",
      " [ -138.31477483  -626.8456467    260.06514332  -545.93773862\n",
      "   1327.54493352  -342.06867784   804.89857589 -1814.95084622\n",
      "   -527.24372815  1377.77726593]\n",
      " [   52.62482823   630.38741766  -802.01563628   422.99350887\n",
      "   -342.06867784   567.62339081  -784.96159688  -277.20907592\n",
      "   -682.87025574  -386.76077704]\n",
      " [   72.33703854  -954.37124171   996.82047703  -703.64533013\n",
      "    804.89857589  -784.96159688  1296.18237335  -262.44669011\n",
      "    562.82407565   977.53051642]\n",
      " [   69.07514816   133.47008391   811.27728133   324.98643081\n",
      "  -1814.95084622  -277.20907592  -262.44669011  3671.56640454\n",
      "   2048.49490354 -1889.79854791]\n",
      " [ -137.98434368  -543.12085764  1195.18158078  -235.2096108\n",
      "   -527.24372815  -682.87025574   562.82407565  2048.49490354\n",
      "   1704.63880751  -589.50986592]\n",
      " [   19.13432625  -690.3494485    275.46720024  -615.45500484\n",
      "   1377.77726593  -386.76077704   977.53051642 -1889.79854791\n",
      "   -589.50986592  1528.84634986]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:32<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 969 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5913.136\n",
      "w[1]     287.910\n",
      "w[2]   -1405.192\n",
      "w[3]    -318.995\n",
      "w[4]   -1862.251\n",
      "w[5]     279.084\n",
      "w[6]    2227.126\n",
      "w[7]    1050.031\n",
      "w[8]   -1786.107\n",
      "w[9]    1043.761\n",
      "Name: mean, dtype: float64\n",
      "[[  302.78082581    68.52771136  -125.46082471    16.67718733\n",
      "   -149.0886258     52.02220032    74.9008599     86.19354258\n",
      "   -132.71473631    12.90178303]\n",
      " [   68.52771136   763.53613142  -845.51092294   542.53065005\n",
      "   -635.92864542   636.51765778  -964.27880407   139.93113371\n",
      "   -546.29553574  -699.97118278]\n",
      " [ -125.46082471  -845.51092294  1208.67060493  -531.29292381\n",
      "    260.89369431  -809.65928144  1007.08427985   821.1665959\n",
      "   1206.87477409   277.73538465]\n",
      " [   16.67718733   542.53065005  -531.29292381   404.78919042\n",
      "   -553.8755532    427.20738188  -711.02932667   332.45371308\n",
      "   -235.92349252  -623.85977042]\n",
      " [ -149.0886258   -635.92864542   260.89369431  -553.8755532\n",
      "   1357.11303127  -345.05047342   812.31598885 -1859.73407106\n",
      "   -541.99254576  1403.53208464]\n",
      " [   52.02220032   636.51765778  -809.65928144   427.20738188\n",
      "   -345.05047342   573.16878901  -793.21962766  -280.13175637\n",
      "   -689.29248532  -390.92131501]\n",
      " [   74.9008599   -964.27880407  1007.08427985  -711.02932667\n",
      "    812.31598885  -793.21962766  1310.59373036  -264.04048909\n",
      "    568.77250364   987.90572495]\n",
      " [   86.19354258   139.93113371   821.1665959    332.45371308\n",
      "  -1859.73407106  -280.13175637  -264.04048909  3750.4854966\n",
      "   2082.97603654 -1927.52203999]\n",
      " [ -132.71473631  -546.29553574  1206.87477409  -235.92349252\n",
      "   -541.99254576  -689.29248532   568.77250364  2082.97603654\n",
      "   1725.45913172  -601.55219782]\n",
      " [   12.90178303  -699.97118278   277.73538465  -623.85977042\n",
      "   1403.53208464  -390.92131501   987.90572495 -1927.52203999\n",
      "   -601.55219782  1553.29647862]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:23<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 961 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5913.731\n",
      "w[1]     289.311\n",
      "w[2]   -1408.271\n",
      "w[3]    -318.388\n",
      "w[4]   -1861.095\n",
      "w[5]     280.826\n",
      "w[6]    2225.783\n",
      "w[7]    1045.059\n",
      "w[8]   -1790.438\n",
      "w[9]    1045.213\n",
      "Name: mean, dtype: float64\n",
      "[[ 3.03707358e+02  7.62319535e+01 -1.32364962e+02  2.24603361e+01\n",
      "  -1.58357001e+02  5.77298533e+01  6.50881481e+01  9.37920022e+01\n",
      "  -1.34602339e+02  2.84338968e+00]\n",
      " [ 7.62319535e+01  7.78365995e+02 -8.68013433e+02  5.51112800e+02\n",
      "  -6.41440401e+02  6.50764965e+02 -9.78872983e+02  1.25536382e+02\n",
      "  -5.69823916e+02 -7.02839201e+02]\n",
      " [-1.32364962e+02 -8.68013433e+02  1.24496064e+03 -5.44153182e+02\n",
      "   2.62746564e+02 -8.32544074e+02  1.03148325e+03  8.55080515e+02\n",
      "   1.24776210e+03  2.77901992e+02]\n",
      " [ 2.24603361e+01  5.51112800e+02 -5.44153182e+02  4.09697335e+02\n",
      "  -5.58120725e+02  4.35278368e+02 -7.18797511e+02  3.25857229e+02\n",
      "  -2.49065051e+02 -6.25885025e+02]\n",
      " [-1.58357001e+02 -6.41440401e+02  2.62746564e+02 -5.58120725e+02\n",
      "   1.37410719e+03 -3.47169887e+02  8.15188360e+02 -1.88398611e+03\n",
      "  -5.48241296e+02  1.41682849e+03]\n",
      " [ 5.77298533e+01  6.50764965e+02 -8.32544074e+02  4.35278368e+02\n",
      "  -3.47169887e+02  5.87509755e+02 -8.07974974e+02 -3.00114422e+02\n",
      "  -7.14857000e+02 -3.91270438e+02]\n",
      " [ 6.50881481e+01 -9.78872983e+02  1.03148325e+03 -7.18797511e+02\n",
      "   8.15188360e+02 -8.07974974e+02  1.32349879e+03 -2.43448621e+02\n",
      "   5.96720922e+02  9.86741226e+02]\n",
      " [ 9.37920022e+01  1.25536382e+02  8.55080515e+02  3.25857229e+02\n",
      "  -1.88398611e+03 -3.00114422e+02 -2.43448621e+02  3.82208180e+03\n",
      "   2.13389817e+03 -1.94758799e+03]\n",
      " [-1.34602339e+02 -5.69823916e+02  1.24776210e+03 -2.49065051e+02\n",
      "  -5.48241296e+02 -7.14857000e+02  5.96720922e+02  2.13389817e+03\n",
      "   1.77519870e+03 -6.07036177e+02]\n",
      " [ 2.84338968e+00 -7.02839201e+02  2.77901992e+02 -6.25885025e+02\n",
      "   1.41682849e+03 -3.91270438e+02  9.86741226e+02 -1.94758799e+03\n",
      "  -6.07036177e+02  1.56195130e+03]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 12:12<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1123 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5914.306\n",
      "w[1]     290.822\n",
      "w[2]   -1411.237\n",
      "w[3]    -317.643\n",
      "w[4]   -1860.421\n",
      "w[5]     282.568\n",
      "w[6]    2224.257\n",
      "w[7]    1040.961\n",
      "w[8]   -1794.324\n",
      "w[9]    1046.133\n",
      "Name: mean, dtype: float64\n",
      "[[  302.04546604    73.66767087  -135.95436519    19.12118228\n",
      "   -144.09984883    58.22942697    68.5179852     67.72697405\n",
      "   -147.28360448    17.22152866]\n",
      " [   73.66767087   753.8697401   -838.57334963   534.2250121\n",
      "   -624.61229974   629.38186866  -948.27882329   129.17313163\n",
      "   -547.24206396  -684.37959761]\n",
      " [ -135.95436519  -838.57334963  1212.82754241  -522.5645337\n",
      "    240.88159785  -807.5442642    990.79231382   857.09110961\n",
      "   1227.24766991   250.09394135]\n",
      " [   19.12118228   534.2250121   -522.5645337    398.48707059\n",
      "   -547.81966697   420.16589058  -698.70235978   331.84913426\n",
      "   -230.76256011  -615.45045683]\n",
      " [ -144.09984883  -624.61229974   240.88159785  -547.81966697\n",
      "   1357.82481534  -332.91930099   800.87766009 -1881.58966456\n",
      "   -566.20273322  1406.40772678]\n",
      " [   58.22942697   629.38186866  -807.5442642    420.16589058\n",
      "   -332.91930099   568.88304195  -779.75157324  -297.15665023\n",
      "   -696.44301491  -374.02800039]\n",
      " [   68.5179852   -948.27882329   990.79231382  -698.70235978\n",
      "    800.87766009  -779.75157324  1285.95895136  -262.60118796\n",
      "    559.7810809    970.93067056]\n",
      " [   67.72697405   129.17313163   857.09110961   331.84913426\n",
      "  -1881.58966456  -297.15665023  -262.60118796  3822.21080631\n",
      "   2142.25204315 -1960.52504667]\n",
      " [ -147.28360448  -547.24206396  1227.24766991  -230.76256011\n",
      "   -566.20273322  -696.44301491   559.7810809   2142.25204315\n",
      "   1767.73090367  -635.40650978]\n",
      " [   17.22152866  -684.37959761   250.09394135  -615.45045683\n",
      "   1406.40772678  -374.02800039   970.93067056 -1960.52504667\n",
      "   -635.40650978  1557.68151257]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:59<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 993 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5914.905\n",
      "w[1]     292.988\n",
      "w[2]   -1414.840\n",
      "w[3]    -316.408\n",
      "w[4]   -1860.429\n",
      "w[5]     284.820\n",
      "w[6]    2221.870\n",
      "w[7]    1037.297\n",
      "w[8]   -1798.485\n",
      "w[9]    1046.283\n",
      "Name: mean, dtype: float64\n",
      "[[  301.03269302    76.85292615  -141.09692311    21.19006415\n",
      "   -143.15051485    61.70201555    63.93090782    61.18073674\n",
      "   -153.26255064    17.23955014]\n",
      " [   76.85292615   738.17036075  -828.16809307   521.04985713\n",
      "   -602.14134037   618.67278574  -925.18867102   104.25132947\n",
      "   -551.05919209  -657.46229095]\n",
      " [ -141.09692311  -828.16809307  1208.03276033  -513.13007699\n",
      "    224.15769036  -801.01852726   973.60838483   878.85009199\n",
      "   1234.19949253   228.52966757]\n",
      " [   21.19006415   521.04985713  -513.13007699   387.62839987\n",
      "   -529.81071556   410.94781803  -679.72777605   313.02416798\n",
      "   -232.46273764  -594.10950233]\n",
      " [ -143.15051485  -602.14134037   224.15769036  -529.81071556\n",
      "   1325.46293476  -317.38058045   771.03724634 -1847.95282818\n",
      "   -564.31993134  1371.00845271]\n",
      " [   61.70201555   618.67278574  -801.01852726   410.94781803\n",
      "   -317.38058045   561.68512295  -763.23057779  -315.17454872\n",
      "   -700.20904915  -354.66859628]\n",
      " [   63.93090782  -925.18867102   973.60838483  -679.72777605\n",
      "    771.03724634  -763.23057779  1252.24075938  -232.85231336\n",
      "    561.23838988   934.7285815 ]\n",
      " [   61.18073674   104.25132947   878.85009199   313.02416798\n",
      "  -1847.95282818  -315.17454872  -232.85231336  3792.139849\n",
      "   2146.82862431 -1926.91572554]\n",
      " [ -153.26255064  -551.05919209  1234.19949253  -232.46273764\n",
      "   -564.31993134  -700.20904915   561.23838988  2146.82862431\n",
      "   1776.03824819  -636.64912275]\n",
      " [   17.23955014  -657.46229095   228.52966757  -594.10950233\n",
      "   1371.00845271  -354.66859628   934.7285815  -1926.91572554\n",
      "   -636.64912275  1518.08397819]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:55<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 982 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5915.400\n",
      "w[1]     294.067\n",
      "w[2]   -1417.313\n",
      "w[3]    -315.964\n",
      "w[4]   -1859.392\n",
      "w[5]     286.196\n",
      "w[6]    2220.865\n",
      "w[7]    1033.136\n",
      "w[8]   -1802.034\n",
      "w[9]    1047.571\n",
      "Name: mean, dtype: float64\n",
      "[[  303.19275546    81.30558898  -146.16397378    24.23599521\n",
      "   -147.89331938    65.3156712     59.19560041    63.33449585\n",
      "   -156.50746373    13.07249107]\n",
      " [   81.30558898   729.23934335  -822.27727482   513.3891676\n",
      "   -590.9638039    612.39283172  -910.57355447    92.46023972\n",
      "   -553.00866373  -642.30482928]\n",
      " [ -146.16397378  -822.27727482  1200.36740785  -508.890493\n",
      "    224.69665574  -795.19885308   963.3247564    870.43447522\n",
      "   1226.79701926   225.69896657]\n",
      " [   24.23599521   513.3891676   -508.890493     380.89573732\n",
      "   -518.30902399   405.94763106  -667.49422746   299.11202882\n",
      "   -236.0499163   -579.52196448]\n",
      " [ -147.89331938  -590.9638039    224.69665574  -518.30902399\n",
      "   1297.2437411   -312.73154469   752.19666143 -1802.7744533\n",
      "   -544.11265011  1337.4270303 ]\n",
      " [   65.3156712    612.39283172  -795.19885308   405.94763106\n",
      "   -312.73154469   556.56162445  -752.90714901  -316.72649666\n",
      "   -697.78096994  -347.13614243]\n",
      " [   59.19560041  -910.57355447   963.3247564   -667.49422746\n",
      "    752.19666143  -752.90714901  1229.73492738  -213.49679545\n",
      "    563.30484764   910.80367276]\n",
      " [   63.33449585    92.46023972   870.43447522   299.11202882\n",
      "  -1802.7744533   -316.72649666  -213.49679545  3712.37375864\n",
      "   2107.65390195 -1876.77750808]\n",
      " [ -156.50746373  -553.00866373  1226.79701926  -236.0499163\n",
      "   -544.11265011  -697.78096994   563.30484764  2107.65390195\n",
      "   1755.69998686  -616.91594462]\n",
      " [   13.07249107  -642.30482928   225.69896657  -579.52196448\n",
      "   1337.4270303   -347.13614243   910.80367276 -1876.77750808\n",
      "   -616.91594462  1478.80363056]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:57<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 988 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5915.706\n",
      "w[1]     295.320\n",
      "w[2]   -1420.333\n",
      "w[3]    -315.473\n",
      "w[4]   -1857.754\n",
      "w[5]     287.876\n",
      "w[6]    2219.584\n",
      "w[7]    1027.493\n",
      "w[8]   -1806.518\n",
      "w[9]    1049.370\n",
      "Name: mean, dtype: float64\n",
      "[[  299.91083235    80.78310851  -143.46396138    24.67973491\n",
      "   -149.40016763    64.30520603    57.71145123    68.64198353\n",
      "   -151.54514605     9.53716685]\n",
      " [   80.78310851   717.10003068  -809.06924011   504.64663248\n",
      "   -581.00007188   602.27271103  -894.91110798    90.01321637\n",
      "   -544.64024778  -630.78103396]\n",
      " [ -143.46396138  -809.06924011  1184.11203544  -500.03756716\n",
      "    215.96420997  -783.64873953   947.73695137   867.71414468\n",
      "   1213.69716106   216.72725016]\n",
      " [   24.67973491   504.64663248  -500.03756716   374.36079558\n",
      "   -510.42926898   398.84229169  -655.66200338   295.5151447\n",
      "   -231.43398446  -569.97340777]\n",
      " [ -149.40016763  -581.00007188   215.96420997  -510.42926898\n",
      "   1286.45882771  -305.04092561   737.99084965 -1794.359601\n",
      "   -546.55167705  1323.9675187 ]\n",
      " [   64.30520603   602.27271103  -783.64873953   398.84229169\n",
      "   -305.04092561   547.96691073  -740.24100209  -317.20624137\n",
      "   -689.67559731  -338.54614931]\n",
      " [   57.71145123  -894.91110798   947.73695137  -655.66200338\n",
      "    737.99084965  -740.24100209  1208.09864423  -206.59880646\n",
      "    555.63075373   893.19380751]\n",
      " [   68.64198353    90.01321637   867.71414468   295.5151447\n",
      "  -1794.359601    -317.20624137  -206.59880646  3695.91437931\n",
      "   2097.97657301 -1864.24581927]\n",
      " [ -151.54514605  -544.64024778  1213.69716106  -231.43398446\n",
      "   -546.55167705  -689.67559731   555.63075373  2097.97657301\n",
      "   1741.47657581  -617.28887456]\n",
      " [    9.53716685  -630.78103396   216.72725016  -569.97340777\n",
      "   1323.9675187   -338.54614931   893.19380751 -1864.24581927\n",
      "   -617.28887456  1461.10990605]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:29<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 954 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5916.369\n",
      "w[1]     296.518\n",
      "w[2]   -1422.900\n",
      "w[3]    -314.944\n",
      "w[4]   -1856.986\n",
      "w[5]     289.325\n",
      "w[6]    2218.502\n",
      "w[7]    1023.651\n",
      "w[8]   -1810.049\n",
      "w[9]    1050.463\n",
      "Name: mean, dtype: float64\n",
      "[[ 3.03281065e+02  8.84109227e+01 -1.51592664e+02  2.99680501e+01\n",
      "  -1.57891993e+02  7.03662699e+01  4.95037423e+01  7.33910450e+01\n",
      "  -1.56148819e+02  1.92776108e+00]\n",
      " [ 8.84109227e+01  7.30706363e+02 -8.31666249e+02  5.12097324e+02\n",
      "  -5.83312126e+02  6.16059685e+02 -9.07926753e+02  7.03969448e+01\n",
      "  -5.70271373e+02 -6.29965043e+02]\n",
      " [-1.51592664e+02 -8.31666249e+02  1.21833114e+03 -5.13540082e+02\n",
      "   2.22844735e+02 -8.05606499e+02  9.72169879e+02  8.92013178e+02\n",
      "   1.24938379e+03  2.21231668e+02]\n",
      " [ 2.99680501e+01  5.12097324e+02 -5.13540082e+02  3.78089264e+02\n",
      "  -5.10402732e+02  4.06741002e+02 -6.62065392e+02  2.81581227e+02\n",
      "  -2.47848699e+02 -5.67518572e+02]\n",
      " [-1.57891993e+02 -5.83312126e+02  2.22844735e+02 -5.10402732e+02\n",
      "   1.28572880e+03 -3.08028420e+02  7.35918885e+02 -1.78583514e+03\n",
      "  -5.36019276e+02  1.31841691e+03]\n",
      " [ 7.03662699e+01  6.16059685e+02 -8.05606499e+02  4.06741002e+02\n",
      "  -3.08028420e+02  5.61695438e+02 -7.54439270e+02 -3.35047343e+02\n",
      "  -7.13719343e+02 -3.39378181e+02]\n",
      " [ 4.95037423e+01 -9.07926753e+02  9.72169879e+02 -6.62065392e+02\n",
      "   7.35918885e+02 -7.54439270e+02  1.21977646e+03 -1.78326162e+02\n",
      "   5.86201204e+02  8.87392429e+02]\n",
      " [ 7.33910450e+01  7.03969448e+01  8.92013178e+02  2.81581227e+02\n",
      "  -1.78583514e+03 -3.35047343e+02 -1.78326162e+02  3.70697309e+03\n",
      "   2.11791627e+03 -1.85070956e+03]\n",
      " [-1.56148819e+02 -5.70271373e+02  1.24938379e+03 -2.47848699e+02\n",
      "  -5.36019276e+02 -7.13719343e+02  5.86201204e+02  2.11791627e+03\n",
      "   1.77543930e+03 -6.06604960e+02]\n",
      " [ 1.92776108e+00 -6.29965043e+02  2.21231668e+02 -5.67518572e+02\n",
      "   1.31841691e+03 -3.39378181e+02  8.87392429e+02 -1.85070956e+03\n",
      "  -6.06604960e+02  1.45073814e+03]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:50<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1012 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5916.688\n",
      "w[1]     297.148\n",
      "w[2]   -1425.108\n",
      "w[3]    -314.867\n",
      "w[4]   -1855.098\n",
      "w[5]     290.431\n",
      "w[6]    2218.022\n",
      "w[7]    1018.428\n",
      "w[8]   -1813.803\n",
      "w[9]    1052.594\n",
      "Name: mean, dtype: float64\n",
      "[[  310.66083754    86.48784313  -151.97138015    27.53499393\n",
      "   -156.62745424    69.10978871    56.10760942    70.31197846\n",
      "   -159.52615735     7.80166225]\n",
      " [   86.48784313   734.05554423  -843.09183627   512.87262581\n",
      "   -571.47150583   622.13451422  -912.39152964    40.24680978\n",
      "   -590.06088652  -618.88426898]\n",
      " [ -151.97138015  -843.09183627  1245.93303221  -518.20293476\n",
      "    206.07676163  -821.19074386   985.09881881   946.50032047\n",
      "   1290.95219183   204.25726451]\n",
      " [   27.53499393   512.87262581  -518.20293476   377.96012717\n",
      "   -503.0013172    409.1233344   -663.89275739   265.33967686\n",
      "   -257.12145634  -561.21305342]\n",
      " [ -156.62745424  -571.47150583   206.07676163  -503.0013172\n",
      "   1282.31851263  -296.68185459   721.61297928 -1797.40617418\n",
      "   -552.72837251  1314.57903612]\n",
      " [   69.10978871   622.13451422  -821.19074386   409.1233344\n",
      "   -296.68185459   570.46466179  -761.96639844  -368.66308075\n",
      "   -737.98437637  -328.64981922]\n",
      " [   56.10760942  -912.39152964   985.09881881  -663.89275739\n",
      "    721.61297928  -761.96639844  1228.07737417  -143.17238696\n",
      "    607.90982371   876.57867767]\n",
      " [   70.31197846    40.24680978   946.50032047   265.33967686\n",
      "  -1797.40617418  -368.66308075  -143.17238696  3780.49549281\n",
      "   2186.64338965 -1862.23096371]\n",
      " [ -159.52615735  -590.06088652  1290.95219183  -257.12145634\n",
      "   -552.72837251  -737.98437637   607.90982371  2186.64338965\n",
      "   1833.29491016  -624.59490749]\n",
      " [    7.80166225  -618.88426898   204.25726451  -561.21305342\n",
      "   1314.57903612  -328.64981922   876.57867767 -1862.23096371\n",
      "   -624.59490749  1449.24142924]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:36<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 973 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5916.878\n",
      "w[1]     297.986\n",
      "w[2]   -1427.228\n",
      "w[3]    -314.559\n",
      "w[4]   -1853.831\n",
      "w[5]     291.597\n",
      "w[6]    2217.165\n",
      "w[7]    1014.281\n",
      "w[8]   -1817.022\n",
      "w[9]    1053.970\n",
      "Name: mean, dtype: float64\n",
      "[[  306.26583821    85.20932723  -149.36578673    27.14563886\n",
      "   -154.93780635    67.88255619    55.36159092    70.61940749\n",
      "   -156.34095906     7.04173149]\n",
      " [   85.20932723   741.26460621  -859.30171442   516.15386855\n",
      "   -562.1255237    631.54848622  -921.68922204     9.29661365\n",
      "   -613.67871183  -610.4406184 ]\n",
      " [ -149.36578673  -859.30171442  1268.29553721  -528.92386913\n",
      "    209.69932773  -836.75708761  1007.37962564   963.21728565\n",
      "   1312.60844949   210.98096843]\n",
      " [   27.14563886   516.15386855  -528.92386913   378.64434251\n",
      "   -493.05263118   414.71886416  -667.66195056   238.9296389\n",
      "   -275.31925189  -551.27534495]\n",
      " [ -154.93780635  -562.1255237    209.69932773  -493.05263118\n",
      "   1249.51359611  -294.48600201   708.65527446 -1742.39635097\n",
      "   -528.05308353  1280.36965581]\n",
      " [   67.88255619   631.54848622  -836.75708761   414.71886416\n",
      "   -294.48600201   580.50340774  -774.47781271  -387.73847513\n",
      "   -756.28594652  -327.86665662]\n",
      " [   55.36159092  -921.68922204  1007.37962564  -667.66195056\n",
      "    708.65527446  -774.47781271  1238.65567031  -100.27858607\n",
      "    641.23194666   863.30263173]\n",
      " [   70.61940749     9.29661365   963.21728565   238.9296389\n",
      "  -1742.39635097  -387.73847513  -100.27858607  3711.04897854\n",
      "   2169.56368205 -1801.71409262]\n",
      " [ -156.34095906  -613.67871183  1312.60844949  -275.31925189\n",
      "   -528.05308353  -756.28594652   641.23194666  2169.56368205\n",
      "   1840.38312176  -594.80863955]\n",
      " [    7.04173149  -610.4406184    210.98096843  -551.27534495\n",
      "   1280.36965581  -327.86665662   863.30263173 -1801.71409262\n",
      "   -594.80863955  1412.16005863]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:46<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 983 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5917.295\n",
      "w[1]     298.645\n",
      "w[2]   -1429.240\n",
      "w[3]    -314.414\n",
      "w[4]   -1852.406\n",
      "w[5]     292.627\n",
      "w[6]    2216.670\n",
      "w[7]    1009.987\n",
      "w[8]   -1820.291\n",
      "w[9]    1055.659\n",
      "Name: mean, dtype: float64\n",
      "[[  300.36821777    85.10009708  -147.75064511    27.83867753\n",
      "   -153.86690787    67.72384263    52.25529317    70.94675238\n",
      "   -153.48294335     4.76860968]\n",
      " [   85.10009708   726.61783004  -840.69437617   506.23159096\n",
      "   -554.74995799   618.34690568  -902.97130542    16.66666002\n",
      "   -597.65584328  -601.46340804]\n",
      " [ -147.75064511  -840.69437617  1242.04090257  -517.0204458\n",
      "    203.98859335  -819.02148413   984.62522101   945.3600645\n",
      "   1286.53529298   204.35749855]\n",
      " [   27.83867753   506.23159096  -517.0204458    371.70570293\n",
      "   -487.29751136   405.99953539  -654.50988068   241.974779\n",
      "   -265.96767928  -543.93201662]\n",
      " [ -153.86690787  -554.74995799   203.98859335  -487.29751136\n",
      "   1238.79392691  -289.47980944   699.40983657 -1731.46629474\n",
      "   -527.82136278  1268.92741444]\n",
      " [   67.72384263   618.34690568  -819.02148413   405.99953539\n",
      "   -289.47980944   568.20333882  -757.73076173  -377.5353488\n",
      "   -739.69137112  -321.56971558]\n",
      " [   52.25529317  -902.97130542   984.62522101  -654.50988068\n",
      "    699.40983657  -757.73076173  1212.9225511   -108.74135778\n",
      "    622.7433798    850.13544363]\n",
      " [   70.94675238    16.66666002   945.3600645    241.974779\n",
      "  -1731.46629474  -377.5353488   -108.74135778  3675.73251377\n",
      "   2142.50111717 -1790.37930704]\n",
      " [ -153.48294335  -597.65584328  1286.53529298  -265.96767928\n",
      "   -527.82136278  -739.69137112   622.7433798   2142.50111717\n",
      "   1810.30921754  -594.13830777]\n",
      " [    4.76860968  -601.46340804   204.35749855  -543.93201662\n",
      "   1268.92741444  -321.56971558   850.13544363 -1790.37930704\n",
      "   -594.13830777  1397.87600374]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 12:39<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1185 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5917.700\n",
      "w[1]     300.237\n",
      "w[2]   -1432.437\n",
      "w[3]    -313.634\n",
      "w[4]   -1851.442\n",
      "w[5]     294.507\n",
      "w[6]    2214.965\n",
      "w[7]    1005.221\n",
      "w[8]   -1824.565\n",
      "w[9]    1056.774\n",
      "Name: mean, dtype: float64\n",
      "[[  306.94913193    84.0112364   -148.5216615     26.11944125\n",
      "   -153.54755433    67.07594169    57.3739691     69.14211412\n",
      "   -156.58415141     9.06132621]\n",
      " [   84.0112364    727.11056389  -841.06698191   506.80263739\n",
      "   -555.06667684   618.82967363  -904.34428479    17.0047703\n",
      "   -597.48836057  -602.63519501]\n",
      " [ -148.5216615   -841.06698191  1242.62377107  -517.32051414\n",
      "    204.83295734  -819.36851802   984.85925903   944.50718173\n",
      "   1286.76593034   204.97875412]\n",
      " [   26.11944125   506.80263739  -517.32051414   372.38255718\n",
      "   -487.47317371   406.52659394  -656.29330995   242.16620344\n",
      "   -265.64800988  -545.28996985]\n",
      " [ -153.54755433  -555.06667684   204.83295734  -487.47317371\n",
      "   1238.09342044  -290.05503249   700.00139765 -1729.56804788\n",
      "   -526.43572409  1268.56358014]\n",
      " [   67.07594169   618.82967363  -819.36851802   406.52659394\n",
      "   -290.05503249   568.61709393  -758.84898747  -376.8068059\n",
      "   -739.44484596  -322.7230237 ]\n",
      " [   57.3739691   -904.34428479   984.85925903  -656.29330995\n",
      "    700.00139765  -758.84898747  1217.73617811  -109.99834268\n",
      "    620.99683176   854.08837411]\n",
      " [   69.14211412    17.0047703    944.50718173   242.16620344\n",
      "  -1729.56804788  -376.8068059   -109.99834268  3671.8718696\n",
      "   2140.61367719 -1789.55556172]\n",
      " [ -156.58415141  -597.48836057  1286.76593034  -265.64800988\n",
      "   -526.43572409  -739.44484596   620.99683176  2140.61367719\n",
      "   1810.43281306  -594.4439875 ]\n",
      " [    9.06132621  -602.63519501   204.97875412  -545.28996985\n",
      "   1268.56358014  -322.7230237    854.08837411 -1789.55556172\n",
      "   -594.4439875   1400.28429244]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:36<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1039 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5918.258\n",
      "w[1]     301.312\n",
      "w[2]   -1434.507\n",
      "w[3]    -313.103\n",
      "w[4]   -1851.135\n",
      "w[5]     295.714\n",
      "w[6]    2213.946\n",
      "w[7]    1002.612\n",
      "w[8]   -1827.213\n",
      "w[9]    1057.327\n",
      "Name: mean, dtype: float64\n",
      "[[ 3.14620131e+02  8.87450507e+01 -1.53063990e+02  2.92053987e+01\n",
      "  -1.63147063e+02  7.01021682e+01  5.50798254e+01  7.89947383e+01\n",
      "  -1.57748825e+02  2.98777995e+00]\n",
      " [ 8.87450507e+01  7.61070524e+02 -8.75393174e+02  5.31634327e+02\n",
      "  -5.90082070e+02  6.45638974e+02 -9.46877867e+02  3.69558333e+01\n",
      "  -6.14306457e+02 -6.39999926e+02]\n",
      " [-1.53063990e+02 -8.75393174e+02  1.27746583e+03 -5.42378326e+02\n",
      "   2.39689533e+02 -8.46505179e+02  1.02788733e+03  9.25296798e+02\n",
      "   1.30416837e+03  2.42454332e+02]\n",
      " [ 2.92053987e+01  5.31634327e+02 -5.42378326e+02  3.90577192e+02\n",
      "  -5.12943233e+02  4.26155318e+02 -6.87613893e+02  2.56613097e+02\n",
      "  -2.77882288e+02 -5.72660316e+02]\n",
      " [-1.63147063e+02 -5.90082070e+02  2.39689533e+02 -5.12943233e+02\n",
      "   1.27821609e+03 -3.17138018e+02  7.41584594e+02 -1.75657992e+03\n",
      "  -5.10784561e+02  1.30834237e+03]\n",
      " [ 7.01021682e+01  6.45638974e+02 -8.46505179e+02  4.26155318e+02\n",
      "  -3.17138018e+02  5.89841232e+02 -7.92763064e+02 -3.61905557e+02\n",
      "  -7.52897406e+02 -3.52101379e+02]\n",
      " [ 5.50798254e+01 -9.46877867e+02  1.02788733e+03 -6.87613893e+02\n",
      "   7.41584594e+02 -7.92763064e+02  1.27291564e+03 -1.31688258e+02\n",
      "   6.42463788e+02  9.00605584e+02]\n",
      " [ 7.89947383e+01  3.69558333e+01  9.25296798e+02  2.56613097e+02\n",
      "  -1.75657992e+03 -3.61905557e+02 -1.31688258e+02  3.69402712e+03\n",
      "   2.13366283e+03 -1.81367064e+03]\n",
      " [-1.57748825e+02 -6.14306457e+02  1.30416837e+03 -2.77882288e+02\n",
      "  -5.10784561e+02 -7.52897406e+02  6.42463788e+02  2.13366283e+03\n",
      "   1.81986272e+03 -5.76744299e+02]\n",
      " [ 2.98777995e+00 -6.39999926e+02  2.42454332e+02 -5.72660316e+02\n",
      "   1.30834237e+03 -3.52101379e+02  9.00605584e+02 -1.81367064e+03\n",
      "  -5.76744299e+02  1.44197448e+03]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 10:06<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1003 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5918.617\n",
      "w[1]     302.837\n",
      "w[2]   -1437.449\n",
      "w[3]    -312.327\n",
      "w[4]   -1850.408\n",
      "w[5]     297.467\n",
      "w[6]    2212.280\n",
      "w[7]     998.478\n",
      "w[8]   -1831.041\n",
      "w[9]    1058.173\n",
      "Name: mean, dtype: float64\n",
      "[[  310.35132608    87.79332583  -154.91682528    28.07732452\n",
      "   -154.70667128    70.82977018    54.51981405    63.96125008\n",
      "   -163.9977715      9.49562058]\n",
      " [   87.79332583   772.44229276  -883.50350812   540.83197932\n",
      "   -605.73986695   653.46348962  -962.76197405    53.35689116\n",
      "   -613.10572754  -658.12195741]\n",
      " [ -154.91682528  -883.50350812  1289.67677076  -547.1524695\n",
      "    241.04213119  -854.34823619  1037.04716027   935.73772438\n",
      "   1317.50631081   243.52339999]\n",
      " [   28.07732452   540.83197932  -547.1524695    398.48339029\n",
      "   -528.52823611   431.82130149  -700.8790886    276.31290748\n",
      "   -272.94436567  -590.61167756]\n",
      " [ -154.70667128  -605.73986695   241.04213119  -528.52823611\n",
      "   1312.71369799  -324.75154631   768.41981479 -1809.84853856\n",
      "   -533.72897607  1351.1398129 ]\n",
      " [   70.82977018   653.46348962  -854.34823619   431.82130149\n",
      "   -324.75154631   595.97289357  -802.67472758  -357.96786133\n",
      "   -757.0195616   -360.42163007]\n",
      " [   54.51981405  -962.76197405  1037.04716027  -700.8790886\n",
      "    768.41981479  -802.67472758  1294.4038169   -164.55677637\n",
      "    635.72918855   930.0551976 ]\n",
      " [   63.96125008    53.35689116   935.73772438   276.31290748\n",
      "  -1809.84853856  -357.96786133  -164.55677637  3789.17493005\n",
      "   2183.68650659 -1880.22393057]\n",
      " [ -163.9977715   -613.10572754  1317.50631081  -272.94436567\n",
      "   -533.72897607  -757.0195616    635.72918855  2183.68650659\n",
      "   1851.23643049  -604.75416898]\n",
      " [    9.49562058  -658.12195741   243.52339999  -590.61167756\n",
      "   1351.1398129   -360.42163007   930.0551976  -1880.22393057\n",
      "   -604.75416898  1492.62454084]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 10:24<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1015 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5919.067\n",
      "w[1]     304.754\n",
      "w[2]   -1440.615\n",
      "w[3]    -311.222\n",
      "w[4]   -1850.404\n",
      "w[5]     299.461\n",
      "w[6]    2210.124\n",
      "w[7]     995.248\n",
      "w[8]   -1834.677\n",
      "w[9]    1058.264\n",
      "Name: mean, dtype: float64\n",
      "[[  308.01869858    77.8927366   -143.32836921    21.27366984\n",
      "   -146.49737393    62.43041883    66.24482307    62.85610731\n",
      "   -155.82490705    17.68905017]\n",
      " [   77.8927366    749.73724974  -852.69514441   526.609844\n",
      "   -591.8183001    632.95100087  -938.93674537    63.2393701\n",
      "   -585.05693946  -647.16593216]\n",
      " [ -143.32836921  -852.69514441  1256.38404709  -525.60496727\n",
      "    208.38574561  -829.72977012  1002.62076565   952.64964236\n",
      "   1298.29797271   212.99906949]\n",
      " [   21.27366984   526.609844    -525.60496727   390.17141718\n",
      "   -523.37430113   418.13361258  -686.57161035   290.42041248\n",
      "   -250.40421038  -587.87725353]\n",
      " [ -146.49737393  -591.8183001    208.38574561  -523.37430113\n",
      "   1326.8686841   -306.8939796    756.72590192 -1865.53411844\n",
      "   -581.40088025  1369.70983645]\n",
      " [   62.43041883   632.95100087  -829.72977012   418.13361258\n",
      "   -306.8939796    578.66700945  -780.44193214  -360.60698022\n",
      "   -738.80115309  -344.60819312]\n",
      " [   66.24482307  -938.93674537  1002.62076565  -686.57161035\n",
      "    756.72590192  -780.44193214  1270.40442265  -181.73958011\n",
      "    601.67715406   922.41845736]\n",
      " [   62.85610731    63.2393701    952.64964236   290.42041248\n",
      "  -1865.53411844  -360.60698022  -181.73958011  3893.68876438\n",
      "   2238.60951817 -1940.71559447]\n",
      " [ -155.82490705  -585.05693946  1298.29797271  -250.40421038\n",
      "   -581.40088025  -738.80115309   601.67715406  2238.60951817\n",
      "   1858.30245364  -652.93690882]\n",
      " [   17.68905017  -647.16593216   212.99906949  -587.87725353\n",
      "   1369.70983645  -344.60819312   922.41845736 -1940.71559447\n",
      "   -652.93690882  1516.10764415]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 10:03<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1002 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5919.333\n",
      "w[1]     306.048\n",
      "w[2]   -1443.119\n",
      "w[3]    -310.560\n",
      "w[4]   -1849.759\n",
      "w[5]     300.955\n",
      "w[6]    2208.692\n",
      "w[7]     991.693\n",
      "w[8]   -1837.944\n",
      "w[9]    1058.990\n",
      "Name: mean, dtype: float64\n",
      "[[  302.93797466    73.75145156  -135.0004681     19.55603375\n",
      "   -146.65807309    57.90141996    68.54227646    71.95296241\n",
      "   -144.98499509    14.89744778]\n",
      " [   73.75145156   738.51977793  -834.67337931   520.27788808\n",
      "   -590.26189888   621.58846029  -927.10946066    79.25175932\n",
      "   -564.9039655   -646.87900961]\n",
      " [ -135.0004681   -834.67337931  1235.1134498   -513.60835376\n",
      "    191.56634803  -814.66957168   983.51093342   957.0809052\n",
      "   1283.17869297   198.3414866 ]\n",
      " [   19.55603375   520.27788808  -513.60835376   387.01509069\n",
      "   -526.0249423    410.9393928   -679.79854419   306.80254813\n",
      "   -234.91585674  -591.09203668]\n",
      " [ -146.65807309  -590.26189888   191.56634803  -526.0249423\n",
      "   1351.85535629  -299.58447299   756.51419464 -1921.84693928\n",
      "   -616.11321367  1395.9813437 ]\n",
      " [   57.90141996   621.58846029  -814.66957168   410.9393928\n",
      "   -299.58447299   568.45051615  -768.22675697  -356.61318868\n",
      "   -725.52805609  -338.43246367]\n",
      " [   68.54227646  -927.10946066   983.51093342  -679.79854419\n",
      "    756.51419464  -768.22675697  1256.85306977  -200.78506947\n",
      "    580.01111946   922.39750231]\n",
      " [   71.95296241    79.25175932   957.0809052    306.80254813\n",
      "  -1921.84693928  -356.61318868  -200.78506947  3986.19735605\n",
      "   2277.22353066 -1996.63853058]\n",
      " [ -144.98499509  -564.9039655   1283.17869297  -234.91585674\n",
      "   -616.11321367  -725.52805609   580.01111946  2277.22353066\n",
      "   1860.79679388  -685.29715786]\n",
      " [   14.89744778  -646.87900961   198.3414866   -591.09203668\n",
      "   1395.9813437   -338.43246367   922.39750231 -1996.63853058\n",
      "   -685.29715786  1542.30247186]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 09:50<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 994 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5919.660\n",
      "w[1]     306.998\n",
      "w[2]   -1445.279\n",
      "w[3]    -310.156\n",
      "w[4]   -1848.808\n",
      "w[5]     302.169\n",
      "w[6]    2207.743\n",
      "w[7]     987.995\n",
      "w[8]   -1841.043\n",
      "w[9]    1060.105\n",
      "Name: mean, dtype: float64\n",
      "[[  302.34546902    76.61035065  -134.15979408    22.62260202\n",
      "   -155.49818711    58.72722514    63.95488602    86.66174128\n",
      "   -138.24932223     5.01441268]\n",
      " [   76.61035065   750.35842286  -840.48770716   530.35572684\n",
      "   -613.98175614   628.37721386  -942.05045534   110.31529662\n",
      "   -556.91239704  -671.37312052]\n",
      " [ -134.15979408  -840.48770716  1239.590686    -518.3012963\n",
      "    198.97652488  -818.86563361   991.73589633   950.11730001\n",
      "   1283.22442344   207.14021806]\n",
      " [   22.62260202   530.35572684  -518.3012963    395.61393766\n",
      "   -547.05700037   416.55777787  -692.23534463   334.82088126\n",
      "   -227.44239756  -612.47875881]\n",
      " [ -155.49818711  -613.98175614   198.97652488  -547.05700037\n",
      "   1408.71052549  -311.17322044   785.50810753 -2003.05696879\n",
      "   -642.06081063  1453.17095107]\n",
      " [   58.72722514   628.37721386  -818.86563361   416.55777787\n",
      "   -311.17322044   572.76693373  -777.07383275  -342.83082847\n",
      "   -722.99002213  -350.80575283]\n",
      " [   63.95488602  -942.05045534   991.73589633  -692.23534463\n",
      "    785.50810753  -777.07383275  1275.0779875   -237.58575663\n",
      "    571.75165486   951.78677964]\n",
      " [   86.66174128   110.31529662   950.11730001   334.82088126\n",
      "  -2003.05696879  -342.83082847  -237.58575663  4105.90625684\n",
      "   2317.80277849 -2076.92596651]\n",
      " [ -138.24932223  -556.91239704  1283.22442344  -227.44239756\n",
      "   -642.06081063  -722.99002213   571.75165486  2317.80277849\n",
      "   1875.79255691  -709.66181326]\n",
      " [    5.01441268  -671.37312052   207.14021806  -612.47875881\n",
      "   1453.17095107  -350.80575283   951.78677964 -2076.92596651\n",
      "   -709.66181326  1599.34923367]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 10:39<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1043 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5920.247\n",
      "w[1]     308.496\n",
      "w[2]   -1447.898\n",
      "w[3]    -309.345\n",
      "w[4]   -1848.704\n",
      "w[5]     303.763\n",
      "w[6]    2206.197\n",
      "w[7]     985.142\n",
      "w[8]   -1844.185\n",
      "w[9]    1060.428\n",
      "Name: mean, dtype: float64\n",
      "[[  302.89683466    83.33314811  -136.53669725    28.61300237\n",
      "   -169.85621762    62.24608481    54.77368969   106.68670957\n",
      "   -131.77499908   -10.47627438]\n",
      " [   83.33314811   753.48871507  -849.95714054   530.67782696\n",
      "   -609.97335776   632.85431987  -941.85708432    93.8977833\n",
      "   -572.06856666  -663.43245382]\n",
      " [ -136.53669725  -849.95714054  1252.51102035  -524.33998197\n",
      "    203.40686815  -827.6385042   1002.6332856    956.40253724\n",
      "   1295.56757487   211.22755193]\n",
      " [   28.61300237   530.67782696  -524.33998197   394.04839518\n",
      "   -541.00726509   418.60295071  -688.77041963   318.72762545\n",
      "   -239.85197159  -602.57269269]\n",
      " [ -169.85621762  -609.97335776   203.40686815  -541.00726509\n",
      "   1398.86286609  -310.07253009   771.50128073 -1981.87397527\n",
      "   -626.62661002  1433.98583177]\n",
      " [   62.24608481   632.85431987  -827.6385042    418.60295071\n",
      "   -310.07253009   577.78243891  -780.62597271  -353.70700458\n",
      "   -734.57067082  -347.94034551]\n",
      " [   54.77368969  -941.85708432  1002.6332856   -688.77041963\n",
      "    771.50128073  -780.62597271  1268.56731501  -203.85849482\n",
      "    595.68746987   931.51247244]\n",
      " [  106.68670957    93.8977833    956.40253724   318.72762545\n",
      "  -1981.87397527  -353.70700458  -203.85849482  4077.23978784\n",
      "   2305.48323864 -2041.37506195]\n",
      " [ -131.77499908  -572.06856666  1295.56757487  -239.85197159\n",
      "   -626.62661002  -734.57067082   595.68746987  2305.48323864\n",
      "   1877.83909604  -688.24284313]\n",
      " [  -10.47627438  -663.43245382   211.22755193  -602.57269269\n",
      "   1433.98583177  -347.94034551   931.51247244 -2041.37506195\n",
      "   -688.24284313  1569.25102967]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 10:58<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1066 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5920.523\n",
      "w[1]     309.790\n",
      "w[2]   -1450.089\n",
      "w[3]    -308.606\n",
      "w[4]   -1848.602\n",
      "w[5]     305.128\n",
      "w[6]    2204.735\n",
      "w[7]     982.767\n",
      "w[8]   -1846.752\n",
      "w[9]    1060.576\n",
      "Name: mean, dtype: float64\n",
      "[[  298.54832855    80.72091585  -131.54425378    27.57097144\n",
      "   -168.85868115    59.55842419    55.59692107   110.47264525\n",
      "   -125.53152792   -11.7397088 ]\n",
      " [   80.72091585   735.51485319  -825.82285791   519.06951365\n",
      "   -601.92261117   616.25490783  -920.25330056   105.58875842\n",
      "   -549.71023157  -654.86890935]\n",
      " [ -131.54425378  -825.82285791  1214.35798637  -510.21617214\n",
      "    201.71723976  -803.19787566   975.13611123   920.41950229\n",
      "   1252.87349324   210.17904035]\n",
      " [   27.57097144   519.06951365  -510.21617214   386.15689939\n",
      "   -533.64483541   408.40957502  -674.29070714   321.34234733\n",
      "   -228.62037726  -594.39409481]\n",
      " [ -168.85868115  -601.92261117   201.71723976  -533.64483541\n",
      "   1379.4324354   -306.22637313   760.60698191 -1952.9737078\n",
      "   -616.34018696  1413.43560892]\n",
      " [   59.55842419   616.25490783  -803.19787566   408.40957502\n",
      "   -306.22637313   561.62074308  -761.08820575  -335.06067039\n",
      "   -709.14897187  -343.9637216 ]\n",
      " [   55.59692107  -920.25330056   975.13611123  -674.29070714\n",
      "    760.60698191  -761.08820575  1241.16701529  -214.2802428\n",
      "    571.9947421    918.58064148]\n",
      " [  110.47264525   105.58875842   920.41950229   321.34234733\n",
      "  -1952.9737078   -335.06067039  -214.2802428   3995.22871368\n",
      "   2245.93146929 -2009.86875473]\n",
      " [ -125.53152792  -549.71023157  1252.87349324  -228.62037726\n",
      "   -616.34018696  -709.14897187   571.9947421   2245.93146929\n",
      "   1822.03168279  -675.81884822]\n",
      " [  -11.7397088   -654.86890935   210.17904035  -594.39409481\n",
      "   1413.43560892  -343.9637216    918.58064148 -2009.86875473\n",
      "   -675.81884822  1546.14574251]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 10:55<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1057 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5920.619\n",
      "w[1]     311.550\n",
      "w[2]   -1453.041\n",
      "w[3]    -307.584\n",
      "w[4]   -1848.333\n",
      "w[5]     307.002\n",
      "w[6]    2202.594\n",
      "w[7]     979.357\n",
      "w[8]   -1850.224\n",
      "w[9]    1060.765\n",
      "Name: mean, dtype: float64\n",
      "[[  305.40951937    87.73638333  -136.33481443    32.78860794\n",
      "   -183.4414323     63.70587054    49.71735021   128.06013455\n",
      "   -123.57573812   -23.78337114]\n",
      " [   87.73638333   742.17040776  -830.36125548   524.07945907\n",
      "   -616.46471946   620.11447506  -925.70805048   123.39432394\n",
      "   -547.29856426  -666.88065224]\n",
      " [ -136.33481443  -830.36125548  1217.74294564  -513.52911654\n",
      "    211.16762675  -805.95683504   978.77962905   909.36738349\n",
      "   1251.8220396    217.75884657]\n",
      " [   32.78860794   524.07945907  -513.52911654   389.97257634\n",
      "   -544.75238602   411.27292542  -678.46032305   335.12590859\n",
      "   -226.55728631  -603.67874622]\n",
      " [ -183.4414323   -616.46471946   211.16762675  -544.75238602\n",
      "   1411.23575096  -314.53183689   772.94050393 -1992.53095377\n",
      "   -622.14552579  1440.26050138]\n",
      " [   63.70587054   620.11447506  -805.95683504   411.27292542\n",
      "   -314.53183689   563.90407691  -764.19089203  -325.09059747\n",
      "   -707.96261559  -350.71470251]\n",
      " [   49.71735021  -925.70805048   978.77962905  -678.46032305\n",
      "    772.94050393  -764.19089203  1245.65952073  -229.62634654\n",
      "    569.57554095   928.87347941]\n",
      " [  128.06013455   123.39432394   909.36738349   335.12590859\n",
      "  -1992.53095377  -325.09059747  -229.62634654  4045.27627738\n",
      "   2254.00305583 -2043.6842706 ]\n",
      " [ -123.57573812  -547.29856426  1251.8220396   -226.55728631\n",
      "   -622.14552579  -707.96261559   569.57554095  2254.00305583\n",
      "   1823.97378381  -681.32317498]\n",
      " [  -23.78337114  -666.88065224   217.75884657  -603.67874622\n",
      "   1440.26050138  -350.71470251   928.87347941 -2043.6842706\n",
      "   -681.32317498  1568.98626014]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 10:33<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1046 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5920.527\n",
      "w[1]     313.082\n",
      "w[2]   -1455.780\n",
      "w[3]    -306.721\n",
      "w[4]   -1847.706\n",
      "w[5]     308.717\n",
      "w[6]    2200.660\n",
      "w[7]     975.608\n",
      "w[8]   -1853.634\n",
      "w[9]    1061.247\n",
      "Name: mean, dtype: float64\n",
      "[[  299.73577641    91.08243773  -141.59217113    35.21331371\n",
      "   -179.98947962    67.57634824    42.55937779   117.83156927\n",
      "   -129.90540121   -23.81725824]\n",
      " [   91.08243773   738.54353909  -827.08710445   521.09836843\n",
      "   -614.46767776   617.07861343  -919.08156683   123.41824283\n",
      "   -545.92539563  -662.44240697]\n",
      " [ -141.59217113  -827.08710445  1225.00484631  -508.18648284\n",
      "    192.94339473  -807.15234143   970.27180293   945.7716915\n",
      "   1273.29617372   195.05305952]\n",
      " [   35.21331371   521.09836843  -508.18648284   388.18649302\n",
      "   -547.5069413    407.73864228  -673.53031601   344.76926679\n",
      "   -219.53443236  -604.86944312]\n",
      " [ -179.98947962  -614.46767776   192.94339473  -547.5069413\n",
      "   1435.56264719  -306.65195998   774.2176749  -2049.80974453\n",
      "   -659.32746488  1467.85556849]\n",
      " [   67.57634824   617.07861343  -807.15234143   407.73864228\n",
      "   -306.65195998   562.86293699  -757.56323385  -338.9512992\n",
      "   -715.55181805  -339.79571287]\n",
      " [   42.55937779  -919.08156683   970.27180293  -673.53031601\n",
      "    774.2176749   -757.56323385  1233.33835409  -239.79551256\n",
      "    561.42386147   925.34969146]\n",
      " [  117.83156927   123.41824283   945.7716915    344.76926679\n",
      "  -2049.80974453  -338.9512992   -239.79551256  4173.44937508\n",
      "   2334.85603595 -2110.33813132]\n",
      " [ -129.90540121  -545.92539563  1273.29617372  -219.53443236\n",
      "   -659.32746488  -715.55181805   561.42386147  2334.85603595\n",
      "   1873.89994096  -724.5387024 ]\n",
      " [  -23.81725824  -662.44240697   195.05305952  -604.86944312\n",
      "   1467.85556849  -339.79571287   925.34969146 -2110.33813132\n",
      "   -724.5387024   1597.73862525]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 10:59<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1067 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5920.917\n",
      "w[1]     314.377\n",
      "w[2]   -1458.123\n",
      "w[3]    -306.029\n",
      "w[4]   -1847.407\n",
      "w[5]     310.138\n",
      "w[6]    2199.272\n",
      "w[7]     972.749\n",
      "w[8]   -1856.535\n",
      "w[9]    1061.677\n",
      "Name: mean, dtype: float64\n",
      "[[  300.11689987    95.51389078  -152.38475147    36.91432389\n",
      "   -173.45440791    73.58316219    37.69873754    96.66718235\n",
      "   -146.11893432   -17.03682774]\n",
      " [   95.51389078   763.02349614  -859.18258425   537.14228985\n",
      "   -627.53795761   639.29133678  -948.14970097   111.16546741\n",
      "   -574.30808114  -675.8793745 ]\n",
      " [ -152.38475147  -859.18258425  1276.37358947  -526.59060421\n",
      "    196.93043877  -839.55644758  1004.6430455    992.29140612\n",
      "   1330.70370694   195.92203822]\n",
      " [   36.91432389   537.14228985  -526.59060421   399.43044518\n",
      "   -559.92056953   421.35189756  -693.53343131   345.53779221\n",
      "   -232.40029355  -618.43366567]\n",
      " [ -173.45440791  -627.53795761   196.93043877  -559.92056953\n",
      "   1460.05667236  -314.00370936   795.99409667 -2084.82567383\n",
      "   -672.61717692  1498.60440309]\n",
      " [   73.58316219   639.29133678  -839.55644758   421.35189756\n",
      "   -314.00370936   584.15932895  -782.50266112  -360.63514432\n",
      "   -748.42223274  -346.090331  ]\n",
      " [   37.69873754  -948.14970097  1004.6430455   -693.53343131\n",
      "    795.99409667  -782.50266112  1268.52779402  -238.86548431\n",
      "    586.86554755   948.17147126]\n",
      " [   96.66718235   111.16546741   992.29140612   345.53779221\n",
      "  -2084.82567383  -360.63514432  -238.86548431  4277.23024494\n",
      "   2415.06813686 -2158.33044515]\n",
      " [ -146.11893432  -574.30808114  1330.70370694  -232.40029355\n",
      "   -672.61717692  -748.42223274   586.86554755  2415.06813686\n",
      "   1950.68821613  -745.35644527]\n",
      " [  -17.03682774  -675.8793745    195.92203822  -618.43366567\n",
      "   1498.60440309  -346.090331     948.17147126 -2158.33044515\n",
      "   -745.35644527  1635.30037632]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 12:39<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1243 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5921.153\n",
      "w[1]     315.100\n",
      "w[2]   -1459.920\n",
      "w[3]    -305.759\n",
      "w[4]   -1846.418\n",
      "w[5]     311.124\n",
      "w[6]    2198.568\n",
      "w[7]     969.360\n",
      "w[8]   -1859.232\n",
      "w[9]    1062.797\n",
      "Name: mean, dtype: float64\n",
      "[[  297.6511059     92.4325939   -147.81914894    35.09702218\n",
      "   -171.57356867    70.77623784    40.34645274    98.59670858\n",
      "   -141.53651666   -16.20626833]\n",
      " [   92.4325939    732.9201744   -821.45187346   516.85706345\n",
      "   -609.88296755   612.46772633  -910.8115806    121.69964225\n",
      "   -543.08745363  -656.32108019]\n",
      " [ -147.81914894  -821.45187346  1219.41045742  -503.64011628\n",
      "    191.3431326   -802.17349307   959.45727265   943.20289463\n",
      "   1269.97689605   189.26114388]\n",
      " [   35.09702218   516.85706345  -503.64011628   385.12159649\n",
      "   -543.82804235   404.22948192  -667.91429096   343.50199861\n",
      "   -216.88622835  -600.67818067]\n",
      " [ -171.57356867  -609.88296755   191.3431326   -543.82804235\n",
      "   1420.58763531  -304.83651929   771.96075195 -2028.49435699\n",
      "   -653.85592177  1456.47719238]\n",
      " [   70.77623784   612.46772633  -802.17349307   404.22948192\n",
      "   -304.83651929   558.77196686  -749.75070578  -337.10819062\n",
      "   -712.18153076  -335.61906316]\n",
      " [   40.34645274  -910.8115806    959.45727265  -667.91429096\n",
      "    771.96075195  -749.75070578  1221.40315881  -246.80257861\n",
      "    551.65805502   920.97955951]\n",
      " [   98.59670858   121.69964225   943.20289463   343.50199861\n",
      "  -2028.49435699  -337.10819062  -246.80257861  4138.83249418\n",
      "   2323.81957148 -2098.75787343]\n",
      " [ -141.53651666  -543.08745363  1269.97689605  -216.88622835\n",
      "   -653.85592177  -712.18153076   551.65805502  2323.81957148\n",
      "   1870.05162167  -725.73752228]\n",
      " [  -16.20626833  -656.32108019   189.26114388  -600.67818067\n",
      "   1456.47719238  -335.61906316   920.97955951 -2098.75787343\n",
      "   -725.73752228  1589.57831576]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 12:34<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1228 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5921.358\n",
      "w[1]     315.286\n",
      "w[2]   -1461.021\n",
      "w[3]    -305.845\n",
      "w[4]   -1845.166\n",
      "w[5]     311.619\n",
      "w[6]    2198.537\n",
      "w[7]     966.281\n",
      "w[8]   -1861.317\n",
      "w[9]    1064.221\n",
      "Name: mean, dtype: float64\n",
      "[[  293.93911305    91.15795876  -149.36812812    33.69404374\n",
      "   -163.25130887    71.14731545    40.46932478    84.19936821\n",
      "   -147.39540227    -9.42166649]\n",
      " [   91.15795876   728.93223337  -820.44786096   513.24930655\n",
      "   -600.31309875   610.53347079  -905.86841143   107.61828294\n",
      "   -547.72672239  -646.54644278]\n",
      " [ -149.36812812  -820.44786096  1221.85340576  -501.95191388\n",
      "    185.63284337  -802.58731414   956.93938186   955.00625191\n",
      "   1276.83365922   182.16413467]\n",
      " [   33.69404374   513.24930655  -501.95191388   382.06159408\n",
      "   -536.30933942   402.19645859  -663.66450259   333.40618062\n",
      "   -219.41348486  -593.20073334]\n",
      " [ -163.25130887  -600.31309875   185.63284337  -536.30933942\n",
      "   1399.71996446  -299.32919682   763.17404075 -2002.08132606\n",
      "   -649.39348889  1438.39090415]\n",
      " [   71.14731545   610.53347079  -802.58731414   402.19645859\n",
      "   -299.32919682   558.10382782  -746.74158837  -346.36401239\n",
      "   -716.29691817  -329.36564036]\n",
      " [   40.46932478  -905.86841143   956.93938186  -663.66450259\n",
      "    763.17404075  -746.74158837  1214.68821929  -235.37480039\n",
      "    554.50045397   911.2822063 ]\n",
      " [   84.19936821   107.61828294   955.00625191   333.40618062\n",
      "  -2002.08132606  -346.36401239  -235.37480039  4110.55917876\n",
      "   2324.44477363 -2078.01118495]\n",
      " [ -147.39540227  -547.72672239  1276.83365922  -219.41348486\n",
      "   -649.39348889  -716.29691817   554.50045397  2324.44477363\n",
      "   1876.60234516  -724.09557602]\n",
      " [   -9.42166649  -646.54644278   182.16413467  -593.20073334\n",
      "   1438.39090415  -329.36564036   911.2822063  -2078.01118495\n",
      "   -724.09557602  1573.53515932]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 12:02<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1190 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5921.875\n",
      "w[1]     316.168\n",
      "w[2]   -1462.923\n",
      "w[3]    -305.461\n",
      "w[4]   -1844.596\n",
      "w[5]     312.686\n",
      "w[6]    2197.758\n",
      "w[7]     963.425\n",
      "w[8]   -1863.944\n",
      "w[9]    1065.051\n",
      "Name: mean, dtype: float64\n",
      "[[  290.12334278    93.12631546  -150.96756657    35.47549486\n",
      "   -163.41316228    72.93036089    35.88175534    83.05379602\n",
      "   -148.0475452    -11.93600361]\n",
      " [   93.12631546   747.10013055  -842.70026926   525.54297069\n",
      "   -611.72321729   626.53461448  -928.31460668   102.79383866\n",
      "   -565.83182142  -659.01533047]\n",
      " [ -150.96756657  -842.70026926  1249.37641157  -516.9785198\n",
      "    198.66410705  -822.34444395   984.74884556   962.56497551\n",
      "   1299.61468543   196.80905612]\n",
      " [   35.47549486   525.54297069  -516.9785198    390.35946883\n",
      "   -544.34618529   412.97704933  -678.63733636   330.6234598\n",
      "   -231.57226252  -601.7361747 ]\n",
      " [ -163.41316228  -611.72321729   198.66410705  -544.34618529\n",
      "   1407.8052053   -309.14567416   778.03495372 -2001.41541052\n",
      "   -639.81600837  1447.96779604]\n",
      " [   72.93036089   626.53461448  -822.34444395   412.97704933\n",
      "   -309.14567416   572.24562488  -766.44002473  -351.11847795\n",
      "   -732.54958896  -340.03524945]\n",
      " [   35.88175534  -928.31460668   984.74884556  -678.63733636\n",
      "    778.03495372  -766.44002473  1241.27871871  -230.15246035\n",
      "    577.32860429   926.27653401]\n",
      " [   83.05379602   102.79383866   962.56497551   330.6234598\n",
      "  -2001.41541052  -351.11847795  -230.15246035  4117.02823376\n",
      "   2332.46889012 -2077.89321737]\n",
      " [ -148.0475452   -565.83182142  1299.61468543  -231.57226252\n",
      "   -639.81600837  -732.54958896   577.32860429  2332.46889012\n",
      "   1895.9300157   -713.01971471]\n",
      " [  -11.93600361  -659.01533047   196.80905612  -601.7361747\n",
      "   1447.96779604  -340.03524945   926.27653401 -2077.89321737\n",
      "   -713.01971471  1583.43901312]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 12:55<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1260 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5922.078\n",
      "w[1]     316.757\n",
      "w[2]   -1464.515\n",
      "w[3]    -305.269\n",
      "w[4]   -1843.584\n",
      "w[5]     313.540\n",
      "w[6]    2197.195\n",
      "w[7]     960.216\n",
      "w[8]   -1866.414\n",
      "w[9]    1066.189\n",
      "Name: mean, dtype: float64\n",
      "[[  294.10072586    94.16948002  -149.39501493    36.59531192\n",
      "   -171.30799157    72.34557382    36.27040347    96.87639113\n",
      "   -142.40242323   -18.0524012 ]\n",
      " [   94.16948002   745.96728874  -836.06002265   526.01168705\n",
      "   -620.82796524   623.3352598   -926.95004715   123.9912202\n",
      "   -552.79349167  -667.94330184]\n",
      " [ -149.39501493  -836.06002265  1229.25603332  -515.51317623\n",
      "    214.81619352  -811.74999955   978.46821735   916.52898613\n",
      "   1266.34424486   214.17212738]\n",
      " [   36.59531192   526.01168705  -515.51317623   391.12146465\n",
      "   -548.80724867   412.48967322  -678.90144466   339.22804382\n",
      "   -227.31034562  -605.8623698 ]\n",
      " [ -171.30799157  -620.82796524   214.81619352  -548.80724867\n",
      "   1408.89687318  -318.59302969   785.02868172 -1986.62805076\n",
      "   -620.42995194  1445.42339424]\n",
      " [   72.34557382   623.3352598   -811.74999955   412.48967322\n",
      "   -318.59302969   566.76847286  -763.43204123  -325.3499402\n",
      "   -714.45815465  -350.06835211]\n",
      " [   36.27040347  -926.95004715   978.46821735  -678.90144466\n",
      "    785.02868172  -763.43204123  1240.27616349  -247.79678969\n",
      "    565.58513563   933.79647155]\n",
      " [   96.87639113   123.9912202    916.52898613   339.22804382\n",
      "  -1986.62805076  -325.3499402   -247.79678969  4046.66237933\n",
      "   2267.96217023 -2056.27695711]\n",
      " [ -142.40242323  -552.79349167  1266.34424486  -227.31034562\n",
      "   -620.42995194  -714.45815465   565.58513563  2267.96217023\n",
      "   1844.87912108  -690.49935037]\n",
      " [  -18.0524012   -667.94330184   214.17212738  -605.8623698\n",
      "   1445.42339424  -350.06835211   933.79647155 -2056.27695711\n",
      "   -690.49935037  1578.07923491]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 11:54<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1211 seconds.\n",
      "The acceptance probability does not match the target. It is 0.6964981228069422, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5922.419\n",
      "w[1]     317.736\n",
      "w[2]   -1466.253\n",
      "w[3]    -304.740\n",
      "w[4]   -1843.451\n",
      "w[5]     314.595\n",
      "w[6]    2196.169\n",
      "w[7]     958.218\n",
      "w[8]   -1868.527\n",
      "w[9]    1066.445\n",
      "Name: mean, dtype: float64\n",
      "[[  293.52340498    90.80889792  -146.89899458    33.943826\n",
      "   -166.21336354    70.13291764    40.4531923     91.45454832\n",
      "   -142.76265599   -12.78314901]\n",
      " [   90.80889792   731.27222335  -818.50337546   515.98231231\n",
      "   -609.31525878   610.77265188  -909.68090562   124.05164112\n",
      "   -539.8041608   -656.53741559]\n",
      " [ -146.89899458  -818.50337546  1212.11905542  -502.52170208\n",
      "    195.37441407  -798.19838711   956.57882832   929.3904836\n",
      "   1259.2215399    193.64427355]\n",
      " [   33.943826     515.98231231  -502.52170208   384.53901393\n",
      "   -542.47064158   403.52600208  -667.42227419   342.70456704\n",
      "   -216.23619022  -599.88786449]\n",
      " [ -166.21336354  -609.31525878   195.37441407  -542.47064158\n",
      "   1408.21111002  -306.63778379   773.50602167 -2005.69549547\n",
      "   -643.05154061  1446.76163324]\n",
      " [   70.13291764   610.77265188  -798.19838711   403.52600208\n",
      "   -306.63778379   556.56883185  -748.14246298  -330.14178717\n",
      "   -706.53628073  -337.69420292]\n",
      " [   40.4531923   -909.68090562   956.57882832  -667.42227419\n",
      "    773.50602167  -748.14246298  1220.23063478  -252.31937085\n",
      "    547.56020032   922.62078465]\n",
      " [   91.45454832   124.05164112   929.3904836    342.70456704\n",
      "  -2005.69549547  -330.14178717  -252.31937085  4089.9993423\n",
      "   2296.19743194 -2079.6344029 ]\n",
      " [ -142.76265599  -539.8041608   1259.2215399   -216.23619022\n",
      "   -643.05154061  -706.53628073   547.56020032  2296.19743194\n",
      "   1851.76311744  -715.67803148]\n",
      " [  -12.78314901  -656.53741559   193.64427355  -599.88786449\n",
      "   1446.76163324  -337.69420292   922.62078465 -2079.6344029\n",
      "   -715.67803148  1581.63207372]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 11:28<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1202 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5922.849\n",
      "w[1]     318.708\n",
      "w[2]   -1467.902\n",
      "w[3]    -304.199\n",
      "w[4]   -1843.509\n",
      "w[5]     315.607\n",
      "w[6]    2195.185\n",
      "w[7]     956.616\n",
      "w[8]   -1870.440\n",
      "w[9]    1066.549\n",
      "Name: mean, dtype: float64\n",
      "[[  295.72620996    94.72638532  -155.28648818    35.6203656\n",
      "   -163.5105199     74.86765708    36.96993069    78.55657119\n",
      "   -154.54245626    -9.04318566]\n",
      " [   94.72638532   740.90661351  -829.95579877   522.40164668\n",
      "   -617.74371652   618.84576785  -920.12962916   125.31927932\n",
      "   -548.30197238  -664.04638638]\n",
      " [ -155.28648818  -829.95579877  1231.90189177  -508.34444152\n",
      "    196.78071049  -809.9388249    966.15242381   948.0085455\n",
      "   1282.89061384   191.29023375]\n",
      " [   35.6203656    522.40164668  -508.34444152   389.32750305\n",
      "   -550.69673503   408.25981788  -675.12249153   349.563728\n",
      "   -217.91345295  -608.19082157]\n",
      " [ -163.5105199   -617.74371652   196.78071049  -550.69673503\n",
      "   1427.08218211  -310.79016165   787.15166415 -2034.19405053\n",
      "   -654.48874931  1469.08569061]\n",
      " [   74.86765708   618.84576785  -809.9388249    408.25981788\n",
      "   -310.79016165   564.06269077  -755.81702732  -335.95949258\n",
      "   -718.36314048  -340.06351878]\n",
      " [   36.96993069  -920.12962916   966.15242381  -675.12249153\n",
      "    787.15166415  -755.81702732  1232.31416099  -263.70301002\n",
      "    550.45008955   935.95090217]\n",
      " [   78.55657119   125.31927932   948.0085455    349.563728\n",
      "  -2034.19405053  -335.95949258  -263.70301002  4154.8564752\n",
      "   2339.23869691 -2117.42352981]\n",
      " [ -154.54245626  -548.30197238  1282.89061384  -217.91345295\n",
      "   -654.48874931  -718.36314048   550.45008955  2339.23869691\n",
      "   1889.084589    -733.85694682]\n",
      " [   -9.04318566  -664.04638638   191.29023375  -608.19082157\n",
      "   1469.08569061  -340.06351878   935.95090217 -2117.42352981\n",
      "   -733.85694682  1608.0919062 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 18:00<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 1717 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[0]    5922.777\n",
      "w[1]     319.312\n",
      "w[2]   -1469.315\n",
      "w[3]    -303.931\n",
      "w[4]   -1842.678\n",
      "w[5]     316.420\n",
      "w[6]    2194.443\n",
      "w[7]     953.884\n",
      "w[8]   -1872.522\n",
      "w[9]    1067.334\n",
      "Name: mean, dtype: float64\n",
      "[[  298.83585649   107.38288159  -174.88577985    43.14794963\n",
      "   -165.55770823    87.47327194    22.6553405     61.59606038\n",
      "   -175.85325216   -10.56036077]\n",
      " [  107.38288159   757.33378515  -853.39027475   532.0634397\n",
      "   -628.78657625   633.68802805  -934.41866278   117.98823377\n",
      "   -570.98117109  -669.82853213]\n",
      " [ -174.88577985  -853.39027475  1268.56127781  -521.25830701\n",
      "    208.05339066  -832.24572436   985.37374758   968.93726529\n",
      "   1322.13155773   193.95210035]\n",
      " [   43.14794963   532.0634397   -521.25830701   395.20915379\n",
      "   -558.68769558   416.64246681  -683.57726117   348.49486372\n",
      "   -229.36198148  -613.11077678]\n",
      " [ -165.55770823  -628.78657625   208.05339066  -558.68769558\n",
      "   1438.17742366  -319.56618581   800.62661495 -2040.07150888\n",
      "   -648.4668714   1480.54862785]\n",
      " [   87.47327194   633.68802805  -832.24572436   416.64246681\n",
      "   -319.56618581   577.81419299  -767.98875348  -345.71283974\n",
      "   -741.22030789  -343.35217182]\n",
      " [   22.6553405   -934.41866278   985.37374758  -683.57726117\n",
      "    800.62661495  -767.98875348  1243.13689738  -264.39584255\n",
      "    567.4145513    943.12997701]\n",
      " [   61.59606038   117.98823377   968.93726529   348.49486372\n",
      "  -2040.07150888  -345.71283974  -264.39584255  4186.61049585\n",
      "   2371.18838841 -2132.6910031 ]\n",
      " [ -175.85325216  -570.98117109  1322.13155773  -229.36198148\n",
      "   -648.4668714   -741.22030789   567.4145513   2371.18838841\n",
      "   1935.02497933  -737.75133528]\n",
      " [  -10.56036077  -669.82853213   193.95210035  -613.11077678\n",
      "   1480.54862785  -343.35217182   943.12997701 -2132.6910031\n",
      "   -737.75133528  1619.75840474]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-162-7d1d6bf4f203>:7: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-162-7d1d6bf4f203>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mmu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mlikelihood\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'likelihood'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mβ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mtrace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m11000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m123\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mw_mean\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0maz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"mean\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mw_T\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"w\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymc3\\sampling.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(draws, step, init, n_init, start, trace, chain_idx, chains, cores, tune, progressbar, model, random_seed, discard_tuned_samples, compute_convergence_checks, callback, jitter_max_retries, return_inferencedata, idata_kwargs, mp_ctx, pickle_backend, **kwargs)\u001b[0m\n\u001b[0;32m    557\u001b[0m         \u001b[0m_print_step_hierarchy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m             \u001b[0mtrace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_mp_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0msample_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparallel_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPickleError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m             \u001b[0m_log\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Could not pickle model, sampling singlethreaded.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymc3\\sampling.py\u001b[0m in \u001b[0;36m_mp_sample\u001b[1;34m(draws, tune, step, chains, cores, chain, random_seed, start, progressbar, trace, model, callback, discard_tuned_samples, mp_ctx, pickle_backend, **kwargs)\u001b[0m\n\u001b[0;32m   1459\u001b[0m         \u001b[0mtraces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1461\u001b[1;33m     sampler = ps.ParallelSampler(\n\u001b[0m\u001b[0;32m   1462\u001b[0m         \u001b[0mdraws\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1463\u001b[0m         \u001b[0mtune\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymc3\\parallel_sampling.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, draws, tune, chains, cores, seeds, start_points, step_method, start_chain_num, progressbar, mp_ctx, pickle_backend)\u001b[0m\n\u001b[0;32m    429\u001b[0m                 \u001b[0mstep_method_pickled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdill\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_method\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m         self._samplers = [\n\u001b[0m\u001b[0;32m    432\u001b[0m             ProcessAdapter(\n\u001b[0;32m    433\u001b[0m                 \u001b[0mdraws\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymc3\\parallel_sampling.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m         self._samplers = [\n\u001b[1;32m--> 432\u001b[1;33m             ProcessAdapter(\n\u001b[0m\u001b[0;32m    433\u001b[0m                 \u001b[0mdraws\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[0mtune\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymc3\\parallel_sampling.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, draws, tune, step_method, step_method_pickled, chain, seed, start, mp_ctx, pickle_backend)\u001b[0m\n\u001b[0;32m    290\u001b[0m             ),\n\u001b[0;32m    291\u001b[0m         )\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m         \u001b[1;31m# Close the remote pipe, so that we get notified if the other\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;31m# end is closed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    119\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "while count < 1000:\n",
    "    with pm.Model() as our_first_model:\n",
    "        w = pm.MvNormal('w', mu=w_mean, cov=w_cov, shape=(num_of_vars, ))\n",
    "        mu = pm.math.dot(X, w)\n",
    "        likelihood = pm.Normal('likelihood', mu=mu, sigma=1/β, observed=y)\n",
    "        trace = pm.sample(11000, random_seed=123)\n",
    "    w_mean= az.summary(trace)[\"mean\"]\n",
    "    w_T = trace[\"w\"].T\n",
    "    w_cov = np.cov(w_T)\n",
    "    print(w_mean)\n",
    "    print(w_cov)\n",
    "    count += 1\n",
    "df = az.summary(trace)\n",
    "df.to_csv('result2.csv')\n",
    "axes = az.plot_trace(trace)\n",
    "fig = axes.ravel()[0].figure\n",
    "fig.savefig(\"result2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = az.summary(trace)\n",
    "df.to_csv('result2.csv')\n",
    "axes = az.plot_trace(trace)\n",
    "fig = axes.ravel()[0].figure\n",
    "fig.savefig(\"result2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_cov = np.array([[298.83585649,   107.38288159,  -174.88577985,    43.14794963,\n",
    "   -165.55770823,    87.47327194,    22.6553405,     61.59606038,\n",
    "   -175.85325216,   -10.56036077],\n",
    " [  107.38288159,   757.33378515,  -853.39027475,   532.0634397,\n",
    "   -628.78657625,   633.68802805,  -934.41866278,   117.98823377,\n",
    "   -570.98117109,  -669.82853213],\n",
    " [ -174.88577985,  -853.39027475,  1268.56127781,  -521.25830701,\n",
    "    208.05339066,  -832.24572436,   985.37374758,   968.93726529,\n",
    "   1322.13155773,   193.95210035],\n",
    " [   43.14794963,   532.0634397,   -521.25830701,   395.20915379,\n",
    "   -558.68769558,   416.64246681,  -683.57726117,   348.49486372,\n",
    "   -229.36198148,  -613.11077678],\n",
    " [ -165.55770823,  -628.78657625,   208.05339066,  -558.68769558,\n",
    "   1438.17742366,  -319.56618581,   800.62661495, -2040.07150888,\n",
    "   -648.4668714,   1480.54862785],\n",
    " [   87.47327194,   633.68802805,  -832.24572436,   416.64246681,\n",
    "   -319.56618581,   577.81419299, -767.98875348,  -345.71283974,\n",
    "   -741.22030789,  -343.35217182],\n",
    " [   22.6553405,   -934.41866278,   985.37374758,  -683.57726117,\n",
    "    800.62661495,  -767.98875348,  1243.13689738,  -264.39584255,\n",
    "    567.4145513,    943.12997701],\n",
    " [   61.59606038,   117.98823377,   968.93726529,   348.49486372,\n",
    "  -2040.07150888,  -345.71283974,  -264.39584255,  4186.61049585,\n",
    "   2371.18838841, -2132.6910031 ],\n",
    " [ -175.85325216,  -570.98117109,  1322.13155773,  -229.36198148,\n",
    "   -648.4668714,   -741.22030789,   567.4145513,   2371.18838841,\n",
    "   1935.02497933,  -737.75133528],\n",
    " [  -10.56036077,  -669.82853213,   193.95210035,  -613.11077678,\n",
    "   1480.54862785,  -343.35217182,   943.12997701, -2132.6910031,\n",
    "   -737.75133528,  1619.75840474]])\n",
    "w_mean = np.array([5922.777,319.312,-1469.315,-303.931,-1842.678,316.420,2194.443,953.884,-1872.522,1067.334])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3658.804426431423"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "62210.2-65869.00442643142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18230908140467642"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3658.804426431423/20069.238450661025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-0682c2401cf9>:5: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(11000, random_seed=123)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 05:50<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 11_000 draw iterations (4_000 + 44_000 draws total) took 384 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as our_first_model:\n",
    "    w = pm.MvNormal('w', mu=w_mean, cov=w_cov, shape=(num_of_vars, ))\n",
    "    mu = pm.math.dot(X, w)\n",
    "    likelihood = pm.Normal('likelihood', mu=mu, sigma=1/β, observed=y)\n",
    "    trace = pm.sample(11000, random_seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>w[0]</th>\n",
       "      <td>5923.249</td>\n",
       "      <td>17.003</td>\n",
       "      <td>5892.438</td>\n",
       "      <td>5955.858</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.099</td>\n",
       "      <td>14761.0</td>\n",
       "      <td>14650.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w[1]</th>\n",
       "      <td>320.520</td>\n",
       "      <td>27.313</td>\n",
       "      <td>269.030</td>\n",
       "      <td>371.311</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.223</td>\n",
       "      <td>7507.0</td>\n",
       "      <td>9426.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w[2]</th>\n",
       "      <td>-1471.987</td>\n",
       "      <td>35.186</td>\n",
       "      <td>-1540.296</td>\n",
       "      <td>-1407.853</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.283</td>\n",
       "      <td>7741.0</td>\n",
       "      <td>9804.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w[3]</th>\n",
       "      <td>-303.400</td>\n",
       "      <td>19.771</td>\n",
       "      <td>-340.097</td>\n",
       "      <td>-265.961</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.160</td>\n",
       "      <td>7633.0</td>\n",
       "      <td>9756.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w[4]</th>\n",
       "      <td>-1841.656</td>\n",
       "      <td>37.889</td>\n",
       "      <td>-1912.131</td>\n",
       "      <td>-1770.395</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.289</td>\n",
       "      <td>8635.0</td>\n",
       "      <td>10820.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w[5]</th>\n",
       "      <td>317.930</td>\n",
       "      <td>23.792</td>\n",
       "      <td>273.314</td>\n",
       "      <td>362.474</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.194</td>\n",
       "      <td>7548.0</td>\n",
       "      <td>9705.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w[6]</th>\n",
       "      <td>2193.262</td>\n",
       "      <td>34.987</td>\n",
       "      <td>2127.410</td>\n",
       "      <td>2257.968</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.281</td>\n",
       "      <td>7761.0</td>\n",
       "      <td>9647.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w[7]</th>\n",
       "      <td>949.542</td>\n",
       "      <td>64.376</td>\n",
       "      <td>824.981</td>\n",
       "      <td>1065.995</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.479</td>\n",
       "      <td>9059.0</td>\n",
       "      <td>11617.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w[8]</th>\n",
       "      <td>-1876.279</td>\n",
       "      <td>43.459</td>\n",
       "      <td>-1956.040</td>\n",
       "      <td>-1792.297</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.332</td>\n",
       "      <td>8548.0</td>\n",
       "      <td>10370.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w[9]</th>\n",
       "      <td>1068.585</td>\n",
       "      <td>40.140</td>\n",
       "      <td>992.592</td>\n",
       "      <td>1143.341</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.307</td>\n",
       "      <td>8562.0</td>\n",
       "      <td>10663.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean      sd    hdi_3%   hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "w[0]  5923.249  17.003  5892.438  5955.858      0.140    0.099   14761.0   \n",
       "w[1]   320.520  27.313   269.030   371.311      0.315    0.223    7507.0   \n",
       "w[2] -1471.987  35.186 -1540.296 -1407.853      0.400    0.283    7741.0   \n",
       "w[3]  -303.400  19.771  -340.097  -265.961      0.226    0.160    7633.0   \n",
       "w[4] -1841.656  37.889 -1912.131 -1770.395      0.408    0.289    8635.0   \n",
       "w[5]   317.930  23.792   273.314   362.474      0.274    0.194    7548.0   \n",
       "w[6]  2193.262  34.987  2127.410  2257.968      0.397    0.281    7761.0   \n",
       "w[7]   949.542  64.376   824.981  1065.995      0.677    0.479    9059.0   \n",
       "w[8] -1876.279  43.459 -1956.040 -1792.297      0.470    0.332    8548.0   \n",
       "w[9]  1068.585  40.140   992.592  1143.341      0.434    0.307    8562.0   \n",
       "\n",
       "      ess_tail  r_hat  \n",
       "w[0]   14650.0    1.0  \n",
       "w[1]    9426.0    1.0  \n",
       "w[2]    9804.0    1.0  \n",
       "w[3]    9756.0    1.0  \n",
       "w[4]   10820.0    1.0  \n",
       "w[5]    9705.0    1.0  \n",
       "w[6]    9647.0    1.0  \n",
       "w[7]   11617.0    1.0  \n",
       "w[8]   10370.0    1.0  \n",
       "w[9]   10663.0    1.0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "az.plot_trace(trace)\n",
    "az.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14420.525814520894 19218.8\n",
      "11560.185908749243 19433.3\n",
      "10767.355202511451 18658.1\n",
      "10109.522146413272 19146.5\n",
      "5805.408522370659 19379.9\n",
      "2078.043470775408 19170.7\n",
      "2169.897961502956 18326.6\n",
      "5615.948124172923 18546.0\n",
      "4059.7282192968646 18247.2\n",
      "3653.5402595280757 18023.6\n",
      "2126.563181951829 18808.9\n",
      "3402.0444798919652 19176.8\n",
      "1783.3715847401156 19273.8\n",
      "2514.049855599462 19434.9\n",
      "4176.292337794234 21352.2\n",
      "15646.247780348778 22825.4\n",
      "22104.764045558444 23127.9\n",
      "21270.706846286783 23844.0\n",
      "17430.34227000504 23474.9\n",
      "13315.49556860096 22728.5\n",
      "17429.887112050914 23823.2\n",
      "19220.270287942865 23257.9\n",
      "17597.35244515186 23736.5\n",
      "13629.331462445392 24689.6\n",
      "16182.723718254003 26454.4\n",
      "20632.178955815416 26261.3\n",
      "23346.550963571794 27057.8\n",
      "23335.859152829893 27376.0\n",
      "20746.76487437824 28868.7\n",
      "25158.559817083733 28949.4\n",
      "22329.37387253918 29359.9\n",
      "16944.432687942128 32193.3\n",
      "33472.635781196666 32958.9\n",
      "34968.847057282 32022.6\n",
      "38181.63067914347 33991.5\n",
      "40016.70889405446 36793.2\n",
      "46851.0441205206 39460.2\n",
      "53940.147267767825 40599.3\n",
      "55969.681228220725 40151.9\n",
      "45778.72297517822 38192.2\n",
      "48714.81264924623 35544.3\n",
      "50790.899523708256 34076.1\n",
      "46059.64228193752 37382.2\n",
      "49882.07769854248 39175.7\n",
      "53058.08772469142 36845.8\n",
      "52565.524827577916 36019.5\n",
      "41130.7261832731 35839.6\n",
      "34856.803943531 36613.2\n",
      "37034.255232271935 36002.9\n",
      "37745.888966136066 35476.3\n",
      "32424.769956186658 30842.1\n",
      "37275.23216089861 33000.5\n",
      "39081.806231168805 32088.9\n",
      "29605.424638255692 32241.3\n",
      "25941.55902507837 32252.3\n",
      "33541.80537598011 32502.1\n",
      "29281.406653669586 30404.0\n",
      "29904.839850094337 33374.8\n",
      "37220.52817528028 34301.8\n",
      "53188.32632542154 34283.1\n",
      "39835.0052558425 33108.1\n",
      "36338.706776617524 33515.7\n",
      "34411.213145260816 35485.2\n",
      "40779.06662787057 37646.8\n",
      "42636.373056211916 36982.1\n",
      "43077.00850199498 38297.6\n",
      "40294.81206682462 39256.6\n",
      "42377.31460979258 38852.9\n",
      "36023.799904473075 46395.7\n",
      "68536.1732444759 46508.6\n",
      "63277.256598391104 44836.0\n",
      "60039.319084040515 47990.7\n",
      "62530.08516155245 47371.7\n",
      "60788.94376161634 47168.7\n",
      "49395.964495784225 48643.4\n",
      "49890.339834633734 47936.3\n",
      "48162.19117977688 49169.7\n",
      "49932.55433409569 52079.2\n",
      "58476.77388673071 51582.2\n",
      "51899.247838621784 55906.6\n",
      "68149.85448011312 55923.7\n",
      "60925.14270133653 57433.8\n",
      "61128.36920105586 54111.8\n",
      "64220.68270505324 48911.2\n",
      "67145.41516028382 49697.5\n",
      "60944.62449713565 46928.5\n",
      "64291.34135464649 46345.6\n",
      "56693.28861100446 46136.7\n",
      "50784.651450558486 45164.0\n",
      "45414.07875163301 49595.5\n",
      "59504.432342486216 48424.2\n",
      "54239.52439883386 50395.1\n",
      "63707.7474521866 48428.0\n",
      "55546.90323392446 48792.5\n",
      "54619.74287767062 48855.6\n",
      "42702.80502892622 50982.3\n",
      "48267.39617027526 52311.0\n",
      "49967.410508291054 54879.0\n",
      "54604.36112989964 55851.9\n",
      "57758.14438336135 57799.5\n",
      "58129.1449464525 57265.1\n",
      "55167.57483572859 61195.3\n",
      "66894.13802486956 59113.7\n",
      "57361.140706724684 55791.3\n",
      "63459.693106515515 56889.7\n",
      "56220.80043566407 58913.5\n",
      "59861.46076455464 57656.0\n",
      "58493.08121830684 58088.0\n",
      "58130.25907939348 58093.4\n",
      "50790.77328151993 57383.8\n",
      "48328.093023123045 54158.3\n",
      "53345.19547292031 54452.5\n",
      "50346.13335330881 52325.4\n",
      "56468.88148216642 51322.3\n",
      "50275.745697382765 55036.1\n",
      "56362.91469179051 55862.9\n",
      "51019.86587239379 55765.2\n",
      "46940.53883738695 57616.2\n",
      "54495.09708067518 58771.3\n",
      "54932.57153144659 58763.7\n",
      "55636.8890274908 58718.3\n",
      "49002.69219319772 58977.3\n",
      "48743.8612848375 57059.9\n",
      "47162.688228183455 58199.9\n",
      "44226.56362863975 58993.4\n",
      "49005.904748575565 57996.3\n",
      "50291.96356493676 55948.7\n",
      "48844.26799803147 58077.4\n",
      "47889.97009501023 58118.7\n",
      "48850.82661964694 59748.4\n",
      "54392.20275568087 59978.7\n",
      "46477.85085334519 59863.8\n",
      "50404.49605969325 63540.9\n",
      "61758.11799326881 62980.4\n",
      "62135.821996137514 63216.0\n",
      "61742.50482220223 61379.7\n",
      "55974.09558996013 60041.9\n",
      "52346.16879485395 56207.1\n",
      "65018.779943880254 55646.1\n",
      "55874.74137238473 56483.2\n",
      "63982.358098851204 53820.2\n",
      "57496.43487333474 51729.5\n",
      "64971.253207402115 51143.6\n",
      "58153.98116318952 50088.9\n",
      "46576.93097828119 48963.6\n",
      "43906.55761232963 54020.5\n",
      "62909.52193233217 55036.5\n",
      "58671.748363578896 54841.4\n",
      "56991.572110190886 53560.8\n",
      "53094.92476386333 57720.3\n",
      "67453.85185433917 57807.1\n",
      "52515.59668616971 56603.8\n",
      "51723.80442311373 57169.8\n",
      "55627.469582652004 53741.5\n",
      "55302.50824295469 57441.3\n",
      "59576.89955894563 56405.4\n",
      "57802.478505779654 57337.2\n",
      "60418.46737413442 58840.1\n",
      "55296.3420233256 58238.3\n",
      "54458.41708017739 55848.9\n",
      "59717.57192675201 56695.7\n",
      "51392.43593905658 49384.2\n",
      "66533.49866907322 49704.6\n",
      "56469.22915917819 49839.8\n",
      "53023.203726504806 46708.8\n",
      "50016.5571032584 46426.4\n",
      "52251.54986930656 43541.3\n",
      "50684.05899347475 42897.3\n",
      "46273.76031631008 36720.5\n",
      "65534.70797528641 40717.2\n",
      "67476.5852377177 37297.4\n",
      "67213.88764166152 37448.3\n",
      "55796.964165674275 34679.7\n",
      "54765.68743672908 38750.6\n",
      "64761.6602285376 38378.3\n",
      "55282.31635391153 39249.2\n",
      "52952.376889880295 38417.3\n",
      "46406.54275485787 35662.5\n",
      "48480.154790857196 34584.6\n",
      "39657.733776007444 35652.8\n",
      "36449.98639969271 37298.6\n",
      "37055.07065024946 36687.6\n",
      "34925.646872156896 37555.8\n",
      "34266.8684310022 39187.3\n",
      "34915.899701988696 36851.3\n",
      "33326.78359276639 35520.0\n",
      "26929.42826395616 35815.4\n",
      "21966.16135438531 33578.0\n",
      "31693.31864345173 33382.9\n",
      "27964.909460423987 37332.2\n",
      "35875.03333477273 36649.4\n",
      "33978.91592029223 37314.6\n",
      "33874.287568263244 35467.5\n",
      "30942.210253791673 39022.9\n",
      "36961.52409238079 40529.4\n",
      "38867.685464951144 40156.1\n",
      "37232.25421122812 38336.0\n",
      "35227.43930840773 38052.0\n",
      "29741.145454801637 35749.4\n",
      "29150.34542231486 35513.4\n",
      "20941.541835994296 35595.8\n",
      "20409.240640522934 31692.0\n",
      "28892.94352188929 32496.4\n",
      "28356.54155035578 33674.3\n",
      "31527.483840723544 34665.8\n",
      "32830.26785318297 31594.0\n",
      "36521.53249404429 32243.4\n",
      "28407.457196766965 34678.5\n",
      "31634.791333548055 34475.9\n",
      "31883.364803949476 35834.7\n",
      "34714.479667656706 35026.9\n",
      "28502.986546931766 33543.6\n",
      "31019.326398460937 33813.4\n",
      "23768.363560287788 34742.8\n",
      "23727.19135219621 35298.2\n",
      "21620.18903223364 33687.8\n",
      "21411.128401887774 34225.6\n",
      "18463.121816511615 33867.8\n",
      "17659.34353693308 32866.3\n",
      "19532.801745022243 33797.4\n",
      "21700.218289784083 33510.6\n",
      "12128.903914429553 34227.7\n",
      "14656.753040240277 33113.0\n",
      "18286.36551999797 32728.1\n",
      "14559.146400339896 32820.7\n",
      "11608.30424688869 31840.5\n",
      "15894.923983596014 31394.0\n",
      "10717.094806266614 31518.6\n",
      "7314.00748012576 31785.4\n",
      "5713.840713896781 30837.2\n",
      "11037.455031512642 29793.8\n",
      "13311.859354284858 32131.4\n",
      "21077.471572365783 32298.9\n",
      "15256.829471852736 33603.3\n",
      "19446.58823536845 33824.8\n",
      "12469.17154989659 35391.1\n",
      "15689.231409498232 37276.6\n",
      "37405.34255265222 39452.0\n",
      "46065.39125882057 40003.2\n",
      "37703.82332770743 40001.4\n",
      "32207.735010538345 42203.4\n",
      "35137.02075131837 41553.7\n",
      "26046.60060909695 39878.3\n",
      "29940.357078649184 39168.4\n",
      "28413.772262017763 38130.3\n",
      "27128.608111277346 39736.9\n",
      "28662.006964703723 40867.2\n",
      "30096.101551143714 42795.4\n",
      "34079.730321585346 44614.2\n",
      "32290.313536691712 43792.8\n",
      "29972.377246884134 46284.3\n",
      "40456.18057270675 45593.8\n",
      "34690.4604352353 45564.3\n",
      "34578.36164012745 44403.4\n",
      "31097.342613812914 47809.1\n",
      "42366.112158736716 47081.5\n",
      "31805.74893902945 46991.3\n",
      "31079.52933722958 45996.3\n",
      "33785.473932818924 44691.6\n",
      "34858.82662725798 44723.8\n",
      "32616.575214783494 46755.9\n",
      "36227.79337151392 49324.0\n",
      "41974.96420693314 48875.8\n",
      "35751.947478639006 49254.5\n",
      "28873.506696025615 49539.7\n",
      "36947.37749493932 47714.7\n",
      "45255.766317156864 48994.5\n",
      "37425.49091027673 46831.6\n",
      "38491.815156054145 49064.3\n",
      "38544.727131551044 48897.1\n",
      "31020.029647869727 48777.4\n",
      "30952.058619872314 46992.7\n",
      "33331.16553435491 47130.4\n",
      "33235.610906290014 48819.4\n",
      "40447.307662150255 49274.3\n",
      "41942.72244558853 49999.0\n",
      "40439.724692738666 49918.4\n",
      "30546.510518380917 51768.6\n",
      "33039.78504692479 52672.1\n",
      "39834.35748023481 46779.6\n",
      "53397.67837361151 46061.4\n",
      "38238.1656926204 46385.6\n",
      "40351.469426644195 44842.8\n",
      "49943.87107477723 45161.9\n",
      "37126.83413864354 46062.3\n",
      "31677.745731494382 44949.5\n",
      "48784.46438596674 47077.5\n",
      "52703.85398964058 48130.6\n",
      "42114.68685494173 47748.0\n",
      "42460.37829344402 47282.8\n",
      "34509.27275496257 48306.7\n",
      "31744.326826041048 47238.7\n",
      "25855.875835935647 42870.6\n",
      "44057.54251430843 40651.3\n",
      "48744.17564897578 43551.6\n",
      "44015.16297584068 44869.2\n",
      "40574.05076704186 42819.9\n",
      "43614.1361774462 42686.8\n",
      "29417.93659724648 43203.4\n",
      "31671.78673640745 42172.6\n",
      "34636.143393960825 41022.3\n",
      "33739.80225928928 41536.8\n",
      "32013.302338045498 43823.3\n",
      "43253.99301236182 48146.0\n",
      "53588.80893650524 47666.9\n",
      "41897.86045657995 48200.1\n",
      "40655.065387974 49227.3\n",
      "43731.73990308597 51469.3\n",
      "53574.48377563957 55323.2\n",
      "61383.476656429535 53783.9\n",
      "58516.73006474828 53914.7\n",
      "55034.35891139114 54942.5\n",
      "48715.640440918214 54687.7\n",
      "44006.937612141875 57477.3\n",
      "56618.617208282136 56015.9\n",
      "52997.51866921269 57380.1\n",
      "51674.46164025947 57345.8\n",
      "48433.318605030356 61672.5\n",
      "68632.28273230357 60861.1\n",
      "54902.48133030215 61527.5\n",
      "51764.04903730217 62056.3\n",
      "54764.77816679179 64278.5\n",
      "74815.51560395023 65979.1\n",
      "64127.14939049417 62210.2\n",
      "65869.00442643142 60697.3\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for i in range(325):\n",
    "    y_hat = np.dot(X[i],w_mean)\n",
    "    print(y_hat, y[i])\n",
    "    errors.append(y[i] - y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10036.296738948993"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-93-6e8112245b3d>:9: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(1000, random_seed=123, start={'w': w_mean,'y': 0})\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [y, w]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 01:44<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 185 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as prediction_model:\n",
    "    w = pm.MvNormal('w', mu=w_mean, cov=w_cov, shape=(num_of_vars, ))\n",
    "    mu = pm.math.dot(X[-1,:], w)\n",
    "    error_std = 10036.296738948993\n",
    "    y = pm.Normal('y', mu=mu, sigma=error_std)\n",
    "    x_norm = pm.math.dot(X[-1,:], X[-1,:].T)\n",
    "    y_sigma = error_std + pm.math.dot(w_cov, x_norm)\n",
    "    #likilihood = pm.Normal('likelihood', mu=y, sigma=y_sigma, observed=X[-1,:])\n",
    "    trace = pm.sample(1000, random_seed=123, start={'w': w_mean,'y': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\arviz\\data\\io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'w'}>,\n",
       "        <AxesSubplot:title={'center':'w'}>],\n",
       "       [<AxesSubplot:title={'center':'y'}>,\n",
       "        <AxesSubplot:title={'center':'y'}>]], dtype=object)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "az.plot_trace(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.dot(X[-1,:], w_mean)\n",
    "error_std = 10036.296738948993\n",
    "x_norm = np.dot(X[-1,:], X[-1,:].T)\n",
    "y_sigma = error_std + np.dot(w_cov, x_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65869.00442643142"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20069.238450661025"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "40138.47690132205/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='likelihood / likelihood'>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daisu\\anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py:132: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "az.plot_ppc(az.from_pymc3(posterior_predictive=ppc, model=our_first_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[-1,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = (ppc[\"w\"] * X[:, None]).T\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "\n",
    "ax.plot(X, y, \"o\", ms=4, alpha=0.4, label=\"Data\")\n",
    "ax.plot(X, y.mean(0), label=\"Mean outcome\", alpha=0.6)\n",
    "az.plot_hpd(\n",
    "    X,\n",
    "    y_hat,\n",
    "    ax=ax,\n",
    "    fill_kwargs={\"alpha\": 0.8, \"label\": \"Mean outcome 94% HPD\"},\n",
    ")\n",
    "az.plot_hpd(\n",
    "    predictor_scaled,\n",
    "    ppc[\"obs\"],\n",
    "    ax=ax,\n",
    "    fill_kwargs={\"alpha\": 0.8, \"color\": \"#a1dab4\", \"label\": \"Outcome 94% HPD\"},\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Predictor (stdz)\")\n",
    "ax.set_ylabel(\"Outcome (stdz)\")\n",
    "ax.set_title(\"Posterior predictive checks\")\n",
    "ax.legend(ncol=2, fontsize=10);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
